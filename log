WARNING:tensorflow:From /vilsrv-storage/dinari/miniconda3/envs/condirit/lib/python3.8/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.

Num of model parameters 2211073 

Num of model parameters 2211073 

W0514 15:14:23.239608 140128494741248 utils.py:10] No checkpoint found at output/checkpoints-meta/checkpoint.pth. Returned the same state as input
I0514 15:14:23.262072 140128494741248 xla_bridge.py:260] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I0514 15:14:23.262353 140128494741248 xla_bridge.py:260] Unable to initialize backend 'gpu': NOT_FOUND: Could not find registered platform with name: "cuda". Available platform names are: Host Interpreter
I0514 15:14:23.262863 140128494741248 xla_bridge.py:260] Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.
W0514 15:14:23.263019 140128494741248 xla_bridge.py:265] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0514 15:14:23.265131 140128494741248 dataset_info.py:361] Load dataset info from /home/tohamy/tensorflow_datasets/fashion_mnist/3.0.1
W0514 15:14:23.267769 140128494741248 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.
W0514 15:14:23.267889 140128494741248 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.
I0514 15:14:23.268148 140128494741248 dataset_builder.py:282] Reusing dataset fashion_mnist (/home/tohamy/tensorflow_datasets/fashion_mnist/3.0.1)
I0514 15:14:23.268295 140128494741248 dataset_builder.py:477] Constructing tf.data.Dataset for split train, from /home/tohamy/tensorflow_datasets/fashion_mnist/3.0.1
W0514 15:14:24.925084 140128494741248 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.
W0514 15:14:24.925433 140128494741248 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.
I0514 15:14:24.925703 140128494741248 dataset_builder.py:282] Reusing dataset fashion_mnist (/home/tohamy/tensorflow_datasets/fashion_mnist/3.0.1)
I0514 15:14:24.925873 140128494741248 dataset_builder.py:477] Constructing tf.data.Dataset for split test, from /home/tohamy/tensorflow_datasets/fashion_mnist/3.0.1
I0514 15:14:25.099773 140128494741248 run_lib.py:133] Starting training loop at step 0.

 Start training.

I0514 15:14:28.045424 140128494741248 run_lib.py:152] step: 0, training_loss: 5.22586e+02
I0514 15:14:28.518650 140128494741248 run_lib.py:165] step: 0, eval_loss: 5.08919e+02
I0514 15:14:34.942015 140128494741248 run_lib.py:152] step: 50, training_loss: 5.12100e+02
I0514 15:14:41.754541 140128494741248 run_lib.py:152] step: 100, training_loss: 5.02622e+02
I0514 15:14:41.805588 140128494741248 run_lib.py:165] step: 100, eval_loss: 5.10872e+02
I0514 15:14:48.285634 140128494741248 run_lib.py:152] step: 150, training_loss: 4.95059e+02
I0514 15:14:55.100921 140128494741248 run_lib.py:152] step: 200, training_loss: 4.74399e+02
I0514 15:14:55.153842 140128494741248 run_lib.py:165] step: 200, eval_loss: 4.76812e+02
I0514 15:15:02.006222 140128494741248 run_lib.py:152] step: 250, training_loss: 4.53637e+02
I0514 15:15:08.829026 140128494741248 run_lib.py:152] step: 300, training_loss: 4.29263e+02
I0514 15:15:08.890173 140128494741248 run_lib.py:165] step: 300, eval_loss: 4.43704e+02
I0514 15:15:15.325175 140128494741248 run_lib.py:152] step: 350, training_loss: 4.09181e+02
I0514 15:15:21.758324 140128494741248 run_lib.py:152] step: 400, training_loss: 3.65361e+02
I0514 15:15:21.824008 140128494741248 run_lib.py:165] step: 400, eval_loss: 3.94838e+02
I0514 15:15:28.643603 140128494741248 run_lib.py:152] step: 450, training_loss: 3.21824e+02
I0514 15:15:35.321391 140128494741248 run_lib.py:152] step: 500, training_loss: 2.89779e+02
I0514 15:15:35.376681 140128494741248 run_lib.py:165] step: 500, eval_loss: 3.20930e+02
I0514 15:15:41.638470 140128494741248 run_lib.py:152] step: 550, training_loss: 2.46975e+02
I0514 15:15:48.218047 140128494741248 run_lib.py:152] step: 600, training_loss: 2.19693e+02
I0514 15:15:48.273843 140128494741248 run_lib.py:165] step: 600, eval_loss: 2.48314e+02
I0514 15:15:55.066375 140128494741248 run_lib.py:152] step: 650, training_loss: 1.95579e+02
I0514 15:16:01.533497 140128494741248 run_lib.py:152] step: 700, training_loss: 1.53199e+02
I0514 15:16:01.581624 140128494741248 run_lib.py:165] step: 700, eval_loss: 1.87745e+02
I0514 15:16:08.105730 140128494741248 run_lib.py:152] step: 750, training_loss: 1.17152e+02
I0514 15:16:14.917441 140128494741248 run_lib.py:152] step: 800, training_loss: 9.97839e+01
I0514 15:16:14.977895 140128494741248 run_lib.py:165] step: 800, eval_loss: 1.15935e+02
I0514 15:16:21.680342 140128494741248 run_lib.py:152] step: 850, training_loss: 7.54883e+01
I0514 15:16:28.332475 140128494741248 run_lib.py:152] step: 900, training_loss: 1.00159e+02
I0514 15:16:28.383069 140128494741248 run_lib.py:165] step: 900, eval_loss: 8.85200e+01
I0514 15:16:34.604644 140128494741248 run_lib.py:152] step: 950, training_loss: 8.81759e+01
I0514 15:16:41.468297 140128494741248 run_lib.py:152] step: 1000, training_loss: 5.41705e+01
I0514 15:16:41.520510 140128494741248 run_lib.py:165] step: 1000, eval_loss: 8.49882e+01
I0514 15:16:47.764981 140128494741248 run_lib.py:152] step: 1050, training_loss: 8.37033e+01
I0514 15:16:53.911788 140128494741248 run_lib.py:152] step: 1100, training_loss: 7.10874e+01
I0514 15:16:53.965466 140128494741248 run_lib.py:165] step: 1100, eval_loss: 5.22479e+01
I0514 15:17:00.644885 140128494741248 run_lib.py:152] step: 1150, training_loss: 6.08276e+01
I0514 15:17:06.930812 140128494741248 run_lib.py:152] step: 1200, training_loss: 4.61209e+01
I0514 15:17:06.982760 140128494741248 run_lib.py:165] step: 1200, eval_loss: 5.66179e+01
I0514 15:17:13.163464 140128494741248 run_lib.py:152] step: 1250, training_loss: 4.68763e+01
I0514 15:17:19.497424 140128494741248 run_lib.py:152] step: 1300, training_loss: 4.46459e+01
I0514 15:17:19.547715 140128494741248 run_lib.py:165] step: 1300, eval_loss: 3.43127e+01
I0514 15:17:26.022305 140128494741248 run_lib.py:152] step: 1350, training_loss: 5.65812e+01
I0514 15:17:32.287274 140128494741248 run_lib.py:152] step: 1400, training_loss: 4.70613e+01
I0514 15:17:32.339200 140128494741248 run_lib.py:165] step: 1400, eval_loss: 4.49041e+01
I0514 15:17:38.533582 140128494741248 run_lib.py:152] step: 1450, training_loss: 4.76741e+01
I0514 15:17:45.035114 140128494741248 run_lib.py:152] step: 1500, training_loss: 5.11591e+01
I0514 15:17:45.090810 140128494741248 run_lib.py:165] step: 1500, eval_loss: 5.07527e+01
I0514 15:17:51.313405 140128494741248 run_lib.py:152] step: 1550, training_loss: 4.89496e+01
I0514 15:17:57.504996 140128494741248 run_lib.py:152] step: 1600, training_loss: 4.02122e+01
I0514 15:17:57.558602 140128494741248 run_lib.py:165] step: 1600, eval_loss: 5.79688e+01
I0514 15:18:03.693027 140128494741248 run_lib.py:152] step: 1650, training_loss: 4.97905e+01
I0514 15:18:09.997771 140128494741248 run_lib.py:152] step: 1700, training_loss: 5.27877e+01
I0514 15:18:10.050097 140128494741248 run_lib.py:165] step: 1700, eval_loss: 4.88674e+01
I0514 15:18:16.162586 140128494741248 run_lib.py:152] step: 1750, training_loss: 4.03042e+01
I0514 15:18:22.341738 140128494741248 run_lib.py:152] step: 1800, training_loss: 3.99510e+01
I0514 15:18:22.395699 140128494741248 run_lib.py:165] step: 1800, eval_loss: 3.94120e+01
I0514 15:18:28.808276 140128494741248 run_lib.py:152] step: 1850, training_loss: 3.96959e+01
I0514 15:18:34.915086 140128494741248 run_lib.py:152] step: 1900, training_loss: 3.89404e+01
I0514 15:18:34.966234 140128494741248 run_lib.py:165] step: 1900, eval_loss: 4.99139e+01
I0514 15:18:41.140226 140128494741248 run_lib.py:152] step: 1950, training_loss: 3.76545e+01
I0514 15:18:47.361990 140128494741248 run_lib.py:152] step: 2000, training_loss: 5.04126e+01
I0514 15:18:47.413380 140128494741248 run_lib.py:165] step: 2000, eval_loss: 4.96070e+01
I0514 15:18:53.808383 140128494741248 run_lib.py:152] step: 2050, training_loss: 8.08954e+01
I0514 15:19:00.023430 140128494741248 run_lib.py:152] step: 2100, training_loss: 5.06263e+01
I0514 15:19:00.073061 140128494741248 run_lib.py:165] step: 2100, eval_loss: 4.32587e+01
I0514 15:19:06.317010 140128494741248 run_lib.py:152] step: 2150, training_loss: 3.89178e+01
I0514 15:19:12.745190 140128494741248 run_lib.py:152] step: 2200, training_loss: 6.14599e+01
I0514 15:19:12.799721 140128494741248 run_lib.py:165] step: 2200, eval_loss: 4.06780e+01
I0514 15:19:18.929524 140128494741248 run_lib.py:152] step: 2250, training_loss: 3.99130e+01
I0514 15:19:25.019146 140128494741248 run_lib.py:152] step: 2300, training_loss: 4.71747e+01
I0514 15:19:25.069597 140128494741248 run_lib.py:165] step: 2300, eval_loss: 4.75716e+01
I0514 15:19:31.221950 140128494741248 run_lib.py:152] step: 2350, training_loss: 4.44722e+01
I0514 15:19:37.580730 140128494741248 run_lib.py:152] step: 2400, training_loss: 5.52634e+01
I0514 15:19:37.633433 140128494741248 run_lib.py:165] step: 2400, eval_loss: 4.21602e+01
I0514 15:19:43.816324 140128494741248 run_lib.py:152] step: 2450, training_loss: 6.61877e+01
I0514 15:19:49.976706 140128494741248 run_lib.py:152] step: 2500, training_loss: 3.05432e+01
I0514 15:19:50.029368 140128494741248 run_lib.py:165] step: 2500, eval_loss: 4.19547e+01
I0514 15:19:56.476360 140128494741248 run_lib.py:152] step: 2550, training_loss: 2.97523e+01
I0514 15:20:02.632813 140128494741248 run_lib.py:152] step: 2600, training_loss: 3.55757e+01
I0514 15:20:02.680423 140128494741248 run_lib.py:165] step: 2600, eval_loss: 3.10314e+01
I0514 15:20:08.869409 140128494741248 run_lib.py:152] step: 2650, training_loss: 3.97058e+01
I0514 15:20:15.019569 140128494741248 run_lib.py:152] step: 2700, training_loss: 5.76284e+01
I0514 15:20:15.076517 140128494741248 run_lib.py:165] step: 2700, eval_loss: 3.05879e+01
I0514 15:20:21.485391 140128494741248 run_lib.py:152] step: 2750, training_loss: 3.48463e+01
I0514 15:20:27.591775 140128494741248 run_lib.py:152] step: 2800, training_loss: 4.70985e+01
I0514 15:20:27.639258 140128494741248 run_lib.py:165] step: 2800, eval_loss: 6.85230e+01
I0514 15:20:33.847501 140128494741248 run_lib.py:152] step: 2850, training_loss: 3.61643e+01
I0514 15:20:40.241499 140128494741248 run_lib.py:152] step: 2900, training_loss: 4.65868e+01
I0514 15:20:40.291602 140128494741248 run_lib.py:165] step: 2900, eval_loss: 4.07653e+01
I0514 15:20:46.511107 140128494741248 run_lib.py:152] step: 2950, training_loss: 4.17932e+01
I0514 15:20:52.672634 140128494741248 run_lib.py:152] step: 3000, training_loss: 5.26978e+01
I0514 15:20:52.721113 140128494741248 run_lib.py:165] step: 3000, eval_loss: 4.67233e+01
I0514 15:20:58.865237 140128494741248 run_lib.py:152] step: 3050, training_loss: 5.50509e+01
I0514 15:21:05.302444 140128494741248 run_lib.py:152] step: 3100, training_loss: 5.59649e+01
I0514 15:21:05.351288 140128494741248 run_lib.py:165] step: 3100, eval_loss: 3.10574e+01
I0514 15:21:11.526638 140128494741248 run_lib.py:152] step: 3150, training_loss: 3.06697e+01
I0514 15:21:17.681380 140128494741248 run_lib.py:152] step: 3200, training_loss: 4.43537e+01
I0514 15:21:17.735046 140128494741248 run_lib.py:165] step: 3200, eval_loss: 6.56322e+01
I0514 15:21:24.099150 140128494741248 run_lib.py:152] step: 3250, training_loss: 4.29337e+01
I0514 15:21:30.208603 140128494741248 run_lib.py:152] step: 3300, training_loss: 3.61604e+01
I0514 15:21:30.258029 140128494741248 run_lib.py:165] step: 3300, eval_loss: 3.00034e+01
I0514 15:21:36.431247 140128494741248 run_lib.py:152] step: 3350, training_loss: 5.89249e+01
I0514 15:21:42.839225 140128494741248 run_lib.py:152] step: 3400, training_loss: 5.17416e+01
I0514 15:21:42.895428 140128494741248 run_lib.py:165] step: 3400, eval_loss: 3.95243e+01
I0514 15:21:49.044696 140128494741248 run_lib.py:152] step: 3450, training_loss: 5.62316e+01
I0514 15:21:55.237335 140128494741248 run_lib.py:152] step: 3500, training_loss: 4.02745e+01
I0514 15:21:55.289747 140128494741248 run_lib.py:165] step: 3500, eval_loss: 3.26390e+01
I0514 15:22:01.407292 140128494741248 run_lib.py:152] step: 3550, training_loss: 2.84381e+01
I0514 15:22:07.800536 140128494741248 run_lib.py:152] step: 3600, training_loss: 3.00108e+01
I0514 15:22:07.849680 140128494741248 run_lib.py:165] step: 3600, eval_loss: 2.50969e+01
I0514 15:22:14.060325 140128494741248 run_lib.py:152] step: 3650, training_loss: 3.60452e+01
I0514 15:22:20.190979 140128494741248 run_lib.py:152] step: 3700, training_loss: 3.56923e+01
I0514 15:22:20.236229 140128494741248 run_lib.py:165] step: 3700, eval_loss: 3.53918e+01
I0514 15:22:26.655274 140128494741248 run_lib.py:152] step: 3750, training_loss: 4.53845e+01
I0514 15:22:32.754035 140128494741248 run_lib.py:152] step: 3800, training_loss: 2.88380e+01
I0514 15:22:32.804708 140128494741248 run_lib.py:165] step: 3800, eval_loss: 4.20485e+01
I0514 15:22:38.904078 140128494741248 run_lib.py:152] step: 3850, training_loss: 4.59299e+01
I0514 15:22:45.047786 140128494741248 run_lib.py:152] step: 3900, training_loss: 6.51642e+01
I0514 15:22:45.096599 140128494741248 run_lib.py:165] step: 3900, eval_loss: 5.33293e+01
I0514 15:22:51.447767 140128494741248 run_lib.py:152] step: 3950, training_loss: 1.96422e+01
I0514 15:22:57.509903 140128494741248 run_lib.py:152] step: 4000, training_loss: 2.96365e+01
I0514 15:22:57.566168 140128494741248 run_lib.py:165] step: 4000, eval_loss: 4.14628e+01
I0514 15:23:03.665182 140128494741248 run_lib.py:152] step: 4050, training_loss: 6.05287e+01
I0514 15:23:10.029987 140128494741248 run_lib.py:152] step: 4100, training_loss: 4.59879e+01
I0514 15:23:10.087277 140128494741248 run_lib.py:165] step: 4100, eval_loss: 3.78326e+01
I0514 15:23:16.210301 140128494741248 run_lib.py:152] step: 4150, training_loss: 6.41528e+01
I0514 15:23:22.316907 140128494741248 run_lib.py:152] step: 4200, training_loss: 3.80168e+01
I0514 15:23:22.362157 140128494741248 run_lib.py:165] step: 4200, eval_loss: 4.14798e+01
I0514 15:23:28.499834 140128494741248 run_lib.py:152] step: 4250, training_loss: 3.04519e+01
I0514 15:23:34.902375 140128494741248 run_lib.py:152] step: 4300, training_loss: 4.78307e+01
I0514 15:23:34.955323 140128494741248 run_lib.py:165] step: 4300, eval_loss: 3.35606e+01
I0514 15:23:41.061263 140128494741248 run_lib.py:152] step: 4350, training_loss: 3.76781e+01
I0514 15:23:47.149656 140128494741248 run_lib.py:152] step: 4400, training_loss: 3.36972e+01
I0514 15:23:47.206424 140128494741248 run_lib.py:165] step: 4400, eval_loss: 3.20652e+01
I0514 15:23:53.542361 140128494741248 run_lib.py:152] step: 4450, training_loss: 6.14052e+01
I0514 15:23:59.578742 140128494741248 run_lib.py:152] step: 4500, training_loss: 3.71511e+01
I0514 15:23:59.627390 140128494741248 run_lib.py:165] step: 4500, eval_loss: 3.21168e+01
I0514 15:24:05.812296 140128494741248 run_lib.py:152] step: 4550, training_loss: 4.99584e+01
I0514 15:24:11.996072 140128494741248 run_lib.py:152] step: 4600, training_loss: 4.18986e+01
I0514 15:24:12.054271 140128494741248 run_lib.py:165] step: 4600, eval_loss: 4.73975e+01
I0514 15:24:18.442291 140128494741248 run_lib.py:152] step: 4650, training_loss: 3.68190e+01
I0514 15:24:24.585873 140128494741248 run_lib.py:152] step: 4700, training_loss: 4.54050e+01
I0514 15:24:24.634519 140128494741248 run_lib.py:165] step: 4700, eval_loss: 4.73088e+01
I0514 15:24:30.817829 140128494741248 run_lib.py:152] step: 4750, training_loss: 4.12315e+01
I0514 15:24:37.110689 140128494741248 run_lib.py:152] step: 4800, training_loss: 2.11638e+01
I0514 15:24:37.162531 140128494741248 run_lib.py:165] step: 4800, eval_loss: 2.95002e+01
I0514 15:24:43.339266 140128494741248 run_lib.py:152] step: 4850, training_loss: 4.07950e+01
I0514 15:24:49.546036 140128494741248 run_lib.py:152] step: 4900, training_loss: 3.87615e+01
I0514 15:24:49.609468 140128494741248 run_lib.py:165] step: 4900, eval_loss: 3.83540e+01
I0514 15:24:55.748494 140128494741248 run_lib.py:152] step: 4950, training_loss: 4.76936e+01
I0514 15:25:02.118733 140128494741248 run_lib.py:152] step: 5000, training_loss: 7.43334e+01
I0514 15:25:02.168788 140128494741248 run_lib.py:165] step: 5000, eval_loss: 3.21863e+01
I0514 15:25:08.388617 140128494741248 run_lib.py:152] step: 5050, training_loss: 4.60607e+01
I0514 15:25:14.447252 140128494741248 run_lib.py:152] step: 5100, training_loss: 6.00930e+01
I0514 15:25:14.496945 140128494741248 run_lib.py:165] step: 5100, eval_loss: 3.49978e+01
I0514 15:25:20.875598 140128494741248 run_lib.py:152] step: 5150, training_loss: 5.58459e+01
I0514 15:25:27.038656 140128494741248 run_lib.py:152] step: 5200, training_loss: 3.01876e+01
I0514 15:25:27.098429 140128494741248 run_lib.py:165] step: 5200, eval_loss: 3.10945e+01
I0514 15:25:33.202100 140128494741248 run_lib.py:152] step: 5250, training_loss: 5.12087e+01
I0514 15:25:39.312625 140128494741248 run_lib.py:152] step: 5300, training_loss: 4.20185e+01
I0514 15:25:39.361220 140128494741248 run_lib.py:165] step: 5300, eval_loss: 2.82651e+01
I0514 15:25:45.768880 140128494741248 run_lib.py:152] step: 5350, training_loss: 3.80281e+01
I0514 15:25:51.923427 140128494741248 run_lib.py:152] step: 5400, training_loss: 3.96126e+01
I0514 15:25:51.979768 140128494741248 run_lib.py:165] step: 5400, eval_loss: 3.43093e+01
I0514 15:25:58.167187 140128494741248 run_lib.py:152] step: 5450, training_loss: 4.80568e+01
I0514 15:26:04.532621 140128494741248 run_lib.py:152] step: 5500, training_loss: 3.77115e+01
I0514 15:26:04.587710 140128494741248 run_lib.py:165] step: 5500, eval_loss: 4.16890e+01
I0514 15:26:10.775033 140128494741248 run_lib.py:152] step: 5550, training_loss: 3.18072e+01
I0514 15:26:16.821654 140128494741248 run_lib.py:152] step: 5600, training_loss: 3.63611e+01
I0514 15:26:16.870771 140128494741248 run_lib.py:165] step: 5600, eval_loss: 2.08250e+01
I0514 15:26:22.981463 140128494741248 run_lib.py:152] step: 5650, training_loss: 2.94891e+01
I0514 15:26:29.383865 140128494741248 run_lib.py:152] step: 5700, training_loss: 5.49506e+01
I0514 15:26:29.442322 140128494741248 run_lib.py:165] step: 5700, eval_loss: 3.44497e+01
I0514 15:26:35.570027 140128494741248 run_lib.py:152] step: 5750, training_loss: 2.96531e+01
I0514 15:26:41.734954 140128494741248 run_lib.py:152] step: 5800, training_loss: 2.70860e+01
I0514 15:26:41.785792 140128494741248 run_lib.py:165] step: 5800, eval_loss: 4.47417e+01
I0514 15:26:48.157966 140128494741248 run_lib.py:152] step: 5850, training_loss: 4.40064e+01
I0514 15:26:54.336525 140128494741248 run_lib.py:152] step: 5900, training_loss: 2.10743e+01
I0514 15:26:54.388185 140128494741248 run_lib.py:165] step: 5900, eval_loss: 3.28396e+01
I0514 15:27:00.560964 140128494741248 run_lib.py:152] step: 5950, training_loss: 5.12160e+01
I0514 15:27:06.730572 140128494741248 run_lib.py:152] step: 6000, training_loss: 3.65809e+01
I0514 15:27:06.783118 140128494741248 run_lib.py:165] step: 6000, eval_loss: 2.64576e+01
I0514 15:27:13.183140 140128494741248 run_lib.py:152] step: 6050, training_loss: 2.87763e+01
I0514 15:27:19.316968 140128494741248 run_lib.py:152] step: 6100, training_loss: 5.13614e+01
I0514 15:27:19.365660 140128494741248 run_lib.py:165] step: 6100, eval_loss: 4.92505e+01
I0514 15:27:25.562169 140128494741248 run_lib.py:152] step: 6150, training_loss: 5.47095e+01
I0514 15:27:31.942914 140128494741248 run_lib.py:152] step: 6200, training_loss: 4.32720e+01
I0514 15:27:32.000271 140128494741248 run_lib.py:165] step: 6200, eval_loss: 4.12798e+01
I0514 15:27:38.245340 140128494741248 run_lib.py:152] step: 6250, training_loss: 3.98415e+01
I0514 15:27:44.466293 140128494741248 run_lib.py:152] step: 6300, training_loss: 3.50136e+01
I0514 15:27:44.514987 140128494741248 run_lib.py:165] step: 6300, eval_loss: 3.53395e+01
I0514 15:27:50.666838 140128494741248 run_lib.py:152] step: 6350, training_loss: 4.38965e+01
I0514 15:27:56.999473 140128494741248 run_lib.py:152] step: 6400, training_loss: 4.78797e+01
I0514 15:27:57.051875 140128494741248 run_lib.py:165] step: 6400, eval_loss: 4.80117e+01
I0514 15:28:03.205873 140128494741248 run_lib.py:152] step: 6450, training_loss: 5.81716e+01
I0514 15:28:09.330422 140128494741248 run_lib.py:152] step: 6500, training_loss: 3.33260e+01
I0514 15:28:09.385448 140128494741248 run_lib.py:165] step: 6500, eval_loss: 4.48337e+01
I0514 15:28:15.752485 140128494741248 run_lib.py:152] step: 6550, training_loss: 2.24889e+01
I0514 15:28:21.946989 140128494741248 run_lib.py:152] step: 6600, training_loss: 3.50661e+01
I0514 15:28:22.000149 140128494741248 run_lib.py:165] step: 6600, eval_loss: 4.86136e+01
I0514 15:28:28.153182 140128494741248 run_lib.py:152] step: 6650, training_loss: 2.40008e+01
I0514 15:28:34.308883 140128494741248 run_lib.py:152] step: 6700, training_loss: 5.24658e+01
I0514 15:28:34.358968 140128494741248 run_lib.py:165] step: 6700, eval_loss: 4.22201e+01
I0514 15:28:40.790804 140128494741248 run_lib.py:152] step: 6750, training_loss: 4.39428e+01
I0514 15:28:46.925895 140128494741248 run_lib.py:152] step: 6800, training_loss: 3.08085e+01
I0514 15:28:46.976575 140128494741248 run_lib.py:165] step: 6800, eval_loss: 6.15403e+01
I0514 15:28:53.038490 140128494741248 run_lib.py:152] step: 6850, training_loss: 3.01239e+01
I0514 15:28:59.433287 140128494741248 run_lib.py:152] step: 6900, training_loss: 3.10444e+01
I0514 15:28:59.480560 140128494741248 run_lib.py:165] step: 6900, eval_loss: 2.70325e+01
I0514 15:29:05.689467 140128494741248 run_lib.py:152] step: 6950, training_loss: 5.06204e+01
I0514 15:29:11.773093 140128494741248 run_lib.py:152] step: 7000, training_loss: 4.99517e+01
I0514 15:29:11.826487 140128494741248 run_lib.py:165] step: 7000, eval_loss: 4.75427e+01
I0514 15:29:18.048532 140128494741248 run_lib.py:152] step: 7050, training_loss: 3.25064e+01
I0514 15:29:24.371269 140128494741248 run_lib.py:152] step: 7100, training_loss: 3.18255e+01
I0514 15:29:24.418735 140128494741248 run_lib.py:165] step: 7100, eval_loss: 2.55075e+01
I0514 15:29:30.595269 140128494741248 run_lib.py:152] step: 7150, training_loss: 4.85204e+01
I0514 15:29:36.687817 140128494741248 run_lib.py:152] step: 7200, training_loss: 5.20379e+01
I0514 15:29:36.738520 140128494741248 run_lib.py:165] step: 7200, eval_loss: 2.57680e+01
I0514 15:29:43.143550 140128494741248 run_lib.py:152] step: 7250, training_loss: 4.29376e+01
I0514 15:29:49.313289 140128494741248 run_lib.py:152] step: 7300, training_loss: 3.82991e+01
I0514 15:29:49.368448 140128494741248 run_lib.py:165] step: 7300, eval_loss: 4.32856e+01
I0514 15:29:55.501281 140128494741248 run_lib.py:152] step: 7350, training_loss: 4.09294e+01
I0514 15:30:01.707383 140128494741248 run_lib.py:152] step: 7400, training_loss: 4.20412e+01
I0514 15:30:01.760132 140128494741248 run_lib.py:165] step: 7400, eval_loss: 3.80673e+01
I0514 15:30:08.191312 140128494741248 run_lib.py:152] step: 7450, training_loss: 4.39638e+01
I0514 15:30:14.398609 140128494741248 run_lib.py:152] step: 7500, training_loss: 3.74692e+01
I0514 15:30:14.447398 140128494741248 run_lib.py:165] step: 7500, eval_loss: 4.04018e+01
I0514 15:30:20.631614 140128494741248 run_lib.py:152] step: 7550, training_loss: 4.14512e+01
I0514 15:30:27.077828 140128494741248 run_lib.py:152] step: 7600, training_loss: 2.71055e+01
I0514 15:30:27.132374 140128494741248 run_lib.py:165] step: 7600, eval_loss: 3.96803e+01
I0514 15:30:33.302687 140128494741248 run_lib.py:152] step: 7650, training_loss: 3.70986e+01
I0514 15:30:39.499503 140128494741248 run_lib.py:152] step: 7700, training_loss: 4.62912e+01
I0514 15:30:39.548660 140128494741248 run_lib.py:165] step: 7700, eval_loss: 3.78370e+01
I0514 15:30:45.741820 140128494741248 run_lib.py:152] step: 7750, training_loss: 5.15094e+01
I0514 15:30:52.155291 140128494741248 run_lib.py:152] step: 7800, training_loss: 3.92578e+01
I0514 15:30:52.206792 140128494741248 run_lib.py:165] step: 7800, eval_loss: 2.98645e+01
I0514 15:30:58.353159 140128494741248 run_lib.py:152] step: 7850, training_loss: 3.91259e+01
I0514 15:31:04.447309 140128494741248 run_lib.py:152] step: 7900, training_loss: 3.01744e+01
I0514 15:31:04.507711 140128494741248 run_lib.py:165] step: 7900, eval_loss: 3.62129e+01
I0514 15:31:10.906747 140128494741248 run_lib.py:152] step: 7950, training_loss: 4.00177e+01
I0514 15:31:17.011590 140128494741248 run_lib.py:152] step: 8000, training_loss: 2.37349e+01
I0514 15:31:17.063869 140128494741248 run_lib.py:165] step: 8000, eval_loss: 6.24670e+01
I0514 15:31:23.257600 140128494741248 run_lib.py:152] step: 8050, training_loss: 4.45914e+01
I0514 15:31:29.606762 140128494741248 run_lib.py:152] step: 8100, training_loss: 4.19072e+01
I0514 15:31:29.657457 140128494741248 run_lib.py:165] step: 8100, eval_loss: 3.67342e+01
I0514 15:31:35.731021 140128494741248 run_lib.py:152] step: 8150, training_loss: 4.73694e+01
I0514 15:31:41.867115 140128494741248 run_lib.py:152] step: 8200, training_loss: 3.43991e+01
I0514 15:31:41.920206 140128494741248 run_lib.py:165] step: 8200, eval_loss: 1.68288e+01
I0514 15:31:48.050979 140128494741248 run_lib.py:152] step: 8250, training_loss: 4.19576e+01
I0514 15:31:54.371389 140128494741248 run_lib.py:152] step: 8300, training_loss: 3.86414e+01
I0514 15:31:54.419988 140128494741248 run_lib.py:165] step: 8300, eval_loss: 3.64811e+01
I0514 15:32:00.584667 140128494741248 run_lib.py:152] step: 8350, training_loss: 3.47010e+01
I0514 15:32:06.758229 140128494741248 run_lib.py:152] step: 8400, training_loss: 2.73188e+01
I0514 15:32:06.815484 140128494741248 run_lib.py:165] step: 8400, eval_loss: 2.58871e+01
I0514 15:32:13.152150 140128494741248 run_lib.py:152] step: 8450, training_loss: 4.26369e+01
I0514 15:32:19.366016 140128494741248 run_lib.py:152] step: 8500, training_loss: 2.35981e+01
I0514 15:32:19.415240 140128494741248 run_lib.py:165] step: 8500, eval_loss: 3.73275e+01
I0514 15:32:25.604026 140128494741248 run_lib.py:152] step: 8550, training_loss: 4.30499e+01
I0514 15:32:31.693064 140128494741248 run_lib.py:152] step: 8600, training_loss: 3.59020e+01
I0514 15:32:31.746201 140128494741248 run_lib.py:165] step: 8600, eval_loss: 3.65126e+01
I0514 15:32:38.149655 140128494741248 run_lib.py:152] step: 8650, training_loss: 2.69004e+01
I0514 15:32:44.269775 140128494741248 run_lib.py:152] step: 8700, training_loss: 4.84280e+01
I0514 15:32:44.322497 140128494741248 run_lib.py:165] step: 8700, eval_loss: 5.78384e+01
I0514 15:32:50.481472 140128494741248 run_lib.py:152] step: 8750, training_loss: 3.77110e+01
I0514 15:32:56.843719 140128494741248 run_lib.py:152] step: 8800, training_loss: 4.40893e+01
I0514 15:32:56.894330 140128494741248 run_lib.py:165] step: 8800, eval_loss: 3.93185e+01
I0514 15:33:03.098616 140128494741248 run_lib.py:152] step: 8850, training_loss: 5.23188e+01
I0514 15:33:09.203115 140128494741248 run_lib.py:152] step: 8900, training_loss: 4.44541e+01
I0514 15:33:09.253213 140128494741248 run_lib.py:165] step: 8900, eval_loss: 3.12806e+01
I0514 15:33:15.435541 140128494741248 run_lib.py:152] step: 8950, training_loss: 3.50147e+01
I0514 15:33:21.878793 140128494741248 run_lib.py:152] step: 9000, training_loss: 4.24975e+01
I0514 15:33:21.934000 140128494741248 run_lib.py:165] step: 9000, eval_loss: 5.52816e+01
I0514 15:33:28.144298 140128494741248 run_lib.py:152] step: 9050, training_loss: 3.51312e+01
I0514 15:33:34.335298 140128494741248 run_lib.py:152] step: 9100, training_loss: 3.13643e+01
I0514 15:33:34.389679 140128494741248 run_lib.py:165] step: 9100, eval_loss: 5.51132e+01
I0514 15:33:40.826140 140128494741248 run_lib.py:152] step: 9150, training_loss: 3.94694e+01
I0514 15:33:46.953266 140128494741248 run_lib.py:152] step: 9200, training_loss: 4.57526e+01
I0514 15:33:47.005323 140128494741248 run_lib.py:165] step: 9200, eval_loss: 3.26238e+01
I0514 15:33:53.178665 140128494741248 run_lib.py:152] step: 9250, training_loss: 2.32829e+01
I0514 15:33:59.343025 140128494741248 run_lib.py:152] step: 9300, training_loss: 5.26813e+01
I0514 15:33:59.403357 140128494741248 run_lib.py:165] step: 9300, eval_loss: 3.35445e+01
I0514 15:34:05.847029 140128494741248 run_lib.py:152] step: 9350, training_loss: 2.74788e+01
I0514 15:34:11.959717 140128494741248 run_lib.py:152] step: 9400, training_loss: 3.95017e+01
I0514 15:34:12.015890 140128494741248 run_lib.py:165] step: 9400, eval_loss: 2.78003e+01
I0514 15:34:18.128574 140128494741248 run_lib.py:152] step: 9450, training_loss: 4.15802e+01
I0514 15:34:24.536283 140128494741248 run_lib.py:152] step: 9500, training_loss: 2.00291e+01
I0514 15:34:24.590205 140128494741248 run_lib.py:165] step: 9500, eval_loss: 4.56589e+01
I0514 15:34:30.717359 140128494741248 run_lib.py:152] step: 9550, training_loss: 4.75701e+01
I0514 15:34:36.879720 140128494741248 run_lib.py:152] step: 9600, training_loss: 2.67467e+01
I0514 15:34:36.935796 140128494741248 run_lib.py:165] step: 9600, eval_loss: 4.17006e+01
I0514 15:34:43.134164 140128494741248 run_lib.py:152] step: 9650, training_loss: 3.29710e+01
I0514 15:34:49.525319 140128494741248 run_lib.py:152] step: 9700, training_loss: 3.31863e+01
I0514 15:34:49.577419 140128494741248 run_lib.py:165] step: 9700, eval_loss: 4.67257e+01
I0514 15:34:55.637528 140128494741248 run_lib.py:152] step: 9750, training_loss: 4.09278e+01
I0514 15:35:01.870276 140128494741248 run_lib.py:152] step: 9800, training_loss: 3.76039e+01
I0514 15:35:01.929826 140128494741248 run_lib.py:165] step: 9800, eval_loss: 5.03325e+01
I0514 15:35:08.350292 140128494741248 run_lib.py:152] step: 9850, training_loss: 2.50908e+01
I0514 15:35:14.513253 140128494741248 run_lib.py:152] step: 9900, training_loss: 4.63469e+01
I0514 15:35:14.563271 140128494741248 run_lib.py:165] step: 9900, eval_loss: 4.73922e+01
I0514 15:35:20.768299 140128494741248 run_lib.py:152] step: 9950, training_loss: 3.84117e+01
I0514 15:35:26.965006 140128494741248 run_lib.py:152] step: 10000, training_loss: 3.61327e+01
I0514 15:35:27.151464 140128494741248 run_lib.py:165] step: 10000, eval_loss: 3.05701e+01
I0514 15:35:33.598294 140128494741248 run_lib.py:152] step: 10050, training_loss: 4.19902e+01
I0514 15:35:39.853503 140128494741248 run_lib.py:152] step: 10100, training_loss: 4.10739e+01
I0514 15:35:39.902351 140128494741248 run_lib.py:165] step: 10100, eval_loss: 2.30139e+01
I0514 15:35:46.001083 140128494741248 run_lib.py:152] step: 10150, training_loss: 3.87812e+01
I0514 15:35:52.331700 140128494741248 run_lib.py:152] step: 10200, training_loss: 4.76438e+01
I0514 15:35:52.382622 140128494741248 run_lib.py:165] step: 10200, eval_loss: 3.12297e+01
I0514 15:35:58.502602 140128494741248 run_lib.py:152] step: 10250, training_loss: 2.58784e+01
I0514 15:36:04.678031 140128494741248 run_lib.py:152] step: 10300, training_loss: 3.95530e+01
I0514 15:36:04.737665 140128494741248 run_lib.py:165] step: 10300, eval_loss: 4.13286e+01
I0514 15:36:10.903570 140128494741248 run_lib.py:152] step: 10350, training_loss: 3.90861e+01
I0514 15:36:17.323263 140128494741248 run_lib.py:152] step: 10400, training_loss: 4.80953e+01
I0514 15:36:17.373729 140128494741248 run_lib.py:165] step: 10400, eval_loss: 4.38854e+01
I0514 15:36:23.491691 140128494741248 run_lib.py:152] step: 10450, training_loss: 4.12231e+01
I0514 15:36:29.699409 140128494741248 run_lib.py:152] step: 10500, training_loss: 4.19311e+01
I0514 15:36:29.755616 140128494741248 run_lib.py:165] step: 10500, eval_loss: 3.08443e+01
I0514 15:36:36.197754 140128494741248 run_lib.py:152] step: 10550, training_loss: 3.29227e+01
I0514 15:36:42.411116 140128494741248 run_lib.py:152] step: 10600, training_loss: 3.76205e+01
I0514 15:36:42.463951 140128494741248 run_lib.py:165] step: 10600, eval_loss: 4.14964e+01
I0514 15:36:48.630998 140128494741248 run_lib.py:152] step: 10650, training_loss: 4.44625e+01
I0514 15:36:54.805807 140128494741248 run_lib.py:152] step: 10700, training_loss: 4.00445e+01
I0514 15:36:54.854052 140128494741248 run_lib.py:165] step: 10700, eval_loss: 4.54161e+01
I0514 15:37:01.291883 140128494741248 run_lib.py:152] step: 10750, training_loss: 4.02445e+01
I0514 15:37:07.454191 140128494741248 run_lib.py:152] step: 10800, training_loss: 4.06160e+01
I0514 15:37:07.508572 140128494741248 run_lib.py:165] step: 10800, eval_loss: 3.63631e+01
I0514 15:37:13.722448 140128494741248 run_lib.py:152] step: 10850, training_loss: 2.33322e+01
I0514 15:37:20.112726 140128494741248 run_lib.py:152] step: 10900, training_loss: 3.77269e+01
I0514 15:37:20.162940 140128494741248 run_lib.py:165] step: 10900, eval_loss: 3.95254e+01
I0514 15:37:26.239421 140128494741248 run_lib.py:152] step: 10950, training_loss: 3.54428e+01
I0514 15:37:32.390920 140128494741248 run_lib.py:152] step: 11000, training_loss: 3.60497e+01
I0514 15:37:32.445749 140128494741248 run_lib.py:165] step: 11000, eval_loss: 2.48639e+01
I0514 15:37:38.654238 140128494741248 run_lib.py:152] step: 11050, training_loss: 3.08850e+01
I0514 15:37:45.018659 140128494741248 run_lib.py:152] step: 11100, training_loss: 5.36263e+01
I0514 15:37:45.071794 140128494741248 run_lib.py:165] step: 11100, eval_loss: 2.92528e+01
I0514 15:37:51.153697 140128494741248 run_lib.py:152] step: 11150, training_loss: 3.18392e+01
I0514 15:37:57.311979 140128494741248 run_lib.py:152] step: 11200, training_loss: 3.24735e+01
I0514 15:37:57.359035 140128494741248 run_lib.py:165] step: 11200, eval_loss: 2.62271e+01
I0514 15:38:03.739442 140128494741248 run_lib.py:152] step: 11250, training_loss: 3.84391e+01
I0514 15:38:09.885045 140128494741248 run_lib.py:152] step: 11300, training_loss: 3.89831e+01
I0514 15:38:09.938199 140128494741248 run_lib.py:165] step: 11300, eval_loss: 4.70186e+01
I0514 15:38:16.096432 140128494741248 run_lib.py:152] step: 11350, training_loss: 3.97667e+01
I0514 15:38:22.294248 140128494741248 run_lib.py:152] step: 11400, training_loss: 3.86738e+01
I0514 15:38:22.348492 140128494741248 run_lib.py:165] step: 11400, eval_loss: 2.50865e+01
I0514 15:38:28.801291 140128494741248 run_lib.py:152] step: 11450, training_loss: 2.64467e+01
I0514 15:38:34.930142 140128494741248 run_lib.py:152] step: 11500, training_loss: 4.66447e+01
I0514 15:38:34.979783 140128494741248 run_lib.py:165] step: 11500, eval_loss: 3.13913e+01
I0514 15:38:41.119948 140128494741248 run_lib.py:152] step: 11550, training_loss: 3.53708e+01
I0514 15:38:47.548077 140128494741248 run_lib.py:152] step: 11600, training_loss: 4.30968e+01
I0514 15:38:47.602528 140128494741248 run_lib.py:165] step: 11600, eval_loss: 5.08357e+01
I0514 15:38:53.628013 140128494741248 run_lib.py:152] step: 11650, training_loss: 3.58263e+01
I0514 15:38:59.813353 140128494741248 run_lib.py:152] step: 11700, training_loss: 5.04413e+01
I0514 15:38:59.869247 140128494741248 run_lib.py:165] step: 11700, eval_loss: 4.00773e+01
I0514 15:39:06.089319 140128494741248 run_lib.py:152] step: 11750, training_loss: 2.71511e+01
I0514 15:39:12.535229 140128494741248 run_lib.py:152] step: 11800, training_loss: 2.71378e+01
I0514 15:39:12.588486 140128494741248 run_lib.py:165] step: 11800, eval_loss: 2.96749e+01
I0514 15:39:18.722238 140128494741248 run_lib.py:152] step: 11850, training_loss: 2.28281e+01
I0514 15:39:24.923795 140128494741248 run_lib.py:152] step: 11900, training_loss: 4.59575e+01
I0514 15:39:24.976500 140128494741248 run_lib.py:165] step: 11900, eval_loss: 2.97799e+01
I0514 15:39:31.327401 140128494741248 run_lib.py:152] step: 11950, training_loss: 3.99881e+01
I0514 15:39:37.573112 140128494741248 run_lib.py:152] step: 12000, training_loss: 3.82024e+01
I0514 15:39:37.622446 140128494741248 run_lib.py:165] step: 12000, eval_loss: 9.76396e+00
I0514 15:39:43.799605 140128494741248 run_lib.py:152] step: 12050, training_loss: 3.51641e+01
I0514 15:39:49.934858 140128494741248 run_lib.py:152] step: 12100, training_loss: 3.67291e+01
I0514 15:39:49.989460 140128494741248 run_lib.py:165] step: 12100, eval_loss: 4.21470e+01
I0514 15:39:56.374372 140128494741248 run_lib.py:152] step: 12150, training_loss: 4.23617e+01
I0514 15:40:02.467724 140128494741248 run_lib.py:152] step: 12200, training_loss: 4.00706e+01
I0514 15:40:02.518824 140128494741248 run_lib.py:165] step: 12200, eval_loss: 4.01932e+01
I0514 15:40:08.751060 140128494741248 run_lib.py:152] step: 12250, training_loss: 5.80510e+01
I0514 15:40:15.152415 140128494741248 run_lib.py:152] step: 12300, training_loss: 3.46279e+01
I0514 15:40:15.202445 140128494741248 run_lib.py:165] step: 12300, eval_loss: 2.72494e+01
I0514 15:40:21.337492 140128494741248 run_lib.py:152] step: 12350, training_loss: 3.44174e+01
I0514 15:40:27.509918 140128494741248 run_lib.py:152] step: 12400, training_loss: 1.76760e+01
I0514 15:40:27.566136 140128494741248 run_lib.py:165] step: 12400, eval_loss: 4.21179e+01
I0514 15:40:33.818374 140128494741248 run_lib.py:152] step: 12450, training_loss: 3.60072e+01
I0514 15:40:40.241642 140128494741248 run_lib.py:152] step: 12500, training_loss: 3.47326e+01
I0514 15:40:40.292565 140128494741248 run_lib.py:165] step: 12500, eval_loss: 2.77551e+01
I0514 15:40:46.616571 140128494741248 run_lib.py:152] step: 12550, training_loss: 4.67422e+01
I0514 15:40:52.809887 140128494741248 run_lib.py:152] step: 12600, training_loss: 5.40941e+01
I0514 15:40:52.863080 140128494741248 run_lib.py:165] step: 12600, eval_loss: 3.64712e+01
I0514 15:40:59.345113 140128494741248 run_lib.py:152] step: 12650, training_loss: 3.05747e+01
I0514 15:41:05.526206 140128494741248 run_lib.py:152] step: 12700, training_loss: 4.41526e+01
I0514 15:41:05.578628 140128494741248 run_lib.py:165] step: 12700, eval_loss: 3.72476e+01
I0514 15:41:11.724000 140128494741248 run_lib.py:152] step: 12750, training_loss: 2.97879e+01
I0514 15:41:18.143718 140128494741248 run_lib.py:152] step: 12800, training_loss: 2.63961e+01
I0514 15:41:18.196372 140128494741248 run_lib.py:165] step: 12800, eval_loss: 4.95399e+01
I0514 15:41:24.358611 140128494741248 run_lib.py:152] step: 12850, training_loss: 4.32876e+01
I0514 15:41:30.526458 140128494741248 run_lib.py:152] step: 12900, training_loss: 3.37952e+01
I0514 15:41:30.577415 140128494741248 run_lib.py:165] step: 12900, eval_loss: 5.39757e+01
I0514 15:41:36.791440 140128494741248 run_lib.py:152] step: 12950, training_loss: 4.66447e+01
I0514 15:41:43.074029 140128494741248 run_lib.py:152] step: 13000, training_loss: 3.34433e+01
I0514 15:41:43.127004 140128494741248 run_lib.py:165] step: 13000, eval_loss: 3.54370e+01
I0514 15:41:49.382961 140128494741248 run_lib.py:152] step: 13050, training_loss: 5.19089e+01
I0514 15:41:55.621567 140128494741248 run_lib.py:152] step: 13100, training_loss: 3.56505e+01
I0514 15:41:55.677521 140128494741248 run_lib.py:165] step: 13100, eval_loss: 4.31370e+01
I0514 15:42:02.053024 140128494741248 run_lib.py:152] step: 13150, training_loss: 4.44866e+01
I0514 15:42:08.241099 140128494741248 run_lib.py:152] step: 13200, training_loss: 3.33775e+01
I0514 15:42:08.296715 140128494741248 run_lib.py:165] step: 13200, eval_loss: 3.81384e+01
I0514 15:42:14.423677 140128494741248 run_lib.py:152] step: 13250, training_loss: 2.13724e+01
I0514 15:42:20.606103 140128494741248 run_lib.py:152] step: 13300, training_loss: 3.71278e+01
I0514 15:42:20.661362 140128494741248 run_lib.py:165] step: 13300, eval_loss: 2.67647e+01
I0514 15:42:27.014372 140128494741248 run_lib.py:152] step: 13350, training_loss: 3.32040e+01
I0514 15:42:33.209540 140128494741248 run_lib.py:152] step: 13400, training_loss: 2.30606e+01
I0514 15:42:33.257694 140128494741248 run_lib.py:165] step: 13400, eval_loss: 3.33558e+01
I0514 15:42:39.395438 140128494741248 run_lib.py:152] step: 13450, training_loss: 3.01173e+01
I0514 15:42:45.762278 140128494741248 run_lib.py:152] step: 13500, training_loss: 4.39010e+01
I0514 15:42:45.814250 140128494741248 run_lib.py:165] step: 13500, eval_loss: 2.27721e+01
I0514 15:42:51.942777 140128494741248 run_lib.py:152] step: 13550, training_loss: 3.76950e+01
I0514 15:42:58.103238 140128494741248 run_lib.py:152] step: 13600, training_loss: 5.15430e+01
I0514 15:42:58.154677 140128494741248 run_lib.py:165] step: 13600, eval_loss: 3.20210e+01
I0514 15:43:04.335417 140128494741248 run_lib.py:152] step: 13650, training_loss: 2.16501e+01
I0514 15:43:10.738150 140128494741248 run_lib.py:152] step: 13700, training_loss: 2.60004e+01
I0514 15:43:10.789665 140128494741248 run_lib.py:165] step: 13700, eval_loss: 2.55507e+01
I0514 15:43:17.072698 140128494741248 run_lib.py:152] step: 13750, training_loss: 3.63203e+01
I0514 15:43:23.309379 140128494741248 run_lib.py:152] step: 13800, training_loss: 3.98359e+01
I0514 15:43:23.360708 140128494741248 run_lib.py:165] step: 13800, eval_loss: 5.57551e+01
I0514 15:43:29.805080 140128494741248 run_lib.py:152] step: 13850, training_loss: 5.56153e+01
I0514 15:43:36.020906 140128494741248 run_lib.py:152] step: 13900, training_loss: 4.03160e+01
I0514 15:43:36.071999 140128494741248 run_lib.py:165] step: 13900, eval_loss: 3.72478e+01
I0514 15:43:42.203134 140128494741248 run_lib.py:152] step: 13950, training_loss: 2.75417e+01
I0514 15:43:48.375786 140128494741248 run_lib.py:152] step: 14000, training_loss: 6.18228e+01
I0514 15:43:48.429401 140128494741248 run_lib.py:165] step: 14000, eval_loss: 2.93484e+01
I0514 15:43:54.875849 140128494741248 run_lib.py:152] step: 14050, training_loss: 3.72421e+01
I0514 15:44:01.039308 140128494741248 run_lib.py:152] step: 14100, training_loss: 4.25463e+01
I0514 15:44:01.090746 140128494741248 run_lib.py:165] step: 14100, eval_loss: 3.70246e+01
I0514 15:44:07.188640 140128494741248 run_lib.py:152] step: 14150, training_loss: 2.11562e+01
I0514 15:44:13.632418 140128494741248 run_lib.py:152] step: 14200, training_loss: 4.66496e+01
I0514 15:44:13.688429 140128494741248 run_lib.py:165] step: 14200, eval_loss: 2.88908e+01
I0514 15:44:19.931517 140128494741248 run_lib.py:152] step: 14250, training_loss: 4.46335e+01
I0514 15:44:26.148263 140128494741248 run_lib.py:152] step: 14300, training_loss: 3.23862e+01
I0514 15:44:26.197406 140128494741248 run_lib.py:165] step: 14300, eval_loss: 3.85123e+01
I0514 15:44:32.352329 140128494741248 run_lib.py:152] step: 14350, training_loss: 3.52457e+01
I0514 15:44:38.858011 140128494741248 run_lib.py:152] step: 14400, training_loss: 4.88436e+01
I0514 15:44:38.914212 140128494741248 run_lib.py:165] step: 14400, eval_loss: 2.64022e+01
I0514 15:44:45.102744 140128494741248 run_lib.py:152] step: 14450, training_loss: 3.91582e+01
I0514 15:44:51.266933 140128494741248 run_lib.py:152] step: 14500, training_loss: 4.42844e+01
I0514 15:44:51.320387 140128494741248 run_lib.py:165] step: 14500, eval_loss: 3.15623e+01
I0514 15:44:57.799954 140128494741248 run_lib.py:152] step: 14550, training_loss: 4.36832e+01
I0514 15:45:03.896210 140128494741248 run_lib.py:152] step: 14600, training_loss: 4.00768e+01
I0514 15:45:03.953575 140128494741248 run_lib.py:165] step: 14600, eval_loss: 3.28745e+01
I0514 15:45:10.147104 140128494741248 run_lib.py:152] step: 14650, training_loss: 2.81450e+01
I0514 15:45:16.324086 140128494741248 run_lib.py:152] step: 14700, training_loss: 3.00463e+01
I0514 15:45:16.378304 140128494741248 run_lib.py:165] step: 14700, eval_loss: 4.57196e+01
I0514 15:45:22.757683 140128494741248 run_lib.py:152] step: 14750, training_loss: 4.44460e+01
I0514 15:45:28.892253 140128494741248 run_lib.py:152] step: 14800, training_loss: 3.44721e+01
I0514 15:45:28.941087 140128494741248 run_lib.py:165] step: 14800, eval_loss: 2.87538e+01
I0514 15:45:35.164448 140128494741248 run_lib.py:152] step: 14850, training_loss: 5.76485e+01
I0514 15:45:41.568511 140128494741248 run_lib.py:152] step: 14900, training_loss: 3.32305e+01
I0514 15:45:41.618486 140128494741248 run_lib.py:165] step: 14900, eval_loss: 4.36932e+01
I0514 15:45:47.795143 140128494741248 run_lib.py:152] step: 14950, training_loss: 4.50141e+01
I0514 15:45:54.035959 140128494741248 run_lib.py:152] step: 15000, training_loss: 3.88621e+01
I0514 15:45:54.085091 140128494741248 run_lib.py:165] step: 15000, eval_loss: 4.69466e+01
I0514 15:46:00.280366 140128494741248 run_lib.py:152] step: 15050, training_loss: 4.60106e+01
I0514 15:46:06.764264 140128494741248 run_lib.py:152] step: 15100, training_loss: 2.66878e+01
I0514 15:46:06.814519 140128494741248 run_lib.py:165] step: 15100, eval_loss: 4.20097e+01
I0514 15:46:13.022793 140128494741248 run_lib.py:152] step: 15150, training_loss: 5.08495e+01
I0514 15:46:19.248510 140128494741248 run_lib.py:152] step: 15200, training_loss: 2.67330e+01
I0514 15:46:19.304263 140128494741248 run_lib.py:165] step: 15200, eval_loss: 5.24853e+01
I0514 15:46:25.772700 140128494741248 run_lib.py:152] step: 15250, training_loss: 3.88696e+01
I0514 15:46:31.900991 140128494741248 run_lib.py:152] step: 15300, training_loss: 2.72179e+01
I0514 15:46:31.950852 140128494741248 run_lib.py:165] step: 15300, eval_loss: 3.90858e+01
I0514 15:46:38.195362 140128494741248 run_lib.py:152] step: 15350, training_loss: 5.09417e+01
I0514 15:46:44.335031 140128494741248 run_lib.py:152] step: 15400, training_loss: 4.28813e+01
I0514 15:46:44.387516 140128494741248 run_lib.py:165] step: 15400, eval_loss: 3.18445e+01
I0514 15:46:50.794895 140128494741248 run_lib.py:152] step: 15450, training_loss: 4.23744e+01
I0514 15:46:56.981599 140128494741248 run_lib.py:152] step: 15500, training_loss: 3.17372e+01
I0514 15:46:57.036385 140128494741248 run_lib.py:165] step: 15500, eval_loss: 4.35264e+01
I0514 15:47:03.293405 140128494741248 run_lib.py:152] step: 15550, training_loss: 3.14035e+01
I0514 15:47:09.684278 140128494741248 run_lib.py:152] step: 15600, training_loss: 3.78189e+01
I0514 15:47:09.742428 140128494741248 run_lib.py:165] step: 15600, eval_loss: 3.44241e+01
I0514 15:47:16.075424 140128494741248 run_lib.py:152] step: 15650, training_loss: 3.33577e+01
I0514 15:47:22.203564 140128494741248 run_lib.py:152] step: 15700, training_loss: 3.23239e+01
I0514 15:47:22.259850 140128494741248 run_lib.py:165] step: 15700, eval_loss: 3.20276e+01
I0514 15:47:28.460325 140128494741248 run_lib.py:152] step: 15750, training_loss: 4.55911e+01
I0514 15:47:34.755717 140128494741248 run_lib.py:152] step: 15800, training_loss: 1.98285e+01
I0514 15:47:34.807690 140128494741248 run_lib.py:165] step: 15800, eval_loss: 3.48963e+01
I0514 15:47:41.053142 140128494741248 run_lib.py:152] step: 15850, training_loss: 3.50987e+01
I0514 15:47:47.179810 140128494741248 run_lib.py:152] step: 15900, training_loss: 4.85706e+01
I0514 15:47:47.235557 140128494741248 run_lib.py:165] step: 15900, eval_loss: 4.40464e+01
I0514 15:47:53.675952 140128494741248 run_lib.py:152] step: 15950, training_loss: 4.37879e+01
I0514 15:47:59.798018 140128494741248 run_lib.py:152] step: 16000, training_loss: 4.57999e+01
I0514 15:47:59.845303 140128494741248 run_lib.py:165] step: 16000, eval_loss: 2.50285e+01
I0514 15:48:05.966892 140128494741248 run_lib.py:152] step: 16050, training_loss: 2.41720e+01
I0514 15:48:12.124273 140128494741248 run_lib.py:152] step: 16100, training_loss: 4.24348e+01
I0514 15:48:12.180258 140128494741248 run_lib.py:165] step: 16100, eval_loss: 3.24689e+01
I0514 15:48:18.606190 140128494741248 run_lib.py:152] step: 16150, training_loss: 3.08351e+01
I0514 15:48:24.707456 140128494741248 run_lib.py:152] step: 16200, training_loss: 4.13062e+01
I0514 15:48:24.762296 140128494741248 run_lib.py:165] step: 16200, eval_loss: 2.45864e+01
I0514 15:48:30.919227 140128494741248 run_lib.py:152] step: 16250, training_loss: 5.53846e+01
I0514 15:48:37.372350 140128494741248 run_lib.py:152] step: 16300, training_loss: 3.22928e+01
I0514 15:48:37.426285 140128494741248 run_lib.py:165] step: 16300, eval_loss: 4.82845e+01
I0514 15:48:43.627927 140128494741248 run_lib.py:152] step: 16350, training_loss: 4.28815e+01
I0514 15:48:49.808305 140128494741248 run_lib.py:152] step: 16400, training_loss: 2.51233e+01
I0514 15:48:49.858739 140128494741248 run_lib.py:165] step: 16400, eval_loss: 2.50065e+01
I0514 15:48:56.061767 140128494741248 run_lib.py:152] step: 16450, training_loss: 4.00904e+01
I0514 15:49:02.362551 140128494741248 run_lib.py:152] step: 16500, training_loss: 1.96414e+01
I0514 15:49:02.415657 140128494741248 run_lib.py:165] step: 16500, eval_loss: 2.58430e+01
I0514 15:49:08.624286 140128494741248 run_lib.py:152] step: 16550, training_loss: 3.42607e+01
I0514 15:49:14.804093 140128494741248 run_lib.py:152] step: 16600, training_loss: 6.06824e+01
I0514 15:49:14.854456 140128494741248 run_lib.py:165] step: 16600, eval_loss: 3.14229e+01
I0514 15:49:21.221464 140128494741248 run_lib.py:152] step: 16650, training_loss: 4.48234e+01
I0514 15:49:27.377713 140128494741248 run_lib.py:152] step: 16700, training_loss: 2.64987e+01
I0514 15:49:27.431596 140128494741248 run_lib.py:165] step: 16700, eval_loss: 2.70482e+01
I0514 15:49:33.625772 140128494741248 run_lib.py:152] step: 16750, training_loss: 3.59091e+01
I0514 15:49:39.797000 140128494741248 run_lib.py:152] step: 16800, training_loss: 1.84271e+01
I0514 15:49:39.851205 140128494741248 run_lib.py:165] step: 16800, eval_loss: 3.57303e+01
I0514 15:49:46.328759 140128494741248 run_lib.py:152] step: 16850, training_loss: 4.21641e+01
I0514 15:49:52.552809 140128494741248 run_lib.py:152] step: 16900, training_loss: 5.51414e+01
I0514 15:49:52.607827 140128494741248 run_lib.py:165] step: 16900, eval_loss: 2.94550e+01
I0514 15:49:58.756229 140128494741248 run_lib.py:152] step: 16950, training_loss: 4.95277e+01
I0514 15:50:05.154424 140128494741248 run_lib.py:152] step: 17000, training_loss: 4.35285e+01
I0514 15:50:05.207943 140128494741248 run_lib.py:165] step: 17000, eval_loss: 4.85614e+01
I0514 15:50:11.440419 140128494741248 run_lib.py:152] step: 17050, training_loss: 3.25035e+01
I0514 15:50:17.666258 140128494741248 run_lib.py:152] step: 17100, training_loss: 4.89791e+01
I0514 15:50:17.718527 140128494741248 run_lib.py:165] step: 17100, eval_loss: 3.62955e+01
I0514 15:50:23.874539 140128494741248 run_lib.py:152] step: 17150, training_loss: 4.13705e+01
I0514 15:50:30.188121 140128494741248 run_lib.py:152] step: 17200, training_loss: 4.61751e+01
I0514 15:50:30.247047 140128494741248 run_lib.py:165] step: 17200, eval_loss: 3.61352e+01
I0514 15:50:36.372055 140128494741248 run_lib.py:152] step: 17250, training_loss: 3.02377e+01
I0514 15:50:42.452707 140128494741248 run_lib.py:152] step: 17300, training_loss: 2.40651e+01
I0514 15:50:42.503741 140128494741248 run_lib.py:165] step: 17300, eval_loss: 4.23481e+01
I0514 15:50:48.918656 140128494741248 run_lib.py:152] step: 17350, training_loss: 3.54834e+01
I0514 15:50:55.067709 140128494741248 run_lib.py:152] step: 17400, training_loss: 3.07219e+01
I0514 15:50:55.117475 140128494741248 run_lib.py:165] step: 17400, eval_loss: 3.84696e+01
I0514 15:51:01.419948 140128494741248 run_lib.py:152] step: 17450, training_loss: 3.03116e+01
I0514 15:51:07.862956 140128494741248 run_lib.py:152] step: 17500, training_loss: 3.45638e+01
I0514 15:51:07.917921 140128494741248 run_lib.py:165] step: 17500, eval_loss: 4.71447e+01
I0514 15:51:14.182649 140128494741248 run_lib.py:152] step: 17550, training_loss: 2.50942e+01
I0514 15:51:20.354140 140128494741248 run_lib.py:152] step: 17600, training_loss: 4.88559e+01
I0514 15:51:20.415130 140128494741248 run_lib.py:165] step: 17600, eval_loss: 3.05074e+01
I0514 15:51:26.568124 140128494741248 run_lib.py:152] step: 17650, training_loss: 2.19071e+01
I0514 15:51:33.019834 140128494741248 run_lib.py:152] step: 17700, training_loss: 2.88761e+01
I0514 15:51:33.080197 140128494741248 run_lib.py:165] step: 17700, eval_loss: 5.73745e+01
I0514 15:51:39.154091 140128494741248 run_lib.py:152] step: 17750, training_loss: 2.61855e+01
I0514 15:51:45.328079 140128494741248 run_lib.py:152] step: 17800, training_loss: 3.66733e+01
I0514 15:51:45.381623 140128494741248 run_lib.py:165] step: 17800, eval_loss: 2.99008e+01
I0514 15:51:51.731543 140128494741248 run_lib.py:152] step: 17850, training_loss: 4.32643e+01
I0514 15:51:57.928211 140128494741248 run_lib.py:152] step: 17900, training_loss: 2.41191e+01
I0514 15:51:57.981997 140128494741248 run_lib.py:165] step: 17900, eval_loss: 4.55822e+01
I0514 15:52:04.140605 140128494741248 run_lib.py:152] step: 17950, training_loss: 3.18069e+01
I0514 15:52:10.333665 140128494741248 run_lib.py:152] step: 18000, training_loss: 3.96408e+01
I0514 15:52:10.384523 140128494741248 run_lib.py:165] step: 18000, eval_loss: 2.96342e+01
I0514 15:52:16.775594 140128494741248 run_lib.py:152] step: 18050, training_loss: 3.14383e+01
I0514 15:52:23.003696 140128494741248 run_lib.py:152] step: 18100, training_loss: 3.21999e+01
I0514 15:52:23.056273 140128494741248 run_lib.py:165] step: 18100, eval_loss: 3.13403e+01
I0514 15:52:29.220706 140128494741248 run_lib.py:152] step: 18150, training_loss: 3.25109e+01
I0514 15:52:35.698654 140128494741248 run_lib.py:152] step: 18200, training_loss: 4.80336e+01
I0514 15:52:35.753316 140128494741248 run_lib.py:165] step: 18200, eval_loss: 5.31457e+01
I0514 15:52:41.934983 140128494741248 run_lib.py:152] step: 18250, training_loss: 3.48933e+01
I0514 15:52:48.071716 140128494741248 run_lib.py:152] step: 18300, training_loss: 4.73799e+01
I0514 15:52:48.121467 140128494741248 run_lib.py:165] step: 18300, eval_loss: 3.60621e+01
I0514 15:52:54.323589 140128494741248 run_lib.py:152] step: 18350, training_loss: 4.57774e+01
I0514 15:53:00.689133 140128494741248 run_lib.py:152] step: 18400, training_loss: 1.71980e+01
I0514 15:53:00.742789 140128494741248 run_lib.py:165] step: 18400, eval_loss: 2.91122e+01
I0514 15:53:06.937839 140128494741248 run_lib.py:152] step: 18450, training_loss: 2.43431e+01
I0514 15:53:13.082310 140128494741248 run_lib.py:152] step: 18500, training_loss: 3.64534e+01
I0514 15:53:13.130931 140128494741248 run_lib.py:165] step: 18500, eval_loss: 3.39373e+01
I0514 15:53:19.533223 140128494741248 run_lib.py:152] step: 18550, training_loss: 4.59617e+01
I0514 15:53:25.668572 140128494741248 run_lib.py:152] step: 18600, training_loss: 3.93130e+01
I0514 15:53:25.718907 140128494741248 run_lib.py:165] step: 18600, eval_loss: 3.71078e+01
I0514 15:53:31.930445 140128494741248 run_lib.py:152] step: 18650, training_loss: 5.08567e+01
I0514 15:53:38.057205 140128494741248 run_lib.py:152] step: 18700, training_loss: 3.76919e+01
I0514 15:53:38.108234 140128494741248 run_lib.py:165] step: 18700, eval_loss: 2.75990e+01
I0514 15:53:44.402172 140128494741248 run_lib.py:152] step: 18750, training_loss: 4.96537e+01
I0514 15:53:50.592871 140128494741248 run_lib.py:152] step: 18800, training_loss: 3.68966e+01
I0514 15:53:50.637596 140128494741248 run_lib.py:165] step: 18800, eval_loss: 2.87723e+01
I0514 15:53:56.859268 140128494741248 run_lib.py:152] step: 18850, training_loss: 3.95858e+01
I0514 15:54:03.182438 140128494741248 run_lib.py:152] step: 18900, training_loss: 3.22504e+01
I0514 15:54:03.237782 140128494741248 run_lib.py:165] step: 18900, eval_loss: 3.53791e+01
I0514 15:54:09.428571 140128494741248 run_lib.py:152] step: 18950, training_loss: 4.34673e+01
I0514 15:54:15.612281 140128494741248 run_lib.py:152] step: 19000, training_loss: 3.18903e+01
I0514 15:54:15.661508 140128494741248 run_lib.py:165] step: 19000, eval_loss: 3.95409e+01
I0514 15:54:21.877238 140128494741248 run_lib.py:152] step: 19050, training_loss: 3.85246e+01
I0514 15:54:28.264131 140128494741248 run_lib.py:152] step: 19100, training_loss: 2.72846e+01
I0514 15:54:28.320797 140128494741248 run_lib.py:165] step: 19100, eval_loss: 3.42344e+01
I0514 15:54:34.888199 140128494741248 run_lib.py:152] step: 19150, training_loss: 3.23789e+01
I0514 15:54:41.090670 140128494741248 run_lib.py:152] step: 19200, training_loss: 4.12419e+01
I0514 15:54:41.144237 140128494741248 run_lib.py:165] step: 19200, eval_loss: 4.26281e+01
I0514 15:54:47.597088 140128494741248 run_lib.py:152] step: 19250, training_loss: 4.72870e+01
I0514 15:54:53.848617 140128494741248 run_lib.py:152] step: 19300, training_loss: 4.36012e+01
I0514 15:54:53.902789 140128494741248 run_lib.py:165] step: 19300, eval_loss: 2.69869e+01
I0514 15:55:00.082691 140128494741248 run_lib.py:152] step: 19350, training_loss: 5.97622e+01
I0514 15:55:06.315040 140128494741248 run_lib.py:152] step: 19400, training_loss: 4.29986e+01
I0514 15:55:06.368673 140128494741248 run_lib.py:165] step: 19400, eval_loss: 3.69555e+01
I0514 15:55:12.847074 140128494741248 run_lib.py:152] step: 19450, training_loss: 3.37418e+01
I0514 15:55:19.005573 140128494741248 run_lib.py:152] step: 19500, training_loss: 3.24733e+01
I0514 15:55:19.059563 140128494741248 run_lib.py:165] step: 19500, eval_loss: 2.54030e+01
I0514 15:55:25.245441 140128494741248 run_lib.py:152] step: 19550, training_loss: 2.20661e+01
I0514 15:55:31.656855 140128494741248 run_lib.py:152] step: 19600, training_loss: 4.26706e+01
I0514 15:55:31.710536 140128494741248 run_lib.py:165] step: 19600, eval_loss: 2.62502e+01
I0514 15:55:37.845187 140128494741248 run_lib.py:152] step: 19650, training_loss: 3.48647e+01
I0514 15:55:43.991968 140128494741248 run_lib.py:152] step: 19700, training_loss: 2.79819e+01
I0514 15:55:44.050278 140128494741248 run_lib.py:165] step: 19700, eval_loss: 2.79178e+01
I0514 15:55:50.267401 140128494741248 run_lib.py:152] step: 19750, training_loss: 4.83729e+01
I0514 15:55:56.723069 140128494741248 run_lib.py:152] step: 19800, training_loss: 2.36318e+01
I0514 15:55:56.778019 140128494741248 run_lib.py:165] step: 19800, eval_loss: 3.85490e+01
I0514 15:56:02.963385 140128494741248 run_lib.py:152] step: 19850, training_loss: 3.27855e+01
I0514 15:56:09.160707 140128494741248 run_lib.py:152] step: 19900, training_loss: 2.89964e+01
I0514 15:56:09.215356 140128494741248 run_lib.py:165] step: 19900, eval_loss: 1.88816e+01
I0514 15:56:15.687047 140128494741248 run_lib.py:152] step: 19950, training_loss: 5.53426e+01
I0514 15:56:21.869869 140128494741248 run_lib.py:152] step: 20000, training_loss: 3.93542e+01
I0514 15:56:22.078243 140128494741248 run_lib.py:165] step: 20000, eval_loss: 5.45521e+01
I0514 15:56:28.298784 140128494741248 run_lib.py:152] step: 20050, training_loss: 4.48713e+01
I0514 15:56:34.546579 140128494741248 run_lib.py:152] step: 20100, training_loss: 3.60609e+01
I0514 15:56:34.599075 140128494741248 run_lib.py:165] step: 20100, eval_loss: 3.72475e+01
I0514 15:56:40.985948 140128494741248 run_lib.py:152] step: 20150, training_loss: 4.15126e+01
I0514 15:56:47.201458 140128494741248 run_lib.py:152] step: 20200, training_loss: 1.71818e+01
I0514 15:56:47.254424 140128494741248 run_lib.py:165] step: 20200, eval_loss: 1.89419e+01
I0514 15:56:53.528065 140128494741248 run_lib.py:152] step: 20250, training_loss: 3.85575e+01
I0514 15:56:59.948619 140128494741248 run_lib.py:152] step: 20300, training_loss: 2.51764e+01
I0514 15:57:00.004199 140128494741248 run_lib.py:165] step: 20300, eval_loss: 4.31751e+01
I0514 15:57:06.212818 140128494741248 run_lib.py:152] step: 20350, training_loss: 1.80058e+01
I0514 15:57:12.427466 140128494741248 run_lib.py:152] step: 20400, training_loss: 3.79104e+01
I0514 15:57:12.480455 140128494741248 run_lib.py:165] step: 20400, eval_loss: 4.45003e+01
I0514 15:57:18.655728 140128494741248 run_lib.py:152] step: 20450, training_loss: 2.77839e+01
I0514 15:57:25.066876 140128494741248 run_lib.py:152] step: 20500, training_loss: 2.62329e+01
I0514 15:57:25.119350 140128494741248 run_lib.py:165] step: 20500, eval_loss: 2.09314e+01
I0514 15:57:31.382852 140128494741248 run_lib.py:152] step: 20550, training_loss: 3.24742e+01
I0514 15:57:37.599241 140128494741248 run_lib.py:152] step: 20600, training_loss: 2.88023e+01
I0514 15:57:37.653596 140128494741248 run_lib.py:165] step: 20600, eval_loss: 3.97186e+01
I0514 15:57:44.129249 140128494741248 run_lib.py:152] step: 20650, training_loss: 4.14597e+01
I0514 15:57:50.299781 140128494741248 run_lib.py:152] step: 20700, training_loss: 2.89998e+01
I0514 15:57:50.348098 140128494741248 run_lib.py:165] step: 20700, eval_loss: 4.01154e+01
I0514 15:57:56.569343 140128494741248 run_lib.py:152] step: 20750, training_loss: 2.62981e+01
I0514 15:58:02.942243 140128494741248 run_lib.py:152] step: 20800, training_loss: 5.24630e+01
I0514 15:58:02.993918 140128494741248 run_lib.py:165] step: 20800, eval_loss: 2.51759e+01
I0514 15:58:09.202450 140128494741248 run_lib.py:152] step: 20850, training_loss: 2.36782e+01
I0514 15:58:15.522351 140128494741248 run_lib.py:152] step: 20900, training_loss: 2.62038e+01
I0514 15:58:15.576642 140128494741248 run_lib.py:165] step: 20900, eval_loss: 4.79237e+01
I0514 15:58:21.774000 140128494741248 run_lib.py:152] step: 20950, training_loss: 3.13888e+01
I0514 15:58:28.207819 140128494741248 run_lib.py:152] step: 21000, training_loss: 4.71980e+01
I0514 15:58:28.259649 140128494741248 run_lib.py:165] step: 21000, eval_loss: 2.65405e+01
I0514 15:58:34.386471 140128494741248 run_lib.py:152] step: 21050, training_loss: 2.52541e+01
I0514 15:58:40.532284 140128494741248 run_lib.py:152] step: 21100, training_loss: 1.84614e+01
I0514 15:58:40.584678 140128494741248 run_lib.py:165] step: 21100, eval_loss: 3.93639e+01
I0514 15:58:46.928238 140128494741248 run_lib.py:152] step: 21150, training_loss: 3.00242e+01
I0514 15:58:53.178932 140128494741248 run_lib.py:152] step: 21200, training_loss: 4.72887e+01
I0514 15:58:53.231952 140128494741248 run_lib.py:165] step: 21200, eval_loss: 3.05793e+01
I0514 15:58:59.340200 140128494741248 run_lib.py:152] step: 21250, training_loss: 2.75314e+01
I0514 15:59:05.543098 140128494741248 run_lib.py:152] step: 21300, training_loss: 4.44198e+01
I0514 15:59:05.594533 140128494741248 run_lib.py:165] step: 21300, eval_loss: 4.91642e+01
I0514 15:59:12.074120 140128494741248 run_lib.py:152] step: 21350, training_loss: 4.17998e+01
I0514 15:59:18.213495 140128494741248 run_lib.py:152] step: 21400, training_loss: 4.03603e+01
I0514 15:59:18.268568 140128494741248 run_lib.py:165] step: 21400, eval_loss: 4.02703e+01
I0514 15:59:24.417720 140128494741248 run_lib.py:152] step: 21450, training_loss: 4.41205e+01
I0514 15:59:30.864826 140128494741248 run_lib.py:152] step: 21500, training_loss: 3.61876e+01
I0514 15:59:30.913789 140128494741248 run_lib.py:165] step: 21500, eval_loss: 3.92764e+01
I0514 15:59:37.031296 140128494741248 run_lib.py:152] step: 21550, training_loss: 3.04284e+01
I0514 15:59:43.234446 140128494741248 run_lib.py:152] step: 21600, training_loss: 2.84619e+01
I0514 15:59:43.284769 140128494741248 run_lib.py:165] step: 21600, eval_loss: 2.82099e+01
I0514 15:59:49.515472 140128494741248 run_lib.py:152] step: 21650, training_loss: 2.05022e+01
I0514 15:59:55.902418 140128494741248 run_lib.py:152] step: 21700, training_loss: 2.92732e+01
I0514 15:59:55.955801 140128494741248 run_lib.py:165] step: 21700, eval_loss: 3.00231e+01
I0514 16:00:02.107588 140128494741248 run_lib.py:152] step: 21750, training_loss: 2.67066e+01
I0514 16:00:08.316605 140128494741248 run_lib.py:152] step: 21800, training_loss: 3.36975e+01
I0514 16:00:08.367106 140128494741248 run_lib.py:165] step: 21800, eval_loss: 4.01654e+01
I0514 16:00:14.827809 140128494741248 run_lib.py:152] step: 21850, training_loss: 2.77348e+01
I0514 16:00:20.968021 140128494741248 run_lib.py:152] step: 21900, training_loss: 4.54920e+01
I0514 16:00:21.021373 140128494741248 run_lib.py:165] step: 21900, eval_loss: 3.51008e+01
I0514 16:00:27.214625 140128494741248 run_lib.py:152] step: 21950, training_loss: 2.38895e+01
I0514 16:00:33.462261 140128494741248 run_lib.py:152] step: 22000, training_loss: 2.47504e+01
I0514 16:00:33.512484 140128494741248 run_lib.py:165] step: 22000, eval_loss: 3.67490e+01
I0514 16:00:40.003506 140128494741248 run_lib.py:152] step: 22050, training_loss: 4.02974e+01
I0514 16:00:46.166635 140128494741248 run_lib.py:152] step: 22100, training_loss: 3.13226e+01
I0514 16:00:46.215709 140128494741248 run_lib.py:165] step: 22100, eval_loss: 3.40651e+01
I0514 16:00:52.491793 140128494741248 run_lib.py:152] step: 22150, training_loss: 4.12250e+01
I0514 16:00:58.922032 140128494741248 run_lib.py:152] step: 22200, training_loss: 3.29762e+01
I0514 16:00:58.975039 140128494741248 run_lib.py:165] step: 22200, eval_loss: 3.05255e+01
I0514 16:01:05.185629 140128494741248 run_lib.py:152] step: 22250, training_loss: 2.83224e+01
I0514 16:01:11.390336 140128494741248 run_lib.py:152] step: 22300, training_loss: 4.14986e+01
I0514 16:01:11.443769 140128494741248 run_lib.py:165] step: 22300, eval_loss: 2.65655e+01
I0514 16:01:17.649299 140128494741248 run_lib.py:152] step: 22350, training_loss: 3.08804e+01
I0514 16:01:23.986338 140128494741248 run_lib.py:152] step: 22400, training_loss: 2.16809e+01
I0514 16:01:24.037108 140128494741248 run_lib.py:165] step: 22400, eval_loss: 2.35764e+01
I0514 16:01:30.262208 140128494741248 run_lib.py:152] step: 22450, training_loss: 4.54325e+01
I0514 16:01:36.451117 140128494741248 run_lib.py:152] step: 22500, training_loss: 3.12433e+01
I0514 16:01:36.506676 140128494741248 run_lib.py:165] step: 22500, eval_loss: 2.30507e+01
I0514 16:01:42.962773 140128494741248 run_lib.py:152] step: 22550, training_loss: 3.79621e+01
I0514 16:01:49.163798 140128494741248 run_lib.py:152] step: 22600, training_loss: 2.91590e+01
I0514 16:01:49.215767 140128494741248 run_lib.py:165] step: 22600, eval_loss: 4.77005e+01
I0514 16:01:55.482885 140128494741248 run_lib.py:152] step: 22650, training_loss: 4.79345e+01
I0514 16:02:01.972165 140128494741248 run_lib.py:152] step: 22700, training_loss: 4.17056e+01
I0514 16:02:02.025150 140128494741248 run_lib.py:165] step: 22700, eval_loss: 1.25349e+01
I0514 16:02:08.184111 140128494741248 run_lib.py:152] step: 22750, training_loss: 3.43421e+01
I0514 16:02:14.397221 140128494741248 run_lib.py:152] step: 22800, training_loss: 2.86064e+01
I0514 16:02:14.453357 140128494741248 run_lib.py:165] step: 22800, eval_loss: 1.98262e+01
I0514 16:02:20.672171 140128494741248 run_lib.py:152] step: 22850, training_loss: 4.52431e+01
I0514 16:02:27.048672 140128494741248 run_lib.py:152] step: 22900, training_loss: 3.17564e+01
I0514 16:02:27.095406 140128494741248 run_lib.py:165] step: 22900, eval_loss: 4.19079e+01
I0514 16:02:33.264605 140128494741248 run_lib.py:152] step: 22950, training_loss: 2.52445e+01
I0514 16:02:39.399075 140128494741248 run_lib.py:152] step: 23000, training_loss: 3.65381e+01
I0514 16:02:39.454005 140128494741248 run_lib.py:165] step: 23000, eval_loss: 1.84243e+01
I0514 16:02:45.936544 140128494741248 run_lib.py:152] step: 23050, training_loss: 2.55857e+01
I0514 16:02:52.073805 140128494741248 run_lib.py:152] step: 23100, training_loss: 3.73499e+01
I0514 16:02:52.127829 140128494741248 run_lib.py:165] step: 23100, eval_loss: 3.03680e+01
I0514 16:02:58.245180 140128494741248 run_lib.py:152] step: 23150, training_loss: 3.54072e+01
I0514 16:03:04.415406 140128494741248 run_lib.py:152] step: 23200, training_loss: 1.81903e+01
I0514 16:03:04.471697 140128494741248 run_lib.py:165] step: 23200, eval_loss: 2.63463e+01
I0514 16:03:10.873420 140128494741248 run_lib.py:152] step: 23250, training_loss: 5.65545e+01
I0514 16:03:17.083449 140128494741248 run_lib.py:152] step: 23300, training_loss: 2.85876e+01
I0514 16:03:17.132178 140128494741248 run_lib.py:165] step: 23300, eval_loss: 2.83920e+01
I0514 16:03:23.217668 140128494741248 run_lib.py:152] step: 23350, training_loss: 3.25412e+01
I0514 16:03:29.564184 140128494741248 run_lib.py:152] step: 23400, training_loss: 4.89901e+01
I0514 16:03:29.616759 140128494741248 run_lib.py:165] step: 23400, eval_loss: 1.96811e+01
I0514 16:03:35.752272 140128494741248 run_lib.py:152] step: 23450, training_loss: 3.08495e+01
I0514 16:03:41.874541 140128494741248 run_lib.py:152] step: 23500, training_loss: 4.34720e+01
I0514 16:03:41.931269 140128494741248 run_lib.py:165] step: 23500, eval_loss: 3.87802e+01
I0514 16:03:48.115465 140128494741248 run_lib.py:152] step: 23550, training_loss: 5.28879e+01
I0514 16:03:54.504503 140128494741248 run_lib.py:152] step: 23600, training_loss: 2.58173e+01
I0514 16:03:54.555753 140128494741248 run_lib.py:165] step: 23600, eval_loss: 2.52074e+01
I0514 16:04:00.693777 140128494741248 run_lib.py:152] step: 23650, training_loss: 2.65691e+01
I0514 16:04:06.849371 140128494741248 run_lib.py:152] step: 23700, training_loss: 3.07600e+01
I0514 16:04:06.900312 140128494741248 run_lib.py:165] step: 23700, eval_loss: 4.70542e+01
I0514 16:04:13.338948 140128494741248 run_lib.py:152] step: 23750, training_loss: 3.29109e+01
I0514 16:04:19.487385 140128494741248 run_lib.py:152] step: 23800, training_loss: 4.77559e+01
I0514 16:04:19.541344 140128494741248 run_lib.py:165] step: 23800, eval_loss: 3.81305e+01
I0514 16:04:25.705180 140128494741248 run_lib.py:152] step: 23850, training_loss: 3.52306e+01
I0514 16:04:31.954172 140128494741248 run_lib.py:152] step: 23900, training_loss: 3.37349e+01
I0514 16:04:32.014761 140128494741248 run_lib.py:165] step: 23900, eval_loss: 4.89026e+01
I0514 16:04:38.347128 140128494741248 run_lib.py:152] step: 23950, training_loss: 2.64093e+01
I0514 16:04:44.538820 140128494741248 run_lib.py:152] step: 24000, training_loss: 4.53004e+01
I0514 16:04:44.591370 140128494741248 run_lib.py:165] step: 24000, eval_loss: 2.86324e+01
I0514 16:04:50.811357 140128494741248 run_lib.py:152] step: 24050, training_loss: 4.24183e+01
I0514 16:04:57.242458 140128494741248 run_lib.py:152] step: 24100, training_loss: 4.30690e+01
I0514 16:04:57.295552 140128494741248 run_lib.py:165] step: 24100, eval_loss: 2.14380e+01
I0514 16:05:03.512767 140128494741248 run_lib.py:152] step: 24150, training_loss: 3.72376e+01
I0514 16:05:09.768458 140128494741248 run_lib.py:152] step: 24200, training_loss: 4.64337e+01
I0514 16:05:09.827817 140128494741248 run_lib.py:165] step: 24200, eval_loss: 3.80914e+01
I0514 16:05:16.025706 140128494741248 run_lib.py:152] step: 24250, training_loss: 2.93160e+01
I0514 16:05:22.414794 140128494741248 run_lib.py:152] step: 24300, training_loss: 4.31398e+01
I0514 16:05:22.467921 140128494741248 run_lib.py:165] step: 24300, eval_loss: 4.98065e+01
I0514 16:05:28.623868 140128494741248 run_lib.py:152] step: 24350, training_loss: 2.81294e+01
I0514 16:05:34.744138 140128494741248 run_lib.py:152] step: 24400, training_loss: 3.63420e+01
I0514 16:05:34.794366 140128494741248 run_lib.py:165] step: 24400, eval_loss: 3.88638e+01
I0514 16:05:41.239618 140128494741248 run_lib.py:152] step: 24450, training_loss: 1.77103e+01
I0514 16:05:47.449377 140128494741248 run_lib.py:152] step: 24500, training_loss: 3.93088e+01
I0514 16:05:47.498978 140128494741248 run_lib.py:165] step: 24500, eval_loss: 3.53943e+01
I0514 16:05:53.741574 140128494741248 run_lib.py:152] step: 24550, training_loss: 3.18306e+01
I0514 16:06:00.106033 140128494741248 run_lib.py:152] step: 24600, training_loss: 5.87620e+01
I0514 16:06:00.154562 140128494741248 run_lib.py:165] step: 24600, eval_loss: 2.08740e+01
I0514 16:06:06.242347 140128494741248 run_lib.py:152] step: 24650, training_loss: 4.15082e+01
I0514 16:06:12.393892 140128494741248 run_lib.py:152] step: 24700, training_loss: 4.14867e+01
I0514 16:06:12.453984 140128494741248 run_lib.py:165] step: 24700, eval_loss: 3.98404e+01
I0514 16:06:18.606545 140128494741248 run_lib.py:152] step: 24750, training_loss: 4.19060e+01
I0514 16:06:25.073487 140128494741248 run_lib.py:152] step: 24800, training_loss: 3.93024e+01
I0514 16:06:25.123692 140128494741248 run_lib.py:165] step: 24800, eval_loss: 2.79687e+01
I0514 16:06:31.315371 140128494741248 run_lib.py:152] step: 24850, training_loss: 2.74208e+01
I0514 16:06:37.546170 140128494741248 run_lib.py:152] step: 24900, training_loss: 4.12274e+01
I0514 16:06:37.598724 140128494741248 run_lib.py:165] step: 24900, eval_loss: 4.86428e+01
I0514 16:06:44.059174 140128494741248 run_lib.py:152] step: 24950, training_loss: 3.30953e+01
I0514 16:06:50.288987 140128494741248 run_lib.py:152] step: 25000, training_loss: 3.37825e+01
I0514 16:06:50.339054 140128494741248 run_lib.py:165] step: 25000, eval_loss: 1.53285e+01
I0514 16:06:56.447953 140128494741248 run_lib.py:152] step: 25050, training_loss: 2.48628e+01
I0514 16:07:02.587306 140128494741248 run_lib.py:152] step: 25100, training_loss: 2.43854e+01
I0514 16:07:02.642852 140128494741248 run_lib.py:165] step: 25100, eval_loss: 2.83868e+01
I0514 16:07:09.078606 140128494741248 run_lib.py:152] step: 25150, training_loss: 4.22786e+01
I0514 16:07:15.321638 140128494741248 run_lib.py:152] step: 25200, training_loss: 2.94303e+01
I0514 16:07:15.381362 140128494741248 run_lib.py:165] step: 25200, eval_loss: 2.22456e+01
I0514 16:07:21.556961 140128494741248 run_lib.py:152] step: 25250, training_loss: 3.51121e+01
I0514 16:07:27.983443 140128494741248 run_lib.py:152] step: 25300, training_loss: 2.78859e+01
I0514 16:07:28.032355 140128494741248 run_lib.py:165] step: 25300, eval_loss: 3.93433e+01
I0514 16:07:34.131906 140128494741248 run_lib.py:152] step: 25350, training_loss: 3.05390e+01
I0514 16:07:40.362458 140128494741248 run_lib.py:152] step: 25400, training_loss: 3.85669e+01
I0514 16:07:40.414624 140128494741248 run_lib.py:165] step: 25400, eval_loss: 4.19822e+01
I0514 16:07:46.571264 140128494741248 run_lib.py:152] step: 25450, training_loss: 4.82305e+01
I0514 16:07:53.022634 140128494741248 run_lib.py:152] step: 25500, training_loss: 3.03266e+01
I0514 16:07:53.076121 140128494741248 run_lib.py:165] step: 25500, eval_loss: 3.39714e+01
I0514 16:07:59.302102 140128494741248 run_lib.py:152] step: 25550, training_loss: 2.11482e+01
I0514 16:08:05.409859 140128494741248 run_lib.py:152] step: 25600, training_loss: 2.92151e+01
I0514 16:08:05.460067 140128494741248 run_lib.py:165] step: 25600, eval_loss: 5.92584e+01
I0514 16:08:11.979972 140128494741248 run_lib.py:152] step: 25650, training_loss: 3.68556e+01
I0514 16:08:18.122738 140128494741248 run_lib.py:152] step: 25700, training_loss: 3.65759e+01
I0514 16:08:18.178299 140128494741248 run_lib.py:165] step: 25700, eval_loss: 3.07712e+01
I0514 16:08:24.361138 140128494741248 run_lib.py:152] step: 25750, training_loss: 3.77737e+01
I0514 16:08:30.605390 140128494741248 run_lib.py:152] step: 25800, training_loss: 4.62727e+01
I0514 16:08:30.656824 140128494741248 run_lib.py:165] step: 25800, eval_loss: 3.79084e+01
I0514 16:08:37.076796 140128494741248 run_lib.py:152] step: 25850, training_loss: 5.37860e+01
I0514 16:08:43.324940 140128494741248 run_lib.py:152] step: 25900, training_loss: 4.30807e+01
I0514 16:08:43.377394 140128494741248 run_lib.py:165] step: 25900, eval_loss: 2.28286e+01
I0514 16:08:49.562235 140128494741248 run_lib.py:152] step: 25950, training_loss: 4.03041e+01
I0514 16:08:55.967244 140128494741248 run_lib.py:152] step: 26000, training_loss: 3.23493e+01
I0514 16:08:56.017957 140128494741248 run_lib.py:165] step: 26000, eval_loss: 3.17929e+01
I0514 16:09:02.161369 140128494741248 run_lib.py:152] step: 26050, training_loss: 4.30857e+01
I0514 16:09:08.399689 140128494741248 run_lib.py:152] step: 26100, training_loss: 2.06493e+01
I0514 16:09:08.454723 140128494741248 run_lib.py:165] step: 26100, eval_loss: 2.39512e+01
I0514 16:09:14.557916 140128494741248 run_lib.py:152] step: 26150, training_loss: 3.79800e+01
I0514 16:09:20.941023 140128494741248 run_lib.py:152] step: 26200, training_loss: 3.03888e+01
I0514 16:09:20.994429 140128494741248 run_lib.py:165] step: 26200, eval_loss: 2.53654e+01
I0514 16:09:27.151382 140128494741248 run_lib.py:152] step: 26250, training_loss: 3.38567e+01
I0514 16:09:33.261234 140128494741248 run_lib.py:152] step: 26300, training_loss: 3.73484e+01
I0514 16:09:33.313437 140128494741248 run_lib.py:165] step: 26300, eval_loss: 3.08124e+01
I0514 16:09:39.742742 140128494741248 run_lib.py:152] step: 26350, training_loss: 2.42668e+01
I0514 16:09:45.925104 140128494741248 run_lib.py:152] step: 26400, training_loss: 2.44881e+01
I0514 16:09:45.976452 140128494741248 run_lib.py:165] step: 26400, eval_loss: 2.61929e+01
I0514 16:09:52.108604 140128494741248 run_lib.py:152] step: 26450, training_loss: 4.35327e+01
I0514 16:09:58.348682 140128494741248 run_lib.py:152] step: 26500, training_loss: 2.86475e+01
I0514 16:09:58.401362 140128494741248 run_lib.py:165] step: 26500, eval_loss: 4.07369e+01
I0514 16:10:04.775573 140128494741248 run_lib.py:152] step: 26550, training_loss: 2.09999e+01
I0514 16:10:10.982709 140128494741248 run_lib.py:152] step: 26600, training_loss: 3.53825e+01
I0514 16:10:11.039769 140128494741248 run_lib.py:165] step: 26600, eval_loss: 3.23282e+01
I0514 16:10:17.231452 140128494741248 run_lib.py:152] step: 26650, training_loss: 1.64824e+01
I0514 16:10:23.728102 140128494741248 run_lib.py:152] step: 26700, training_loss: 2.25092e+01
I0514 16:10:23.782063 140128494741248 run_lib.py:165] step: 26700, eval_loss: 3.00351e+01
I0514 16:10:30.058237 140128494741248 run_lib.py:152] step: 26750, training_loss: 3.05190e+01
I0514 16:10:36.238712 140128494741248 run_lib.py:152] step: 26800, training_loss: 2.74021e+01
I0514 16:10:36.295339 140128494741248 run_lib.py:165] step: 26800, eval_loss: 4.17031e+01
I0514 16:10:42.528935 140128494741248 run_lib.py:152] step: 26850, training_loss: 4.67465e+01
I0514 16:10:49.115569 140128494741248 run_lib.py:152] step: 26900, training_loss: 2.92143e+01
I0514 16:10:49.165705 140128494741248 run_lib.py:165] step: 26900, eval_loss: 2.44874e+01
I0514 16:10:55.288090 140128494741248 run_lib.py:152] step: 26950, training_loss: 3.86736e+01
I0514 16:11:01.450839 140128494741248 run_lib.py:152] step: 27000, training_loss: 4.25923e+01
I0514 16:11:01.500895 140128494741248 run_lib.py:165] step: 27000, eval_loss: 2.88402e+01
I0514 16:11:07.927016 140128494741248 run_lib.py:152] step: 27050, training_loss: 2.57023e+01
I0514 16:11:14.156903 140128494741248 run_lib.py:152] step: 27100, training_loss: 2.36093e+01
I0514 16:11:14.220120 140128494741248 run_lib.py:165] step: 27100, eval_loss: 2.76910e+01
I0514 16:11:20.418391 140128494741248 run_lib.py:152] step: 27150, training_loss: 5.44077e+01
I0514 16:11:26.597876 140128494741248 run_lib.py:152] step: 27200, training_loss: 6.38893e+01
I0514 16:11:26.646671 140128494741248 run_lib.py:165] step: 27200, eval_loss: 3.21583e+01
I0514 16:11:33.044965 140128494741248 run_lib.py:152] step: 27250, training_loss: 2.39224e+01
I0514 16:11:39.210287 140128494741248 run_lib.py:152] step: 27300, training_loss: 2.47770e+01
I0514 16:11:39.261131 140128494741248 run_lib.py:165] step: 27300, eval_loss: 3.60123e+01
I0514 16:11:45.511662 140128494741248 run_lib.py:152] step: 27350, training_loss: 2.14723e+01
I0514 16:11:52.012125 140128494741248 run_lib.py:152] step: 27400, training_loss: 4.66719e+01
I0514 16:11:52.060610 140128494741248 run_lib.py:165] step: 27400, eval_loss: 3.28875e+01
I0514 16:11:58.272623 140128494741248 run_lib.py:152] step: 27450, training_loss: 3.61610e+01
I0514 16:12:04.467413 140128494741248 run_lib.py:152] step: 27500, training_loss: 1.84183e+01
I0514 16:12:04.516144 140128494741248 run_lib.py:165] step: 27500, eval_loss: 4.14642e+01
I0514 16:12:10.655790 140128494741248 run_lib.py:152] step: 27550, training_loss: 4.30291e+01
I0514 16:12:16.998855 140128494741248 run_lib.py:152] step: 27600, training_loss: 3.45162e+01
I0514 16:12:17.047803 140128494741248 run_lib.py:165] step: 27600, eval_loss: 2.96460e+01
I0514 16:12:23.220482 140128494741248 run_lib.py:152] step: 27650, training_loss: 3.54063e+01
I0514 16:12:29.423750 140128494741248 run_lib.py:152] step: 27700, training_loss: 3.68704e+01
I0514 16:12:29.482118 140128494741248 run_lib.py:165] step: 27700, eval_loss: 2.00607e+01
I0514 16:12:35.815467 140128494741248 run_lib.py:152] step: 27750, training_loss: 3.60777e+01
I0514 16:12:42.024113 140128494741248 run_lib.py:152] step: 27800, training_loss: 4.48478e+01
I0514 16:12:42.082556 140128494741248 run_lib.py:165] step: 27800, eval_loss: 2.79501e+01
I0514 16:12:48.231917 140128494741248 run_lib.py:152] step: 27850, training_loss: 3.47731e+01
I0514 16:12:54.673327 140128494741248 run_lib.py:152] step: 27900, training_loss: 3.63513e+01
I0514 16:12:54.728204 140128494741248 run_lib.py:165] step: 27900, eval_loss: 1.92672e+01
I0514 16:13:00.836833 140128494741248 run_lib.py:152] step: 27950, training_loss: 3.08416e+01
I0514 16:13:07.101617 140128494741248 run_lib.py:152] step: 28000, training_loss: 1.90558e+01
I0514 16:13:07.156566 140128494741248 run_lib.py:165] step: 28000, eval_loss: 3.44162e+01
I0514 16:13:13.262387 140128494741248 run_lib.py:152] step: 28050, training_loss: 2.85874e+01
I0514 16:13:19.739457 140128494741248 run_lib.py:152] step: 28100, training_loss: 4.21394e+01
I0514 16:13:19.794810 140128494741248 run_lib.py:165] step: 28100, eval_loss: 5.17875e+01
I0514 16:13:26.030008 140128494741248 run_lib.py:152] step: 28150, training_loss: 3.10063e+01
I0514 16:13:32.218621 140128494741248 run_lib.py:152] step: 28200, training_loss: 4.50227e+01
I0514 16:13:32.278202 140128494741248 run_lib.py:165] step: 28200, eval_loss: 3.41983e+01
I0514 16:13:38.764537 140128494741248 run_lib.py:152] step: 28250, training_loss: 4.27446e+01
I0514 16:13:44.970186 140128494741248 run_lib.py:152] step: 28300, training_loss: 2.45211e+01
I0514 16:13:45.021736 140128494741248 run_lib.py:165] step: 28300, eval_loss: 3.67510e+01
I0514 16:13:51.229295 140128494741248 run_lib.py:152] step: 28350, training_loss: 3.26710e+01
I0514 16:13:57.413677 140128494741248 run_lib.py:152] step: 28400, training_loss: 4.66721e+01
I0514 16:13:57.469102 140128494741248 run_lib.py:165] step: 28400, eval_loss: 2.25551e+01
I0514 16:14:03.821576 140128494741248 run_lib.py:152] step: 28450, training_loss: 1.86468e+01
I0514 16:14:10.004724 140128494741248 run_lib.py:152] step: 28500, training_loss: 3.01122e+01
I0514 16:14:10.057489 140128494741248 run_lib.py:165] step: 28500, eval_loss: 3.89693e+01
I0514 16:14:16.191650 140128494741248 run_lib.py:152] step: 28550, training_loss: 3.46216e+01
I0514 16:14:22.604651 140128494741248 run_lib.py:152] step: 28600, training_loss: 2.49766e+01
I0514 16:14:22.653773 140128494741248 run_lib.py:165] step: 28600, eval_loss: 3.36467e+01
I0514 16:14:28.825059 140128494741248 run_lib.py:152] step: 28650, training_loss: 3.80277e+01
I0514 16:14:35.019359 140128494741248 run_lib.py:152] step: 28700, training_loss: 2.07739e+01
I0514 16:14:35.074187 140128494741248 run_lib.py:165] step: 28700, eval_loss: 3.93893e+01
I0514 16:14:41.333182 140128494741248 run_lib.py:152] step: 28750, training_loss: 4.20524e+01
I0514 16:14:47.770442 140128494741248 run_lib.py:152] step: 28800, training_loss: 4.58825e+01
I0514 16:14:47.825795 140128494741248 run_lib.py:165] step: 28800, eval_loss: 4.11431e+01
I0514 16:14:54.017474 140128494741248 run_lib.py:152] step: 28850, training_loss: 3.47028e+01
I0514 16:15:00.219123 140128494741248 run_lib.py:152] step: 28900, training_loss: 2.91520e+01
I0514 16:15:00.273055 140128494741248 run_lib.py:165] step: 28900, eval_loss: 2.82724e+01
I0514 16:15:06.694651 140128494741248 run_lib.py:152] step: 28950, training_loss: 2.70418e+01
I0514 16:15:12.929809 140128494741248 run_lib.py:152] step: 29000, training_loss: 2.33459e+01
I0514 16:15:12.982909 140128494741248 run_lib.py:165] step: 29000, eval_loss: 3.12349e+01
I0514 16:15:19.184496 140128494741248 run_lib.py:152] step: 29050, training_loss: 3.31882e+01
I0514 16:15:25.402622 140128494741248 run_lib.py:152] step: 29100, training_loss: 4.31631e+01
I0514 16:15:25.458309 140128494741248 run_lib.py:165] step: 29100, eval_loss: 5.20528e+01
I0514 16:15:31.925570 140128494741248 run_lib.py:152] step: 29150, training_loss: 3.83385e+01
I0514 16:15:38.039066 140128494741248 run_lib.py:152] step: 29200, training_loss: 2.72064e+01
I0514 16:15:38.091513 140128494741248 run_lib.py:165] step: 29200, eval_loss: 3.72601e+01
I0514 16:15:44.343670 140128494741248 run_lib.py:152] step: 29250, training_loss: 2.92609e+01
I0514 16:15:50.865175 140128494741248 run_lib.py:152] step: 29300, training_loss: 3.87062e+01
I0514 16:15:50.914994 140128494741248 run_lib.py:165] step: 29300, eval_loss: 1.93140e+01
I0514 16:15:57.165521 140128494741248 run_lib.py:152] step: 29350, training_loss: 4.67798e+01
I0514 16:16:03.329914 140128494741248 run_lib.py:152] step: 29400, training_loss: 5.18378e+01
I0514 16:16:03.382411 140128494741248 run_lib.py:165] step: 29400, eval_loss: 2.39113e+01
I0514 16:16:09.650762 140128494741248 run_lib.py:152] step: 29450, training_loss: 3.52723e+01
I0514 16:16:16.081202 140128494741248 run_lib.py:152] step: 29500, training_loss: 3.18529e+01
I0514 16:16:16.130439 140128494741248 run_lib.py:165] step: 29500, eval_loss: 3.77795e+01
I0514 16:16:22.315399 140128494741248 run_lib.py:152] step: 29550, training_loss: 3.86357e+01
I0514 16:16:28.445454 140128494741248 run_lib.py:152] step: 29600, training_loss: 4.57230e+01
I0514 16:16:28.498616 140128494741248 run_lib.py:165] step: 29600, eval_loss: 4.00849e+01
I0514 16:16:34.858537 140128494741248 run_lib.py:152] step: 29650, training_loss: 4.64455e+01
I0514 16:16:41.116724 140128494741248 run_lib.py:152] step: 29700, training_loss: 4.33330e+01
I0514 16:16:41.170726 140128494741248 run_lib.py:165] step: 29700, eval_loss: 4.02829e+01
I0514 16:16:47.434319 140128494741248 run_lib.py:152] step: 29750, training_loss: 1.99903e+01
I0514 16:16:53.596379 140128494741248 run_lib.py:152] step: 29800, training_loss: 4.01138e+01
I0514 16:16:53.652512 140128494741248 run_lib.py:165] step: 29800, eval_loss: 4.33377e+01
I0514 16:17:00.031347 140128494741248 run_lib.py:152] step: 29850, training_loss: 3.64356e+01
I0514 16:17:06.207116 140128494741248 run_lib.py:152] step: 29900, training_loss: 5.83128e+01
I0514 16:17:06.258730 140128494741248 run_lib.py:165] step: 29900, eval_loss: 2.85118e+01
I0514 16:17:12.456810 140128494741248 run_lib.py:152] step: 29950, training_loss: 2.70732e+01
I0514 16:17:18.840165 140128494741248 run_lib.py:152] step: 30000, training_loss: 3.88323e+01
I0514 16:17:19.047167 140128494741248 run_lib.py:165] step: 30000, eval_loss: 3.42329e+01
I0514 16:17:25.205604 140128494741248 run_lib.py:152] step: 30050, training_loss: 4.81114e+01
I0514 16:17:31.383089 140128494741248 run_lib.py:152] step: 30100, training_loss: 3.95216e+01
I0514 16:17:31.437638 140128494741248 run_lib.py:165] step: 30100, eval_loss: 2.96835e+01
I0514 16:17:37.626840 140128494741248 run_lib.py:152] step: 30150, training_loss: 2.62282e+01
I0514 16:17:43.986055 140128494741248 run_lib.py:152] step: 30200, training_loss: 2.99808e+01
I0514 16:17:44.036253 140128494741248 run_lib.py:165] step: 30200, eval_loss: 3.59412e+01
I0514 16:17:50.229628 140128494741248 run_lib.py:152] step: 30250, training_loss: 3.86808e+01
I0514 16:17:56.394688 140128494741248 run_lib.py:152] step: 30300, training_loss: 3.07428e+01
I0514 16:17:56.451100 140128494741248 run_lib.py:165] step: 30300, eval_loss: 4.79432e+01
I0514 16:18:02.848271 140128494741248 run_lib.py:152] step: 30350, training_loss: 4.38184e+01
I0514 16:18:09.128139 140128494741248 run_lib.py:152] step: 30400, training_loss: 3.73869e+01
I0514 16:18:09.178824 140128494741248 run_lib.py:165] step: 30400, eval_loss: 3.51208e+01
I0514 16:18:15.453052 140128494741248 run_lib.py:152] step: 30450, training_loss: 4.41017e+01
I0514 16:18:21.655081 140128494741248 run_lib.py:152] step: 30500, training_loss: 3.86482e+01
I0514 16:18:21.704681 140128494741248 run_lib.py:165] step: 30500, eval_loss: 2.24021e+01
I0514 16:18:28.171818 140128494741248 run_lib.py:152] step: 30550, training_loss: 3.14380e+01
I0514 16:18:34.357687 140128494741248 run_lib.py:152] step: 30600, training_loss: 4.70340e+01
I0514 16:18:34.410847 140128494741248 run_lib.py:165] step: 30600, eval_loss: 2.89889e+01
I0514 16:18:40.632650 140128494741248 run_lib.py:152] step: 30650, training_loss: 2.16990e+01
I0514 16:18:47.100129 140128494741248 run_lib.py:152] step: 30700, training_loss: 3.91206e+01
I0514 16:18:47.149715 140128494741248 run_lib.py:165] step: 30700, eval_loss: 3.09703e+01
I0514 16:18:53.319283 140128494741248 run_lib.py:152] step: 30750, training_loss: 3.78067e+01
I0514 16:18:59.452324 140128494741248 run_lib.py:152] step: 30800, training_loss: 3.26989e+01
I0514 16:18:59.503612 140128494741248 run_lib.py:165] step: 30800, eval_loss: 2.18544e+01
I0514 16:19:05.755760 140128494741248 run_lib.py:152] step: 30850, training_loss: 4.13398e+01
I0514 16:19:12.224485 140128494741248 run_lib.py:152] step: 30900, training_loss: 4.12327e+01
I0514 16:19:12.280088 140128494741248 run_lib.py:165] step: 30900, eval_loss: 2.76356e+01
I0514 16:19:18.464512 140128494741248 run_lib.py:152] step: 30950, training_loss: 5.17804e+01
I0514 16:19:24.721955 140128494741248 run_lib.py:152] step: 31000, training_loss: 4.87252e+01
I0514 16:19:24.770299 140128494741248 run_lib.py:165] step: 31000, eval_loss: 4.90928e+01
I0514 16:19:31.205873 140128494741248 run_lib.py:152] step: 31050, training_loss: 5.30168e+01
I0514 16:19:37.445638 140128494741248 run_lib.py:152] step: 31100, training_loss: 3.47280e+01
I0514 16:19:37.493635 140128494741248 run_lib.py:165] step: 31100, eval_loss: 3.64124e+01
I0514 16:19:43.647695 140128494741248 run_lib.py:152] step: 31150, training_loss: 3.52805e+01
I0514 16:19:49.889503 140128494741248 run_lib.py:152] step: 31200, training_loss: 3.84052e+01
I0514 16:19:49.943138 140128494741248 run_lib.py:165] step: 31200, eval_loss: 2.89257e+01
I0514 16:19:56.299860 140128494741248 run_lib.py:152] step: 31250, training_loss: 4.13748e+01
I0514 16:20:02.551202 140128494741248 run_lib.py:152] step: 31300, training_loss: 3.19565e+01
I0514 16:20:02.603321 140128494741248 run_lib.py:165] step: 31300, eval_loss: 3.24294e+01
I0514 16:20:08.734157 140128494741248 run_lib.py:152] step: 31350, training_loss: 2.96314e+01
I0514 16:20:15.148366 140128494741248 run_lib.py:152] step: 31400, training_loss: 4.48042e+01
I0514 16:20:15.194741 140128494741248 run_lib.py:165] step: 31400, eval_loss: 3.36529e+01
I0514 16:20:21.358779 140128494741248 run_lib.py:152] step: 31450, training_loss: 2.57985e+01
I0514 16:20:27.596461 140128494741248 run_lib.py:152] step: 31500, training_loss: 2.68503e+01
I0514 16:20:27.646345 140128494741248 run_lib.py:165] step: 31500, eval_loss: 1.66075e+01
I0514 16:20:33.799169 140128494741248 run_lib.py:152] step: 31550, training_loss: 3.21995e+01
I0514 16:20:40.178418 140128494741248 run_lib.py:152] step: 31600, training_loss: 3.82851e+01
I0514 16:20:40.228619 140128494741248 run_lib.py:165] step: 31600, eval_loss: 3.90884e+01
I0514 16:20:46.364661 140128494741248 run_lib.py:152] step: 31650, training_loss: 4.46394e+01
I0514 16:20:52.617471 140128494741248 run_lib.py:152] step: 31700, training_loss: 2.67110e+01
I0514 16:20:52.683562 140128494741248 run_lib.py:165] step: 31700, eval_loss: 2.14065e+01
I0514 16:20:59.028722 140128494741248 run_lib.py:152] step: 31750, training_loss: 2.67428e+01
I0514 16:21:05.342055 140128494741248 run_lib.py:152] step: 31800, training_loss: 3.02936e+01
I0514 16:21:05.394938 140128494741248 run_lib.py:165] step: 31800, eval_loss: 2.53950e+01
I0514 16:21:11.567436 140128494741248 run_lib.py:152] step: 31850, training_loss: 3.14631e+01
I0514 16:21:17.785990 140128494741248 run_lib.py:152] step: 31900, training_loss: 3.86638e+01
I0514 16:21:17.847545 140128494741248 run_lib.py:165] step: 31900, eval_loss: 3.15350e+01
I0514 16:21:24.200227 140128494741248 run_lib.py:152] step: 31950, training_loss: 2.09748e+01
I0514 16:21:30.410795 140128494741248 run_lib.py:152] step: 32000, training_loss: 3.11932e+01
I0514 16:21:30.467264 140128494741248 run_lib.py:165] step: 32000, eval_loss: 2.49611e+01
I0514 16:21:36.677450 140128494741248 run_lib.py:152] step: 32050, training_loss: 5.13707e+01
I0514 16:21:43.067938 140128494741248 run_lib.py:152] step: 32100, training_loss: 4.84745e+01
I0514 16:21:43.123116 140128494741248 run_lib.py:165] step: 32100, eval_loss: 1.89779e+01
I0514 16:21:49.293286 140128494741248 run_lib.py:152] step: 32150, training_loss: 3.28416e+01
I0514 16:21:55.557807 140128494741248 run_lib.py:152] step: 32200, training_loss: 3.51270e+01
I0514 16:21:55.609474 140128494741248 run_lib.py:165] step: 32200, eval_loss: 2.90041e+01
I0514 16:22:01.797251 140128494741248 run_lib.py:152] step: 32250, training_loss: 2.35086e+01
I0514 16:22:08.322731 140128494741248 run_lib.py:152] step: 32300, training_loss: 2.69902e+01
I0514 16:22:08.377475 140128494741248 run_lib.py:165] step: 32300, eval_loss: 3.74400e+01
I0514 16:22:14.544872 140128494741248 run_lib.py:152] step: 32350, training_loss: 2.76016e+01
I0514 16:22:20.742484 140128494741248 run_lib.py:152] step: 32400, training_loss: 3.73178e+01
I0514 16:22:20.793982 140128494741248 run_lib.py:165] step: 32400, eval_loss: 1.76250e+01
I0514 16:22:27.214732 140128494741248 run_lib.py:152] step: 32450, training_loss: 4.53246e+01
I0514 16:22:33.397650 140128494741248 run_lib.py:152] step: 32500, training_loss: 1.92687e+01
I0514 16:22:33.454140 140128494741248 run_lib.py:165] step: 32500, eval_loss: 2.88390e+01
I0514 16:22:39.559448 140128494741248 run_lib.py:152] step: 32550, training_loss: 1.87287e+01
I0514 16:22:46.017315 140128494741248 run_lib.py:152] step: 32600, training_loss: 2.87275e+01
I0514 16:22:46.072602 140128494741248 run_lib.py:165] step: 32600, eval_loss: 2.36927e+01
I0514 16:22:52.219105 140128494741248 run_lib.py:152] step: 32650, training_loss: 2.71500e+01
I0514 16:22:58.457767 140128494741248 run_lib.py:152] step: 32700, training_loss: 3.22495e+01
I0514 16:22:58.514108 140128494741248 run_lib.py:165] step: 32700, eval_loss: 3.40017e+01
I0514 16:23:04.724854 140128494741248 run_lib.py:152] step: 32750, training_loss: 2.68577e+01
I0514 16:23:11.213436 140128494741248 run_lib.py:152] step: 32800, training_loss: 4.33177e+01
I0514 16:23:11.266010 140128494741248 run_lib.py:165] step: 32800, eval_loss: 3.57048e+01
I0514 16:23:17.473489 140128494741248 run_lib.py:152] step: 32850, training_loss: 4.78928e+01
I0514 16:23:23.700819 140128494741248 run_lib.py:152] step: 32900, training_loss: 1.67025e+01
I0514 16:23:23.753778 140128494741248 run_lib.py:165] step: 32900, eval_loss: 3.11170e+01
I0514 16:23:30.151602 140128494741248 run_lib.py:152] step: 32950, training_loss: 1.75061e+01
I0514 16:23:36.270400 140128494741248 run_lib.py:152] step: 33000, training_loss: 4.59404e+01
I0514 16:23:36.322231 140128494741248 run_lib.py:165] step: 33000, eval_loss: 3.75596e+01
I0514 16:23:42.552277 140128494741248 run_lib.py:152] step: 33050, training_loss: 2.95011e+01
I0514 16:23:48.731666 140128494741248 run_lib.py:152] step: 33100, training_loss: 3.44497e+01
I0514 16:23:48.780099 140128494741248 run_lib.py:165] step: 33100, eval_loss: 5.02596e+01
I0514 16:23:55.135672 140128494741248 run_lib.py:152] step: 33150, training_loss: 4.35817e+01
I0514 16:24:01.382623 140128494741248 run_lib.py:152] step: 33200, training_loss: 2.16173e+01
I0514 16:24:01.439396 140128494741248 run_lib.py:165] step: 33200, eval_loss: 3.82154e+01
I0514 16:24:07.678697 140128494741248 run_lib.py:152] step: 33250, training_loss: 2.90833e+01
I0514 16:24:14.062014 140128494741248 run_lib.py:152] step: 33300, training_loss: 3.51056e+01
I0514 16:24:14.114400 140128494741248 run_lib.py:165] step: 33300, eval_loss: 3.53638e+01
I0514 16:24:20.269354 140128494741248 run_lib.py:152] step: 33350, training_loss: 4.06615e+01
I0514 16:24:26.476955 140128494741248 run_lib.py:152] step: 33400, training_loss: 4.17220e+01
I0514 16:24:26.528960 140128494741248 run_lib.py:165] step: 33400, eval_loss: 3.15161e+01
I0514 16:24:32.694787 140128494741248 run_lib.py:152] step: 33450, training_loss: 2.82350e+01
I0514 16:24:39.087631 140128494741248 run_lib.py:152] step: 33500, training_loss: 4.49874e+01
I0514 16:24:39.140166 140128494741248 run_lib.py:165] step: 33500, eval_loss: 2.88208e+01
I0514 16:24:45.353121 140128494741248 run_lib.py:152] step: 33550, training_loss: 2.72254e+01
I0514 16:24:51.547925 140128494741248 run_lib.py:152] step: 33600, training_loss: 3.22973e+01
I0514 16:24:51.602350 140128494741248 run_lib.py:165] step: 33600, eval_loss: 3.34204e+01
I0514 16:24:58.050808 140128494741248 run_lib.py:152] step: 33650, training_loss: 4.86242e+01
I0514 16:25:04.285692 140128494741248 run_lib.py:152] step: 33700, training_loss: 3.19357e+01
I0514 16:25:04.334850 140128494741248 run_lib.py:165] step: 33700, eval_loss: 3.13447e+01
I0514 16:25:10.533426 140128494741248 run_lib.py:152] step: 33750, training_loss: 2.77926e+01
I0514 16:25:16.680131 140128494741248 run_lib.py:152] step: 33800, training_loss: 1.97471e+01
I0514 16:25:16.729189 140128494741248 run_lib.py:165] step: 33800, eval_loss: 3.46305e+01
I0514 16:25:23.333086 140128494741248 run_lib.py:152] step: 33850, training_loss: 4.31976e+01
I0514 16:25:29.518226 140128494741248 run_lib.py:152] step: 33900, training_loss: 2.36992e+01
I0514 16:25:29.574326 140128494741248 run_lib.py:165] step: 33900, eval_loss: 3.01877e+01
I0514 16:25:35.801965 140128494741248 run_lib.py:152] step: 33950, training_loss: 3.25570e+01
I0514 16:25:42.243646 140128494741248 run_lib.py:152] step: 34000, training_loss: 4.14751e+01
I0514 16:25:42.292470 140128494741248 run_lib.py:165] step: 34000, eval_loss: 3.11022e+01
I0514 16:25:48.484356 140128494741248 run_lib.py:152] step: 34050, training_loss: 3.87968e+01
I0514 16:25:54.753901 140128494741248 run_lib.py:152] step: 34100, training_loss: 3.26836e+01
I0514 16:25:54.808741 140128494741248 run_lib.py:165] step: 34100, eval_loss: 3.18745e+01
I0514 16:26:00.978577 140128494741248 run_lib.py:152] step: 34150, training_loss: 2.21997e+01
I0514 16:26:07.468480 140128494741248 run_lib.py:152] step: 34200, training_loss: 4.06796e+01
I0514 16:26:07.524443 140128494741248 run_lib.py:165] step: 34200, eval_loss: 2.78385e+01
I0514 16:26:13.697129 140128494741248 run_lib.py:152] step: 34250, training_loss: 3.67518e+01
I0514 16:26:19.880584 140128494741248 run_lib.py:152] step: 34300, training_loss: 3.68223e+01
I0514 16:26:19.932995 140128494741248 run_lib.py:165] step: 34300, eval_loss: 3.28671e+01
I0514 16:26:26.320353 140128494741248 run_lib.py:152] step: 34350, training_loss: 3.14040e+01
I0514 16:26:32.514891 140128494741248 run_lib.py:152] step: 34400, training_loss: 3.83188e+01
I0514 16:26:32.572197 140128494741248 run_lib.py:165] step: 34400, eval_loss: 3.25314e+01
I0514 16:26:38.726824 140128494741248 run_lib.py:152] step: 34450, training_loss: 2.83282e+01
I0514 16:26:45.031639 140128494741248 run_lib.py:152] step: 34500, training_loss: 3.00786e+01
I0514 16:26:45.080992 140128494741248 run_lib.py:165] step: 34500, eval_loss: 3.26465e+01
I0514 16:26:51.438873 140128494741248 run_lib.py:152] step: 34550, training_loss: 2.80131e+01
I0514 16:26:57.732816 140128494741248 run_lib.py:152] step: 34600, training_loss: 3.49549e+01
I0514 16:26:57.782472 140128494741248 run_lib.py:165] step: 34600, eval_loss: 1.76296e+01
I0514 16:27:04.058090 140128494741248 run_lib.py:152] step: 34650, training_loss: 4.70701e+01
I0514 16:27:10.483920 140128494741248 run_lib.py:152] step: 34700, training_loss: 3.56195e+01
I0514 16:27:10.536401 140128494741248 run_lib.py:165] step: 34700, eval_loss: 2.35759e+01
I0514 16:27:16.746127 140128494741248 run_lib.py:152] step: 34750, training_loss: 5.22981e+01
I0514 16:27:22.955483 140128494741248 run_lib.py:152] step: 34800, training_loss: 3.39619e+01
I0514 16:27:23.012639 140128494741248 run_lib.py:165] step: 34800, eval_loss: 1.92765e+01
I0514 16:27:29.191124 140128494741248 run_lib.py:152] step: 34850, training_loss: 3.93217e+01
I0514 16:27:35.602429 140128494741248 run_lib.py:152] step: 34900, training_loss: 3.97031e+01
I0514 16:27:35.653462 140128494741248 run_lib.py:165] step: 34900, eval_loss: 4.73721e+01
I0514 16:27:41.744844 140128494741248 run_lib.py:152] step: 34950, training_loss: 2.77075e+01
I0514 16:27:47.918324 140128494741248 run_lib.py:152] step: 35000, training_loss: 2.96800e+01
I0514 16:27:47.967812 140128494741248 run_lib.py:165] step: 35000, eval_loss: 2.59309e+01
I0514 16:27:54.486069 140128494741248 run_lib.py:152] step: 35050, training_loss: 4.92428e+01
I0514 16:28:00.725612 140128494741248 run_lib.py:152] step: 35100, training_loss: 4.14959e+01
I0514 16:28:00.778295 140128494741248 run_lib.py:165] step: 35100, eval_loss: 2.34258e+01
I0514 16:28:06.981186 140128494741248 run_lib.py:152] step: 35150, training_loss: 2.99426e+01
I0514 16:28:13.103025 140128494741248 run_lib.py:152] step: 35200, training_loss: 2.52665e+01
I0514 16:28:13.159576 140128494741248 run_lib.py:165] step: 35200, eval_loss: 2.32457e+01
I0514 16:28:19.603936 140128494741248 run_lib.py:152] step: 35250, training_loss: 3.03263e+01
I0514 16:28:25.794059 140128494741248 run_lib.py:152] step: 35300, training_loss: 3.29916e+01
I0514 16:28:25.844661 140128494741248 run_lib.py:165] step: 35300, eval_loss: 3.42833e+01
I0514 16:28:32.036714 140128494741248 run_lib.py:152] step: 35350, training_loss: 3.11631e+01
I0514 16:28:38.371498 140128494741248 run_lib.py:152] step: 35400, training_loss: 3.80992e+01
I0514 16:28:38.424516 140128494741248 run_lib.py:165] step: 35400, eval_loss: 2.01915e+01
I0514 16:28:44.677952 140128494741248 run_lib.py:152] step: 35450, training_loss: 3.51562e+01
I0514 16:28:50.826958 140128494741248 run_lib.py:152] step: 35500, training_loss: 3.13226e+01
I0514 16:28:50.887805 140128494741248 run_lib.py:165] step: 35500, eval_loss: 3.27163e+01
I0514 16:28:57.083927 140128494741248 run_lib.py:152] step: 35550, training_loss: 2.66726e+01
I0514 16:29:03.600189 140128494741248 run_lib.py:152] step: 35600, training_loss: 2.55737e+01
I0514 16:29:03.651612 140128494741248 run_lib.py:165] step: 35600, eval_loss: 2.98030e+01
I0514 16:29:09.955670 140128494741248 run_lib.py:152] step: 35650, training_loss: 1.61118e+01
I0514 16:29:16.184239 140128494741248 run_lib.py:152] step: 35700, training_loss: 3.11083e+01
I0514 16:29:16.235216 140128494741248 run_lib.py:165] step: 35700, eval_loss: 2.20212e+01
I0514 16:29:22.715360 140128494741248 run_lib.py:152] step: 35750, training_loss: 2.64008e+01
I0514 16:29:28.818931 140128494741248 run_lib.py:152] step: 35800, training_loss: 3.53494e+01
I0514 16:29:28.870166 140128494741248 run_lib.py:165] step: 35800, eval_loss: 2.49308e+01
I0514 16:29:35.037137 140128494741248 run_lib.py:152] step: 35850, training_loss: 3.08419e+01
I0514 16:29:41.235934 140128494741248 run_lib.py:152] step: 35900, training_loss: 2.80006e+01
I0514 16:29:41.292744 140128494741248 run_lib.py:165] step: 35900, eval_loss: 4.44076e+01
I0514 16:29:47.732613 140128494741248 run_lib.py:152] step: 35950, training_loss: 4.00723e+01
I0514 16:29:53.837630 140128494741248 run_lib.py:152] step: 36000, training_loss: 3.82489e+01
I0514 16:29:53.887983 140128494741248 run_lib.py:165] step: 36000, eval_loss: 4.70032e+01
I0514 16:30:00.108353 140128494741248 run_lib.py:152] step: 36050, training_loss: 2.58140e+01
I0514 16:30:06.479704 140128494741248 run_lib.py:152] step: 36100, training_loss: 4.45671e+01
I0514 16:30:06.528420 140128494741248 run_lib.py:165] step: 36100, eval_loss: 2.32192e+01
I0514 16:30:12.645675 140128494741248 run_lib.py:152] step: 36150, training_loss: 3.60557e+01
I0514 16:30:18.783959 140128494741248 run_lib.py:152] step: 36200, training_loss: 2.67640e+01
I0514 16:30:18.832582 140128494741248 run_lib.py:165] step: 36200, eval_loss: 3.07094e+01
I0514 16:30:25.010897 140128494741248 run_lib.py:152] step: 36250, training_loss: 2.74670e+01
I0514 16:30:31.483402 140128494741248 run_lib.py:152] step: 36300, training_loss: 2.68037e+01
I0514 16:30:31.536367 140128494741248 run_lib.py:165] step: 36300, eval_loss: 2.97897e+01
I0514 16:30:37.679127 140128494741248 run_lib.py:152] step: 36350, training_loss: 3.24883e+01
I0514 16:30:43.869240 140128494741248 run_lib.py:152] step: 36400, training_loss: 4.15436e+01
I0514 16:30:43.921344 140128494741248 run_lib.py:165] step: 36400, eval_loss: 3.36441e+01
I0514 16:30:50.416331 140128494741248 run_lib.py:152] step: 36450, training_loss: 4.54270e+01
I0514 16:30:56.726985 140128494741248 run_lib.py:152] step: 36500, training_loss: 4.26432e+01
I0514 16:30:56.778509 140128494741248 run_lib.py:165] step: 36500, eval_loss: 4.20626e+01
I0514 16:31:03.012172 140128494741248 run_lib.py:152] step: 36550, training_loss: 3.56308e+01
I0514 16:31:09.198209 140128494741248 run_lib.py:152] step: 36600, training_loss: 4.83732e+01
I0514 16:31:09.255312 140128494741248 run_lib.py:165] step: 36600, eval_loss: 3.73655e+01
I0514 16:31:15.682013 140128494741248 run_lib.py:152] step: 36650, training_loss: 2.64979e+01
I0514 16:31:21.949657 140128494741248 run_lib.py:152] step: 36700, training_loss: 3.36683e+01
I0514 16:31:21.999393 140128494741248 run_lib.py:165] step: 36700, eval_loss: 3.11257e+01
I0514 16:31:28.165340 140128494741248 run_lib.py:152] step: 36750, training_loss: 2.41005e+01
I0514 16:31:34.689284 140128494741248 run_lib.py:152] step: 36800, training_loss: 4.23867e+01
I0514 16:31:34.741160 140128494741248 run_lib.py:165] step: 36800, eval_loss: 2.89589e+01
I0514 16:31:40.869507 140128494741248 run_lib.py:152] step: 36850, training_loss: 2.10399e+01
I0514 16:31:47.055894 140128494741248 run_lib.py:152] step: 36900, training_loss: 2.87012e+01
I0514 16:31:47.116604 140128494741248 run_lib.py:165] step: 36900, eval_loss: 3.02100e+01
I0514 16:31:53.260572 140128494741248 run_lib.py:152] step: 36950, training_loss: 3.99945e+01
I0514 16:31:59.676511 140128494741248 run_lib.py:152] step: 37000, training_loss: 2.75865e+01
I0514 16:31:59.725622 140128494741248 run_lib.py:165] step: 37000, eval_loss: 2.51906e+01
I0514 16:32:05.913793 140128494741248 run_lib.py:152] step: 37050, training_loss: 4.70422e+01
I0514 16:32:12.109750 140128494741248 run_lib.py:152] step: 37100, training_loss: 4.50647e+01
I0514 16:32:12.160256 140128494741248 run_lib.py:165] step: 37100, eval_loss: 4.75811e+01
I0514 16:32:18.537593 140128494741248 run_lib.py:152] step: 37150, training_loss: 3.52314e+01
I0514 16:32:24.785380 140128494741248 run_lib.py:152] step: 37200, training_loss: 4.07496e+01
I0514 16:32:24.837104 140128494741248 run_lib.py:165] step: 37200, eval_loss: 4.50233e+01
I0514 16:32:30.928615 140128494741248 run_lib.py:152] step: 37250, training_loss: 3.84542e+01
I0514 16:32:37.308113 140128494741248 run_lib.py:152] step: 37300, training_loss: 3.00217e+01
I0514 16:32:37.357054 140128494741248 run_lib.py:165] step: 37300, eval_loss: 5.60136e+01
I0514 16:32:43.486897 140128494741248 run_lib.py:152] step: 37350, training_loss: 4.35663e+01
I0514 16:32:49.597071 140128494741248 run_lib.py:152] step: 37400, training_loss: 2.14377e+01
I0514 16:32:49.651529 140128494741248 run_lib.py:165] step: 37400, eval_loss: 2.24711e+01
I0514 16:32:55.801206 140128494741248 run_lib.py:152] step: 37450, training_loss: 3.72444e+01
I0514 16:33:02.262961 140128494741248 run_lib.py:152] step: 37500, training_loss: 3.62270e+01
I0514 16:33:02.314125 140128494741248 run_lib.py:165] step: 37500, eval_loss: 3.17482e+01
I0514 16:33:08.617176 140128494741248 run_lib.py:152] step: 37550, training_loss: 2.32830e+01
I0514 16:33:14.726857 140128494741248 run_lib.py:152] step: 37600, training_loss: 4.29671e+01
I0514 16:33:14.786335 140128494741248 run_lib.py:165] step: 37600, eval_loss: 2.23231e+01
I0514 16:33:21.272696 140128494741248 run_lib.py:152] step: 37650, training_loss: 4.14384e+01
I0514 16:33:27.507493 140128494741248 run_lib.py:152] step: 37700, training_loss: 4.68286e+01
I0514 16:33:27.563325 140128494741248 run_lib.py:165] step: 37700, eval_loss: 4.52379e+01
I0514 16:33:33.727835 140128494741248 run_lib.py:152] step: 37750, training_loss: 2.77003e+01
I0514 16:33:39.890138 140128494741248 run_lib.py:152] step: 37800, training_loss: 2.66716e+01
I0514 16:33:39.940075 140128494741248 run_lib.py:165] step: 37800, eval_loss: 2.91016e+01
I0514 16:33:46.356796 140128494741248 run_lib.py:152] step: 37850, training_loss: 4.31463e+01
I0514 16:33:52.551057 140128494741248 run_lib.py:152] step: 37900, training_loss: 3.34654e+01
I0514 16:33:52.600415 140128494741248 run_lib.py:165] step: 37900, eval_loss: 1.76814e+01
I0514 16:33:58.813363 140128494741248 run_lib.py:152] step: 37950, training_loss: 4.58552e+01
I0514 16:34:05.194606 140128494741248 run_lib.py:152] step: 38000, training_loss: 3.08108e+01
I0514 16:34:05.250303 140128494741248 run_lib.py:165] step: 38000, eval_loss: 3.38154e+01
I0514 16:34:11.523327 140128494741248 run_lib.py:152] step: 38050, training_loss: 2.40128e+01
I0514 16:34:17.678862 140128494741248 run_lib.py:152] step: 38100, training_loss: 4.21481e+01
I0514 16:34:17.732699 140128494741248 run_lib.py:165] step: 38100, eval_loss: 3.55633e+01
I0514 16:34:23.931035 140128494741248 run_lib.py:152] step: 38150, training_loss: 3.00778e+01
I0514 16:34:30.293549 140128494741248 run_lib.py:152] step: 38200, training_loss: 2.72714e+01
I0514 16:34:30.347757 140128494741248 run_lib.py:165] step: 38200, eval_loss: 3.74044e+01
I0514 16:34:36.564495 140128494741248 run_lib.py:152] step: 38250, training_loss: 4.57827e+01
I0514 16:34:42.724767 140128494741248 run_lib.py:152] step: 38300, training_loss: 3.29971e+01
I0514 16:34:42.770949 140128494741248 run_lib.py:165] step: 38300, eval_loss: 3.50205e+01
I0514 16:34:49.257498 140128494741248 run_lib.py:152] step: 38350, training_loss: 3.86826e+01
I0514 16:34:55.434884 140128494741248 run_lib.py:152] step: 38400, training_loss: 3.00268e+01
I0514 16:34:55.485711 140128494741248 run_lib.py:165] step: 38400, eval_loss: 3.92930e+01
I0514 16:35:01.741966 140128494741248 run_lib.py:152] step: 38450, training_loss: 4.36459e+01
I0514 16:35:07.984725 140128494741248 run_lib.py:152] step: 38500, training_loss: 4.26544e+01
I0514 16:35:08.040795 140128494741248 run_lib.py:165] step: 38500, eval_loss: 2.11604e+01
I0514 16:35:14.460847 140128494741248 run_lib.py:152] step: 38550, training_loss: 2.79886e+01
I0514 16:35:20.694364 140128494741248 run_lib.py:152] step: 38600, training_loss: 3.07324e+01
I0514 16:35:20.746393 140128494741248 run_lib.py:165] step: 38600, eval_loss: 1.68012e+01
I0514 16:35:26.958582 140128494741248 run_lib.py:152] step: 38650, training_loss: 4.64276e+01
I0514 16:35:33.315072 140128494741248 run_lib.py:152] step: 38700, training_loss: 3.25599e+01
I0514 16:35:33.369604 140128494741248 run_lib.py:165] step: 38700, eval_loss: 1.93659e+01
I0514 16:35:39.573426 140128494741248 run_lib.py:152] step: 38750, training_loss: 4.53555e+01
I0514 16:35:45.788230 140128494741248 run_lib.py:152] step: 38800, training_loss: 3.04352e+01
I0514 16:35:45.837387 140128494741248 run_lib.py:165] step: 38800, eval_loss: 2.95052e+01
I0514 16:35:52.044313 140128494741248 run_lib.py:152] step: 38850, training_loss: 3.39919e+01
I0514 16:35:58.407661 140128494741248 run_lib.py:152] step: 38900, training_loss: 4.99440e+01
I0514 16:35:58.459381 140128494741248 run_lib.py:165] step: 38900, eval_loss: 3.79545e+01
I0514 16:36:04.646036 140128494741248 run_lib.py:152] step: 38950, training_loss: 3.40935e+01
I0514 16:36:10.868555 140128494741248 run_lib.py:152] step: 39000, training_loss: 3.16199e+01
I0514 16:36:10.919842 140128494741248 run_lib.py:165] step: 39000, eval_loss: 2.71654e+01
I0514 16:36:17.389376 140128494741248 run_lib.py:152] step: 39050, training_loss: 5.19839e+01
I0514 16:36:23.513213 140128494741248 run_lib.py:152] step: 39100, training_loss: 3.44078e+01
I0514 16:36:23.565402 140128494741248 run_lib.py:165] step: 39100, eval_loss: 3.92903e+01
I0514 16:36:29.764844 140128494741248 run_lib.py:152] step: 39150, training_loss: 2.52498e+01
I0514 16:36:35.906202 140128494741248 run_lib.py:152] step: 39200, training_loss: 4.50120e+01
I0514 16:36:35.958691 140128494741248 run_lib.py:165] step: 39200, eval_loss: 4.66062e+01
I0514 16:36:42.380822 140128494741248 run_lib.py:152] step: 39250, training_loss: 2.79086e+01
I0514 16:36:48.599078 140128494741248 run_lib.py:152] step: 39300, training_loss: 2.70777e+01
I0514 16:36:48.656626 140128494741248 run_lib.py:165] step: 39300, eval_loss: 2.62868e+01
I0514 16:36:54.909613 140128494741248 run_lib.py:152] step: 39350, training_loss: 1.57859e+01
I0514 16:37:01.476243 140128494741248 run_lib.py:152] step: 39400, training_loss: 2.19483e+01
I0514 16:37:01.527448 140128494741248 run_lib.py:165] step: 39400, eval_loss: 2.83332e+01
I0514 16:37:07.812599 140128494741248 run_lib.py:152] step: 39450, training_loss: 3.80410e+01
I0514 16:37:13.930354 140128494741248 run_lib.py:152] step: 39500, training_loss: 2.48119e+01
I0514 16:37:13.982931 140128494741248 run_lib.py:165] step: 39500, eval_loss: 2.24200e+01
I0514 16:37:20.123403 140128494741248 run_lib.py:152] step: 39550, training_loss: 3.43555e+01
I0514 16:37:26.541770 140128494741248 run_lib.py:152] step: 39600, training_loss: 3.09669e+01
I0514 16:37:26.598875 140128494741248 run_lib.py:165] step: 39600, eval_loss: 3.91491e+01
I0514 16:37:32.717147 140128494741248 run_lib.py:152] step: 39650, training_loss: 3.27330e+01
I0514 16:37:38.944598 140128494741248 run_lib.py:152] step: 39700, training_loss: 3.08460e+01
I0514 16:37:38.991599 140128494741248 run_lib.py:165] step: 39700, eval_loss: 3.88837e+01
I0514 16:37:45.434206 140128494741248 run_lib.py:152] step: 39750, training_loss: 2.84390e+01
I0514 16:37:51.598294 140128494741248 run_lib.py:152] step: 39800, training_loss: 3.56162e+01
I0514 16:37:51.649422 140128494741248 run_lib.py:165] step: 39800, eval_loss: 3.41168e+01
I0514 16:37:57.781841 140128494741248 run_lib.py:152] step: 39850, training_loss: 2.10974e+01
I0514 16:38:04.002312 140128494741248 run_lib.py:152] step: 39900, training_loss: 3.80364e+01
I0514 16:38:04.054601 140128494741248 run_lib.py:165] step: 39900, eval_loss: 3.64962e+01
I0514 16:38:10.420673 140128494741248 run_lib.py:152] step: 39950, training_loss: 2.69518e+01
I0514 16:38:16.672157 140128494741248 run_lib.py:152] step: 40000, training_loss: 3.86160e+01
I0514 16:38:16.873224 140128494741248 run_lib.py:165] step: 40000, eval_loss: 3.74059e+01
I0514 16:38:23.030745 140128494741248 run_lib.py:152] step: 40050, training_loss: 3.57147e+01
I0514 16:38:29.436358 140128494741248 run_lib.py:152] step: 40100, training_loss: 3.14931e+01
I0514 16:38:29.487468 140128494741248 run_lib.py:165] step: 40100, eval_loss: 3.28199e+01
I0514 16:38:35.755897 140128494741248 run_lib.py:152] step: 40150, training_loss: 4.16356e+01
I0514 16:38:41.943401 140128494741248 run_lib.py:152] step: 40200, training_loss: 4.90043e+01
I0514 16:38:41.995024 140128494741248 run_lib.py:165] step: 40200, eval_loss: 2.66899e+01
I0514 16:38:48.475895 140128494741248 run_lib.py:152] step: 40250, training_loss: 2.54556e+01
I0514 16:38:54.674921 140128494741248 run_lib.py:152] step: 40300, training_loss: 3.13276e+01
I0514 16:38:54.731070 140128494741248 run_lib.py:165] step: 40300, eval_loss: 3.93323e+01
I0514 16:39:00.930505 140128494741248 run_lib.py:152] step: 40350, training_loss: 1.76886e+01
I0514 16:39:07.079715 140128494741248 run_lib.py:152] step: 40400, training_loss: 3.70728e+01
I0514 16:39:07.135880 140128494741248 run_lib.py:165] step: 40400, eval_loss: 3.54036e+01
I0514 16:39:13.592107 140128494741248 run_lib.py:152] step: 40450, training_loss: 2.80322e+01
I0514 16:39:19.769200 140128494741248 run_lib.py:152] step: 40500, training_loss: 4.77524e+01
I0514 16:39:19.820680 140128494741248 run_lib.py:165] step: 40500, eval_loss: 4.47016e+01
I0514 16:39:25.990428 140128494741248 run_lib.py:152] step: 40550, training_loss: 4.95724e+01
I0514 16:39:32.194518 140128494741248 run_lib.py:152] step: 40600, training_loss: 3.74063e+01
I0514 16:39:32.471072 140128494741248 run_lib.py:165] step: 40600, eval_loss: 3.35188e+01
I0514 16:39:38.673137 140128494741248 run_lib.py:152] step: 40650, training_loss: 3.13690e+01
I0514 16:39:44.861422 140128494741248 run_lib.py:152] step: 40700, training_loss: 2.78971e+01
I0514 16:39:44.912103 140128494741248 run_lib.py:165] step: 40700, eval_loss: 5.38399e+01
I0514 16:39:51.103143 140128494741248 run_lib.py:152] step: 40750, training_loss: 3.28252e+01
I0514 16:39:57.540798 140128494741248 run_lib.py:152] step: 40800, training_loss: 3.19713e+01
I0514 16:39:57.591209 140128494741248 run_lib.py:165] step: 40800, eval_loss: 3.59091e+01
I0514 16:40:03.895405 140128494741248 run_lib.py:152] step: 40850, training_loss: 4.09898e+01
I0514 16:40:10.168819 140128494741248 run_lib.py:152] step: 40900, training_loss: 2.68769e+01
I0514 16:40:10.222769 140128494741248 run_lib.py:165] step: 40900, eval_loss: 3.19417e+01
I0514 16:40:16.625807 140128494741248 run_lib.py:152] step: 40950, training_loss: 3.57799e+01
I0514 16:40:22.897078 140128494741248 run_lib.py:152] step: 41000, training_loss: 5.23520e+01
I0514 16:40:22.961584 140128494741248 run_lib.py:165] step: 41000, eval_loss: 1.93709e+01
I0514 16:40:29.210854 140128494741248 run_lib.py:152] step: 41050, training_loss: 4.15356e+01
I0514 16:40:35.440714 140128494741248 run_lib.py:152] step: 41100, training_loss: 4.08437e+01
I0514 16:40:35.495780 140128494741248 run_lib.py:165] step: 41100, eval_loss: 3.07389e+01
I0514 16:40:41.931488 140128494741248 run_lib.py:152] step: 41150, training_loss: 3.83748e+01
I0514 16:40:48.172247 140128494741248 run_lib.py:152] step: 41200, training_loss: 4.79675e+01
I0514 16:40:48.226263 140128494741248 run_lib.py:165] step: 41200, eval_loss: 2.87400e+01
I0514 16:40:54.461861 140128494741248 run_lib.py:152] step: 41250, training_loss: 2.74552e+01
I0514 16:41:00.907300 140128494741248 run_lib.py:152] step: 41300, training_loss: 3.10186e+01
I0514 16:41:00.965247 140128494741248 run_lib.py:165] step: 41300, eval_loss: 3.67225e+01
I0514 16:41:07.162015 140128494741248 run_lib.py:152] step: 41350, training_loss: 4.04402e+01
I0514 16:41:13.295814 140128494741248 run_lib.py:152] step: 41400, training_loss: 5.22951e+01
I0514 16:41:13.353855 140128494741248 run_lib.py:165] step: 41400, eval_loss: 3.21508e+01
I0514 16:41:19.581479 140128494741248 run_lib.py:152] step: 41450, training_loss: 1.82929e+01
I0514 16:41:26.005880 140128494741248 run_lib.py:152] step: 41500, training_loss: 3.31885e+01
I0514 16:41:26.059764 140128494741248 run_lib.py:165] step: 41500, eval_loss: 4.41463e+01
I0514 16:41:32.233385 140128494741248 run_lib.py:152] step: 41550, training_loss: 3.55386e+01
I0514 16:41:38.425868 140128494741248 run_lib.py:152] step: 41600, training_loss: 3.46610e+01
I0514 16:41:38.479269 140128494741248 run_lib.py:165] step: 41600, eval_loss: 3.12316e+01
I0514 16:41:44.914745 140128494741248 run_lib.py:152] step: 41650, training_loss: 3.34810e+01
I0514 16:41:51.062862 140128494741248 run_lib.py:152] step: 41700, training_loss: 2.67498e+01
I0514 16:41:51.118372 140128494741248 run_lib.py:165] step: 41700, eval_loss: 3.85950e+01
I0514 16:41:57.374750 140128494741248 run_lib.py:152] step: 41750, training_loss: 2.57932e+01
I0514 16:42:03.560029 140128494741248 run_lib.py:152] step: 41800, training_loss: 4.34044e+01
I0514 16:42:03.609280 140128494741248 run_lib.py:165] step: 41800, eval_loss: 3.56198e+01
I0514 16:42:10.023699 140128494741248 run_lib.py:152] step: 41850, training_loss: 1.98955e+01
I0514 16:42:16.217566 140128494741248 run_lib.py:152] step: 41900, training_loss: 3.19758e+01
I0514 16:42:16.268652 140128494741248 run_lib.py:165] step: 41900, eval_loss: 3.80069e+01
I0514 16:42:22.499038 140128494741248 run_lib.py:152] step: 41950, training_loss: 4.46715e+01
I0514 16:42:28.827619 140128494741248 run_lib.py:152] step: 42000, training_loss: 4.68212e+01
I0514 16:42:28.876996 140128494741248 run_lib.py:165] step: 42000, eval_loss: 4.52663e+01
I0514 16:42:35.053719 140128494741248 run_lib.py:152] step: 42050, training_loss: 2.91237e+01
I0514 16:42:41.241845 140128494741248 run_lib.py:152] step: 42100, training_loss: 4.83463e+01
I0514 16:42:41.289892 140128494741248 run_lib.py:165] step: 42100, eval_loss: 2.27820e+01
I0514 16:42:47.504335 140128494741248 run_lib.py:152] step: 42150, training_loss: 4.08447e+01
I0514 16:42:53.919227 140128494741248 run_lib.py:152] step: 42200, training_loss: 3.00049e+01
I0514 16:42:53.974702 140128494741248 run_lib.py:165] step: 42200, eval_loss: 4.72058e+01
I0514 16:43:00.214157 140128494741248 run_lib.py:152] step: 42250, training_loss: 3.76671e+01
I0514 16:43:06.344183 140128494741248 run_lib.py:152] step: 42300, training_loss: 3.63085e+01
I0514 16:43:06.394716 140128494741248 run_lib.py:165] step: 42300, eval_loss: 4.23846e+01
I0514 16:43:12.777056 140128494741248 run_lib.py:152] step: 42350, training_loss: 4.73160e+01
I0514 16:43:18.890836 140128494741248 run_lib.py:152] step: 42400, training_loss: 4.44907e+01
I0514 16:43:18.942069 140128494741248 run_lib.py:165] step: 42400, eval_loss: 2.58957e+01
I0514 16:43:25.129528 140128494741248 run_lib.py:152] step: 42450, training_loss: 2.65696e+01
I0514 16:43:31.222850 140128494741248 run_lib.py:152] step: 42500, training_loss: 3.50339e+01
I0514 16:43:31.274738 140128494741248 run_lib.py:165] step: 42500, eval_loss: 2.03594e+01
I0514 16:43:37.673348 140128494741248 run_lib.py:152] step: 42550, training_loss: 4.07573e+01
I0514 16:43:43.910300 140128494741248 run_lib.py:152] step: 42600, training_loss: 3.14456e+01
I0514 16:43:43.962984 140128494741248 run_lib.py:165] step: 42600, eval_loss: 4.91743e+01
I0514 16:43:50.184000 140128494741248 run_lib.py:152] step: 42650, training_loss: 3.83810e+01
I0514 16:43:56.686967 140128494741248 run_lib.py:152] step: 42700, training_loss: 3.92917e+01
I0514 16:43:56.737149 140128494741248 run_lib.py:165] step: 42700, eval_loss: 3.72185e+01
I0514 16:44:02.922734 140128494741248 run_lib.py:152] step: 42750, training_loss: 2.96292e+01
I0514 16:44:09.071659 140128494741248 run_lib.py:152] step: 42800, training_loss: 4.10036e+01
I0514 16:44:09.131220 140128494741248 run_lib.py:165] step: 42800, eval_loss: 4.42046e+01
I0514 16:44:15.380219 140128494741248 run_lib.py:152] step: 42850, training_loss: 1.63502e+01
I0514 16:44:21.770703 140128494741248 run_lib.py:152] step: 42900, training_loss: 2.33770e+01
I0514 16:44:21.821735 140128494741248 run_lib.py:165] step: 42900, eval_loss: 3.45153e+01
I0514 16:44:28.021429 140128494741248 run_lib.py:152] step: 42950, training_loss: 2.95129e+01
I0514 16:44:34.185817 140128494741248 run_lib.py:152] step: 43000, training_loss: 2.26137e+01
I0514 16:44:34.236253 140128494741248 run_lib.py:165] step: 43000, eval_loss: 3.77848e+01
I0514 16:44:40.582916 140128494741248 run_lib.py:152] step: 43050, training_loss: 3.84344e+01
I0514 16:44:46.877241 140128494741248 run_lib.py:152] step: 43100, training_loss: 4.49057e+01
I0514 16:44:46.943951 140128494741248 run_lib.py:165] step: 43100, eval_loss: 3.80335e+01
I0514 16:44:53.159431 140128494741248 run_lib.py:152] step: 43150, training_loss: 4.17252e+01
I0514 16:44:59.498389 140128494741248 run_lib.py:152] step: 43200, training_loss: 2.98256e+01
I0514 16:44:59.554907 140128494741248 run_lib.py:165] step: 43200, eval_loss: 2.32044e+01
I0514 16:45:05.945882 140128494741248 run_lib.py:152] step: 43250, training_loss: 3.31123e+01
I0514 16:45:12.181527 140128494741248 run_lib.py:152] step: 43300, training_loss: 2.64558e+01
I0514 16:45:12.237632 140128494741248 run_lib.py:165] step: 43300, eval_loss: 2.99626e+01
I0514 16:45:18.412181 140128494741248 run_lib.py:152] step: 43350, training_loss: 2.76846e+01
I0514 16:45:24.846336 140128494741248 run_lib.py:152] step: 43400, training_loss: 3.95388e+01
I0514 16:45:24.896416 140128494741248 run_lib.py:165] step: 43400, eval_loss: 2.15981e+01
I0514 16:45:31.078698 140128494741248 run_lib.py:152] step: 43450, training_loss: 3.86025e+01
I0514 16:45:37.239179 140128494741248 run_lib.py:152] step: 43500, training_loss: 2.93142e+01
I0514 16:45:37.296050 140128494741248 run_lib.py:165] step: 43500, eval_loss: 1.93901e+01
I0514 16:45:43.515344 140128494741248 run_lib.py:152] step: 43550, training_loss: 3.18303e+01
I0514 16:45:49.865618 140128494741248 run_lib.py:152] step: 43600, training_loss: 2.63566e+01
I0514 16:45:49.915926 140128494741248 run_lib.py:165] step: 43600, eval_loss: 1.87247e+01
I0514 16:45:56.137900 140128494741248 run_lib.py:152] step: 43650, training_loss: 2.82237e+01
I0514 16:46:02.301799 140128494741248 run_lib.py:152] step: 43700, training_loss: 2.92108e+01
I0514 16:46:02.351810 140128494741248 run_lib.py:165] step: 43700, eval_loss: 3.13919e+01
I0514 16:46:08.771273 140128494741248 run_lib.py:152] step: 43750, training_loss: 2.89144e+01
I0514 16:46:14.938618 140128494741248 run_lib.py:152] step: 43800, training_loss: 3.72647e+01
I0514 16:46:14.988153 140128494741248 run_lib.py:165] step: 43800, eval_loss: 3.43726e+01
I0514 16:46:21.214103 140128494741248 run_lib.py:152] step: 43850, training_loss: 4.52986e+01
I0514 16:46:27.585424 140128494741248 run_lib.py:152] step: 43900, training_loss: 3.45346e+01
I0514 16:46:27.646151 140128494741248 run_lib.py:165] step: 43900, eval_loss: 2.19038e+01
I0514 16:46:33.827783 140128494741248 run_lib.py:152] step: 43950, training_loss: 3.01978e+01
I0514 16:46:40.034842 140128494741248 run_lib.py:152] step: 44000, training_loss: 5.02383e+01
I0514 16:46:40.087171 140128494741248 run_lib.py:165] step: 44000, eval_loss: 4.01530e+01
I0514 16:46:46.282060 140128494741248 run_lib.py:152] step: 44050, training_loss: 4.05969e+01
I0514 16:46:52.663536 140128494741248 run_lib.py:152] step: 44100, training_loss: 4.63385e+01
I0514 16:46:52.717602 140128494741248 run_lib.py:165] step: 44100, eval_loss: 3.29728e+01
I0514 16:46:58.882167 140128494741248 run_lib.py:152] step: 44150, training_loss: 3.95626e+01
I0514 16:47:05.022531 140128494741248 run_lib.py:152] step: 44200, training_loss: 2.84834e+01
I0514 16:47:05.076036 140128494741248 run_lib.py:165] step: 44200, eval_loss: 2.85318e+01
I0514 16:47:11.481462 140128494741248 run_lib.py:152] step: 44250, training_loss: 2.19682e+01
I0514 16:47:17.633545 140128494741248 run_lib.py:152] step: 44300, training_loss: 1.66753e+01
I0514 16:47:17.681352 140128494741248 run_lib.py:165] step: 44300, eval_loss: 4.06033e+01
I0514 16:47:23.970235 140128494741248 run_lib.py:152] step: 44350, training_loss: 3.55598e+01
I0514 16:47:30.157801 140128494741248 run_lib.py:152] step: 44400, training_loss: 2.72778e+01
I0514 16:47:30.207981 140128494741248 run_lib.py:165] step: 44400, eval_loss: 2.76447e+01
I0514 16:47:36.701162 140128494741248 run_lib.py:152] step: 44450, training_loss: 3.84917e+01
I0514 16:47:42.823204 140128494741248 run_lib.py:152] step: 44500, training_loss: 4.09902e+01
I0514 16:47:42.872730 140128494741248 run_lib.py:165] step: 44500, eval_loss: 4.20151e+01
I0514 16:47:49.141986 140128494741248 run_lib.py:152] step: 44550, training_loss: 5.16774e+01
I0514 16:47:55.517590 140128494741248 run_lib.py:152] step: 44600, training_loss: 2.75994e+01
I0514 16:47:55.566045 140128494741248 run_lib.py:165] step: 44600, eval_loss: 3.98781e+01
I0514 16:48:01.795291 140128494741248 run_lib.py:152] step: 44650, training_loss: 5.36259e+01
I0514 16:48:08.077427 140128494741248 run_lib.py:152] step: 44700, training_loss: 3.27160e+01
I0514 16:48:08.126573 140128494741248 run_lib.py:165] step: 44700, eval_loss: 3.54570e+01
I0514 16:48:14.329854 140128494741248 run_lib.py:152] step: 44750, training_loss: 5.63414e+01
I0514 16:48:20.843464 140128494741248 run_lib.py:152] step: 44800, training_loss: 2.37775e+01
I0514 16:48:20.893030 140128494741248 run_lib.py:165] step: 44800, eval_loss: 3.37560e+01
I0514 16:48:27.107142 140128494741248 run_lib.py:152] step: 44850, training_loss: 4.78453e+01
I0514 16:48:33.276282 140128494741248 run_lib.py:152] step: 44900, training_loss: 3.72295e+01
I0514 16:48:33.334933 140128494741248 run_lib.py:165] step: 44900, eval_loss: 4.86931e+01
I0514 16:48:39.818973 140128494741248 run_lib.py:152] step: 44950, training_loss: 4.32980e+01
I0514 16:48:45.940278 140128494741248 run_lib.py:152] step: 45000, training_loss: 3.91748e+01
I0514 16:48:45.989584 140128494741248 run_lib.py:165] step: 45000, eval_loss: 3.06254e+01
I0514 16:48:52.228643 140128494741248 run_lib.py:152] step: 45050, training_loss: 3.46193e+01
I0514 16:48:58.393634 140128494741248 run_lib.py:152] step: 45100, training_loss: 3.02889e+01
I0514 16:48:58.442694 140128494741248 run_lib.py:165] step: 45100, eval_loss: 2.06516e+01
I0514 16:49:04.827153 140128494741248 run_lib.py:152] step: 45150, training_loss: 2.51215e+01
I0514 16:49:11.027029 140128494741248 run_lib.py:152] step: 45200, training_loss: 3.98604e+01
I0514 16:49:11.082374 140128494741248 run_lib.py:165] step: 45200, eval_loss: 2.30488e+01
I0514 16:49:17.246848 140128494741248 run_lib.py:152] step: 45250, training_loss: 3.75554e+01
I0514 16:49:23.687683 140128494741248 run_lib.py:152] step: 45300, training_loss: 1.59222e+01
I0514 16:49:23.738808 140128494741248 run_lib.py:165] step: 45300, eval_loss: 3.41719e+01
I0514 16:49:29.939764 140128494741248 run_lib.py:152] step: 45350, training_loss: 3.03831e+01
I0514 16:49:36.197260 140128494741248 run_lib.py:152] step: 45400, training_loss: 2.47607e+01
I0514 16:49:36.250907 140128494741248 run_lib.py:165] step: 45400, eval_loss: 3.48943e+01
I0514 16:49:42.496041 140128494741248 run_lib.py:152] step: 45450, training_loss: 2.95442e+01
I0514 16:49:48.924295 140128494741248 run_lib.py:152] step: 45500, training_loss: 3.88478e+01
I0514 16:49:48.978742 140128494741248 run_lib.py:165] step: 45500, eval_loss: 5.34315e+01
I0514 16:49:55.201028 140128494741248 run_lib.py:152] step: 45550, training_loss: 3.25740e+01
I0514 16:50:01.405764 140128494741248 run_lib.py:152] step: 45600, training_loss: 3.91886e+01
I0514 16:50:01.467135 140128494741248 run_lib.py:165] step: 45600, eval_loss: 2.86209e+01
I0514 16:50:07.978406 140128494741248 run_lib.py:152] step: 45650, training_loss: 3.67549e+01
I0514 16:50:14.203431 140128494741248 run_lib.py:152] step: 45700, training_loss: 2.55253e+01
I0514 16:50:14.256479 140128494741248 run_lib.py:165] step: 45700, eval_loss: 3.77289e+01
I0514 16:50:20.495452 140128494741248 run_lib.py:152] step: 45750, training_loss: 1.80911e+01
I0514 16:50:26.949835 140128494741248 run_lib.py:152] step: 45800, training_loss: 4.14939e+01
I0514 16:50:27.001490 140128494741248 run_lib.py:165] step: 45800, eval_loss: 3.59204e+01
I0514 16:50:33.200341 140128494741248 run_lib.py:152] step: 45850, training_loss: 2.12062e+01
I0514 16:50:39.445552 140128494741248 run_lib.py:152] step: 45900, training_loss: 2.49509e+01
I0514 16:50:39.494367 140128494741248 run_lib.py:165] step: 45900, eval_loss: 5.36707e+01
I0514 16:50:45.670778 140128494741248 run_lib.py:152] step: 45950, training_loss: 3.58579e+01
I0514 16:50:52.052541 140128494741248 run_lib.py:152] step: 46000, training_loss: 2.67060e+01
I0514 16:50:52.108083 140128494741248 run_lib.py:165] step: 46000, eval_loss: 2.52605e+01
I0514 16:50:58.290925 140128494741248 run_lib.py:152] step: 46050, training_loss: 2.91331e+01
I0514 16:51:04.453783 140128494741248 run_lib.py:152] step: 46100, training_loss: 2.76767e+01
I0514 16:51:04.502763 140128494741248 run_lib.py:165] step: 46100, eval_loss: 1.70137e+01
I0514 16:51:10.974770 140128494741248 run_lib.py:152] step: 46150, training_loss: 4.63832e+01
I0514 16:51:17.120581 140128494741248 run_lib.py:152] step: 46200, training_loss: 4.59105e+01
I0514 16:51:17.168911 140128494741248 run_lib.py:165] step: 46200, eval_loss: 2.97566e+01
I0514 16:51:23.349030 140128494741248 run_lib.py:152] step: 46250, training_loss: 3.65735e+01
I0514 16:51:29.545922 140128494741248 run_lib.py:152] step: 46300, training_loss: 4.09687e+01
I0514 16:51:29.596399 140128494741248 run_lib.py:165] step: 46300, eval_loss: 3.88250e+01
I0514 16:51:36.033076 140128494741248 run_lib.py:152] step: 46350, training_loss: 2.48642e+01
I0514 16:51:42.271602 140128494741248 run_lib.py:152] step: 46400, training_loss: 4.08020e+01
I0514 16:51:42.322242 140128494741248 run_lib.py:165] step: 46400, eval_loss: 3.77924e+01
I0514 16:51:48.504595 140128494741248 run_lib.py:152] step: 46450, training_loss: 3.19629e+01
I0514 16:51:54.924394 140128494741248 run_lib.py:152] step: 46500, training_loss: 4.11618e+01
I0514 16:51:54.971683 140128494741248 run_lib.py:165] step: 46500, eval_loss: 3.80925e+01
I0514 16:52:01.171183 140128494741248 run_lib.py:152] step: 46550, training_loss: 3.73362e+01
I0514 16:52:07.379227 140128494741248 run_lib.py:152] step: 46600, training_loss: 2.45416e+01
I0514 16:52:07.430663 140128494741248 run_lib.py:165] step: 46600, eval_loss: 3.30202e+01
I0514 16:52:13.530982 140128494741248 run_lib.py:152] step: 46650, training_loss: 3.41284e+01
I0514 16:52:19.946221 140128494741248 run_lib.py:152] step: 46700, training_loss: 3.27671e+01
I0514 16:52:20.005663 140128494741248 run_lib.py:165] step: 46700, eval_loss: 3.48344e+01
I0514 16:52:26.157728 140128494741248 run_lib.py:152] step: 46750, training_loss: 4.18784e+01
I0514 16:52:32.368981 140128494741248 run_lib.py:152] step: 46800, training_loss: 4.34763e+01
I0514 16:52:32.425925 140128494741248 run_lib.py:165] step: 46800, eval_loss: 3.23385e+01
I0514 16:52:38.904435 140128494741248 run_lib.py:152] step: 46850, training_loss: 3.69828e+01
I0514 16:52:45.109613 140128494741248 run_lib.py:152] step: 46900, training_loss: 3.94915e+01
I0514 16:52:45.167535 140128494741248 run_lib.py:165] step: 46900, eval_loss: 3.96960e+01
I0514 16:52:51.335961 140128494741248 run_lib.py:152] step: 46950, training_loss: 5.04508e+01
I0514 16:52:57.532399 140128494741248 run_lib.py:152] step: 47000, training_loss: 1.98387e+01
I0514 16:52:57.578884 140128494741248 run_lib.py:165] step: 47000, eval_loss: 2.74376e+01
I0514 16:53:04.059954 140128494741248 run_lib.py:152] step: 47050, training_loss: 1.93742e+01
I0514 16:53:10.341254 140128494741248 run_lib.py:152] step: 47100, training_loss: 3.61937e+01
I0514 16:53:10.390769 140128494741248 run_lib.py:165] step: 47100, eval_loss: 3.64229e+01
I0514 16:53:16.501832 140128494741248 run_lib.py:152] step: 47150, training_loss: 4.65479e+01
I0514 16:53:22.955751 140128494741248 run_lib.py:152] step: 47200, training_loss: 3.80478e+01
I0514 16:53:23.006867 140128494741248 run_lib.py:165] step: 47200, eval_loss: 2.86301e+01
I0514 16:53:29.190372 140128494741248 run_lib.py:152] step: 47250, training_loss: 3.10031e+01
I0514 16:53:35.414463 140128494741248 run_lib.py:152] step: 47300, training_loss: 4.51169e+01
I0514 16:53:35.466590 140128494741248 run_lib.py:165] step: 47300, eval_loss: 2.44183e+01
I0514 16:53:41.607678 140128494741248 run_lib.py:152] step: 47350, training_loss: 3.76410e+01
I0514 16:53:48.068980 140128494741248 run_lib.py:152] step: 47400, training_loss: 2.81142e+01
I0514 16:53:48.122588 140128494741248 run_lib.py:165] step: 47400, eval_loss: 3.94298e+01
I0514 16:53:54.325547 140128494741248 run_lib.py:152] step: 47450, training_loss: 3.30182e+01
I0514 16:54:00.499218 140128494741248 run_lib.py:152] step: 47500, training_loss: 3.65046e+01
I0514 16:54:00.553455 140128494741248 run_lib.py:165] step: 47500, eval_loss: 4.92532e+01
I0514 16:54:06.987730 140128494741248 run_lib.py:152] step: 47550, training_loss: 3.70936e+01
I0514 16:54:13.186290 140128494741248 run_lib.py:152] step: 47600, training_loss: 3.39978e+01
I0514 16:54:13.242460 140128494741248 run_lib.py:165] step: 47600, eval_loss: 1.63416e+01
I0514 16:54:19.814023 140128494741248 run_lib.py:152] step: 47650, training_loss: 3.37272e+01
I0514 16:54:26.437068 140128494741248 run_lib.py:152] step: 47700, training_loss: 6.01913e+01
I0514 16:54:26.493022 140128494741248 run_lib.py:165] step: 47700, eval_loss: 3.09834e+01
I0514 16:54:32.989326 140128494741248 run_lib.py:152] step: 47750, training_loss: 1.59899e+01
I0514 16:54:39.368179 140128494741248 run_lib.py:152] step: 47800, training_loss: 1.99200e+01
I0514 16:54:39.418710 140128494741248 run_lib.py:165] step: 47800, eval_loss: 3.11198e+01
I0514 16:54:45.730163 140128494741248 run_lib.py:152] step: 47850, training_loss: 4.33309e+01
I0514 16:54:52.104379 140128494741248 run_lib.py:152] step: 47900, training_loss: 2.68726e+01
I0514 16:54:52.161472 140128494741248 run_lib.py:165] step: 47900, eval_loss: 4.34192e+01
I0514 16:54:58.364415 140128494741248 run_lib.py:152] step: 47950, training_loss: 3.65325e+01
I0514 16:55:04.521230 140128494741248 run_lib.py:152] step: 48000, training_loss: 2.16502e+01
I0514 16:55:04.569275 140128494741248 run_lib.py:165] step: 48000, eval_loss: 4.35409e+01
I0514 16:55:10.748284 140128494741248 run_lib.py:152] step: 48050, training_loss: 3.87574e+01
I0514 16:55:17.233065 140128494741248 run_lib.py:152] step: 48100, training_loss: 3.27906e+01
I0514 16:55:17.286796 140128494741248 run_lib.py:165] step: 48100, eval_loss: 3.59792e+01
I0514 16:55:23.417379 140128494741248 run_lib.py:152] step: 48150, training_loss: 3.15393e+01
I0514 16:55:29.600575 140128494741248 run_lib.py:152] step: 48200, training_loss: 4.54583e+01
I0514 16:55:29.650161 140128494741248 run_lib.py:165] step: 48200, eval_loss: 3.50830e+01
I0514 16:55:36.190045 140128494741248 run_lib.py:152] step: 48250, training_loss: 2.88209e+01
I0514 16:55:42.398361 140128494741248 run_lib.py:152] step: 48300, training_loss: 2.37396e+01
I0514 16:55:42.454156 140128494741248 run_lib.py:165] step: 48300, eval_loss: 3.82195e+01
I0514 16:55:48.662111 140128494741248 run_lib.py:152] step: 48350, training_loss: 2.69832e+01
I0514 16:55:54.899482 140128494741248 run_lib.py:152] step: 48400, training_loss: 4.15407e+01
I0514 16:55:54.955411 140128494741248 run_lib.py:165] step: 48400, eval_loss: 2.61223e+01
I0514 16:56:01.424181 140128494741248 run_lib.py:152] step: 48450, training_loss: 4.13516e+01
I0514 16:56:07.662298 140128494741248 run_lib.py:152] step: 48500, training_loss: 3.73046e+01
I0514 16:56:07.714138 140128494741248 run_lib.py:165] step: 48500, eval_loss: 3.08486e+01
I0514 16:56:13.889454 140128494741248 run_lib.py:152] step: 48550, training_loss: 4.05148e+01
I0514 16:56:20.341380 140128494741248 run_lib.py:152] step: 48600, training_loss: 3.81646e+01
I0514 16:56:20.395167 140128494741248 run_lib.py:165] step: 48600, eval_loss: 2.38448e+01
I0514 16:56:26.570361 140128494741248 run_lib.py:152] step: 48650, training_loss: 2.62018e+01
I0514 16:56:32.782674 140128494741248 run_lib.py:152] step: 48700, training_loss: 2.51421e+01
I0514 16:56:32.832858 140128494741248 run_lib.py:165] step: 48700, eval_loss: 2.22439e+01
I0514 16:56:39.042993 140128494741248 run_lib.py:152] step: 48750, training_loss: 3.23940e+01
I0514 16:56:45.496142 140128494741248 run_lib.py:152] step: 48800, training_loss: 5.64020e+01
I0514 16:56:45.544383 140128494741248 run_lib.py:165] step: 48800, eval_loss: 3.70709e+01
I0514 16:56:51.694406 140128494741248 run_lib.py:152] step: 48850, training_loss: 2.65285e+01
I0514 16:56:57.871057 140128494741248 run_lib.py:152] step: 48900, training_loss: 3.21292e+01
I0514 16:56:57.930243 140128494741248 run_lib.py:165] step: 48900, eval_loss: 2.94536e+01
I0514 16:57:04.392474 140128494741248 run_lib.py:152] step: 48950, training_loss: 2.79524e+01
I0514 16:57:10.583344 140128494741248 run_lib.py:152] step: 49000, training_loss: 4.50822e+01
I0514 16:57:10.640681 140128494741248 run_lib.py:165] step: 49000, eval_loss: 2.15766e+01
I0514 16:57:16.875662 140128494741248 run_lib.py:152] step: 49050, training_loss: 4.45098e+01
I0514 16:57:23.236594 140128494741248 run_lib.py:152] step: 49100, training_loss: 2.41023e+01
I0514 16:57:23.287705 140128494741248 run_lib.py:165] step: 49100, eval_loss: 2.91876e+01
I0514 16:57:29.452142 140128494741248 run_lib.py:152] step: 49150, training_loss: 2.46133e+01
I0514 16:57:35.577378 140128494741248 run_lib.py:152] step: 49200, training_loss: 3.35656e+01
I0514 16:57:35.629528 140128494741248 run_lib.py:165] step: 49200, eval_loss: 4.70436e+01
I0514 16:57:41.904680 140128494741248 run_lib.py:152] step: 49250, training_loss: 3.34857e+01
I0514 16:57:48.284341 140128494741248 run_lib.py:152] step: 49300, training_loss: 4.36944e+01
I0514 16:57:48.334792 140128494741248 run_lib.py:165] step: 49300, eval_loss: 2.81364e+01
I0514 16:57:54.499961 140128494741248 run_lib.py:152] step: 49350, training_loss: 3.93809e+01
I0514 16:58:00.715864 140128494741248 run_lib.py:152] step: 49400, training_loss: 2.55633e+01
I0514 16:58:00.771631 140128494741248 run_lib.py:165] step: 49400, eval_loss: 3.58758e+01
I0514 16:58:07.223871 140128494741248 run_lib.py:152] step: 49450, training_loss: 5.05887e+01
I0514 16:58:13.275839 140128494741248 run_lib.py:152] step: 49500, training_loss: 2.94062e+01
I0514 16:58:13.332230 140128494741248 run_lib.py:165] step: 49500, eval_loss: 3.45680e+01
I0514 16:58:19.541676 140128494741248 run_lib.py:152] step: 49550, training_loss: 3.76954e+01
I0514 16:58:25.734411 140128494741248 run_lib.py:152] step: 49600, training_loss: 2.72260e+01
I0514 16:58:25.783077 140128494741248 run_lib.py:165] step: 49600, eval_loss: 3.94963e+01
I0514 16:58:32.156756 140128494741248 run_lib.py:152] step: 49650, training_loss: 3.75752e+01
I0514 16:58:38.377240 140128494741248 run_lib.py:152] step: 49700, training_loss: 4.64960e+01
I0514 16:58:38.425901 140128494741248 run_lib.py:165] step: 49700, eval_loss: 3.68497e+01
I0514 16:58:44.619226 140128494741248 run_lib.py:152] step: 49750, training_loss: 3.99663e+01
I0514 16:58:51.107204 140128494741248 run_lib.py:152] step: 49800, training_loss: 4.20886e+01
I0514 16:58:51.163133 140128494741248 run_lib.py:165] step: 49800, eval_loss: 2.23746e+01
I0514 16:58:57.426522 140128494741248 run_lib.py:152] step: 49850, training_loss: 2.41153e+01
I0514 16:59:03.658000 140128494741248 run_lib.py:152] step: 49900, training_loss: 4.23653e+01
I0514 16:59:03.714799 140128494741248 run_lib.py:165] step: 49900, eval_loss: 4.59930e+01
I0514 16:59:09.851176 140128494741248 run_lib.py:152] step: 49950, training_loss: 2.84247e+01
I0514 16:59:16.344753 140128494741248 run_lib.py:152] step: 50000, training_loss: 4.89784e+01
I0514 16:59:16.550798 140128494741248 run_lib.py:165] step: 50000, eval_loss: 2.98852e+01
I0514 17:00:37.232620 140128494741248 run_lib.py:152] step: 50050, training_loss: 2.54206e+01
I0514 17:00:43.744699 140128494741248 run_lib.py:152] step: 50100, training_loss: 2.76217e+01
I0514 17:00:43.792062 140128494741248 run_lib.py:165] step: 50100, eval_loss: 2.21119e+01
I0514 17:00:50.023362 140128494741248 run_lib.py:152] step: 50150, training_loss: 4.05413e+01
I0514 17:00:56.219725 140128494741248 run_lib.py:152] step: 50200, training_loss: 3.91803e+01
I0514 17:00:56.274310 140128494741248 run_lib.py:165] step: 50200, eval_loss: 3.47976e+01
I0514 17:01:02.646533 140128494741248 run_lib.py:152] step: 50250, training_loss: 2.87630e+01
I0514 17:01:08.813021 140128494741248 run_lib.py:152] step: 50300, training_loss: 3.82683e+01
I0514 17:01:08.874094 140128494741248 run_lib.py:165] step: 50300, eval_loss: 2.20537e+01
I0514 17:01:15.120725 140128494741248 run_lib.py:152] step: 50350, training_loss: 2.85867e+01
I0514 17:01:21.299974 140128494741248 run_lib.py:152] step: 50400, training_loss: 3.89196e+01
I0514 17:01:21.349164 140128494741248 run_lib.py:165] step: 50400, eval_loss: 3.04403e+01
I0514 17:01:27.741615 140128494741248 run_lib.py:152] step: 50450, training_loss: 3.64339e+01
I0514 17:01:33.957633 140128494741248 run_lib.py:152] step: 50500, training_loss: 3.09406e+01
I0514 17:01:34.012669 140128494741248 run_lib.py:165] step: 50500, eval_loss: 4.67906e+01
I0514 17:01:40.250857 140128494741248 run_lib.py:152] step: 50550, training_loss: 4.54653e+01
I0514 17:01:46.456767 140128494741248 run_lib.py:152] step: 50600, training_loss: 3.79437e+01
I0514 17:01:46.728677 140128494741248 run_lib.py:165] step: 50600, eval_loss: 2.56007e+01
I0514 17:01:52.968118 140128494741248 run_lib.py:152] step: 50650, training_loss: 2.39286e+01
I0514 17:01:59.117330 140128494741248 run_lib.py:152] step: 50700, training_loss: 2.64056e+01
I0514 17:01:59.166740 140128494741248 run_lib.py:165] step: 50700, eval_loss: 2.05373e+01
I0514 17:02:05.463448 140128494741248 run_lib.py:152] step: 50750, training_loss: 2.93979e+01
I0514 17:02:11.916818 140128494741248 run_lib.py:152] step: 50800, training_loss: 3.08974e+01
I0514 17:02:11.970779 140128494741248 run_lib.py:165] step: 50800, eval_loss: 2.55218e+01
I0514 17:02:18.167475 140128494741248 run_lib.py:152] step: 50850, training_loss: 3.25547e+01
I0514 17:02:24.407152 140128494741248 run_lib.py:152] step: 50900, training_loss: 3.55834e+01
I0514 17:02:24.455229 140128494741248 run_lib.py:165] step: 50900, eval_loss: 4.13966e+01
I0514 17:02:30.944424 140128494741248 run_lib.py:152] step: 50950, training_loss: 2.55070e+01
I0514 17:02:37.206975 140128494741248 run_lib.py:152] step: 51000, training_loss: 3.83754e+01
I0514 17:02:37.262757 140128494741248 run_lib.py:165] step: 51000, eval_loss: 1.53321e+01
I0514 17:02:43.510213 140128494741248 run_lib.py:152] step: 51050, training_loss: 2.93285e+01
I0514 17:02:49.644788 140128494741248 run_lib.py:152] step: 51100, training_loss: 4.93817e+01
I0514 17:02:49.698495 140128494741248 run_lib.py:165] step: 51100, eval_loss: 4.00400e+01
I0514 17:02:56.191998 140128494741248 run_lib.py:152] step: 51150, training_loss: 3.56931e+01
I0514 17:03:02.450801 140128494741248 run_lib.py:152] step: 51200, training_loss: 1.87431e+01
I0514 17:03:02.506396 140128494741248 run_lib.py:165] step: 51200, eval_loss: 2.93040e+01
I0514 17:03:08.788294 140128494741248 run_lib.py:152] step: 51250, training_loss: 4.47833e+01
I0514 17:03:15.244645 140128494741248 run_lib.py:152] step: 51300, training_loss: 5.40037e+01
I0514 17:03:15.299639 140128494741248 run_lib.py:165] step: 51300, eval_loss: 3.39634e+01
I0514 17:03:21.490036 140128494741248 run_lib.py:152] step: 51350, training_loss: 3.89347e+01
I0514 17:03:27.688774 140128494741248 run_lib.py:152] step: 51400, training_loss: 4.16035e+01
I0514 17:03:27.741944 140128494741248 run_lib.py:165] step: 51400, eval_loss: 3.86218e+01
I0514 17:03:33.897137 140128494741248 run_lib.py:152] step: 51450, training_loss: 3.70328e+01
I0514 17:03:40.294977 140128494741248 run_lib.py:152] step: 51500, training_loss: 4.81476e+01
I0514 17:03:40.350768 140128494741248 run_lib.py:165] step: 51500, eval_loss: 3.40294e+01
I0514 17:03:46.492430 140128494741248 run_lib.py:152] step: 51550, training_loss: 3.27112e+01
I0514 17:03:52.677650 140128494741248 run_lib.py:152] step: 51600, training_loss: 3.33762e+01
I0514 17:03:52.726019 140128494741248 run_lib.py:165] step: 51600, eval_loss: 3.42867e+01
I0514 17:03:59.174175 140128494741248 run_lib.py:152] step: 51650, training_loss: 3.68451e+01
I0514 17:04:05.338309 140128494741248 run_lib.py:152] step: 51700, training_loss: 3.68995e+01
I0514 17:04:05.391519 140128494741248 run_lib.py:165] step: 51700, eval_loss: 2.44050e+01
I0514 17:04:11.704455 140128494741248 run_lib.py:152] step: 51750, training_loss: 4.31057e+01
I0514 17:04:17.972558 140128494741248 run_lib.py:152] step: 51800, training_loss: 2.34390e+01
I0514 17:04:18.024548 140128494741248 run_lib.py:165] step: 51800, eval_loss: 2.60926e+01
I0514 17:04:24.554703 140128494741248 run_lib.py:152] step: 51850, training_loss: 1.85714e+01
I0514 17:04:30.674299 140128494741248 run_lib.py:152] step: 51900, training_loss: 3.76155e+01
I0514 17:04:30.728405 140128494741248 run_lib.py:165] step: 51900, eval_loss: 2.90698e+01
I0514 17:04:36.948680 140128494741248 run_lib.py:152] step: 51950, training_loss: 5.06193e+01
I0514 17:04:43.302296 140128494741248 run_lib.py:152] step: 52000, training_loss: 2.36165e+01
I0514 17:04:43.355800 140128494741248 run_lib.py:165] step: 52000, eval_loss: 3.24401e+01
I0514 17:04:49.564189 140128494741248 run_lib.py:152] step: 52050, training_loss: 3.20833e+01
I0514 17:04:55.805646 140128494741248 run_lib.py:152] step: 52100, training_loss: 2.56659e+01
I0514 17:04:55.854371 140128494741248 run_lib.py:165] step: 52100, eval_loss: 3.86237e+01
I0514 17:05:02.102629 140128494741248 run_lib.py:152] step: 52150, training_loss: 3.22260e+01
I0514 17:05:08.531897 140128494741248 run_lib.py:152] step: 52200, training_loss: 2.05618e+01
I0514 17:05:08.582830 140128494741248 run_lib.py:165] step: 52200, eval_loss: 2.84674e+01
I0514 17:05:14.747557 140128494741248 run_lib.py:152] step: 52250, training_loss: 2.14212e+01
I0514 17:05:21.012368 140128494741248 run_lib.py:152] step: 52300, training_loss: 3.11900e+01
I0514 17:05:21.059187 140128494741248 run_lib.py:165] step: 52300, eval_loss: 2.10859e+01
I0514 17:05:27.620231 140128494741248 run_lib.py:152] step: 52350, training_loss: 2.20521e+01
I0514 17:05:33.812108 140128494741248 run_lib.py:152] step: 52400, training_loss: 3.16061e+01
I0514 17:05:33.865109 140128494741248 run_lib.py:165] step: 52400, eval_loss: 1.89282e+01
I0514 17:05:40.028674 140128494741248 run_lib.py:152] step: 52450, training_loss: 3.38011e+01
I0514 17:05:46.274011 140128494741248 run_lib.py:152] step: 52500, training_loss: 2.50912e+01
I0514 17:05:46.328243 140128494741248 run_lib.py:165] step: 52500, eval_loss: 4.73918e+01
I0514 17:05:52.770206 140128494741248 run_lib.py:152] step: 52550, training_loss: 3.37177e+01
I0514 17:05:58.925524 140128494741248 run_lib.py:152] step: 52600, training_loss: 3.59822e+01
I0514 17:05:58.982140 140128494741248 run_lib.py:165] step: 52600, eval_loss: 4.29905e+01
I0514 17:06:05.271074 140128494741248 run_lib.py:152] step: 52650, training_loss: 4.92122e+01
I0514 17:06:11.773674 140128494741248 run_lib.py:152] step: 52700, training_loss: 2.58810e+01
I0514 17:06:11.827416 140128494741248 run_lib.py:165] step: 52700, eval_loss: 4.86331e+01
I0514 17:06:18.103712 140128494741248 run_lib.py:152] step: 52750, training_loss: 2.74076e+01
I0514 17:06:24.291462 140128494741248 run_lib.py:152] step: 52800, training_loss: 3.90623e+01
I0514 17:06:24.349969 140128494741248 run_lib.py:165] step: 52800, eval_loss: 2.87612e+01
I0514 17:06:30.542023 140128494741248 run_lib.py:152] step: 52850, training_loss: 2.72373e+01
I0514 17:06:37.087630 140128494741248 run_lib.py:152] step: 52900, training_loss: 3.24521e+01
I0514 17:06:37.138094 140128494741248 run_lib.py:165] step: 52900, eval_loss: 2.76913e+01
I0514 17:06:43.393862 140128494741248 run_lib.py:152] step: 52950, training_loss: 4.15341e+01
I0514 17:06:49.619796 140128494741248 run_lib.py:152] step: 53000, training_loss: 4.50976e+01
I0514 17:06:49.678133 140128494741248 run_lib.py:165] step: 53000, eval_loss: 3.80928e+01
I0514 17:06:56.127706 140128494741248 run_lib.py:152] step: 53050, training_loss: 3.19164e+01
I0514 17:07:02.277396 140128494741248 run_lib.py:152] step: 53100, training_loss: 2.82225e+01
I0514 17:07:02.331847 140128494741248 run_lib.py:165] step: 53100, eval_loss: 2.50728e+01
I0514 17:07:08.576959 140128494741248 run_lib.py:152] step: 53150, training_loss: 3.43026e+01
I0514 17:07:14.718728 140128494741248 run_lib.py:152] step: 53200, training_loss: 2.96618e+01
I0514 17:07:14.771600 140128494741248 run_lib.py:165] step: 53200, eval_loss: 3.37273e+01
I0514 17:07:21.246451 140128494741248 run_lib.py:152] step: 53250, training_loss: 2.11486e+01
I0514 17:07:27.420432 140128494741248 run_lib.py:152] step: 53300, training_loss: 1.90028e+01
I0514 17:07:27.467489 140128494741248 run_lib.py:165] step: 53300, eval_loss: 3.29531e+01
I0514 17:07:33.706765 140128494741248 run_lib.py:152] step: 53350, training_loss: 5.19055e+01
I0514 17:07:40.186723 140128494741248 run_lib.py:152] step: 53400, training_loss: 3.75030e+01
I0514 17:07:40.234289 140128494741248 run_lib.py:165] step: 53400, eval_loss: 2.71189e+01
I0514 17:07:46.549829 140128494741248 run_lib.py:152] step: 53450, training_loss: 3.47099e+01
I0514 17:07:52.780110 140128494741248 run_lib.py:152] step: 53500, training_loss: 4.10012e+01
I0514 17:07:52.828161 140128494741248 run_lib.py:165] step: 53500, eval_loss: 4.34179e+01
I0514 17:07:58.979456 140128494741248 run_lib.py:152] step: 53550, training_loss: 3.83750e+01
I0514 17:08:05.498355 140128494741248 run_lib.py:152] step: 53600, training_loss: 3.03387e+01
I0514 17:08:05.554690 140128494741248 run_lib.py:165] step: 53600, eval_loss: 2.93302e+01
I0514 17:08:11.793298 140128494741248 run_lib.py:152] step: 53650, training_loss: 2.45022e+01
I0514 17:08:17.976533 140128494741248 run_lib.py:152] step: 53700, training_loss: 3.37646e+01
I0514 17:08:18.028124 140128494741248 run_lib.py:165] step: 53700, eval_loss: 2.75438e+01
I0514 17:08:24.549093 140128494741248 run_lib.py:152] step: 53750, training_loss: 3.42072e+01
I0514 17:08:30.743590 140128494741248 run_lib.py:152] step: 53800, training_loss: 2.21106e+01
I0514 17:08:30.796438 140128494741248 run_lib.py:165] step: 53800, eval_loss: 4.01369e+01
I0514 17:08:37.039777 140128494741248 run_lib.py:152] step: 53850, training_loss: 3.80290e+01
I0514 17:08:43.323542 140128494741248 run_lib.py:152] step: 53900, training_loss: 5.22987e+01
I0514 17:08:43.375626 140128494741248 run_lib.py:165] step: 53900, eval_loss: 4.02561e+01
I0514 17:08:49.728551 140128494741248 run_lib.py:152] step: 53950, training_loss: 1.82549e+01
I0514 17:08:55.913271 140128494741248 run_lib.py:152] step: 54000, training_loss: 3.77774e+01
I0514 17:08:55.963162 140128494741248 run_lib.py:165] step: 54000, eval_loss: 2.20687e+01
I0514 17:09:02.139301 140128494741248 run_lib.py:152] step: 54050, training_loss: 3.82401e+01
I0514 17:09:08.271566 140128494741248 run_lib.py:152] step: 54100, training_loss: 3.55325e+01
I0514 17:09:08.546421 140128494741248 run_lib.py:165] step: 54100, eval_loss: 2.76700e+01
I0514 17:09:14.882041 140128494741248 run_lib.py:152] step: 54150, training_loss: 3.99451e+01
I0514 17:09:21.152215 140128494741248 run_lib.py:152] step: 54200, training_loss: 2.37302e+01
I0514 17:09:21.201817 140128494741248 run_lib.py:165] step: 54200, eval_loss: 2.72528e+01
I0514 17:09:27.522362 140128494741248 run_lib.py:152] step: 54250, training_loss: 3.15371e+01
I0514 17:09:33.956050 140128494741248 run_lib.py:152] step: 54300, training_loss: 2.61089e+01
I0514 17:09:34.007704 140128494741248 run_lib.py:165] step: 54300, eval_loss: 2.97309e+01
I0514 17:09:40.167679 140128494741248 run_lib.py:152] step: 54350, training_loss: 4.73390e+01
I0514 17:09:46.584727 140128494741248 run_lib.py:152] step: 54400, training_loss: 2.95154e+01
I0514 17:09:46.639169 140128494741248 run_lib.py:165] step: 54400, eval_loss: 4.29530e+01
I0514 17:09:53.099133 140128494741248 run_lib.py:152] step: 54450, training_loss: 2.49727e+01
I0514 17:09:59.277135 140128494741248 run_lib.py:152] step: 54500, training_loss: 4.63027e+01
I0514 17:09:59.336138 140128494741248 run_lib.py:165] step: 54500, eval_loss: 2.71153e+01
I0514 17:10:05.567939 140128494741248 run_lib.py:152] step: 54550, training_loss: 3.48916e+01
I0514 17:10:11.740190 140128494741248 run_lib.py:152] step: 54600, training_loss: 5.57130e+01
I0514 17:10:11.792138 140128494741248 run_lib.py:165] step: 54600, eval_loss: 3.14536e+01
I0514 17:10:18.192376 140128494741248 run_lib.py:152] step: 54650, training_loss: 3.11753e+01
I0514 17:10:24.496485 140128494741248 run_lib.py:152] step: 54700, training_loss: 4.15805e+01
I0514 17:10:24.549863 140128494741248 run_lib.py:165] step: 54700, eval_loss: 2.51237e+01
I0514 17:10:30.789335 140128494741248 run_lib.py:152] step: 54750, training_loss: 3.63023e+01
I0514 17:10:37.320820 140128494741248 run_lib.py:152] step: 54800, training_loss: 2.87085e+01
I0514 17:10:37.372322 140128494741248 run_lib.py:165] step: 54800, eval_loss: 1.72296e+01
I0514 17:10:43.598896 140128494741248 run_lib.py:152] step: 54850, training_loss: 4.27636e+01
I0514 17:10:49.763072 140128494741248 run_lib.py:152] step: 54900, training_loss: 3.03672e+01
I0514 17:10:49.811813 140128494741248 run_lib.py:165] step: 54900, eval_loss: 2.78006e+01
I0514 17:10:56.006656 140128494741248 run_lib.py:152] step: 54950, training_loss: 2.28274e+01
I0514 17:11:02.534897 140128494741248 run_lib.py:152] step: 55000, training_loss: 2.80029e+01
I0514 17:11:02.590929 140128494741248 run_lib.py:165] step: 55000, eval_loss: 2.68160e+01
I0514 17:11:08.814457 140128494741248 run_lib.py:152] step: 55050, training_loss: 5.18083e+01
I0514 17:11:15.119389 140128494741248 run_lib.py:152] step: 55100, training_loss: 2.53755e+01
I0514 17:11:15.170856 140128494741248 run_lib.py:165] step: 55100, eval_loss: 3.15990e+01
I0514 17:11:21.567376 140128494741248 run_lib.py:152] step: 55150, training_loss: 3.58106e+01
I0514 17:11:27.836987 140128494741248 run_lib.py:152] step: 55200, training_loss: 4.04240e+01
I0514 17:11:27.892022 140128494741248 run_lib.py:165] step: 55200, eval_loss: 2.62461e+01
I0514 17:11:34.207440 140128494741248 run_lib.py:152] step: 55250, training_loss: 4.94605e+01
I0514 17:11:40.492654 140128494741248 run_lib.py:152] step: 55300, training_loss: 4.63920e+01
I0514 17:11:40.542280 140128494741248 run_lib.py:165] step: 55300, eval_loss: 2.16279e+01
I0514 17:11:46.970235 140128494741248 run_lib.py:152] step: 55350, training_loss: 3.59293e+01
I0514 17:11:53.231109 140128494741248 run_lib.py:152] step: 55400, training_loss: 4.31940e+01
I0514 17:11:53.281800 140128494741248 run_lib.py:165] step: 55400, eval_loss: 2.05210e+01
I0514 17:11:59.501186 140128494741248 run_lib.py:152] step: 55450, training_loss: 3.79466e+01
I0514 17:12:05.926790 140128494741248 run_lib.py:152] step: 55500, training_loss: 2.72415e+01
I0514 17:12:05.983893 140128494741248 run_lib.py:165] step: 55500, eval_loss: 3.06606e+01
I0514 17:12:12.252504 140128494741248 run_lib.py:152] step: 55550, training_loss: 2.42710e+01
I0514 17:12:18.481704 140128494741248 run_lib.py:152] step: 55600, training_loss: 2.16251e+01
I0514 17:12:18.529670 140128494741248 run_lib.py:165] step: 55600, eval_loss: 3.26587e+01
I0514 17:12:24.791767 140128494741248 run_lib.py:152] step: 55650, training_loss: 2.56408e+01
I0514 17:12:31.235681 140128494741248 run_lib.py:152] step: 55700, training_loss: 4.01297e+01
I0514 17:12:31.290873 140128494741248 run_lib.py:165] step: 55700, eval_loss: 3.22198e+01
I0514 17:12:37.542744 140128494741248 run_lib.py:152] step: 55750, training_loss: 3.77136e+01
I0514 17:12:43.812682 140128494741248 run_lib.py:152] step: 55800, training_loss: 2.89023e+01
I0514 17:12:43.860403 140128494741248 run_lib.py:165] step: 55800, eval_loss: 4.73668e+01
I0514 17:12:50.346345 140128494741248 run_lib.py:152] step: 55850, training_loss: 2.90371e+01
I0514 17:12:56.545760 140128494741248 run_lib.py:152] step: 55900, training_loss: 2.75670e+01
I0514 17:12:56.595877 140128494741248 run_lib.py:165] step: 55900, eval_loss: 2.68965e+01
I0514 17:13:02.811840 140128494741248 run_lib.py:152] step: 55950, training_loss: 2.52528e+01
I0514 17:13:09.063513 140128494741248 run_lib.py:152] step: 56000, training_loss: 3.27094e+01
I0514 17:13:09.124094 140128494741248 run_lib.py:165] step: 56000, eval_loss: 1.42476e+01
I0514 17:13:15.484129 140128494741248 run_lib.py:152] step: 56050, training_loss: 2.06756e+01
I0514 17:13:21.736638 140128494741248 run_lib.py:152] step: 56100, training_loss: 3.18114e+01
I0514 17:13:21.787241 140128494741248 run_lib.py:165] step: 56100, eval_loss: 3.44433e+01
I0514 17:13:28.034747 140128494741248 run_lib.py:152] step: 56150, training_loss: 2.76098e+01
I0514 17:13:34.514999 140128494741248 run_lib.py:152] step: 56200, training_loss: 2.56653e+01
I0514 17:13:34.569579 140128494741248 run_lib.py:165] step: 56200, eval_loss: 3.31096e+01
I0514 17:13:40.781835 140128494741248 run_lib.py:152] step: 56250, training_loss: 4.60707e+01
I0514 17:13:47.120065 140128494741248 run_lib.py:152] step: 56300, training_loss: 2.40080e+01
I0514 17:13:47.174603 140128494741248 run_lib.py:165] step: 56300, eval_loss: 3.00988e+01
I0514 17:13:53.390072 140128494741248 run_lib.py:152] step: 56350, training_loss: 3.56307e+01
I0514 17:13:59.893800 140128494741248 run_lib.py:152] step: 56400, training_loss: 3.60839e+01
I0514 17:13:59.950247 140128494741248 run_lib.py:165] step: 56400, eval_loss: 3.05580e+01
I0514 17:14:06.186644 140128494741248 run_lib.py:152] step: 56450, training_loss: 2.42455e+01
I0514 17:14:12.393453 140128494741248 run_lib.py:152] step: 56500, training_loss: 1.98233e+01
I0514 17:14:12.450560 140128494741248 run_lib.py:165] step: 56500, eval_loss: 3.25867e+01
I0514 17:14:18.933795 140128494741248 run_lib.py:152] step: 56550, training_loss: 4.60676e+01
I0514 17:14:25.114103 140128494741248 run_lib.py:152] step: 56600, training_loss: 3.70553e+01
I0514 17:14:25.165723 140128494741248 run_lib.py:165] step: 56600, eval_loss: 3.79558e+01
I0514 17:14:31.305897 140128494741248 run_lib.py:152] step: 56650, training_loss: 3.98915e+01
I0514 17:14:37.580612 140128494741248 run_lib.py:152] step: 56700, training_loss: 4.46542e+01
I0514 17:14:37.635293 140128494741248 run_lib.py:165] step: 56700, eval_loss: 1.68604e+01
I0514 17:14:44.107125 140128494741248 run_lib.py:152] step: 56750, training_loss: 4.37803e+01
I0514 17:14:50.434087 140128494741248 run_lib.py:152] step: 56800, training_loss: 2.11474e+01
I0514 17:14:50.488147 140128494741248 run_lib.py:165] step: 56800, eval_loss: 2.92820e+01
I0514 17:14:56.645922 140128494741248 run_lib.py:152] step: 56850, training_loss: 3.04590e+01
I0514 17:15:03.160202 140128494741248 run_lib.py:152] step: 56900, training_loss: 2.78650e+01
I0514 17:15:03.216131 140128494741248 run_lib.py:165] step: 56900, eval_loss: 3.10308e+01
I0514 17:15:09.459714 140128494741248 run_lib.py:152] step: 56950, training_loss: 3.17308e+01
I0514 17:15:15.710024 140128494741248 run_lib.py:152] step: 57000, training_loss: 3.81167e+01
I0514 17:15:15.766387 140128494741248 run_lib.py:165] step: 57000, eval_loss: 2.86533e+01
I0514 17:15:21.991488 140128494741248 run_lib.py:152] step: 57050, training_loss: 4.09760e+01
I0514 17:15:28.432081 140128494741248 run_lib.py:152] step: 57100, training_loss: 4.12606e+01
I0514 17:15:28.487312 140128494741248 run_lib.py:165] step: 57100, eval_loss: 2.64096e+01
I0514 17:15:34.674757 140128494741248 run_lib.py:152] step: 57150, training_loss: 4.07112e+01
I0514 17:15:40.900611 140128494741248 run_lib.py:152] step: 57200, training_loss: 2.23254e+01
I0514 17:15:40.957618 140128494741248 run_lib.py:165] step: 57200, eval_loss: 3.55448e+01
I0514 17:15:47.413276 140128494741248 run_lib.py:152] step: 57250, training_loss: 5.23965e+01
I0514 17:15:53.648007 140128494741248 run_lib.py:152] step: 57300, training_loss: 3.15200e+01
I0514 17:15:53.699532 140128494741248 run_lib.py:165] step: 57300, eval_loss: 3.24473e+01
I0514 17:15:59.983006 140128494741248 run_lib.py:152] step: 57350, training_loss: 3.09694e+01
I0514 17:16:06.246198 140128494741248 run_lib.py:152] step: 57400, training_loss: 2.53844e+01
I0514 17:16:06.298186 140128494741248 run_lib.py:165] step: 57400, eval_loss: 2.23735e+01
I0514 17:16:12.734357 140128494741248 run_lib.py:152] step: 57450, training_loss: 3.80273e+01
I0514 17:16:18.928507 140128494741248 run_lib.py:152] step: 57500, training_loss: 3.47612e+01
I0514 17:16:18.978837 140128494741248 run_lib.py:165] step: 57500, eval_loss: 4.48560e+01
I0514 17:16:25.146878 140128494741248 run_lib.py:152] step: 57550, training_loss: 3.23082e+01
I0514 17:16:31.349770 140128494741248 run_lib.py:152] step: 57600, training_loss: 1.25367e+01
I0514 17:16:31.621659 140128494741248 run_lib.py:165] step: 57600, eval_loss: 4.42446e+01
I0514 17:16:37.739624 140128494741248 run_lib.py:152] step: 57650, training_loss: 3.68961e+01
I0514 17:16:43.990850 140128494741248 run_lib.py:152] step: 57700, training_loss: 3.61003e+01
I0514 17:16:44.038983 140128494741248 run_lib.py:165] step: 57700, eval_loss: 3.26368e+01
I0514 17:16:50.188446 140128494741248 run_lib.py:152] step: 57750, training_loss: 2.99078e+01
I0514 17:16:56.552584 140128494741248 run_lib.py:152] step: 57800, training_loss: 2.39590e+01
I0514 17:16:56.601212 140128494741248 run_lib.py:165] step: 57800, eval_loss: 3.79815e+01
I0514 17:17:02.831556 140128494741248 run_lib.py:152] step: 57850, training_loss: 4.31234e+01
I0514 17:17:09.041613 140128494741248 run_lib.py:152] step: 57900, training_loss: 3.32070e+01
I0514 17:17:09.090902 140128494741248 run_lib.py:165] step: 57900, eval_loss: 2.59383e+01
I0514 17:17:15.565797 140128494741248 run_lib.py:152] step: 57950, training_loss: 3.84675e+01
I0514 17:17:21.837017 140128494741248 run_lib.py:152] step: 58000, training_loss: 3.88234e+01
I0514 17:17:21.885736 140128494741248 run_lib.py:165] step: 58000, eval_loss: 3.14943e+01
I0514 17:17:28.131498 140128494741248 run_lib.py:152] step: 58050, training_loss: 2.09264e+01
I0514 17:17:34.333828 140128494741248 run_lib.py:152] step: 58100, training_loss: 2.06564e+01
I0514 17:17:34.382813 140128494741248 run_lib.py:165] step: 58100, eval_loss: 3.77925e+01
I0514 17:17:40.862246 140128494741248 run_lib.py:152] step: 58150, training_loss: 3.90828e+01
I0514 17:17:46.999067 140128494741248 run_lib.py:152] step: 58200, training_loss: 2.19496e+01
I0514 17:17:47.051089 140128494741248 run_lib.py:165] step: 58200, eval_loss: 1.71835e+01
I0514 17:17:53.277842 140128494741248 run_lib.py:152] step: 58250, training_loss: 1.91639e+01
I0514 17:17:59.738117 140128494741248 run_lib.py:152] step: 58300, training_loss: 2.81625e+01
I0514 17:17:59.785278 140128494741248 run_lib.py:165] step: 58300, eval_loss: 2.93232e+01
I0514 17:18:06.039746 140128494741248 run_lib.py:152] step: 58350, training_loss: 2.70104e+01
I0514 17:18:12.196244 140128494741248 run_lib.py:152] step: 58400, training_loss: 3.78718e+01
I0514 17:18:12.251003 140128494741248 run_lib.py:165] step: 58400, eval_loss: 2.59882e+01
I0514 17:18:18.487813 140128494741248 run_lib.py:152] step: 58450, training_loss: 1.81865e+01
I0514 17:18:24.943793 140128494741248 run_lib.py:152] step: 58500, training_loss: 2.55680e+01
I0514 17:18:24.993602 140128494741248 run_lib.py:165] step: 58500, eval_loss: 5.02495e+01
I0514 17:18:31.175040 140128494741248 run_lib.py:152] step: 58550, training_loss: 5.00152e+01
I0514 17:18:37.354300 140128494741248 run_lib.py:152] step: 58600, training_loss: 5.57515e+01
I0514 17:18:37.405215 140128494741248 run_lib.py:165] step: 58600, eval_loss: 1.63049e+01
I0514 17:18:43.813957 140128494741248 run_lib.py:152] step: 58650, training_loss: 2.52428e+01
I0514 17:18:50.035423 140128494741248 run_lib.py:152] step: 58700, training_loss: 5.02783e+01
I0514 17:18:50.088824 140128494741248 run_lib.py:165] step: 58700, eval_loss: 3.60586e+01
I0514 17:18:56.285558 140128494741248 run_lib.py:152] step: 58750, training_loss: 2.81813e+01
I0514 17:19:02.532219 140128494741248 run_lib.py:152] step: 58800, training_loss: 3.12673e+01
I0514 17:19:02.586034 140128494741248 run_lib.py:165] step: 58800, eval_loss: 3.78643e+01
I0514 17:19:09.074196 140128494741248 run_lib.py:152] step: 58850, training_loss: 2.34385e+01
I0514 17:19:15.356367 140128494741248 run_lib.py:152] step: 58900, training_loss: 5.04983e+01
I0514 17:19:15.407498 140128494741248 run_lib.py:165] step: 58900, eval_loss: 2.02783e+01
I0514 17:19:21.580195 140128494741248 run_lib.py:152] step: 58950, training_loss: 2.32942e+01
I0514 17:19:28.052837 140128494741248 run_lib.py:152] step: 59000, training_loss: 4.28517e+01
I0514 17:19:28.109850 140128494741248 run_lib.py:165] step: 59000, eval_loss: 3.61996e+01
I0514 17:19:34.369284 140128494741248 run_lib.py:152] step: 59050, training_loss: 2.74072e+01
I0514 17:19:40.564600 140128494741248 run_lib.py:152] step: 59100, training_loss: 3.73848e+01
I0514 17:19:40.614544 140128494741248 run_lib.py:165] step: 59100, eval_loss: 2.78333e+01
I0514 17:19:46.865505 140128494741248 run_lib.py:152] step: 59150, training_loss: 2.44106e+01
I0514 17:19:53.328890 140128494741248 run_lib.py:152] step: 59200, training_loss: 3.37096e+01
I0514 17:19:53.381516 140128494741248 run_lib.py:165] step: 59200, eval_loss: 3.65282e+01
I0514 17:19:59.643590 140128494741248 run_lib.py:152] step: 59250, training_loss: 3.78045e+01
I0514 17:20:05.912199 140128494741248 run_lib.py:152] step: 59300, training_loss: 2.67661e+01
I0514 17:20:05.962379 140128494741248 run_lib.py:165] step: 59300, eval_loss: 2.88245e+01
I0514 17:20:12.377970 140128494741248 run_lib.py:152] step: 59350, training_loss: 3.75723e+01
I0514 17:20:18.560115 140128494741248 run_lib.py:152] step: 59400, training_loss: 3.07482e+01
I0514 17:20:18.611770 140128494741248 run_lib.py:165] step: 59400, eval_loss: 3.17441e+01
I0514 17:20:24.863741 140128494741248 run_lib.py:152] step: 59450, training_loss: 3.03427e+01
I0514 17:20:31.094742 140128494741248 run_lib.py:152] step: 59500, training_loss: 3.95980e+01
I0514 17:20:31.147146 140128494741248 run_lib.py:165] step: 59500, eval_loss: 4.46905e+01
I0514 17:20:37.655249 140128494741248 run_lib.py:152] step: 59550, training_loss: 4.34099e+01
I0514 17:20:43.884362 140128494741248 run_lib.py:152] step: 59600, training_loss: 1.80990e+01
I0514 17:20:43.938561 140128494741248 run_lib.py:165] step: 59600, eval_loss: 2.56325e+01
I0514 17:20:50.177331 140128494741248 run_lib.py:152] step: 59650, training_loss: 3.54106e+01
I0514 17:20:56.664423 140128494741248 run_lib.py:152] step: 59700, training_loss: 2.75582e+01
I0514 17:20:56.715956 140128494741248 run_lib.py:165] step: 59700, eval_loss: 2.08945e+01
I0514 17:21:02.924794 140128494741248 run_lib.py:152] step: 59750, training_loss: 3.92745e+01
I0514 17:21:09.058203 140128494741248 run_lib.py:152] step: 59800, training_loss: 2.46053e+01
I0514 17:21:09.108231 140128494741248 run_lib.py:165] step: 59800, eval_loss: 3.64347e+01
I0514 17:21:15.311419 140128494741248 run_lib.py:152] step: 59850, training_loss: 3.12966e+01
I0514 17:21:21.782863 140128494741248 run_lib.py:152] step: 59900, training_loss: 4.46691e+01
I0514 17:21:21.835308 140128494741248 run_lib.py:165] step: 59900, eval_loss: 1.99564e+01
I0514 17:21:28.033515 140128494741248 run_lib.py:152] step: 59950, training_loss: 3.27465e+01
I0514 17:21:34.387544 140128494741248 run_lib.py:152] step: 60000, training_loss: 2.87472e+01
I0514 17:21:34.594429 140128494741248 run_lib.py:165] step: 60000, eval_loss: 3.04482e+01
I0514 17:21:41.049710 140128494741248 run_lib.py:152] step: 60050, training_loss: 2.32197e+01
I0514 17:21:47.291885 140128494741248 run_lib.py:152] step: 60100, training_loss: 3.79693e+01
I0514 17:21:47.342194 140128494741248 run_lib.py:165] step: 60100, eval_loss: 3.05389e+01
I0514 17:21:53.489834 140128494741248 run_lib.py:152] step: 60150, training_loss: 2.55289e+01
I0514 17:21:59.693690 140128494741248 run_lib.py:152] step: 60200, training_loss: 2.28408e+01
I0514 17:21:59.744700 140128494741248 run_lib.py:165] step: 60200, eval_loss: 3.20658e+01
I0514 17:22:06.173828 140128494741248 run_lib.py:152] step: 60250, training_loss: 2.11863e+01
I0514 17:22:12.369994 140128494741248 run_lib.py:152] step: 60300, training_loss: 3.46881e+01
I0514 17:22:12.423381 140128494741248 run_lib.py:165] step: 60300, eval_loss: 3.48600e+01
I0514 17:22:18.616939 140128494741248 run_lib.py:152] step: 60350, training_loss: 2.67064e+01
I0514 17:22:25.157707 140128494741248 run_lib.py:152] step: 60400, training_loss: 2.50043e+01
I0514 17:22:25.212789 140128494741248 run_lib.py:165] step: 60400, eval_loss: 3.69731e+01
I0514 17:22:31.412959 140128494741248 run_lib.py:152] step: 60450, training_loss: 2.76564e+01
I0514 17:22:37.641189 140128494741248 run_lib.py:152] step: 60500, training_loss: 2.99848e+01
I0514 17:22:37.697762 140128494741248 run_lib.py:165] step: 60500, eval_loss: 2.65644e+01
I0514 17:22:43.890614 140128494741248 run_lib.py:152] step: 60550, training_loss: 2.82992e+01
I0514 17:22:50.375526 140128494741248 run_lib.py:152] step: 60600, training_loss: 2.77045e+01
I0514 17:22:50.424980 140128494741248 run_lib.py:165] step: 60600, eval_loss: 3.04215e+01
I0514 17:22:56.670565 140128494741248 run_lib.py:152] step: 60650, training_loss: 3.39814e+01
I0514 17:23:02.891703 140128494741248 run_lib.py:152] step: 60700, training_loss: 3.42806e+01
I0514 17:23:02.948469 140128494741248 run_lib.py:165] step: 60700, eval_loss: 1.20400e+01
I0514 17:23:09.377825 140128494741248 run_lib.py:152] step: 60750, training_loss: 4.07185e+01
I0514 17:23:15.572004 140128494741248 run_lib.py:152] step: 60800, training_loss: 2.46260e+01
I0514 17:23:15.622967 140128494741248 run_lib.py:165] step: 60800, eval_loss: 3.51172e+01
I0514 17:23:21.801382 140128494741248 run_lib.py:152] step: 60850, training_loss: 3.70858e+01
I0514 17:23:28.114248 140128494741248 run_lib.py:152] step: 60900, training_loss: 2.26470e+01
I0514 17:23:28.166232 140128494741248 run_lib.py:165] step: 60900, eval_loss: 3.23939e+01
I0514 17:23:34.548752 140128494741248 run_lib.py:152] step: 60950, training_loss: 3.09804e+01
I0514 17:23:40.804728 140128494741248 run_lib.py:152] step: 61000, training_loss: 4.25249e+01
I0514 17:23:40.852505 140128494741248 run_lib.py:165] step: 61000, eval_loss: 2.33817e+01
I0514 17:23:47.052274 140128494741248 run_lib.py:152] step: 61050, training_loss: 3.49087e+01
I0514 17:23:53.578607 140128494741248 run_lib.py:152] step: 61100, training_loss: 2.81013e+01
I0514 17:23:53.632713 140128494741248 run_lib.py:165] step: 61100, eval_loss: 3.93867e+01
I0514 17:24:00.069730 140128494741248 run_lib.py:152] step: 61150, training_loss: 3.93900e+01
I0514 17:24:06.287621 140128494741248 run_lib.py:152] step: 61200, training_loss: 4.01670e+01
I0514 17:24:06.337632 140128494741248 run_lib.py:165] step: 61200, eval_loss: 2.26934e+01
I0514 17:24:12.581655 140128494741248 run_lib.py:152] step: 61250, training_loss: 3.77114e+01
I0514 17:24:18.966437 140128494741248 run_lib.py:152] step: 61300, training_loss: 2.96673e+01
I0514 17:24:19.018607 140128494741248 run_lib.py:165] step: 61300, eval_loss: 3.50854e+01
I0514 17:24:25.190500 140128494741248 run_lib.py:152] step: 61350, training_loss: 3.14204e+01
I0514 17:24:31.426909 140128494741248 run_lib.py:152] step: 61400, training_loss: 2.04665e+01
I0514 17:24:31.481674 140128494741248 run_lib.py:165] step: 61400, eval_loss: 3.17606e+01
I0514 17:24:37.945756 140128494741248 run_lib.py:152] step: 61450, training_loss: 3.96380e+01
I0514 17:24:44.222475 140128494741248 run_lib.py:152] step: 61500, training_loss: 3.18221e+01
I0514 17:24:44.271373 140128494741248 run_lib.py:165] step: 61500, eval_loss: 3.39874e+01
I0514 17:24:50.478080 140128494741248 run_lib.py:152] step: 61550, training_loss: 5.44844e+01
I0514 17:24:56.719307 140128494741248 run_lib.py:152] step: 61600, training_loss: 3.53602e+01
I0514 17:24:56.770729 140128494741248 run_lib.py:165] step: 61600, eval_loss: 2.59214e+01
I0514 17:25:03.349372 140128494741248 run_lib.py:152] step: 61650, training_loss: 3.36385e+01
I0514 17:25:09.560297 140128494741248 run_lib.py:152] step: 61700, training_loss: 3.93949e+01
I0514 17:25:09.613713 140128494741248 run_lib.py:165] step: 61700, eval_loss: 4.48987e+01
I0514 17:25:15.833436 140128494741248 run_lib.py:152] step: 61750, training_loss: 2.91341e+01
I0514 17:25:22.328288 140128494741248 run_lib.py:152] step: 61800, training_loss: 4.73749e+01
I0514 17:25:22.377492 140128494741248 run_lib.py:165] step: 61800, eval_loss: 2.49152e+01
I0514 17:25:28.698338 140128494741248 run_lib.py:152] step: 61850, training_loss: 2.91504e+01
I0514 17:25:34.830455 140128494741248 run_lib.py:152] step: 61900, training_loss: 3.70465e+01
I0514 17:25:34.882739 140128494741248 run_lib.py:165] step: 61900, eval_loss: 3.13792e+01
I0514 17:25:41.159195 140128494741248 run_lib.py:152] step: 61950, training_loss: 3.50791e+01
I0514 17:25:47.575880 140128494741248 run_lib.py:152] step: 62000, training_loss: 2.86513e+01
I0514 17:25:47.628296 140128494741248 run_lib.py:165] step: 62000, eval_loss: 1.21166e+01
I0514 17:25:53.921106 140128494741248 run_lib.py:152] step: 62050, training_loss: 5.61473e+01
I0514 17:26:00.163719 140128494741248 run_lib.py:152] step: 62100, training_loss: 2.72227e+01
I0514 17:26:00.213219 140128494741248 run_lib.py:165] step: 62100, eval_loss: 4.49374e+01
I0514 17:26:06.715192 140128494741248 run_lib.py:152] step: 62150, training_loss: 3.03022e+01
I0514 17:26:12.920351 140128494741248 run_lib.py:152] step: 62200, training_loss: 5.61152e+01
I0514 17:26:12.970359 140128494741248 run_lib.py:165] step: 62200, eval_loss: 3.40930e+01
I0514 17:26:19.190083 140128494741248 run_lib.py:152] step: 62250, training_loss: 3.99439e+01
I0514 17:26:25.450534 140128494741248 run_lib.py:152] step: 62300, training_loss: 3.19271e+01
I0514 17:26:25.501247 140128494741248 run_lib.py:165] step: 62300, eval_loss: 3.44103e+01
I0514 17:26:32.016825 140128494741248 run_lib.py:152] step: 62350, training_loss: 4.73600e+01
I0514 17:26:38.272897 140128494741248 run_lib.py:152] step: 62400, training_loss: 2.73594e+01
I0514 17:26:38.323167 140128494741248 run_lib.py:165] step: 62400, eval_loss: 2.10233e+01
I0514 17:26:44.633024 140128494741248 run_lib.py:152] step: 62450, training_loss: 3.09133e+01
I0514 17:26:51.068411 140128494741248 run_lib.py:152] step: 62500, training_loss: 2.96080e+01
I0514 17:26:51.121560 140128494741248 run_lib.py:165] step: 62500, eval_loss: 3.76228e+01
I0514 17:26:57.339176 140128494741248 run_lib.py:152] step: 62550, training_loss: 3.83785e+01
I0514 17:27:03.573804 140128494741248 run_lib.py:152] step: 62600, training_loss: 1.82255e+01
I0514 17:27:03.627221 140128494741248 run_lib.py:165] step: 62600, eval_loss: 3.59304e+01
I0514 17:27:09.933203 140128494741248 run_lib.py:152] step: 62650, training_loss: 1.84424e+01
I0514 17:27:16.412576 140128494741248 run_lib.py:152] step: 62700, training_loss: 2.84276e+01
I0514 17:27:16.464973 140128494741248 run_lib.py:165] step: 62700, eval_loss: 5.12652e+01
I0514 17:27:22.688643 140128494741248 run_lib.py:152] step: 62750, training_loss: 4.28160e+01
I0514 17:27:28.876219 140128494741248 run_lib.py:152] step: 62800, training_loss: 3.01222e+01
I0514 17:27:28.931019 140128494741248 run_lib.py:165] step: 62800, eval_loss: 4.33548e+01
I0514 17:27:35.439596 140128494741248 run_lib.py:152] step: 62850, training_loss: 4.64168e+01
I0514 17:27:41.643880 140128494741248 run_lib.py:152] step: 62900, training_loss: 3.01587e+01
I0514 17:27:41.701538 140128494741248 run_lib.py:165] step: 62900, eval_loss: 3.48264e+01
I0514 17:27:48.042096 140128494741248 run_lib.py:152] step: 62950, training_loss: 4.22438e+01
I0514 17:27:54.310785 140128494741248 run_lib.py:152] step: 63000, training_loss: 3.51369e+01
I0514 17:27:54.360585 140128494741248 run_lib.py:165] step: 63000, eval_loss: 1.25140e+01
I0514 17:28:00.856590 140128494741248 run_lib.py:152] step: 63050, training_loss: 3.05122e+01
I0514 17:28:07.023614 140128494741248 run_lib.py:152] step: 63100, training_loss: 1.87049e+01
I0514 17:28:07.072208 140128494741248 run_lib.py:165] step: 63100, eval_loss: 4.48295e+01
I0514 17:28:13.283963 140128494741248 run_lib.py:152] step: 63150, training_loss: 4.35780e+01
I0514 17:28:19.657620 140128494741248 run_lib.py:152] step: 63200, training_loss: 5.93867e+01
I0514 17:28:19.710704 140128494741248 run_lib.py:165] step: 63200, eval_loss: 2.86601e+01
I0514 17:28:25.991472 140128494741248 run_lib.py:152] step: 63250, training_loss: 2.88880e+01
I0514 17:28:32.249518 140128494741248 run_lib.py:152] step: 63300, training_loss: 2.82459e+01
I0514 17:28:32.305610 140128494741248 run_lib.py:165] step: 63300, eval_loss: 3.39620e+01
I0514 17:28:38.482162 140128494741248 run_lib.py:152] step: 63350, training_loss: 3.47458e+01
I0514 17:28:44.845484 140128494741248 run_lib.py:152] step: 63400, training_loss: 2.69696e+01
I0514 17:28:44.898572 140128494741248 run_lib.py:165] step: 63400, eval_loss: 2.13363e+01
I0514 17:28:51.166028 140128494741248 run_lib.py:152] step: 63450, training_loss: 3.15659e+01
I0514 17:28:57.255252 140128494741248 run_lib.py:152] step: 63500, training_loss: 3.58298e+01
I0514 17:28:57.307123 140128494741248 run_lib.py:165] step: 63500, eval_loss: 3.11403e+01
I0514 17:29:03.758692 140128494741248 run_lib.py:152] step: 63550, training_loss: 5.03393e+01
I0514 17:29:09.978078 140128494741248 run_lib.py:152] step: 63600, training_loss: 4.25729e+01
I0514 17:29:10.033842 140128494741248 run_lib.py:165] step: 63600, eval_loss: 2.41629e+01
I0514 17:29:16.183195 140128494741248 run_lib.py:152] step: 63650, training_loss: 4.46565e+01
I0514 17:29:22.348392 140128494741248 run_lib.py:152] step: 63700, training_loss: 3.89853e+01
I0514 17:29:22.394831 140128494741248 run_lib.py:165] step: 63700, eval_loss: 2.84423e+01
I0514 17:29:28.849300 140128494741248 run_lib.py:152] step: 63750, training_loss: 4.69866e+01
I0514 17:29:35.007526 140128494741248 run_lib.py:152] step: 63800, training_loss: 3.22239e+01
I0514 17:29:35.060261 140128494741248 run_lib.py:165] step: 63800, eval_loss: 5.04440e+01
I0514 17:29:41.351874 140128494741248 run_lib.py:152] step: 63850, training_loss: 4.64081e+01
I0514 17:29:47.830668 140128494741248 run_lib.py:152] step: 63900, training_loss: 4.63225e+01
I0514 17:29:47.884603 140128494741248 run_lib.py:165] step: 63900, eval_loss: 3.55007e+01
I0514 17:29:54.070023 140128494741248 run_lib.py:152] step: 63950, training_loss: 2.21573e+01
I0514 17:30:00.225533 140128494741248 run_lib.py:152] step: 64000, training_loss: 4.54277e+01
I0514 17:30:00.279664 140128494741248 run_lib.py:165] step: 64000, eval_loss: 3.29759e+01
I0514 17:30:06.509446 140128494741248 run_lib.py:152] step: 64050, training_loss: 4.64542e+01
I0514 17:30:13.028897 140128494741248 run_lib.py:152] step: 64100, training_loss: 4.39713e+01
I0514 17:30:13.081147 140128494741248 run_lib.py:165] step: 64100, eval_loss: 3.49154e+01
I0514 17:30:19.206804 140128494741248 run_lib.py:152] step: 64150, training_loss: 3.40298e+01
I0514 17:30:25.479010 140128494741248 run_lib.py:152] step: 64200, training_loss: 3.63071e+01
I0514 17:30:25.533581 140128494741248 run_lib.py:165] step: 64200, eval_loss: 2.88326e+01
I0514 17:30:31.977812 140128494741248 run_lib.py:152] step: 64250, training_loss: 3.49555e+01
I0514 17:30:38.213385 140128494741248 run_lib.py:152] step: 64300, training_loss: 3.97957e+01
I0514 17:30:38.265280 140128494741248 run_lib.py:165] step: 64300, eval_loss: 4.00753e+01
I0514 17:30:44.553190 140128494741248 run_lib.py:152] step: 64350, training_loss: 2.82495e+01
I0514 17:30:50.712085 140128494741248 run_lib.py:152] step: 64400, training_loss: 3.81892e+01
I0514 17:30:50.765534 140128494741248 run_lib.py:165] step: 64400, eval_loss: 4.02586e+01
I0514 17:30:57.265272 140128494741248 run_lib.py:152] step: 64450, training_loss: 2.86889e+01
I0514 17:31:03.553054 140128494741248 run_lib.py:152] step: 64500, training_loss: 2.72743e+01
I0514 17:31:03.602938 140128494741248 run_lib.py:165] step: 64500, eval_loss: 3.63197e+01
I0514 17:31:09.841804 140128494741248 run_lib.py:152] step: 64550, training_loss: 3.78188e+01
I0514 17:31:16.230746 140128494741248 run_lib.py:152] step: 64600, training_loss: 4.67115e+01
I0514 17:31:16.291157 140128494741248 run_lib.py:165] step: 64600, eval_loss: 3.06914e+01
I0514 17:31:22.587046 140128494741248 run_lib.py:152] step: 64650, training_loss: 4.63303e+01
I0514 17:31:28.856884 140128494741248 run_lib.py:152] step: 64700, training_loss: 3.34249e+01
I0514 17:31:28.908593 140128494741248 run_lib.py:165] step: 64700, eval_loss: 2.91814e+01
I0514 17:31:35.053213 140128494741248 run_lib.py:152] step: 64750, training_loss: 3.51358e+01
I0514 17:31:41.509570 140128494741248 run_lib.py:152] step: 64800, training_loss: 3.78197e+01
I0514 17:31:41.558931 140128494741248 run_lib.py:165] step: 64800, eval_loss: 3.21048e+01
I0514 17:31:47.723059 140128494741248 run_lib.py:152] step: 64850, training_loss: 3.82007e+01
I0514 17:31:53.968452 140128494741248 run_lib.py:152] step: 64900, training_loss: 2.97172e+01
I0514 17:31:54.022922 140128494741248 run_lib.py:165] step: 64900, eval_loss: 4.35048e+01
I0514 17:32:00.392634 140128494741248 run_lib.py:152] step: 64950, training_loss: 3.49462e+01
I0514 17:32:06.700091 140128494741248 run_lib.py:152] step: 65000, training_loss: 4.63214e+01
I0514 17:32:06.762309 140128494741248 run_lib.py:165] step: 65000, eval_loss: 1.79763e+01
I0514 17:32:12.935852 140128494741248 run_lib.py:152] step: 65050, training_loss: 2.86201e+01
I0514 17:32:19.165639 140128494741248 run_lib.py:152] step: 65100, training_loss: 2.22955e+01
I0514 17:32:19.219202 140128494741248 run_lib.py:165] step: 65100, eval_loss: 3.38852e+01
I0514 17:32:25.727823 140128494741248 run_lib.py:152] step: 65150, training_loss: 1.39182e+01
I0514 17:32:31.942737 140128494741248 run_lib.py:152] step: 65200, training_loss: 3.48798e+01
I0514 17:32:31.994006 140128494741248 run_lib.py:165] step: 65200, eval_loss: 3.59950e+01
I0514 17:32:38.261728 140128494741248 run_lib.py:152] step: 65250, training_loss: 3.50330e+01
I0514 17:32:44.740511 140128494741248 run_lib.py:152] step: 65300, training_loss: 2.70231e+01
I0514 17:32:44.790147 140128494741248 run_lib.py:165] step: 65300, eval_loss: 2.54750e+01
I0514 17:32:50.991546 140128494741248 run_lib.py:152] step: 65350, training_loss: 4.44686e+01
I0514 17:32:57.199657 140128494741248 run_lib.py:152] step: 65400, training_loss: 3.42421e+01
I0514 17:32:57.253150 140128494741248 run_lib.py:165] step: 65400, eval_loss: 3.81941e+01
I0514 17:33:03.403498 140128494741248 run_lib.py:152] step: 65450, training_loss: 4.71723e+01
I0514 17:33:09.874395 140128494741248 run_lib.py:152] step: 65500, training_loss: 4.88013e+01
I0514 17:33:09.929932 140128494741248 run_lib.py:165] step: 65500, eval_loss: 4.25516e+01
I0514 17:33:16.155067 140128494741248 run_lib.py:152] step: 65550, training_loss: 3.57786e+01
I0514 17:33:22.367254 140128494741248 run_lib.py:152] step: 65600, training_loss: 2.03140e+01
I0514 17:33:22.417501 140128494741248 run_lib.py:165] step: 65600, eval_loss: 2.74922e+01
I0514 17:33:28.811194 140128494741248 run_lib.py:152] step: 65650, training_loss: 2.57202e+01
I0514 17:33:35.085095 140128494741248 run_lib.py:152] step: 65700, training_loss: 2.77970e+01
I0514 17:33:35.137246 140128494741248 run_lib.py:165] step: 65700, eval_loss: 2.13271e+01
I0514 17:33:41.295568 140128494741248 run_lib.py:152] step: 65750, training_loss: 3.89200e+01
I0514 17:33:47.455859 140128494741248 run_lib.py:152] step: 65800, training_loss: 3.31730e+01
I0514 17:33:47.505526 140128494741248 run_lib.py:165] step: 65800, eval_loss: 4.78290e+01
I0514 17:33:54.101960 140128494741248 run_lib.py:152] step: 65850, training_loss: 3.69164e+01
I0514 17:34:00.321578 140128494741248 run_lib.py:152] step: 65900, training_loss: 3.80445e+01
I0514 17:34:00.380259 140128494741248 run_lib.py:165] step: 65900, eval_loss: 4.02139e+01
I0514 17:34:06.696801 140128494741248 run_lib.py:152] step: 65950, training_loss: 3.92864e+01
I0514 17:34:13.093061 140128494741248 run_lib.py:152] step: 66000, training_loss: 2.22579e+01
I0514 17:34:13.152408 140128494741248 run_lib.py:165] step: 66000, eval_loss: 3.13912e+01
I0514 17:34:19.239353 140128494741248 run_lib.py:152] step: 66050, training_loss: 3.49262e+01
I0514 17:34:25.619935 140128494741248 run_lib.py:152] step: 66100, training_loss: 3.24904e+01
I0514 17:34:25.676200 140128494741248 run_lib.py:165] step: 66100, eval_loss: 3.26035e+01
I0514 17:34:31.870118 140128494741248 run_lib.py:152] step: 66150, training_loss: 3.94628e+01
I0514 17:34:38.335943 140128494741248 run_lib.py:152] step: 66200, training_loss: 3.94917e+01
I0514 17:34:38.387957 140128494741248 run_lib.py:165] step: 66200, eval_loss: 2.83986e+01
I0514 17:34:44.659157 140128494741248 run_lib.py:152] step: 66250, training_loss: 2.70091e+01
I0514 17:34:50.941878 140128494741248 run_lib.py:152] step: 66300, training_loss: 2.37179e+01
I0514 17:34:50.997061 140128494741248 run_lib.py:165] step: 66300, eval_loss: 4.03738e+01
I0514 17:34:57.400115 140128494741248 run_lib.py:152] step: 66350, training_loss: 2.88676e+01
I0514 17:35:03.620660 140128494741248 run_lib.py:152] step: 66400, training_loss: 4.12118e+01
I0514 17:35:03.669698 140128494741248 run_lib.py:165] step: 66400, eval_loss: 3.19585e+01
I0514 17:35:09.926875 140128494741248 run_lib.py:152] step: 66450, training_loss: 3.39219e+01
I0514 17:35:16.132113 140128494741248 run_lib.py:152] step: 66500, training_loss: 3.79900e+01
I0514 17:35:16.185699 140128494741248 run_lib.py:165] step: 66500, eval_loss: 3.52979e+01
I0514 17:35:22.614372 140128494741248 run_lib.py:152] step: 66550, training_loss: 3.41377e+01
I0514 17:35:28.880480 140128494741248 run_lib.py:152] step: 66600, training_loss: 4.42780e+01
I0514 17:35:28.935683 140128494741248 run_lib.py:165] step: 66600, eval_loss: 1.15659e+01
I0514 17:35:35.261109 140128494741248 run_lib.py:152] step: 66650, training_loss: 3.79082e+01
I0514 17:35:41.625544 140128494741248 run_lib.py:152] step: 66700, training_loss: 2.83158e+01
I0514 17:35:41.674908 140128494741248 run_lib.py:165] step: 66700, eval_loss: 3.59606e+01
I0514 17:35:47.813469 140128494741248 run_lib.py:152] step: 66750, training_loss: 2.72250e+01
I0514 17:35:53.957051 140128494741248 run_lib.py:152] step: 66800, training_loss: 3.92738e+01
I0514 17:35:54.007001 140128494741248 run_lib.py:165] step: 66800, eval_loss: 2.81488e+01
I0514 17:36:00.192420 140128494741248 run_lib.py:152] step: 66850, training_loss: 2.89548e+01
I0514 17:36:06.643595 140128494741248 run_lib.py:152] step: 66900, training_loss: 2.79353e+01
I0514 17:36:06.696073 140128494741248 run_lib.py:165] step: 66900, eval_loss: 4.13590e+01
I0514 17:36:12.832666 140128494741248 run_lib.py:152] step: 66950, training_loss: 4.37715e+01
I0514 17:36:19.077416 140128494741248 run_lib.py:152] step: 67000, training_loss: 3.61400e+01
I0514 17:36:19.128055 140128494741248 run_lib.py:165] step: 67000, eval_loss: 3.45587e+01
I0514 17:36:25.557578 140128494741248 run_lib.py:152] step: 67050, training_loss: 3.43510e+01
I0514 17:36:31.724899 140128494741248 run_lib.py:152] step: 67100, training_loss: 3.54447e+01
I0514 17:36:31.776721 140128494741248 run_lib.py:165] step: 67100, eval_loss: 1.55713e+01
I0514 17:36:37.933604 140128494741248 run_lib.py:152] step: 67150, training_loss: 2.54586e+01
I0514 17:36:44.179863 140128494741248 run_lib.py:152] step: 67200, training_loss: 3.49747e+01
I0514 17:36:44.230366 140128494741248 run_lib.py:165] step: 67200, eval_loss: 4.20283e+01
I0514 17:36:50.668097 140128494741248 run_lib.py:152] step: 67250, training_loss: 3.55476e+01
I0514 17:36:56.826113 140128494741248 run_lib.py:152] step: 67300, training_loss: 4.86136e+01
I0514 17:36:56.875338 140128494741248 run_lib.py:165] step: 67300, eval_loss: 2.51277e+01
I0514 17:37:03.113112 140128494741248 run_lib.py:152] step: 67350, training_loss: 2.90981e+01
I0514 17:37:09.469258 140128494741248 run_lib.py:152] step: 67400, training_loss: 2.88255e+01
I0514 17:37:09.523105 140128494741248 run_lib.py:165] step: 67400, eval_loss: 2.99462e+01
I0514 17:37:15.682127 140128494741248 run_lib.py:152] step: 67450, training_loss: 2.28903e+01
I0514 17:37:21.830945 140128494741248 run_lib.py:152] step: 67500, training_loss: 2.85083e+01
I0514 17:37:21.889976 140128494741248 run_lib.py:165] step: 67500, eval_loss: 3.56806e+01
I0514 17:37:28.140078 140128494741248 run_lib.py:152] step: 67550, training_loss: 4.29407e+01
I0514 17:37:34.516882 140128494741248 run_lib.py:152] step: 67600, training_loss: 3.75064e+01
I0514 17:37:34.569989 140128494741248 run_lib.py:165] step: 67600, eval_loss: 1.81518e+01
I0514 17:37:40.834294 140128494741248 run_lib.py:152] step: 67650, training_loss: 2.62419e+01
I0514 17:37:47.126640 140128494741248 run_lib.py:152] step: 67700, training_loss: 3.74602e+01
I0514 17:37:47.183393 140128494741248 run_lib.py:165] step: 67700, eval_loss: 2.88438e+01
I0514 17:37:53.592253 140128494741248 run_lib.py:152] step: 67750, training_loss: 3.22245e+01
I0514 17:37:59.689720 140128494741248 run_lib.py:152] step: 67800, training_loss: 4.40586e+01
I0514 17:37:59.743461 140128494741248 run_lib.py:165] step: 67800, eval_loss: 4.35392e+01
I0514 17:38:05.955750 140128494741248 run_lib.py:152] step: 67850, training_loss: 3.63500e+01
I0514 17:38:12.075348 140128494741248 run_lib.py:152] step: 67900, training_loss: 2.69438e+01
I0514 17:38:12.126468 140128494741248 run_lib.py:165] step: 67900, eval_loss: 2.23827e+01
I0514 17:38:18.536880 140128494741248 run_lib.py:152] step: 67950, training_loss: 3.70512e+01
I0514 17:38:24.699029 140128494741248 run_lib.py:152] step: 68000, training_loss: 1.97421e+01
I0514 17:38:24.748201 140128494741248 run_lib.py:165] step: 68000, eval_loss: 3.57109e+01
I0514 17:38:30.967174 140128494741248 run_lib.py:152] step: 68050, training_loss: 3.36032e+01
I0514 17:38:37.408051 140128494741248 run_lib.py:152] step: 68100, training_loss: 3.56373e+01
I0514 17:38:37.459475 140128494741248 run_lib.py:165] step: 68100, eval_loss: 3.34595e+01
I0514 17:38:43.751443 140128494741248 run_lib.py:152] step: 68150, training_loss: 4.59196e+01
I0514 17:38:49.957073 140128494741248 run_lib.py:152] step: 68200, training_loss: 5.26057e+01
I0514 17:38:50.014292 140128494741248 run_lib.py:165] step: 68200, eval_loss: 2.24363e+01
I0514 17:38:56.197000 140128494741248 run_lib.py:152] step: 68250, training_loss: 4.13531e+01
I0514 17:39:02.650364 140128494741248 run_lib.py:152] step: 68300, training_loss: 3.51037e+01
I0514 17:39:02.700628 140128494741248 run_lib.py:165] step: 68300, eval_loss: 5.09522e+01
I0514 17:39:08.972476 140128494741248 run_lib.py:152] step: 68350, training_loss: 2.35232e+01
I0514 17:39:15.105637 140128494741248 run_lib.py:152] step: 68400, training_loss: 2.53162e+01
I0514 17:39:15.155958 140128494741248 run_lib.py:165] step: 68400, eval_loss: 5.32791e+01
I0514 17:39:21.532072 140128494741248 run_lib.py:152] step: 68450, training_loss: 3.14196e+01
I0514 17:39:27.724496 140128494741248 run_lib.py:152] step: 68500, training_loss: 3.95988e+01
I0514 17:39:27.776224 140128494741248 run_lib.py:165] step: 68500, eval_loss: 1.50959e+01
I0514 17:39:33.902397 140128494741248 run_lib.py:152] step: 68550, training_loss: 5.12566e+01
I0514 17:39:40.094975 140128494741248 run_lib.py:152] step: 68600, training_loss: 2.47247e+01
I0514 17:39:40.149528 140128494741248 run_lib.py:165] step: 68600, eval_loss: 3.69880e+01
I0514 17:39:46.477673 140128494741248 run_lib.py:152] step: 68650, training_loss: 3.38211e+01
I0514 17:39:52.743113 140128494741248 run_lib.py:152] step: 68700, training_loss: 4.31935e+01
I0514 17:39:52.796656 140128494741248 run_lib.py:165] step: 68700, eval_loss: 1.97625e+01
I0514 17:39:58.961124 140128494741248 run_lib.py:152] step: 68750, training_loss: 3.24336e+01
I0514 17:40:05.473554 140128494741248 run_lib.py:152] step: 68800, training_loss: 4.17691e+01
I0514 17:40:05.529592 140128494741248 run_lib.py:165] step: 68800, eval_loss: 2.84221e+01
I0514 17:40:11.675222 140128494741248 run_lib.py:152] step: 68850, training_loss: 3.53731e+01
I0514 17:40:17.864187 140128494741248 run_lib.py:152] step: 68900, training_loss: 3.59278e+01
I0514 17:40:17.914008 140128494741248 run_lib.py:165] step: 68900, eval_loss: 3.74563e+01
I0514 17:40:24.118018 140128494741248 run_lib.py:152] step: 68950, training_loss: 4.34615e+01
I0514 17:40:30.555519 140128494741248 run_lib.py:152] step: 69000, training_loss: 4.91854e+01
I0514 17:40:30.611201 140128494741248 run_lib.py:165] step: 69000, eval_loss: 4.96525e+01
I0514 17:40:36.803350 140128494741248 run_lib.py:152] step: 69050, training_loss: 4.30952e+01
I0514 17:40:43.073250 140128494741248 run_lib.py:152] step: 69100, training_loss: 3.88339e+01
I0514 17:40:43.130119 140128494741248 run_lib.py:165] step: 69100, eval_loss: 2.86347e+01
I0514 17:40:49.598497 140128494741248 run_lib.py:152] step: 69150, training_loss: 3.81103e+01
I0514 17:40:55.703235 140128494741248 run_lib.py:152] step: 69200, training_loss: 4.86540e+01
I0514 17:40:55.758587 140128494741248 run_lib.py:165] step: 69200, eval_loss: 3.58571e+01
I0514 17:41:01.998992 140128494741248 run_lib.py:152] step: 69250, training_loss: 3.94099e+01
I0514 17:41:08.149685 140128494741248 run_lib.py:152] step: 69300, training_loss: 3.20103e+01
I0514 17:41:08.200725 140128494741248 run_lib.py:165] step: 69300, eval_loss: 3.24717e+01
I0514 17:41:14.605734 140128494741248 run_lib.py:152] step: 69350, training_loss: 2.83461e+01
I0514 17:41:20.810492 140128494741248 run_lib.py:152] step: 69400, training_loss: 3.76116e+01
I0514 17:41:20.865699 140128494741248 run_lib.py:165] step: 69400, eval_loss: 5.38882e+01
I0514 17:41:27.113194 140128494741248 run_lib.py:152] step: 69450, training_loss: 5.11975e+01
I0514 17:41:33.574521 140128494741248 run_lib.py:152] step: 69500, training_loss: 4.41845e+01
I0514 17:41:33.626927 140128494741248 run_lib.py:165] step: 69500, eval_loss: 2.75179e+01
I0514 17:41:39.853923 140128494741248 run_lib.py:152] step: 69550, training_loss: 2.47531e+01
I0514 17:41:46.043579 140128494741248 run_lib.py:152] step: 69600, training_loss: 3.16839e+01
I0514 17:41:46.092453 140128494741248 run_lib.py:165] step: 69600, eval_loss: 2.51601e+01
I0514 17:41:52.399020 140128494741248 run_lib.py:152] step: 69650, training_loss: 4.51044e+01
I0514 17:41:58.814308 140128494741248 run_lib.py:152] step: 69700, training_loss: 1.94695e+01
I0514 17:41:58.871623 140128494741248 run_lib.py:165] step: 69700, eval_loss: 2.64994e+01
I0514 17:42:05.074202 140128494741248 run_lib.py:152] step: 69750, training_loss: 3.30008e+01
I0514 17:42:11.259123 140128494741248 run_lib.py:152] step: 69800, training_loss: 2.49949e+01
I0514 17:42:11.316565 140128494741248 run_lib.py:165] step: 69800, eval_loss: 3.23975e+01
I0514 17:42:17.718940 140128494741248 run_lib.py:152] step: 69850, training_loss: 3.69159e+01
I0514 17:42:23.956939 140128494741248 run_lib.py:152] step: 69900, training_loss: 3.42656e+01
I0514 17:42:24.005707 140128494741248 run_lib.py:165] step: 69900, eval_loss: 1.09530e+01
I0514 17:42:30.161266 140128494741248 run_lib.py:152] step: 69950, training_loss: 2.19820e+01
I0514 17:42:36.331589 140128494741248 run_lib.py:152] step: 70000, training_loss: 4.77461e+01
I0514 17:42:36.752928 140128494741248 run_lib.py:165] step: 70000, eval_loss: 3.69256e+01
I0514 17:42:42.871223 140128494741248 run_lib.py:152] step: 70050, training_loss: 3.19537e+01
I0514 17:42:49.059885 140128494741248 run_lib.py:152] step: 70100, training_loss: 5.16867e+01
I0514 17:42:49.110956 140128494741248 run_lib.py:165] step: 70100, eval_loss: 3.38089e+01
I0514 17:42:55.339695 140128494741248 run_lib.py:152] step: 70150, training_loss: 3.59329e+01
I0514 17:43:01.886178 140128494741248 run_lib.py:152] step: 70200, training_loss: 3.08344e+01
I0514 17:43:01.944224 140128494741248 run_lib.py:165] step: 70200, eval_loss: 3.38224e+01
I0514 17:43:08.125271 140128494741248 run_lib.py:152] step: 70250, training_loss: 3.66105e+01
I0514 17:43:14.336491 140128494741248 run_lib.py:152] step: 70300, training_loss: 2.97154e+01
I0514 17:43:14.389237 140128494741248 run_lib.py:165] step: 70300, eval_loss: 3.26660e+01
I0514 17:43:20.797071 140128494741248 run_lib.py:152] step: 70350, training_loss: 4.30446e+01
I0514 17:43:27.009511 140128494741248 run_lib.py:152] step: 70400, training_loss: 3.34547e+01
I0514 17:43:27.058702 140128494741248 run_lib.py:165] step: 70400, eval_loss: 4.06317e+01
I0514 17:43:33.194386 140128494741248 run_lib.py:152] step: 70450, training_loss: 4.35847e+01
I0514 17:43:39.467763 140128494741248 run_lib.py:152] step: 70500, training_loss: 3.32173e+01
I0514 17:43:39.522799 140128494741248 run_lib.py:165] step: 70500, eval_loss: 4.80078e+01
I0514 17:43:46.010330 140128494741248 run_lib.py:152] step: 70550, training_loss: 3.36551e+01
I0514 17:43:52.148981 140128494741248 run_lib.py:152] step: 70600, training_loss: 2.48033e+01
I0514 17:43:52.198742 140128494741248 run_lib.py:165] step: 70600, eval_loss: 2.75104e+01
I0514 17:43:58.423058 140128494741248 run_lib.py:152] step: 70650, training_loss: 3.73577e+01
I0514 17:44:04.663429 140128494741248 run_lib.py:152] step: 70700, training_loss: 3.51658e+01
I0514 17:44:04.933636 140128494741248 run_lib.py:165] step: 70700, eval_loss: 3.95832e+01
I0514 17:44:11.096706 140128494741248 run_lib.py:152] step: 70750, training_loss: 4.04994e+01
I0514 17:44:17.359104 140128494741248 run_lib.py:152] step: 70800, training_loss: 3.49098e+01
I0514 17:44:17.412383 140128494741248 run_lib.py:165] step: 70800, eval_loss: 3.51056e+01
I0514 17:44:23.707112 140128494741248 run_lib.py:152] step: 70850, training_loss: 3.27091e+01
I0514 17:44:30.173544 140128494741248 run_lib.py:152] step: 70900, training_loss: 2.67124e+01
I0514 17:44:30.227558 140128494741248 run_lib.py:165] step: 70900, eval_loss: 2.98830e+01
I0514 17:44:36.372837 140128494741248 run_lib.py:152] step: 70950, training_loss: 2.63843e+01
I0514 17:44:42.614159 140128494741248 run_lib.py:152] step: 71000, training_loss: 3.54689e+01
I0514 17:44:42.669870 140128494741248 run_lib.py:165] step: 71000, eval_loss: 2.24486e+01
I0514 17:44:49.050337 140128494741248 run_lib.py:152] step: 71050, training_loss: 3.25060e+01
I0514 17:44:55.308178 140128494741248 run_lib.py:152] step: 71100, training_loss: 3.01424e+01
I0514 17:44:55.359069 140128494741248 run_lib.py:165] step: 71100, eval_loss: 2.24130e+01
I0514 17:45:01.666997 140128494741248 run_lib.py:152] step: 71150, training_loss: 3.77142e+01
I0514 17:45:07.817451 140128494741248 run_lib.py:152] step: 71200, training_loss: 2.84216e+01
I0514 17:45:07.873319 140128494741248 run_lib.py:165] step: 71200, eval_loss: 5.68950e+01
I0514 17:45:14.316567 140128494741248 run_lib.py:152] step: 71250, training_loss: 3.01976e+01
I0514 17:45:20.488179 140128494741248 run_lib.py:152] step: 71300, training_loss: 3.40868e+01
I0514 17:45:20.536263 140128494741248 run_lib.py:165] step: 71300, eval_loss: 3.42160e+01
I0514 17:45:26.748744 140128494741248 run_lib.py:152] step: 71350, training_loss: 3.74621e+01
I0514 17:45:33.266047 140128494741248 run_lib.py:152] step: 71400, training_loss: 4.69842e+01
I0514 17:45:33.319113 140128494741248 run_lib.py:165] step: 71400, eval_loss: 3.38125e+01
I0514 17:45:39.543718 140128494741248 run_lib.py:152] step: 71450, training_loss: 3.44772e+01
I0514 17:45:45.751291 140128494741248 run_lib.py:152] step: 71500, training_loss: 1.66865e+01
I0514 17:45:45.801711 140128494741248 run_lib.py:165] step: 71500, eval_loss: 2.71267e+01
I0514 17:45:51.961599 140128494741248 run_lib.py:152] step: 71550, training_loss: 5.57416e+01
I0514 17:45:58.423663 140128494741248 run_lib.py:152] step: 71600, training_loss: 3.53881e+01
I0514 17:45:58.473395 140128494741248 run_lib.py:165] step: 71600, eval_loss: 2.85472e+01
I0514 17:46:04.601639 140128494741248 run_lib.py:152] step: 71650, training_loss: 4.24819e+01
I0514 17:46:10.786612 140128494741248 run_lib.py:152] step: 71700, training_loss: 3.06910e+01
I0514 17:46:10.838830 140128494741248 run_lib.py:165] step: 71700, eval_loss: 4.04750e+01
I0514 17:46:17.201159 140128494741248 run_lib.py:152] step: 71750, training_loss: 3.41952e+01
I0514 17:46:23.485768 140128494741248 run_lib.py:152] step: 71800, training_loss: 2.88710e+01
I0514 17:46:23.541083 140128494741248 run_lib.py:165] step: 71800, eval_loss: 2.93074e+01
I0514 17:46:29.691878 140128494741248 run_lib.py:152] step: 71850, training_loss: 2.11551e+01
I0514 17:46:35.890637 140128494741248 run_lib.py:152] step: 71900, training_loss: 4.15459e+01
I0514 17:46:35.944318 140128494741248 run_lib.py:165] step: 71900, eval_loss: 2.36501e+01
I0514 17:46:42.396017 140128494741248 run_lib.py:152] step: 71950, training_loss: 3.54326e+01
I0514 17:46:48.659420 140128494741248 run_lib.py:152] step: 72000, training_loss: 3.78050e+01
I0514 17:46:48.709405 140128494741248 run_lib.py:165] step: 72000, eval_loss: 3.97549e+01
I0514 17:46:54.925175 140128494741248 run_lib.py:152] step: 72050, training_loss: 3.74780e+01
I0514 17:47:01.323969 140128494741248 run_lib.py:152] step: 72100, training_loss: 4.59325e+01
I0514 17:47:01.374038 140128494741248 run_lib.py:165] step: 72100, eval_loss: 1.97135e+01
I0514 17:47:07.498294 140128494741248 run_lib.py:152] step: 72150, training_loss: 2.36597e+01
I0514 17:47:13.700212 140128494741248 run_lib.py:152] step: 72200, training_loss: 5.82248e+01
I0514 17:47:13.748586 140128494741248 run_lib.py:165] step: 72200, eval_loss: 2.13091e+01
I0514 17:47:19.884704 140128494741248 run_lib.py:152] step: 72250, training_loss: 3.38961e+01
I0514 17:47:26.348035 140128494741248 run_lib.py:152] step: 72300, training_loss: 2.98172e+01
I0514 17:47:26.402751 140128494741248 run_lib.py:165] step: 72300, eval_loss: 4.35538e+01
I0514 17:47:32.608528 140128494741248 run_lib.py:152] step: 72350, training_loss: 3.71262e+01
I0514 17:47:38.839046 140128494741248 run_lib.py:152] step: 72400, training_loss: 1.89278e+01
I0514 17:47:38.889861 140128494741248 run_lib.py:165] step: 72400, eval_loss: 3.33252e+01
I0514 17:47:45.463734 140128494741248 run_lib.py:152] step: 72450, training_loss: 3.46516e+01
I0514 17:47:51.638635 140128494741248 run_lib.py:152] step: 72500, training_loss: 2.81580e+01
I0514 17:47:51.691841 140128494741248 run_lib.py:165] step: 72500, eval_loss: 2.51097e+01
I0514 17:47:57.940027 140128494741248 run_lib.py:152] step: 72550, training_loss: 2.73615e+01
I0514 17:48:04.180560 140128494741248 run_lib.py:152] step: 72600, training_loss: 2.57720e+01
I0514 17:48:04.231104 140128494741248 run_lib.py:165] step: 72600, eval_loss: 3.36519e+01
I0514 17:48:10.563343 140128494741248 run_lib.py:152] step: 72650, training_loss: 4.87203e+01
I0514 17:48:16.755114 140128494741248 run_lib.py:152] step: 72700, training_loss: 4.62435e+01
I0514 17:48:16.808283 140128494741248 run_lib.py:165] step: 72700, eval_loss: 2.69571e+01
I0514 17:48:23.080596 140128494741248 run_lib.py:152] step: 72750, training_loss: 4.42889e+01
I0514 17:48:29.527523 140128494741248 run_lib.py:152] step: 72800, training_loss: 3.96021e+01
I0514 17:48:29.579727 140128494741248 run_lib.py:165] step: 72800, eval_loss: 3.31824e+01
I0514 17:48:35.716243 140128494741248 run_lib.py:152] step: 72850, training_loss: 3.57307e+01
I0514 17:48:42.005595 140128494741248 run_lib.py:152] step: 72900, training_loss: 2.70692e+01
I0514 17:48:42.056646 140128494741248 run_lib.py:165] step: 72900, eval_loss: 4.20645e+01
I0514 17:48:48.205486 140128494741248 run_lib.py:152] step: 72950, training_loss: 2.35572e+01
I0514 17:48:54.662268 140128494741248 run_lib.py:152] step: 73000, training_loss: 3.14555e+01
I0514 17:48:54.717574 140128494741248 run_lib.py:165] step: 73000, eval_loss: 2.10966e+01
I0514 17:49:00.989260 140128494741248 run_lib.py:152] step: 73050, training_loss: 3.90096e+01
I0514 17:49:07.290784 140128494741248 run_lib.py:152] step: 73100, training_loss: 4.96987e+01
I0514 17:49:07.341269 140128494741248 run_lib.py:165] step: 73100, eval_loss: 3.32174e+01
I0514 17:49:13.794945 140128494741248 run_lib.py:152] step: 73150, training_loss: 3.26799e+01
I0514 17:49:19.994424 140128494741248 run_lib.py:152] step: 73200, training_loss: 3.58515e+01
I0514 17:49:20.046532 140128494741248 run_lib.py:165] step: 73200, eval_loss: 3.42174e+01
I0514 17:49:26.228253 140128494741248 run_lib.py:152] step: 73250, training_loss: 4.01822e+01
I0514 17:49:32.389478 140128494741248 run_lib.py:152] step: 73300, training_loss: 3.00268e+01
I0514 17:49:32.439461 140128494741248 run_lib.py:165] step: 73300, eval_loss: 2.08501e+01
I0514 17:49:38.968677 140128494741248 run_lib.py:152] step: 73350, training_loss: 3.98741e+01
I0514 17:49:45.160613 140128494741248 run_lib.py:152] step: 73400, training_loss: 2.97800e+01
I0514 17:49:45.208016 140128494741248 run_lib.py:165] step: 73400, eval_loss: 3.60003e+01
I0514 17:49:51.458897 140128494741248 run_lib.py:152] step: 73450, training_loss: 3.28305e+01
I0514 17:49:57.961071 140128494741248 run_lib.py:152] step: 73500, training_loss: 3.36177e+01
I0514 17:49:58.014291 140128494741248 run_lib.py:165] step: 73500, eval_loss: 3.53959e+01
I0514 17:50:04.249635 140128494741248 run_lib.py:152] step: 73550, training_loss: 4.10688e+01
I0514 17:50:10.413380 140128494741248 run_lib.py:152] step: 73600, training_loss: 3.97890e+01
I0514 17:50:10.469773 140128494741248 run_lib.py:165] step: 73600, eval_loss: 3.60049e+01
I0514 17:50:16.647904 140128494741248 run_lib.py:152] step: 73650, training_loss: 4.69629e+01
I0514 17:50:23.191386 140128494741248 run_lib.py:152] step: 73700, training_loss: 2.65126e+01
I0514 17:50:23.243838 140128494741248 run_lib.py:165] step: 73700, eval_loss: 3.82248e+01
I0514 17:50:29.416687 140128494741248 run_lib.py:152] step: 73750, training_loss: 2.02036e+01
I0514 17:50:35.583386 140128494741248 run_lib.py:152] step: 73800, training_loss: 2.59415e+01
I0514 17:50:35.637806 140128494741248 run_lib.py:165] step: 73800, eval_loss: 1.79617e+01
I0514 17:50:42.127201 140128494741248 run_lib.py:152] step: 73850, training_loss: 2.31337e+01
I0514 17:50:48.358404 140128494741248 run_lib.py:152] step: 73900, training_loss: 3.45807e+01
I0514 17:50:48.409467 140128494741248 run_lib.py:165] step: 73900, eval_loss: 2.81670e+01
I0514 17:50:54.605935 140128494741248 run_lib.py:152] step: 73950, training_loss: 4.69933e+01
I0514 17:51:00.864830 140128494741248 run_lib.py:152] step: 74000, training_loss: 4.46025e+01
I0514 17:51:00.918484 140128494741248 run_lib.py:165] step: 74000, eval_loss: 2.44991e+01
I0514 17:51:07.387219 140128494741248 run_lib.py:152] step: 74050, training_loss: 3.88017e+01
I0514 17:51:13.549526 140128494741248 run_lib.py:152] step: 74100, training_loss: 2.70848e+01
I0514 17:51:13.602018 140128494741248 run_lib.py:165] step: 74100, eval_loss: 4.32652e+01
I0514 17:51:19.810686 140128494741248 run_lib.py:152] step: 74150, training_loss: 2.66558e+01
I0514 17:51:25.952627 140128494741248 run_lib.py:152] step: 74200, training_loss: 3.03667e+01
I0514 17:51:26.230353 140128494741248 run_lib.py:165] step: 74200, eval_loss: 3.65473e+01
I0514 17:51:32.466870 140128494741248 run_lib.py:152] step: 74250, training_loss: 4.06828e+01
I0514 17:51:38.714729 140128494741248 run_lib.py:152] step: 74300, training_loss: 4.85309e+01
I0514 17:51:38.765939 140128494741248 run_lib.py:165] step: 74300, eval_loss: 1.89971e+01
I0514 17:51:44.977361 140128494741248 run_lib.py:152] step: 74350, training_loss: 1.77718e+01
I0514 17:51:51.457697 140128494741248 run_lib.py:152] step: 74400, training_loss: 2.74721e+01
I0514 17:51:51.511725 140128494741248 run_lib.py:165] step: 74400, eval_loss: 2.44766e+01
I0514 17:51:57.613835 140128494741248 run_lib.py:152] step: 74450, training_loss: 4.48833e+01
I0514 17:52:03.792581 140128494741248 run_lib.py:152] step: 74500, training_loss: 3.57307e+01
I0514 17:52:03.839979 140128494741248 run_lib.py:165] step: 74500, eval_loss: 1.93206e+01
I0514 17:52:10.320609 140128494741248 run_lib.py:152] step: 74550, training_loss: 2.75245e+01
I0514 17:52:16.523741 140128494741248 run_lib.py:152] step: 74600, training_loss: 2.92411e+01
I0514 17:52:16.580249 140128494741248 run_lib.py:165] step: 74600, eval_loss: 3.05371e+01
I0514 17:52:22.789401 140128494741248 run_lib.py:152] step: 74650, training_loss: 3.58431e+01
I0514 17:52:29.017368 140128494741248 run_lib.py:152] step: 74700, training_loss: 4.88244e+01
I0514 17:52:29.073496 140128494741248 run_lib.py:165] step: 74700, eval_loss: 3.81377e+01
I0514 17:52:35.575053 140128494741248 run_lib.py:152] step: 74750, training_loss: 2.23956e+01
I0514 17:52:41.869320 140128494741248 run_lib.py:152] step: 74800, training_loss: 2.09025e+01
I0514 17:52:41.918831 140128494741248 run_lib.py:165] step: 74800, eval_loss: 4.34036e+01
I0514 17:52:48.098783 140128494741248 run_lib.py:152] step: 74850, training_loss: 3.13746e+01
I0514 17:52:54.603421 140128494741248 run_lib.py:152] step: 74900, training_loss: 3.03444e+01
I0514 17:52:54.655074 140128494741248 run_lib.py:165] step: 74900, eval_loss: 3.85148e+01
I0514 17:53:00.892273 140128494741248 run_lib.py:152] step: 74950, training_loss: 2.36473e+01
I0514 17:53:07.154155 140128494741248 run_lib.py:152] step: 75000, training_loss: 4.10155e+01
I0514 17:53:07.208710 140128494741248 run_lib.py:165] step: 75000, eval_loss: 5.27092e+01
I0514 17:53:13.470969 140128494741248 run_lib.py:152] step: 75050, training_loss: 2.70318e+01
I0514 17:53:19.807916 140128494741248 run_lib.py:152] step: 75100, training_loss: 3.06964e+01
I0514 17:53:19.856941 140128494741248 run_lib.py:165] step: 75100, eval_loss: 3.60381e+01
I0514 17:53:26.119189 140128494741248 run_lib.py:152] step: 75150, training_loss: 3.14505e+01
I0514 17:53:32.335195 140128494741248 run_lib.py:152] step: 75200, training_loss: 4.29801e+01
I0514 17:53:32.387902 140128494741248 run_lib.py:165] step: 75200, eval_loss: 4.02219e+01
I0514 17:53:38.854815 140128494741248 run_lib.py:152] step: 75250, training_loss: 3.53739e+01
I0514 17:53:45.117623 140128494741248 run_lib.py:152] step: 75300, training_loss: 3.00070e+01
I0514 17:53:45.166178 140128494741248 run_lib.py:165] step: 75300, eval_loss: 2.75455e+01
I0514 17:53:51.368016 140128494741248 run_lib.py:152] step: 75350, training_loss: 5.05613e+01
I0514 17:53:57.582399 140128494741248 run_lib.py:152] step: 75400, training_loss: 2.70784e+01
I0514 17:53:57.637672 140128494741248 run_lib.py:165] step: 75400, eval_loss: 1.52927e+01
I0514 17:54:04.029319 140128494741248 run_lib.py:152] step: 75450, training_loss: 3.28305e+01
I0514 17:54:10.284229 140128494741248 run_lib.py:152] step: 75500, training_loss: 2.64402e+01
I0514 17:54:10.338365 140128494741248 run_lib.py:165] step: 75500, eval_loss: 2.77226e+01
I0514 17:54:16.543212 140128494741248 run_lib.py:152] step: 75550, training_loss: 3.34933e+01
I0514 17:54:23.003479 140128494741248 run_lib.py:152] step: 75600, training_loss: 3.12187e+01
I0514 17:54:23.054367 140128494741248 run_lib.py:165] step: 75600, eval_loss: 3.21890e+01
I0514 17:54:29.250106 140128494741248 run_lib.py:152] step: 75650, training_loss: 2.93578e+01
I0514 17:54:35.465510 140128494741248 run_lib.py:152] step: 75700, training_loss: 3.30514e+01
I0514 17:54:35.517777 140128494741248 run_lib.py:165] step: 75700, eval_loss: 4.29539e+01
I0514 17:54:41.774352 140128494741248 run_lib.py:152] step: 75750, training_loss: 5.37230e+01
I0514 17:54:48.237781 140128494741248 run_lib.py:152] step: 75800, training_loss: 4.20549e+01
I0514 17:54:48.289463 140128494741248 run_lib.py:165] step: 75800, eval_loss: 2.36622e+01
I0514 17:54:54.493656 140128494741248 run_lib.py:152] step: 75850, training_loss: 4.76808e+01
I0514 17:55:00.730365 140128494741248 run_lib.py:152] step: 75900, training_loss: 3.04097e+01
I0514 17:55:00.779150 140128494741248 run_lib.py:165] step: 75900, eval_loss: 4.17363e+01
I0514 17:55:07.207680 140128494741248 run_lib.py:152] step: 75950, training_loss: 3.10496e+01
I0514 17:55:13.453636 140128494741248 run_lib.py:152] step: 76000, training_loss: 4.13775e+01
I0514 17:55:13.504051 140128494741248 run_lib.py:165] step: 76000, eval_loss: 3.65507e+01
I0514 17:55:19.645867 140128494741248 run_lib.py:152] step: 76050, training_loss: 3.29655e+01
I0514 17:55:25.831208 140128494741248 run_lib.py:152] step: 76100, training_loss: 2.48274e+01
I0514 17:55:25.896098 140128494741248 run_lib.py:165] step: 76100, eval_loss: 3.06626e+01
I0514 17:55:32.312788 140128494741248 run_lib.py:152] step: 76150, training_loss: 2.81170e+01
I0514 17:55:38.515764 140128494741248 run_lib.py:152] step: 76200, training_loss: 2.03572e+01
I0514 17:55:38.566178 140128494741248 run_lib.py:165] step: 76200, eval_loss: 3.40297e+01
I0514 17:55:44.824443 140128494741248 run_lib.py:152] step: 76250, training_loss: 3.01038e+01
I0514 17:55:51.269489 140128494741248 run_lib.py:152] step: 76300, training_loss: 1.79669e+01
I0514 17:55:51.325497 140128494741248 run_lib.py:165] step: 76300, eval_loss: 2.13742e+01
I0514 17:55:57.486680 140128494741248 run_lib.py:152] step: 76350, training_loss: 2.36140e+01
I0514 17:56:03.601726 140128494741248 run_lib.py:152] step: 76400, training_loss: 4.58533e+01
I0514 17:56:03.653279 140128494741248 run_lib.py:165] step: 76400, eval_loss: 2.48857e+01
I0514 17:56:09.862627 140128494741248 run_lib.py:152] step: 76450, training_loss: 3.75968e+01
I0514 17:56:16.282378 140128494741248 run_lib.py:152] step: 76500, training_loss: 4.12827e+01
I0514 17:56:16.340718 140128494741248 run_lib.py:165] step: 76500, eval_loss: 3.28662e+01
I0514 17:56:22.512216 140128494741248 run_lib.py:152] step: 76550, training_loss: 3.01107e+01
I0514 17:56:28.705050 140128494741248 run_lib.py:152] step: 76600, training_loss: 2.07061e+01
I0514 17:56:28.757716 140128494741248 run_lib.py:165] step: 76600, eval_loss: 2.94885e+01
I0514 17:56:35.192235 140128494741248 run_lib.py:152] step: 76650, training_loss: 3.23771e+01
I0514 17:56:41.364908 140128494741248 run_lib.py:152] step: 76700, training_loss: 4.66790e+01
I0514 17:56:41.416148 140128494741248 run_lib.py:165] step: 76700, eval_loss: 2.98775e+01
I0514 17:56:47.600782 140128494741248 run_lib.py:152] step: 76750, training_loss: 4.33657e+01
I0514 17:56:53.783282 140128494741248 run_lib.py:152] step: 76800, training_loss: 1.97614e+01
I0514 17:56:53.833964 140128494741248 run_lib.py:165] step: 76800, eval_loss: 2.77967e+01
I0514 17:57:00.268105 140128494741248 run_lib.py:152] step: 76850, training_loss: 2.82687e+01
I0514 17:57:06.501215 140128494741248 run_lib.py:152] step: 76900, training_loss: 2.13840e+01
I0514 17:57:06.558511 140128494741248 run_lib.py:165] step: 76900, eval_loss: 2.90549e+01
I0514 17:57:12.698340 140128494741248 run_lib.py:152] step: 76950, training_loss: 5.07976e+01
I0514 17:57:19.136725 140128494741248 run_lib.py:152] step: 77000, training_loss: 5.24150e+01
I0514 17:57:19.187950 140128494741248 run_lib.py:165] step: 77000, eval_loss: 2.91941e+01
I0514 17:57:25.343473 140128494741248 run_lib.py:152] step: 77050, training_loss: 4.01374e+01
I0514 17:57:31.646963 140128494741248 run_lib.py:152] step: 77100, training_loss: 1.83208e+01
I0514 17:57:31.698027 140128494741248 run_lib.py:165] step: 77100, eval_loss: 2.70692e+01
I0514 17:57:37.866780 140128494741248 run_lib.py:152] step: 77150, training_loss: 2.88851e+01
I0514 17:57:44.351833 140128494741248 run_lib.py:152] step: 77200, training_loss: 3.98698e+01
I0514 17:57:44.404412 140128494741248 run_lib.py:165] step: 77200, eval_loss: 5.23671e+01
I0514 17:57:50.591331 140128494741248 run_lib.py:152] step: 77250, training_loss: 3.90704e+01
I0514 17:57:56.750132 140128494741248 run_lib.py:152] step: 77300, training_loss: 2.29401e+01
I0514 17:57:56.801914 140128494741248 run_lib.py:165] step: 77300, eval_loss: 3.41214e+01
I0514 17:58:03.218680 140128494741248 run_lib.py:152] step: 77350, training_loss: 3.41109e+01
I0514 17:58:09.510855 140128494741248 run_lib.py:152] step: 77400, training_loss: 3.05801e+01
I0514 17:58:09.565568 140128494741248 run_lib.py:165] step: 77400, eval_loss: 2.48901e+01
I0514 17:58:15.688483 140128494741248 run_lib.py:152] step: 77450, training_loss: 2.82799e+01
I0514 17:58:21.934602 140128494741248 run_lib.py:152] step: 77500, training_loss: 4.13580e+01
I0514 17:58:21.993098 140128494741248 run_lib.py:165] step: 77500, eval_loss: 4.23459e+01
I0514 17:58:28.530943 140128494741248 run_lib.py:152] step: 77550, training_loss: 4.60229e+01
I0514 17:58:34.824464 140128494741248 run_lib.py:152] step: 77600, training_loss: 2.41064e+01
I0514 17:58:34.880826 140128494741248 run_lib.py:165] step: 77600, eval_loss: 2.56894e+01
I0514 17:58:41.117011 140128494741248 run_lib.py:152] step: 77650, training_loss: 2.51232e+01
I0514 17:58:47.349982 140128494741248 run_lib.py:152] step: 77700, training_loss: 4.49372e+01
I0514 17:58:47.631855 140128494741248 run_lib.py:165] step: 77700, eval_loss: 3.38430e+01
I0514 17:58:53.822052 140128494741248 run_lib.py:152] step: 77750, training_loss: 2.89910e+01
I0514 17:58:59.984245 140128494741248 run_lib.py:152] step: 77800, training_loss: 2.68716e+01
I0514 17:59:00.035761 140128494741248 run_lib.py:165] step: 77800, eval_loss: 4.01660e+01
I0514 17:59:06.266635 140128494741248 run_lib.py:152] step: 77850, training_loss: 3.34018e+01
I0514 17:59:12.711477 140128494741248 run_lib.py:152] step: 77900, training_loss: 3.97720e+01
I0514 17:59:12.762937 140128494741248 run_lib.py:165] step: 77900, eval_loss: 2.42992e+01
I0514 17:59:18.971215 140128494741248 run_lib.py:152] step: 77950, training_loss: 2.85966e+01
I0514 17:59:25.163615 140128494741248 run_lib.py:152] step: 78000, training_loss: 2.61246e+01
I0514 17:59:25.211429 140128494741248 run_lib.py:165] step: 78000, eval_loss: 3.40487e+01
I0514 17:59:31.733985 140128494741248 run_lib.py:152] step: 78050, training_loss: 3.74221e+01
I0514 17:59:37.839887 140128494741248 run_lib.py:152] step: 78100, training_loss: 3.62561e+01
I0514 17:59:37.884973 140128494741248 run_lib.py:165] step: 78100, eval_loss: 4.19655e+01
I0514 17:59:44.094471 140128494741248 run_lib.py:152] step: 78150, training_loss: 2.76887e+01
I0514 17:59:50.348223 140128494741248 run_lib.py:152] step: 78200, training_loss: 5.58253e+01
I0514 17:59:50.403635 140128494741248 run_lib.py:165] step: 78200, eval_loss: 3.36169e+01
I0514 17:59:56.803686 140128494741248 run_lib.py:152] step: 78250, training_loss: 3.54841e+01
I0514 18:00:03.147629 140128494741248 run_lib.py:152] step: 78300, training_loss: 2.59890e+01
I0514 18:00:03.199944 140128494741248 run_lib.py:165] step: 78300, eval_loss: 4.34134e+01
I0514 18:00:09.298028 140128494741248 run_lib.py:152] step: 78350, training_loss: 4.51228e+01
I0514 18:00:15.790423 140128494741248 run_lib.py:152] step: 78400, training_loss: 2.97982e+01
I0514 18:00:15.846425 140128494741248 run_lib.py:165] step: 78400, eval_loss: 3.12963e+01
I0514 18:00:22.077527 140128494741248 run_lib.py:152] step: 78450, training_loss: 3.00649e+01
I0514 18:00:28.379946 140128494741248 run_lib.py:152] step: 78500, training_loss: 3.73572e+01
I0514 18:00:28.435274 140128494741248 run_lib.py:165] step: 78500, eval_loss: 2.53437e+01
I0514 18:00:34.603481 140128494741248 run_lib.py:152] step: 78550, training_loss: 2.93720e+01
I0514 18:00:41.156012 140128494741248 run_lib.py:152] step: 78600, training_loss: 4.10733e+01
I0514 18:00:41.205373 140128494741248 run_lib.py:165] step: 78600, eval_loss: 2.20604e+01
I0514 18:00:47.413248 140128494741248 run_lib.py:152] step: 78650, training_loss: 2.42926e+01
I0514 18:00:53.591305 140128494741248 run_lib.py:152] step: 78700, training_loss: 2.84321e+01
I0514 18:00:53.640950 140128494741248 run_lib.py:165] step: 78700, eval_loss: 3.30350e+01
I0514 18:01:00.097167 140128494741248 run_lib.py:152] step: 78750, training_loss: 4.17876e+01
I0514 18:01:06.376371 140128494741248 run_lib.py:152] step: 78800, training_loss: 3.28394e+01
I0514 18:01:06.428931 140128494741248 run_lib.py:165] step: 78800, eval_loss: 2.27748e+01
I0514 18:01:12.715655 140128494741248 run_lib.py:152] step: 78850, training_loss: 2.29627e+01
I0514 18:01:18.878623 140128494741248 run_lib.py:152] step: 78900, training_loss: 4.91120e+01
I0514 18:01:18.931697 140128494741248 run_lib.py:165] step: 78900, eval_loss: 2.57305e+01
I0514 18:01:25.489280 140128494741248 run_lib.py:152] step: 78950, training_loss: 4.24722e+01
I0514 18:01:31.626454 140128494741248 run_lib.py:152] step: 79000, training_loss: 3.14302e+01
I0514 18:01:31.682085 140128494741248 run_lib.py:165] step: 79000, eval_loss: 2.88209e+01
I0514 18:01:37.971783 140128494741248 run_lib.py:152] step: 79050, training_loss: 3.59737e+01
I0514 18:01:44.467285 140128494741248 run_lib.py:152] step: 79100, training_loss: 3.43308e+01
I0514 18:01:44.519611 140128494741248 run_lib.py:165] step: 79100, eval_loss: 3.66402e+01
I0514 18:01:50.734806 140128494741248 run_lib.py:152] step: 79150, training_loss: 2.72864e+01
I0514 18:01:56.916118 140128494741248 run_lib.py:152] step: 79200, training_loss: 3.57290e+01
I0514 18:01:56.969446 140128494741248 run_lib.py:165] step: 79200, eval_loss: 2.50693e+01
I0514 18:02:03.171678 140128494741248 run_lib.py:152] step: 79250, training_loss: 2.90106e+01
I0514 18:02:09.655160 140128494741248 run_lib.py:152] step: 79300, training_loss: 4.02687e+01
I0514 18:02:09.706836 140128494741248 run_lib.py:165] step: 79300, eval_loss: 3.78205e+01
I0514 18:02:15.885438 140128494741248 run_lib.py:152] step: 79350, training_loss: 3.13976e+01
I0514 18:02:22.126826 140128494741248 run_lib.py:152] step: 79400, training_loss: 3.86635e+01
I0514 18:02:22.176981 140128494741248 run_lib.py:165] step: 79400, eval_loss: 3.22410e+01
I0514 18:02:28.712079 140128494741248 run_lib.py:152] step: 79450, training_loss: 1.92320e+01
I0514 18:02:34.940820 140128494741248 run_lib.py:152] step: 79500, training_loss: 4.06363e+01
I0514 18:02:34.989923 140128494741248 run_lib.py:165] step: 79500, eval_loss: 1.87928e+01
I0514 18:02:41.192114 140128494741248 run_lib.py:152] step: 79550, training_loss: 2.90815e+01
I0514 18:02:47.359460 140128494741248 run_lib.py:152] step: 79600, training_loss: 3.35194e+01
I0514 18:02:47.409418 140128494741248 run_lib.py:165] step: 79600, eval_loss: 2.26506e+01
I0514 18:02:53.867050 140128494741248 run_lib.py:152] step: 79650, training_loss: 2.57949e+01
I0514 18:03:00.067303 140128494741248 run_lib.py:152] step: 79700, training_loss: 3.62106e+01
I0514 18:03:00.121809 140128494741248 run_lib.py:165] step: 79700, eval_loss: 1.57385e+01
I0514 18:03:06.357144 140128494741248 run_lib.py:152] step: 79750, training_loss: 4.31645e+01
I0514 18:03:12.809380 140128494741248 run_lib.py:152] step: 79800, training_loss: 1.70253e+01
I0514 18:03:12.862334 140128494741248 run_lib.py:165] step: 79800, eval_loss: 3.51706e+01
I0514 18:03:19.074889 140128494741248 run_lib.py:152] step: 79850, training_loss: 3.60409e+01
I0514 18:03:25.270240 140128494741248 run_lib.py:152] step: 79900, training_loss: 2.95062e+01
I0514 18:03:25.326828 140128494741248 run_lib.py:165] step: 79900, eval_loss: 2.86918e+01
I0514 18:03:31.513862 140128494741248 run_lib.py:152] step: 79950, training_loss: 3.00410e+01
I0514 18:03:37.931947 140128494741248 run_lib.py:152] step: 80000, training_loss: 3.50583e+01
I0514 18:03:38.132409 140128494741248 run_lib.py:165] step: 80000, eval_loss: 3.07245e+01
I0514 18:03:44.350553 140128494741248 run_lib.py:152] step: 80050, training_loss: 1.51198e+01
I0514 18:03:50.633928 140128494741248 run_lib.py:152] step: 80100, training_loss: 4.92174e+01
I0514 18:03:50.690903 140128494741248 run_lib.py:165] step: 80100, eval_loss: 4.56792e+01
I0514 18:03:57.156180 140128494741248 run_lib.py:152] step: 80150, training_loss: 3.56222e+01
I0514 18:04:03.378303 140128494741248 run_lib.py:152] step: 80200, training_loss: 2.77987e+01
I0514 18:04:03.427242 140128494741248 run_lib.py:165] step: 80200, eval_loss: 2.43315e+01
I0514 18:04:09.678775 140128494741248 run_lib.py:152] step: 80250, training_loss: 3.67466e+01
I0514 18:04:16.013288 140128494741248 run_lib.py:152] step: 80300, training_loss: 1.95983e+01
I0514 18:04:16.066362 140128494741248 run_lib.py:165] step: 80300, eval_loss: 4.33263e+01
I0514 18:04:22.531985 140128494741248 run_lib.py:152] step: 80350, training_loss: 1.86966e+01
I0514 18:04:28.680547 140128494741248 run_lib.py:152] step: 80400, training_loss: 2.29644e+01
I0514 18:04:28.737876 140128494741248 run_lib.py:165] step: 80400, eval_loss: 2.72316e+01
I0514 18:04:34.940056 140128494741248 run_lib.py:152] step: 80450, training_loss: 4.69670e+01
I0514 18:04:41.443557 140128494741248 run_lib.py:152] step: 80500, training_loss: 2.84657e+01
I0514 18:04:41.496534 140128494741248 run_lib.py:165] step: 80500, eval_loss: 2.81011e+01
I0514 18:04:47.675372 140128494741248 run_lib.py:152] step: 80550, training_loss: 3.56668e+01
I0514 18:04:53.860083 140128494741248 run_lib.py:152] step: 80600, training_loss: 3.75757e+01
I0514 18:04:53.915257 140128494741248 run_lib.py:165] step: 80600, eval_loss: 2.93940e+01
I0514 18:05:00.149002 140128494741248 run_lib.py:152] step: 80650, training_loss: 2.53421e+01
I0514 18:05:06.618369 140128494741248 run_lib.py:152] step: 80700, training_loss: 2.62001e+01
I0514 18:05:06.671540 140128494741248 run_lib.py:165] step: 80700, eval_loss: 2.66849e+01
I0514 18:05:12.855484 140128494741248 run_lib.py:152] step: 80750, training_loss: 3.84783e+01
I0514 18:05:19.079135 140128494741248 run_lib.py:152] step: 80800, training_loss: 2.54414e+01
I0514 18:05:19.133952 140128494741248 run_lib.py:165] step: 80800, eval_loss: 3.29773e+01
I0514 18:05:25.603992 140128494741248 run_lib.py:152] step: 80850, training_loss: 2.36630e+01
I0514 18:05:31.721896 140128494741248 run_lib.py:152] step: 80900, training_loss: 3.05116e+01
I0514 18:05:31.778496 140128494741248 run_lib.py:165] step: 80900, eval_loss: 3.99464e+01
I0514 18:05:37.921704 140128494741248 run_lib.py:152] step: 80950, training_loss: 2.69229e+01
I0514 18:05:44.185594 140128494741248 run_lib.py:152] step: 81000, training_loss: 5.78121e+01
I0514 18:05:44.244938 140128494741248 run_lib.py:165] step: 81000, eval_loss: 3.08211e+01
I0514 18:05:50.621406 140128494741248 run_lib.py:152] step: 81050, training_loss: 3.56731e+01
I0514 18:05:56.856116 140128494741248 run_lib.py:152] step: 81100, training_loss: 2.49648e+01
I0514 18:05:56.906215 140128494741248 run_lib.py:165] step: 81100, eval_loss: 3.55435e+01
I0514 18:06:03.078938 140128494741248 run_lib.py:152] step: 81150, training_loss: 4.04319e+01
I0514 18:06:09.559888 140128494741248 run_lib.py:152] step: 81200, training_loss: 2.89912e+01
I0514 18:06:09.618518 140128494741248 run_lib.py:165] step: 81200, eval_loss: 2.57222e+01
I0514 18:06:15.808635 140128494741248 run_lib.py:152] step: 81250, training_loss: 3.21972e+01
I0514 18:06:21.979689 140128494741248 run_lib.py:152] step: 81300, training_loss: 4.50833e+01
I0514 18:06:22.027352 140128494741248 run_lib.py:165] step: 81300, eval_loss: 2.24774e+01
I0514 18:06:28.333113 140128494741248 run_lib.py:152] step: 81350, training_loss: 2.21527e+01
I0514 18:06:34.723037 140128494741248 run_lib.py:152] step: 81400, training_loss: 3.53143e+01
I0514 18:06:34.773667 140128494741248 run_lib.py:165] step: 81400, eval_loss: 1.73350e+01
I0514 18:06:40.996374 140128494741248 run_lib.py:152] step: 81450, training_loss: 4.28651e+01
I0514 18:06:47.213474 140128494741248 run_lib.py:152] step: 81500, training_loss: 1.91688e+01
I0514 18:06:47.264477 140128494741248 run_lib.py:165] step: 81500, eval_loss: 3.18049e+01
I0514 18:06:53.719390 140128494741248 run_lib.py:152] step: 81550, training_loss: 2.82652e+01
I0514 18:07:00.012651 140128494741248 run_lib.py:152] step: 81600, training_loss: 3.30952e+01
I0514 18:07:00.062329 140128494741248 run_lib.py:165] step: 81600, eval_loss: 2.26124e+01
I0514 18:07:06.325920 140128494741248 run_lib.py:152] step: 81650, training_loss: 4.23250e+01
I0514 18:07:12.574186 140128494741248 run_lib.py:152] step: 81700, training_loss: 4.25442e+01
I0514 18:07:12.626814 140128494741248 run_lib.py:165] step: 81700, eval_loss: 2.56496e+01
I0514 18:07:19.071900 140128494741248 run_lib.py:152] step: 81750, training_loss: 2.41735e+01
I0514 18:07:25.352092 140128494741248 run_lib.py:152] step: 81800, training_loss: 3.90430e+01
I0514 18:07:25.401751 140128494741248 run_lib.py:165] step: 81800, eval_loss: 3.12272e+01
I0514 18:07:31.606335 140128494741248 run_lib.py:152] step: 81850, training_loss: 3.32041e+01
I0514 18:07:38.033242 140128494741248 run_lib.py:152] step: 81900, training_loss: 2.93012e+01
I0514 18:07:38.078827 140128494741248 run_lib.py:165] step: 81900, eval_loss: 2.88089e+01
I0514 18:07:44.330753 140128494741248 run_lib.py:152] step: 81950, training_loss: 4.51282e+01
I0514 18:07:50.513756 140128494741248 run_lib.py:152] step: 82000, training_loss: 2.75298e+01
I0514 18:07:50.569562 140128494741248 run_lib.py:165] step: 82000, eval_loss: 3.75504e+01
I0514 18:07:56.825652 140128494741248 run_lib.py:152] step: 82050, training_loss: 2.59132e+01
I0514 18:08:03.291130 140128494741248 run_lib.py:152] step: 82100, training_loss: 3.42572e+01
I0514 18:08:03.341633 140128494741248 run_lib.py:165] step: 82100, eval_loss: 2.45903e+01
I0514 18:08:09.541112 140128494741248 run_lib.py:152] step: 82150, training_loss: 3.68106e+01
I0514 18:08:15.677388 140128494741248 run_lib.py:152] step: 82200, training_loss: 4.56861e+01
I0514 18:08:15.727375 140128494741248 run_lib.py:165] step: 82200, eval_loss: 3.01284e+01
I0514 18:08:22.209268 140128494741248 run_lib.py:152] step: 82250, training_loss: 3.59857e+01
I0514 18:08:28.349203 140128494741248 run_lib.py:152] step: 82300, training_loss: 2.75447e+01
I0514 18:08:28.399645 140128494741248 run_lib.py:165] step: 82300, eval_loss: 3.52725e+01
I0514 18:08:34.602118 140128494741248 run_lib.py:152] step: 82350, training_loss: 3.11193e+01
I0514 18:08:40.740191 140128494741248 run_lib.py:152] step: 82400, training_loss: 3.97009e+01
I0514 18:08:40.793676 140128494741248 run_lib.py:165] step: 82400, eval_loss: 4.79217e+01
I0514 18:08:47.268891 140128494741248 run_lib.py:152] step: 82450, training_loss: 3.38660e+01
I0514 18:08:53.403522 140128494741248 run_lib.py:152] step: 82500, training_loss: 3.45120e+01
I0514 18:08:53.452406 140128494741248 run_lib.py:165] step: 82500, eval_loss: 4.08420e+01
I0514 18:08:59.743941 140128494741248 run_lib.py:152] step: 82550, training_loss: 3.55390e+01
I0514 18:09:06.203767 140128494741248 run_lib.py:152] step: 82600, training_loss: 2.58324e+01
I0514 18:09:06.251386 140128494741248 run_lib.py:165] step: 82600, eval_loss: 4.32563e+01
I0514 18:09:12.558463 140128494741248 run_lib.py:152] step: 82650, training_loss: 2.52781e+01
I0514 18:09:18.689795 140128494741248 run_lib.py:152] step: 82700, training_loss: 4.73349e+01
I0514 18:09:18.735902 140128494741248 run_lib.py:165] step: 82700, eval_loss: 3.42502e+01
I0514 18:09:24.990376 140128494741248 run_lib.py:152] step: 82750, training_loss: 3.22697e+01
I0514 18:09:31.494736 140128494741248 run_lib.py:152] step: 82800, training_loss: 2.55286e+01
I0514 18:09:31.548080 140128494741248 run_lib.py:165] step: 82800, eval_loss: 2.47158e+01
I0514 18:09:37.638846 140128494741248 run_lib.py:152] step: 82850, training_loss: 2.37435e+01
I0514 18:09:43.872918 140128494741248 run_lib.py:152] step: 82900, training_loss: 2.75621e+01
I0514 18:09:43.924134 140128494741248 run_lib.py:165] step: 82900, eval_loss: 3.64767e+01
I0514 18:09:50.374593 140128494741248 run_lib.py:152] step: 82950, training_loss: 3.00375e+01
I0514 18:09:56.587641 140128494741248 run_lib.py:152] step: 83000, training_loss: 4.26004e+01
I0514 18:09:56.644189 140128494741248 run_lib.py:165] step: 83000, eval_loss: 3.24877e+01
I0514 18:10:02.892187 140128494741248 run_lib.py:152] step: 83050, training_loss: 2.11320e+01
I0514 18:10:09.107615 140128494741248 run_lib.py:152] step: 83100, training_loss: 3.85261e+01
I0514 18:10:09.175180 140128494741248 run_lib.py:165] step: 83100, eval_loss: 4.62065e+01
I0514 18:10:15.635082 140128494741248 run_lib.py:152] step: 83150, training_loss: 3.28667e+01
I0514 18:10:21.850602 140128494741248 run_lib.py:152] step: 83200, training_loss: 3.43876e+01
I0514 18:10:21.910046 140128494741248 run_lib.py:165] step: 83200, eval_loss: 2.96179e+01
I0514 18:10:28.206413 140128494741248 run_lib.py:152] step: 83250, training_loss: 3.01657e+01
I0514 18:10:34.604766 140128494741248 run_lib.py:152] step: 83300, training_loss: 3.77011e+01
I0514 18:10:34.657870 140128494741248 run_lib.py:165] step: 83300, eval_loss: 3.04086e+01
I0514 18:10:40.952037 140128494741248 run_lib.py:152] step: 83350, training_loss: 3.10638e+01
I0514 18:10:47.162214 140128494741248 run_lib.py:152] step: 83400, training_loss: 3.35351e+01
I0514 18:10:47.213537 140128494741248 run_lib.py:165] step: 83400, eval_loss: 3.76283e+01
I0514 18:10:53.433681 140128494741248 run_lib.py:152] step: 83450, training_loss: 3.95200e+01
I0514 18:10:59.870583 140128494741248 run_lib.py:152] step: 83500, training_loss: 3.60625e+01
I0514 18:10:59.924452 140128494741248 run_lib.py:165] step: 83500, eval_loss: 2.60093e+01
I0514 18:11:06.188230 140128494741248 run_lib.py:152] step: 83550, training_loss: 4.50853e+01
I0514 18:11:12.383473 140128494741248 run_lib.py:152] step: 83600, training_loss: 3.47104e+01
I0514 18:11:12.435705 140128494741248 run_lib.py:165] step: 83600, eval_loss: 3.96904e+01
I0514 18:11:18.814948 140128494741248 run_lib.py:152] step: 83650, training_loss: 1.60170e+01
I0514 18:11:25.118965 140128494741248 run_lib.py:152] step: 83700, training_loss: 4.72753e+01
I0514 18:11:25.170529 140128494741248 run_lib.py:165] step: 83700, eval_loss: 3.69867e+01
I0514 18:11:31.339465 140128494741248 run_lib.py:152] step: 83750, training_loss: 5.09277e+01
I0514 18:11:37.562234 140128494741248 run_lib.py:152] step: 83800, training_loss: 2.71733e+01
I0514 18:11:37.615548 140128494741248 run_lib.py:165] step: 83800, eval_loss: 2.69419e+01
I0514 18:11:44.042788 140128494741248 run_lib.py:152] step: 83850, training_loss: 2.11270e+01
I0514 18:11:50.306386 140128494741248 run_lib.py:152] step: 83900, training_loss: 3.75558e+01
I0514 18:11:50.361509 140128494741248 run_lib.py:165] step: 83900, eval_loss: 2.95134e+01
I0514 18:11:56.542465 140128494741248 run_lib.py:152] step: 83950, training_loss: 2.19536e+01
I0514 18:12:03.045392 140128494741248 run_lib.py:152] step: 84000, training_loss: 3.09129e+01
I0514 18:12:03.103048 140128494741248 run_lib.py:165] step: 84000, eval_loss: 3.61665e+01
I0514 18:12:09.274211 140128494741248 run_lib.py:152] step: 84050, training_loss: 2.57180e+01
I0514 18:12:15.493700 140128494741248 run_lib.py:152] step: 84100, training_loss: 2.80775e+01
I0514 18:12:15.545683 140128494741248 run_lib.py:165] step: 84100, eval_loss: 2.41626e+01
I0514 18:12:21.650818 140128494741248 run_lib.py:152] step: 84150, training_loss: 2.93115e+01
I0514 18:12:28.075495 140128494741248 run_lib.py:152] step: 84200, training_loss: 3.83765e+01
I0514 18:12:28.126073 140128494741248 run_lib.py:165] step: 84200, eval_loss: 4.29214e+01
I0514 18:12:34.357110 140128494741248 run_lib.py:152] step: 84250, training_loss: 3.07116e+01
I0514 18:12:40.618089 140128494741248 run_lib.py:152] step: 84300, training_loss: 3.69917e+01
I0514 18:12:40.668227 140128494741248 run_lib.py:165] step: 84300, eval_loss: 3.10556e+01
I0514 18:12:47.162247 140128494741248 run_lib.py:152] step: 84350, training_loss: 3.33493e+01
I0514 18:12:53.404170 140128494741248 run_lib.py:152] step: 84400, training_loss: 3.71743e+01
I0514 18:12:53.457940 140128494741248 run_lib.py:165] step: 84400, eval_loss: 2.38807e+01
I0514 18:12:59.642463 140128494741248 run_lib.py:152] step: 84450, training_loss: 3.18918e+01
I0514 18:13:05.971899 140128494741248 run_lib.py:152] step: 84500, training_loss: 2.07283e+01
I0514 18:13:06.023052 140128494741248 run_lib.py:165] step: 84500, eval_loss: 1.64376e+01
I0514 18:13:12.480178 140128494741248 run_lib.py:152] step: 84550, training_loss: 4.82551e+01
I0514 18:13:18.713303 140128494741248 run_lib.py:152] step: 84600, training_loss: 3.86155e+01
I0514 18:13:18.762758 140128494741248 run_lib.py:165] step: 84600, eval_loss: 2.28081e+01
I0514 18:13:24.933771 140128494741248 run_lib.py:152] step: 84650, training_loss: 5.15693e+01
I0514 18:13:31.469884 140128494741248 run_lib.py:152] step: 84700, training_loss: 3.70164e+01
I0514 18:13:31.523797 140128494741248 run_lib.py:165] step: 84700, eval_loss: 1.83117e+01
I0514 18:13:37.755003 140128494741248 run_lib.py:152] step: 84750, training_loss: 1.76226e+01
I0514 18:13:43.994502 140128494741248 run_lib.py:152] step: 84800, training_loss: 5.30475e+01
I0514 18:13:44.046281 140128494741248 run_lib.py:165] step: 84800, eval_loss: 2.50414e+01
I0514 18:13:50.295113 140128494741248 run_lib.py:152] step: 84850, training_loss: 3.37156e+01
I0514 18:13:56.752405 140128494741248 run_lib.py:152] step: 84900, training_loss: 3.91990e+01
I0514 18:13:56.803830 140128494741248 run_lib.py:165] step: 84900, eval_loss: 2.10646e+01
I0514 18:14:03.018417 140128494741248 run_lib.py:152] step: 84950, training_loss: 2.68871e+01
I0514 18:14:09.188194 140128494741248 run_lib.py:152] step: 85000, training_loss: 4.20422e+01
I0514 18:14:09.238607 140128494741248 run_lib.py:165] step: 85000, eval_loss: 4.02892e+01
I0514 18:14:15.711539 140128494741248 run_lib.py:152] step: 85050, training_loss: 4.00274e+01
I0514 18:14:21.970319 140128494741248 run_lib.py:152] step: 85100, training_loss: 2.83506e+01
I0514 18:14:22.022824 140128494741248 run_lib.py:165] step: 85100, eval_loss: 2.63304e+01
I0514 18:14:28.295148 140128494741248 run_lib.py:152] step: 85150, training_loss: 1.79140e+01
I0514 18:14:34.455850 140128494741248 run_lib.py:152] step: 85200, training_loss: 1.66635e+01
I0514 18:14:34.505656 140128494741248 run_lib.py:165] step: 85200, eval_loss: 1.81766e+01
I0514 18:14:40.951982 140128494741248 run_lib.py:152] step: 85250, training_loss: 2.30479e+01
I0514 18:14:47.153796 140128494741248 run_lib.py:152] step: 85300, training_loss: 3.01254e+01
I0514 18:14:47.208569 140128494741248 run_lib.py:165] step: 85300, eval_loss: 3.20958e+01
I0514 18:14:53.339602 140128494741248 run_lib.py:152] step: 85350, training_loss: 2.29648e+01
I0514 18:14:59.893985 140128494741248 run_lib.py:152] step: 85400, training_loss: 3.91259e+01
I0514 18:14:59.947478 140128494741248 run_lib.py:165] step: 85400, eval_loss: 4.28473e+01
I0514 18:15:06.170262 140128494741248 run_lib.py:152] step: 85450, training_loss: 2.67712e+01
I0514 18:15:12.394326 140128494741248 run_lib.py:152] step: 85500, training_loss: 4.09645e+01
I0514 18:15:12.450220 140128494741248 run_lib.py:165] step: 85500, eval_loss: 1.57802e+01
I0514 18:15:18.605126 140128494741248 run_lib.py:152] step: 85550, training_loss: 1.77033e+01
I0514 18:15:25.094870 140128494741248 run_lib.py:152] step: 85600, training_loss: 2.65089e+01
I0514 18:15:25.150082 140128494741248 run_lib.py:165] step: 85600, eval_loss: 1.76910e+01
I0514 18:15:31.371096 140128494741248 run_lib.py:152] step: 85650, training_loss: 2.04807e+01
I0514 18:15:37.624752 140128494741248 run_lib.py:152] step: 85700, training_loss: 4.62395e+01
I0514 18:15:37.676155 140128494741248 run_lib.py:165] step: 85700, eval_loss: 4.38815e+01
I0514 18:15:44.139366 140128494741248 run_lib.py:152] step: 85750, training_loss: 2.67573e+01
I0514 18:15:50.408301 140128494741248 run_lib.py:152] step: 85800, training_loss: 2.16725e+01
I0514 18:15:50.463863 140128494741248 run_lib.py:165] step: 85800, eval_loss: 3.02589e+01
I0514 18:15:56.734958 140128494741248 run_lib.py:152] step: 85850, training_loss: 3.40895e+01
I0514 18:16:02.940249 140128494741248 run_lib.py:152] step: 85900, training_loss: 1.65023e+01
I0514 18:16:02.991527 140128494741248 run_lib.py:165] step: 85900, eval_loss: 1.87846e+01
I0514 18:16:09.506199 140128494741248 run_lib.py:152] step: 85950, training_loss: 3.25747e+01
I0514 18:16:15.769361 140128494741248 run_lib.py:152] step: 86000, training_loss: 2.90588e+01
I0514 18:16:15.818454 140128494741248 run_lib.py:165] step: 86000, eval_loss: 2.57787e+01
I0514 18:16:22.080951 140128494741248 run_lib.py:152] step: 86050, training_loss: 3.59959e+01
I0514 18:16:28.578995 140128494741248 run_lib.py:152] step: 86100, training_loss: 3.70063e+01
I0514 18:16:28.635057 140128494741248 run_lib.py:165] step: 86100, eval_loss: 1.57302e+01
I0514 18:16:34.766075 140128494741248 run_lib.py:152] step: 86150, training_loss: 5.05946e+01
I0514 18:16:40.977678 140128494741248 run_lib.py:152] step: 86200, training_loss: 2.52635e+01
I0514 18:16:41.029992 140128494741248 run_lib.py:165] step: 86200, eval_loss: 4.36040e+01
I0514 18:16:47.290368 140128494741248 run_lib.py:152] step: 86250, training_loss: 2.45703e+01
I0514 18:16:53.752974 140128494741248 run_lib.py:152] step: 86300, training_loss: 3.81609e+01
I0514 18:16:53.804957 140128494741248 run_lib.py:165] step: 86300, eval_loss: 3.44271e+01
I0514 18:16:59.855902 140128494741248 run_lib.py:152] step: 86350, training_loss: 2.91706e+01
I0514 18:17:06.142306 140128494741248 run_lib.py:152] step: 86400, training_loss: 3.03039e+01
I0514 18:17:06.196437 140128494741248 run_lib.py:165] step: 86400, eval_loss: 3.62022e+01
I0514 18:17:12.565990 140128494741248 run_lib.py:152] step: 86450, training_loss: 3.43150e+01
I0514 18:17:18.723937 140128494741248 run_lib.py:152] step: 86500, training_loss: 3.67048e+01
I0514 18:17:18.770975 140128494741248 run_lib.py:165] step: 86500, eval_loss: 2.58415e+01
I0514 18:17:25.031613 140128494741248 run_lib.py:152] step: 86550, training_loss: 4.09598e+01
I0514 18:17:31.242007 140128494741248 run_lib.py:152] step: 86600, training_loss: 1.46216e+01
I0514 18:17:31.296604 140128494741248 run_lib.py:165] step: 86600, eval_loss: 3.70223e+01
I0514 18:17:37.759879 140128494741248 run_lib.py:152] step: 86650, training_loss: 4.77777e+01
I0514 18:17:43.919486 140128494741248 run_lib.py:152] step: 86700, training_loss: 3.24252e+01
I0514 18:17:43.969481 140128494741248 run_lib.py:165] step: 86700, eval_loss: 3.20548e+01
I0514 18:17:50.224586 140128494741248 run_lib.py:152] step: 86750, training_loss: 3.79125e+01
I0514 18:17:56.655330 140128494741248 run_lib.py:152] step: 86800, training_loss: 2.06962e+01
I0514 18:17:56.704705 140128494741248 run_lib.py:165] step: 86800, eval_loss: 4.17380e+01
I0514 18:18:02.988617 140128494741248 run_lib.py:152] step: 86850, training_loss: 2.85906e+01
I0514 18:18:09.176126 140128494741248 run_lib.py:152] step: 86900, training_loss: 3.72259e+01
I0514 18:18:09.230409 140128494741248 run_lib.py:165] step: 86900, eval_loss: 2.33495e+01
I0514 18:18:15.517946 140128494741248 run_lib.py:152] step: 86950, training_loss: 2.86150e+01
I0514 18:18:21.904234 140128494741248 run_lib.py:152] step: 87000, training_loss: 4.87052e+01
I0514 18:18:21.954660 140128494741248 run_lib.py:165] step: 87000, eval_loss: 4.16745e+01
I0514 18:18:28.115759 140128494741248 run_lib.py:152] step: 87050, training_loss: 4.10109e+01
I0514 18:18:34.236494 140128494741248 run_lib.py:152] step: 87100, training_loss: 3.40561e+01
I0514 18:18:34.287342 140128494741248 run_lib.py:165] step: 87100, eval_loss: 4.09765e+01
I0514 18:18:40.757177 140128494741248 run_lib.py:152] step: 87150, training_loss: 4.39570e+01
I0514 18:18:46.981036 140128494741248 run_lib.py:152] step: 87200, training_loss: 2.83638e+01
I0514 18:18:47.031366 140128494741248 run_lib.py:165] step: 87200, eval_loss: 2.21616e+01
I0514 18:18:53.237004 140128494741248 run_lib.py:152] step: 87250, training_loss: 3.49311e+01
I0514 18:18:59.457993 140128494741248 run_lib.py:152] step: 87300, training_loss: 1.97989e+01
I0514 18:18:59.507241 140128494741248 run_lib.py:165] step: 87300, eval_loss: 1.87496e+01
I0514 18:19:06.032711 140128494741248 run_lib.py:152] step: 87350, training_loss: 2.87869e+01
I0514 18:19:12.148558 140128494741248 run_lib.py:152] step: 87400, training_loss: 2.10957e+01
I0514 18:19:12.198871 140128494741248 run_lib.py:165] step: 87400, eval_loss: 2.70147e+01
I0514 18:19:18.427564 140128494741248 run_lib.py:152] step: 87450, training_loss: 4.38590e+01
I0514 18:19:24.784415 140128494741248 run_lib.py:152] step: 87500, training_loss: 4.45031e+01
I0514 18:19:24.833811 140128494741248 run_lib.py:165] step: 87500, eval_loss: 3.39013e+01
I0514 18:19:31.026504 140128494741248 run_lib.py:152] step: 87550, training_loss: 2.61436e+01
I0514 18:19:37.236840 140128494741248 run_lib.py:152] step: 87600, training_loss: 3.46272e+01
I0514 18:19:37.289083 140128494741248 run_lib.py:165] step: 87600, eval_loss: 3.72814e+01
I0514 18:19:43.495012 140128494741248 run_lib.py:152] step: 87650, training_loss: 4.14319e+01
I0514 18:19:49.982694 140128494741248 run_lib.py:152] step: 87700, training_loss: 3.86400e+01
I0514 18:19:50.035612 140128494741248 run_lib.py:165] step: 87700, eval_loss: 3.64855e+01
I0514 18:19:56.315184 140128494741248 run_lib.py:152] step: 87750, training_loss: 3.13926e+01
I0514 18:20:02.589540 140128494741248 run_lib.py:152] step: 87800, training_loss: 2.46280e+01
I0514 18:20:02.639047 140128494741248 run_lib.py:165] step: 87800, eval_loss: 3.99062e+01
I0514 18:20:09.134271 140128494741248 run_lib.py:152] step: 87850, training_loss: 2.47961e+01
I0514 18:20:15.361022 140128494741248 run_lib.py:152] step: 87900, training_loss: 4.71299e+01
I0514 18:20:15.409716 140128494741248 run_lib.py:165] step: 87900, eval_loss: 3.68787e+01
I0514 18:20:21.754597 140128494741248 run_lib.py:152] step: 87950, training_loss: 2.55277e+01
I0514 18:20:27.925634 140128494741248 run_lib.py:152] step: 88000, training_loss: 3.34693e+01
I0514 18:20:27.983774 140128494741248 run_lib.py:165] step: 88000, eval_loss: 3.04254e+01
I0514 18:20:34.436823 140128494741248 run_lib.py:152] step: 88050, training_loss: 2.17093e+01
I0514 18:20:40.644364 140128494741248 run_lib.py:152] step: 88100, training_loss: 1.90388e+01
I0514 18:20:40.692657 140128494741248 run_lib.py:165] step: 88100, eval_loss: 2.25777e+01
I0514 18:20:46.895331 140128494741248 run_lib.py:152] step: 88150, training_loss: 3.93194e+01
I0514 18:20:53.374713 140128494741248 run_lib.py:152] step: 88200, training_loss: 4.20071e+01
I0514 18:20:53.426528 140128494741248 run_lib.py:165] step: 88200, eval_loss: 3.29845e+01
I0514 18:20:59.606471 140128494741248 run_lib.py:152] step: 88250, training_loss: 3.15650e+01
I0514 18:21:05.882278 140128494741248 run_lib.py:152] step: 88300, training_loss: 3.14066e+01
I0514 18:21:05.937797 140128494741248 run_lib.py:165] step: 88300, eval_loss: 3.20125e+01
I0514 18:21:12.100057 140128494741248 run_lib.py:152] step: 88350, training_loss: 2.48480e+01
I0514 18:21:18.499664 140128494741248 run_lib.py:152] step: 88400, training_loss: 4.14410e+01
I0514 18:21:18.550188 140128494741248 run_lib.py:165] step: 88400, eval_loss: 4.00542e+01
I0514 18:21:24.863393 140128494741248 run_lib.py:152] step: 88450, training_loss: 2.33672e+01
I0514 18:21:31.118878 140128494741248 run_lib.py:152] step: 88500, training_loss: 2.06353e+01
I0514 18:21:31.171355 140128494741248 run_lib.py:165] step: 88500, eval_loss: 2.11412e+01
I0514 18:21:37.570590 140128494741248 run_lib.py:152] step: 88550, training_loss: 2.95788e+01
I0514 18:21:43.815982 140128494741248 run_lib.py:152] step: 88600, training_loss: 2.61928e+01
I0514 18:21:43.874036 140128494741248 run_lib.py:165] step: 88600, eval_loss: 2.49069e+01
I0514 18:21:50.106631 140128494741248 run_lib.py:152] step: 88650, training_loss: 3.45822e+01
I0514 18:21:56.404319 140128494741248 run_lib.py:152] step: 88700, training_loss: 5.03409e+01
I0514 18:21:56.456144 140128494741248 run_lib.py:165] step: 88700, eval_loss: 3.30369e+01
I0514 18:22:02.938540 140128494741248 run_lib.py:152] step: 88750, training_loss: 1.79474e+01
I0514 18:22:09.208907 140128494741248 run_lib.py:152] step: 88800, training_loss: 2.95994e+01
I0514 18:22:09.262693 140128494741248 run_lib.py:165] step: 88800, eval_loss: 3.70195e+01
I0514 18:22:15.489276 140128494741248 run_lib.py:152] step: 88850, training_loss: 3.17568e+01
I0514 18:22:21.959728 140128494741248 run_lib.py:152] step: 88900, training_loss: 4.36820e+01
I0514 18:22:22.014497 140128494741248 run_lib.py:165] step: 88900, eval_loss: 3.22396e+01
I0514 18:22:28.212321 140128494741248 run_lib.py:152] step: 88950, training_loss: 3.91498e+01
I0514 18:22:34.415610 140128494741248 run_lib.py:152] step: 89000, training_loss: 2.95741e+01
I0514 18:22:34.467381 140128494741248 run_lib.py:165] step: 89000, eval_loss: 2.05748e+01
I0514 18:22:40.685470 140128494741248 run_lib.py:152] step: 89050, training_loss: 2.96053e+01
I0514 18:22:47.222736 140128494741248 run_lib.py:152] step: 89100, training_loss: 2.99964e+01
I0514 18:22:47.275793 140128494741248 run_lib.py:165] step: 89100, eval_loss: 1.89285e+01
I0514 18:22:53.489744 140128494741248 run_lib.py:152] step: 89150, training_loss: 3.09200e+01
I0514 18:22:59.622712 140128494741248 run_lib.py:152] step: 89200, training_loss: 2.85019e+01
I0514 18:22:59.671292 140128494741248 run_lib.py:165] step: 89200, eval_loss: 2.74102e+01
I0514 18:23:06.149343 140128494741248 run_lib.py:152] step: 89250, training_loss: 2.97811e+01
I0514 18:23:12.332039 140128494741248 run_lib.py:152] step: 89300, training_loss: 3.34785e+01
I0514 18:23:12.385162 140128494741248 run_lib.py:165] step: 89300, eval_loss: 2.54828e+01
I0514 18:23:18.570546 140128494741248 run_lib.py:152] step: 89350, training_loss: 2.89121e+01
I0514 18:23:24.777174 140128494741248 run_lib.py:152] step: 89400, training_loss: 3.22369e+01
I0514 18:23:24.826469 140128494741248 run_lib.py:165] step: 89400, eval_loss: 3.95843e+01
I0514 18:23:31.311985 140128494741248 run_lib.py:152] step: 89450, training_loss: 1.65640e+01
I0514 18:23:37.491461 140128494741248 run_lib.py:152] step: 89500, training_loss: 2.14633e+01
I0514 18:23:37.544526 140128494741248 run_lib.py:165] step: 89500, eval_loss: 2.61187e+01
I0514 18:23:43.732530 140128494741248 run_lib.py:152] step: 89550, training_loss: 4.75288e+01
I0514 18:23:50.123696 140128494741248 run_lib.py:152] step: 89600, training_loss: 3.33119e+01
I0514 18:23:50.182624 140128494741248 run_lib.py:165] step: 89600, eval_loss: 2.70787e+01
I0514 18:23:56.377680 140128494741248 run_lib.py:152] step: 89650, training_loss: 3.50655e+01
I0514 18:24:02.670951 140128494741248 run_lib.py:152] step: 89700, training_loss: 2.35978e+01
I0514 18:24:02.722824 140128494741248 run_lib.py:165] step: 89700, eval_loss: 3.52508e+01
I0514 18:24:08.912205 140128494741248 run_lib.py:152] step: 89750, training_loss: 2.71870e+01
I0514 18:24:15.323325 140128494741248 run_lib.py:152] step: 89800, training_loss: 3.87827e+01
I0514 18:24:15.377131 140128494741248 run_lib.py:165] step: 89800, eval_loss: 3.17915e+01
I0514 18:24:21.561964 140128494741248 run_lib.py:152] step: 89850, training_loss: 3.17819e+01
I0514 18:24:27.776156 140128494741248 run_lib.py:152] step: 89900, training_loss: 3.25263e+01
I0514 18:24:27.826786 140128494741248 run_lib.py:165] step: 89900, eval_loss: 3.37070e+01
I0514 18:24:34.247699 140128494741248 run_lib.py:152] step: 89950, training_loss: 3.34187e+01
I0514 18:24:40.478028 140128494741248 run_lib.py:152] step: 90000, training_loss: 4.27307e+01
I0514 18:24:40.681123 140128494741248 run_lib.py:165] step: 90000, eval_loss: 3.64048e+01
I0514 18:24:46.902338 140128494741248 run_lib.py:152] step: 90050, training_loss: 3.40524e+01
I0514 18:24:53.172534 140128494741248 run_lib.py:152] step: 90100, training_loss: 2.37939e+01
I0514 18:24:53.225723 140128494741248 run_lib.py:165] step: 90100, eval_loss: 4.38576e+01
I0514 18:24:59.755724 140128494741248 run_lib.py:152] step: 90150, training_loss: 2.96049e+01
I0514 18:25:06.031770 140128494741248 run_lib.py:152] step: 90200, training_loss: 1.86783e+01
I0514 18:25:06.081677 140128494741248 run_lib.py:165] step: 90200, eval_loss: 2.84247e+01
I0514 18:25:12.354095 140128494741248 run_lib.py:152] step: 90250, training_loss: 3.10446e+01
I0514 18:25:18.803647 140128494741248 run_lib.py:152] step: 90300, training_loss: 3.66767e+01
I0514 18:25:18.854244 140128494741248 run_lib.py:165] step: 90300, eval_loss: 3.57950e+01
I0514 18:25:25.072065 140128494741248 run_lib.py:152] step: 90350, training_loss: 2.41596e+01
I0514 18:25:31.284175 140128494741248 run_lib.py:152] step: 90400, training_loss: 3.81096e+01
I0514 18:25:31.343790 140128494741248 run_lib.py:165] step: 90400, eval_loss: 3.58858e+01
I0514 18:25:37.565129 140128494741248 run_lib.py:152] step: 90450, training_loss: 3.48364e+01
I0514 18:25:44.032088 140128494741248 run_lib.py:152] step: 90500, training_loss: 2.66841e+01
I0514 18:25:44.081984 140128494741248 run_lib.py:165] step: 90500, eval_loss: 3.67405e+01
I0514 18:25:50.281937 140128494741248 run_lib.py:152] step: 90550, training_loss: 3.77137e+01
I0514 18:25:56.402084 140128494741248 run_lib.py:152] step: 90600, training_loss: 3.57558e+01
I0514 18:25:56.457346 140128494741248 run_lib.py:165] step: 90600, eval_loss: 4.29726e+01
I0514 18:26:02.897973 140128494741248 run_lib.py:152] step: 90650, training_loss: 2.65238e+01
I0514 18:26:09.096203 140128494741248 run_lib.py:152] step: 90700, training_loss: 4.83610e+01
I0514 18:26:09.155777 140128494741248 run_lib.py:165] step: 90700, eval_loss: 2.98573e+01
I0514 18:26:15.327175 140128494741248 run_lib.py:152] step: 90750, training_loss: 3.93480e+01
I0514 18:26:21.600254 140128494741248 run_lib.py:152] step: 90800, training_loss: 2.95234e+01
I0514 18:26:21.656493 140128494741248 run_lib.py:165] step: 90800, eval_loss: 3.04444e+01
I0514 18:26:28.142615 140128494741248 run_lib.py:152] step: 90850, training_loss: 3.54415e+01
I0514 18:26:34.319809 140128494741248 run_lib.py:152] step: 90900, training_loss: 2.30282e+01
I0514 18:26:34.366765 140128494741248 run_lib.py:165] step: 90900, eval_loss: 3.71719e+01
I0514 18:26:40.557487 140128494741248 run_lib.py:152] step: 90950, training_loss: 2.79173e+01
I0514 18:26:47.044410 140128494741248 run_lib.py:152] step: 91000, training_loss: 3.69977e+01
I0514 18:26:47.098379 140128494741248 run_lib.py:165] step: 91000, eval_loss: 1.32348e+01
I0514 18:26:53.235122 140128494741248 run_lib.py:152] step: 91050, training_loss: 2.25754e+01
I0514 18:26:59.427281 140128494741248 run_lib.py:152] step: 91100, training_loss: 4.52848e+01
I0514 18:26:59.476194 140128494741248 run_lib.py:165] step: 91100, eval_loss: 3.29915e+01
I0514 18:27:05.940027 140128494741248 run_lib.py:152] step: 91150, training_loss: 2.04231e+01
I0514 18:27:12.128592 140128494741248 run_lib.py:152] step: 91200, training_loss: 4.02611e+01
I0514 18:27:12.180166 140128494741248 run_lib.py:165] step: 91200, eval_loss: 3.43100e+01
I0514 18:27:18.395214 140128494741248 run_lib.py:152] step: 91250, training_loss: 2.80367e+01
I0514 18:27:24.578732 140128494741248 run_lib.py:152] step: 91300, training_loss: 2.54974e+01
I0514 18:27:24.628201 140128494741248 run_lib.py:165] step: 91300, eval_loss: 2.53196e+01
I0514 18:27:31.128870 140128494741248 run_lib.py:152] step: 91350, training_loss: 2.71936e+01
I0514 18:27:37.252191 140128494741248 run_lib.py:152] step: 91400, training_loss: 2.61621e+01
I0514 18:27:37.302369 140128494741248 run_lib.py:165] step: 91400, eval_loss: 2.72000e+01
I0514 18:27:43.573428 140128494741248 run_lib.py:152] step: 91450, training_loss: 3.97527e+01
I0514 18:27:50.063519 140128494741248 run_lib.py:152] step: 91500, training_loss: 2.33615e+01
I0514 18:27:50.116677 140128494741248 run_lib.py:165] step: 91500, eval_loss: 2.78755e+01
I0514 18:27:56.329913 140128494741248 run_lib.py:152] step: 91550, training_loss: 3.60551e+01
I0514 18:28:02.568946 140128494741248 run_lib.py:152] step: 91600, training_loss: 3.83705e+01
I0514 18:28:02.619223 140128494741248 run_lib.py:165] step: 91600, eval_loss: 4.48025e+01
I0514 18:28:08.800168 140128494741248 run_lib.py:152] step: 91650, training_loss: 3.19159e+01
I0514 18:28:15.247327 140128494741248 run_lib.py:152] step: 91700, training_loss: 2.01788e+01
I0514 18:28:15.297937 140128494741248 run_lib.py:165] step: 91700, eval_loss: 3.40517e+01
I0514 18:28:21.417375 140128494741248 run_lib.py:152] step: 91750, training_loss: 3.15302e+01
I0514 18:28:27.630497 140128494741248 run_lib.py:152] step: 91800, training_loss: 2.92363e+01
I0514 18:28:27.680563 140128494741248 run_lib.py:165] step: 91800, eval_loss: 3.39925e+01
I0514 18:28:34.099523 140128494741248 run_lib.py:152] step: 91850, training_loss: 3.49910e+01
I0514 18:28:40.349350 140128494741248 run_lib.py:152] step: 91900, training_loss: 1.97439e+01
I0514 18:28:40.400245 140128494741248 run_lib.py:165] step: 91900, eval_loss: 3.94760e+01
I0514 18:28:46.590744 140128494741248 run_lib.py:152] step: 91950, training_loss: 2.49495e+01
I0514 18:28:52.770585 140128494741248 run_lib.py:152] step: 92000, training_loss: 4.19437e+01
I0514 18:28:52.826883 140128494741248 run_lib.py:165] step: 92000, eval_loss: 2.94702e+01
I0514 18:28:59.315673 140128494741248 run_lib.py:152] step: 92050, training_loss: 2.38771e+01
I0514 18:29:05.555448 140128494741248 run_lib.py:152] step: 92100, training_loss: 4.61171e+01
I0514 18:29:05.604483 140128494741248 run_lib.py:165] step: 92100, eval_loss: 2.92338e+01
I0514 18:29:11.814429 140128494741248 run_lib.py:152] step: 92150, training_loss: 3.62198e+01
I0514 18:29:18.237622 140128494741248 run_lib.py:152] step: 92200, training_loss: 2.51162e+01
I0514 18:29:18.287088 140128494741248 run_lib.py:165] step: 92200, eval_loss: 3.71242e+01
I0514 18:29:24.532377 140128494741248 run_lib.py:152] step: 92250, training_loss: 3.70879e+01
I0514 18:29:30.625175 140128494741248 run_lib.py:152] step: 92300, training_loss: 3.98158e+01
I0514 18:29:30.678457 140128494741248 run_lib.py:165] step: 92300, eval_loss: 3.81756e+01
I0514 18:29:36.866717 140128494741248 run_lib.py:152] step: 92350, training_loss: 3.47659e+01
I0514 18:29:43.316589 140128494741248 run_lib.py:152] step: 92400, training_loss: 2.91106e+01
I0514 18:29:43.368780 140128494741248 run_lib.py:165] step: 92400, eval_loss: 3.65771e+01
I0514 18:29:49.555507 140128494741248 run_lib.py:152] step: 92450, training_loss: 3.85763e+01
I0514 18:29:55.732245 140128494741248 run_lib.py:152] step: 92500, training_loss: 1.74635e+01
I0514 18:29:55.783103 140128494741248 run_lib.py:165] step: 92500, eval_loss: 3.04348e+01
I0514 18:30:02.193079 140128494741248 run_lib.py:152] step: 92550, training_loss: 3.09006e+01
I0514 18:30:08.407871 140128494741248 run_lib.py:152] step: 92600, training_loss: 4.38932e+01
I0514 18:30:08.462038 140128494741248 run_lib.py:165] step: 92600, eval_loss: 3.19479e+01
I0514 18:30:14.715752 140128494741248 run_lib.py:152] step: 92650, training_loss: 3.20662e+01
I0514 18:30:21.014700 140128494741248 run_lib.py:152] step: 92700, training_loss: 3.79917e+01
I0514 18:30:21.066131 140128494741248 run_lib.py:165] step: 92700, eval_loss: 5.06721e+01
I0514 18:30:27.480555 140128494741248 run_lib.py:152] step: 92750, training_loss: 2.05603e+01
I0514 18:30:33.674454 140128494741248 run_lib.py:152] step: 92800, training_loss: 3.91083e+01
I0514 18:30:33.725739 140128494741248 run_lib.py:165] step: 92800, eval_loss: 4.19604e+01
I0514 18:30:39.925990 140128494741248 run_lib.py:152] step: 92850, training_loss: 6.15042e+01
I0514 18:30:46.401062 140128494741248 run_lib.py:152] step: 92900, training_loss: 3.37178e+01
I0514 18:30:46.459707 140128494741248 run_lib.py:165] step: 92900, eval_loss: 1.00633e+01
I0514 18:30:52.669533 140128494741248 run_lib.py:152] step: 92950, training_loss: 3.32210e+01
I0514 18:30:58.885069 140128494741248 run_lib.py:152] step: 93000, training_loss: 3.61168e+01
I0514 18:30:58.939765 140128494741248 run_lib.py:165] step: 93000, eval_loss: 3.19949e+01
I0514 18:31:05.123775 140128494741248 run_lib.py:152] step: 93050, training_loss: 3.38579e+01
I0514 18:31:11.570646 140128494741248 run_lib.py:152] step: 93100, training_loss: 2.68486e+01
I0514 18:31:11.624060 140128494741248 run_lib.py:165] step: 93100, eval_loss: 3.49435e+01
I0514 18:31:17.930818 140128494741248 run_lib.py:152] step: 93150, training_loss: 2.61943e+01
I0514 18:31:24.139308 140128494741248 run_lib.py:152] step: 93200, training_loss: 4.39619e+01
I0514 18:31:24.193550 140128494741248 run_lib.py:165] step: 93200, eval_loss: 2.43676e+01
I0514 18:31:30.658925 140128494741248 run_lib.py:152] step: 93250, training_loss: 3.70809e+01
I0514 18:31:36.915942 140128494741248 run_lib.py:152] step: 93300, training_loss: 2.79261e+01
I0514 18:31:36.967831 140128494741248 run_lib.py:165] step: 93300, eval_loss: 3.56164e+01
I0514 18:31:43.205689 140128494741248 run_lib.py:152] step: 93350, training_loss: 2.58593e+01
I0514 18:31:49.460145 140128494741248 run_lib.py:152] step: 93400, training_loss: 3.69487e+01
I0514 18:31:49.512371 140128494741248 run_lib.py:165] step: 93400, eval_loss: 2.57419e+01
I0514 18:31:55.935938 140128494741248 run_lib.py:152] step: 93450, training_loss: 3.45281e+01
I0514 18:32:02.156183 140128494741248 run_lib.py:152] step: 93500, training_loss: 2.44361e+01
I0514 18:32:02.210972 140128494741248 run_lib.py:165] step: 93500, eval_loss: 2.84204e+01
I0514 18:32:08.431827 140128494741248 run_lib.py:152] step: 93550, training_loss: 3.75937e+01
I0514 18:32:14.637318 140128494741248 run_lib.py:152] step: 93600, training_loss: 3.56892e+01
I0514 18:32:14.911246 140128494741248 run_lib.py:165] step: 93600, eval_loss: 3.25352e+01
I0514 18:32:21.144877 140128494741248 run_lib.py:152] step: 93650, training_loss: 2.20368e+01
I0514 18:32:27.329646 140128494741248 run_lib.py:152] step: 93700, training_loss: 3.94384e+01
I0514 18:32:27.383810 140128494741248 run_lib.py:165] step: 93700, eval_loss: 4.36248e+01
I0514 18:32:33.595061 140128494741248 run_lib.py:152] step: 93750, training_loss: 4.57725e+01
I0514 18:32:39.918712 140128494741248 run_lib.py:152] step: 93800, training_loss: 3.17912e+01
I0514 18:32:39.968130 140128494741248 run_lib.py:165] step: 93800, eval_loss: 3.55635e+01
I0514 18:32:46.107907 140128494741248 run_lib.py:152] step: 93850, training_loss: 3.35956e+01
I0514 18:32:52.349232 140128494741248 run_lib.py:152] step: 93900, training_loss: 3.68117e+01
I0514 18:32:52.403743 140128494741248 run_lib.py:165] step: 93900, eval_loss: 1.94135e+01
I0514 18:32:58.846845 140128494741248 run_lib.py:152] step: 93950, training_loss: 2.94877e+01
I0514 18:33:05.119426 140128494741248 run_lib.py:152] step: 94000, training_loss: 2.62230e+01
I0514 18:33:05.175070 140128494741248 run_lib.py:165] step: 94000, eval_loss: 3.70143e+01
I0514 18:33:11.387499 140128494741248 run_lib.py:152] step: 94050, training_loss: 2.62654e+01
I0514 18:33:17.656908 140128494741248 run_lib.py:152] step: 94100, training_loss: 3.41424e+01
I0514 18:33:17.710488 140128494741248 run_lib.py:165] step: 94100, eval_loss: 3.16561e+01
I0514 18:33:24.186234 140128494741248 run_lib.py:152] step: 94150, training_loss: 3.26096e+01
I0514 18:33:30.406893 140128494741248 run_lib.py:152] step: 94200, training_loss: 2.11341e+01
I0514 18:33:30.456987 140128494741248 run_lib.py:165] step: 94200, eval_loss: 3.46771e+01
I0514 18:33:36.588339 140128494741248 run_lib.py:152] step: 94250, training_loss: 3.37884e+01
I0514 18:33:43.050962 140128494741248 run_lib.py:152] step: 94300, training_loss: 3.97609e+01
I0514 18:33:43.106984 140128494741248 run_lib.py:165] step: 94300, eval_loss: 2.90543e+01
I0514 18:33:49.329461 140128494741248 run_lib.py:152] step: 94350, training_loss: 3.20261e+01
I0514 18:33:55.527330 140128494741248 run_lib.py:152] step: 94400, training_loss: 2.51785e+01
I0514 18:33:55.581709 140128494741248 run_lib.py:165] step: 94400, eval_loss: 3.58199e+01
I0514 18:34:01.831549 140128494741248 run_lib.py:152] step: 94450, training_loss: 2.69999e+01
I0514 18:34:08.278268 140128494741248 run_lib.py:152] step: 94500, training_loss: 4.51626e+01
I0514 18:34:08.330849 140128494741248 run_lib.py:165] step: 94500, eval_loss: 3.68915e+01
I0514 18:34:14.499113 140128494741248 run_lib.py:152] step: 94550, training_loss: 2.60080e+01
I0514 18:34:20.691349 140128494741248 run_lib.py:152] step: 94600, training_loss: 3.63185e+01
I0514 18:34:20.745436 140128494741248 run_lib.py:165] step: 94600, eval_loss: 4.11225e+01
I0514 18:34:27.172946 140128494741248 run_lib.py:152] step: 94650, training_loss: 2.86929e+01
I0514 18:34:33.408066 140128494741248 run_lib.py:152] step: 94700, training_loss: 4.40200e+01
I0514 18:34:33.458702 140128494741248 run_lib.py:165] step: 94700, eval_loss: 2.75197e+01
I0514 18:34:39.758240 140128494741248 run_lib.py:152] step: 94750, training_loss: 2.94232e+01
I0514 18:34:46.028560 140128494741248 run_lib.py:152] step: 94800, training_loss: 3.62580e+01
I0514 18:34:46.077907 140128494741248 run_lib.py:165] step: 94800, eval_loss: 3.07260e+01
I0514 18:34:52.566949 140128494741248 run_lib.py:152] step: 94850, training_loss: 3.90531e+01
I0514 18:34:58.820350 140128494741248 run_lib.py:152] step: 94900, training_loss: 1.97050e+01
I0514 18:34:58.869455 140128494741248 run_lib.py:165] step: 94900, eval_loss: 4.27583e+01
I0514 18:35:05.179906 140128494741248 run_lib.py:152] step: 94950, training_loss: 2.87124e+01
I0514 18:35:11.607701 140128494741248 run_lib.py:152] step: 95000, training_loss: 4.09557e+01
I0514 18:35:11.660030 140128494741248 run_lib.py:165] step: 95000, eval_loss: 4.10536e+01
I0514 18:35:17.885656 140128494741248 run_lib.py:152] step: 95050, training_loss: 2.69268e+01
I0514 18:35:24.027265 140128494741248 run_lib.py:152] step: 95100, training_loss: 4.88958e+01
I0514 18:35:24.079308 140128494741248 run_lib.py:165] step: 95100, eval_loss: 3.82885e+01
I0514 18:35:30.285811 140128494741248 run_lib.py:152] step: 95150, training_loss: 3.60082e+01
I0514 18:35:36.686609 140128494741248 run_lib.py:152] step: 95200, training_loss: 3.21260e+01
I0514 18:35:36.740567 140128494741248 run_lib.py:165] step: 95200, eval_loss: 1.94775e+01
I0514 18:35:42.938031 140128494741248 run_lib.py:152] step: 95250, training_loss: 3.25407e+01
I0514 18:35:49.125335 140128494741248 run_lib.py:152] step: 95300, training_loss: 3.37141e+01
I0514 18:35:49.178490 140128494741248 run_lib.py:165] step: 95300, eval_loss: 4.11018e+01
I0514 18:35:55.687705 140128494741248 run_lib.py:152] step: 95350, training_loss: 4.71471e+01
I0514 18:36:01.843477 140128494741248 run_lib.py:152] step: 95400, training_loss: 2.66881e+01
I0514 18:36:01.893068 140128494741248 run_lib.py:165] step: 95400, eval_loss: 3.94419e+01
I0514 18:36:08.157574 140128494741248 run_lib.py:152] step: 95450, training_loss: 2.82357e+01
I0514 18:36:14.382279 140128494741248 run_lib.py:152] step: 95500, training_loss: 2.18767e+01
I0514 18:36:14.434350 140128494741248 run_lib.py:165] step: 95500, eval_loss: 3.06098e+01
I0514 18:36:20.844151 140128494741248 run_lib.py:152] step: 95550, training_loss: 4.14311e+01
I0514 18:36:27.048449 140128494741248 run_lib.py:152] step: 95600, training_loss: 3.94652e+01
I0514 18:36:27.101211 140128494741248 run_lib.py:165] step: 95600, eval_loss: 2.81250e+01
I0514 18:36:33.300235 140128494741248 run_lib.py:152] step: 95650, training_loss: 3.19737e+01
I0514 18:36:39.789581 140128494741248 run_lib.py:152] step: 95700, training_loss: 3.29924e+01
I0514 18:36:39.844385 140128494741248 run_lib.py:165] step: 95700, eval_loss: 3.40605e+01
I0514 18:36:46.097031 140128494741248 run_lib.py:152] step: 95750, training_loss: 2.63674e+01
I0514 18:36:52.212102 140128494741248 run_lib.py:152] step: 95800, training_loss: 2.58249e+01
I0514 18:36:52.260514 140128494741248 run_lib.py:165] step: 95800, eval_loss: 2.73647e+01
I0514 18:36:58.516204 140128494741248 run_lib.py:152] step: 95850, training_loss: 2.95214e+01
I0514 18:37:04.938125 140128494741248 run_lib.py:152] step: 95900, training_loss: 3.13897e+01
I0514 18:37:04.989703 140128494741248 run_lib.py:165] step: 95900, eval_loss: 3.84308e+01
I0514 18:37:11.282485 140128494741248 run_lib.py:152] step: 95950, training_loss: 5.22489e+01
I0514 18:37:17.446809 140128494741248 run_lib.py:152] step: 96000, training_loss: 2.64785e+01
I0514 18:37:17.499263 140128494741248 run_lib.py:165] step: 96000, eval_loss: 3.13945e+01
I0514 18:37:24.051584 140128494741248 run_lib.py:152] step: 96050, training_loss: 3.54531e+01
I0514 18:37:30.287629 140128494741248 run_lib.py:152] step: 96100, training_loss: 4.76937e+01
I0514 18:37:30.341956 140128494741248 run_lib.py:165] step: 96100, eval_loss: 3.37018e+01
I0514 18:37:36.608395 140128494741248 run_lib.py:152] step: 96150, training_loss: 3.29392e+01
I0514 18:37:42.807821 140128494741248 run_lib.py:152] step: 96200, training_loss: 2.90036e+01
I0514 18:37:42.859676 140128494741248 run_lib.py:165] step: 96200, eval_loss: 4.56895e+01
I0514 18:37:49.337871 140128494741248 run_lib.py:152] step: 96250, training_loss: 3.60896e+01
I0514 18:37:55.518315 140128494741248 run_lib.py:152] step: 96300, training_loss: 2.20215e+01
I0514 18:37:55.570344 140128494741248 run_lib.py:165] step: 96300, eval_loss: 3.15839e+01
I0514 18:38:01.757306 140128494741248 run_lib.py:152] step: 96350, training_loss: 4.29256e+01
I0514 18:38:08.216599 140128494741248 run_lib.py:152] step: 96400, training_loss: 3.57750e+01
I0514 18:38:08.285738 140128494741248 run_lib.py:165] step: 96400, eval_loss: 3.45271e+01
I0514 18:38:14.486984 140128494741248 run_lib.py:152] step: 96450, training_loss: 1.86647e+01
I0514 18:38:20.823717 140128494741248 run_lib.py:152] step: 96500, training_loss: 2.76507e+01
I0514 18:38:20.872578 140128494741248 run_lib.py:165] step: 96500, eval_loss: 4.38234e+01
I0514 18:38:27.209397 140128494741248 run_lib.py:152] step: 96550, training_loss: 2.69440e+01
I0514 18:38:33.699952 140128494741248 run_lib.py:152] step: 96600, training_loss: 3.04091e+01
I0514 18:38:33.751439 140128494741248 run_lib.py:165] step: 96600, eval_loss: 2.76263e+01
I0514 18:38:39.986283 140128494741248 run_lib.py:152] step: 96650, training_loss: 3.58391e+01
I0514 18:38:46.215216 140128494741248 run_lib.py:152] step: 96700, training_loss: 3.18120e+01
I0514 18:38:46.267817 140128494741248 run_lib.py:165] step: 96700, eval_loss: 4.27328e+01
I0514 18:38:52.710869 140128494741248 run_lib.py:152] step: 96750, training_loss: 1.93590e+01
I0514 18:38:58.911676 140128494741248 run_lib.py:152] step: 96800, training_loss: 2.60201e+01
I0514 18:38:58.968622 140128494741248 run_lib.py:165] step: 96800, eval_loss: 3.23349e+01
I0514 18:39:05.210192 140128494741248 run_lib.py:152] step: 96850, training_loss: 3.39000e+01
I0514 18:39:11.450288 140128494741248 run_lib.py:152] step: 96900, training_loss: 3.20619e+01
I0514 18:39:11.506892 140128494741248 run_lib.py:165] step: 96900, eval_loss: 3.09119e+01
I0514 18:39:17.952886 140128494741248 run_lib.py:152] step: 96950, training_loss: 2.48671e+01
I0514 18:39:24.167999 140128494741248 run_lib.py:152] step: 97000, training_loss: 2.77797e+01
I0514 18:39:24.218727 140128494741248 run_lib.py:165] step: 97000, eval_loss: 2.66143e+01
I0514 18:39:30.426600 140128494741248 run_lib.py:152] step: 97050, training_loss: 2.65552e+01
I0514 18:39:36.617497 140128494741248 run_lib.py:152] step: 97100, training_loss: 2.51038e+01
I0514 18:39:36.907948 140128494741248 run_lib.py:165] step: 97100, eval_loss: 3.32652e+01
I0514 18:39:43.215937 140128494741248 run_lib.py:152] step: 97150, training_loss: 3.32394e+01
I0514 18:39:49.430002 140128494741248 run_lib.py:152] step: 97200, training_loss: 2.85353e+01
I0514 18:39:49.485883 140128494741248 run_lib.py:165] step: 97200, eval_loss: 2.40783e+01
I0514 18:39:55.779854 140128494741248 run_lib.py:152] step: 97250, training_loss: 2.22498e+01
I0514 18:40:02.298793 140128494741248 run_lib.py:152] step: 97300, training_loss: 3.16639e+01
I0514 18:40:02.346740 140128494741248 run_lib.py:165] step: 97300, eval_loss: 2.92748e+01
I0514 18:40:08.521340 140128494741248 run_lib.py:152] step: 97350, training_loss: 2.25362e+01
I0514 18:40:14.677982 140128494741248 run_lib.py:152] step: 97400, training_loss: 2.31430e+01
I0514 18:40:14.727752 140128494741248 run_lib.py:165] step: 97400, eval_loss: 4.63864e+01
I0514 18:40:21.199798 140128494741248 run_lib.py:152] step: 97450, training_loss: 4.21092e+01
I0514 18:40:27.490178 140128494741248 run_lib.py:152] step: 97500, training_loss: 2.26416e+01
I0514 18:40:27.549323 140128494741248 run_lib.py:165] step: 97500, eval_loss: 3.42530e+01
I0514 18:40:33.715220 140128494741248 run_lib.py:152] step: 97550, training_loss: 2.84981e+01
I0514 18:40:39.920540 140128494741248 run_lib.py:152] step: 97600, training_loss: 3.94739e+01
I0514 18:40:39.972673 140128494741248 run_lib.py:165] step: 97600, eval_loss: 2.32162e+01
I0514 18:40:46.428797 140128494741248 run_lib.py:152] step: 97650, training_loss: 2.83972e+01
I0514 18:40:52.631982 140128494741248 run_lib.py:152] step: 97700, training_loss: 2.02834e+01
I0514 18:40:52.682186 140128494741248 run_lib.py:165] step: 97700, eval_loss: 3.01455e+01
I0514 18:40:58.850766 140128494741248 run_lib.py:152] step: 97750, training_loss: 2.26825e+01
I0514 18:41:05.298180 140128494741248 run_lib.py:152] step: 97800, training_loss: 3.26181e+01
I0514 18:41:05.349438 140128494741248 run_lib.py:165] step: 97800, eval_loss: 3.69808e+01
I0514 18:41:11.599933 140128494741248 run_lib.py:152] step: 97850, training_loss: 3.35196e+01
I0514 18:41:17.762644 140128494741248 run_lib.py:152] step: 97900, training_loss: 4.18643e+01
I0514 18:41:17.816632 140128494741248 run_lib.py:165] step: 97900, eval_loss: 1.85756e+01
I0514 18:41:24.026495 140128494741248 run_lib.py:152] step: 97950, training_loss: 2.72652e+01
I0514 18:41:30.421507 140128494741248 run_lib.py:152] step: 98000, training_loss: 3.00297e+01
I0514 18:41:30.474822 140128494741248 run_lib.py:165] step: 98000, eval_loss: 5.71028e+01
I0514 18:41:36.616144 140128494741248 run_lib.py:152] step: 98050, training_loss: 3.66392e+01
I0514 18:41:42.836946 140128494741248 run_lib.py:152] step: 98100, training_loss: 3.28429e+01
I0514 18:41:42.890986 140128494741248 run_lib.py:165] step: 98100, eval_loss: 3.85378e+01
I0514 18:41:49.293496 140128494741248 run_lib.py:152] step: 98150, training_loss: 2.92126e+01
I0514 18:41:55.514852 140128494741248 run_lib.py:152] step: 98200, training_loss: 3.69308e+01
I0514 18:41:55.566653 140128494741248 run_lib.py:165] step: 98200, eval_loss: 2.19665e+01
I0514 18:42:01.744812 140128494741248 run_lib.py:152] step: 98250, training_loss: 1.94980e+01
I0514 18:42:07.961622 140128494741248 run_lib.py:152] step: 98300, training_loss: 3.47347e+01
I0514 18:42:08.018437 140128494741248 run_lib.py:165] step: 98300, eval_loss: 2.78670e+01
I0514 18:42:14.350989 140128494741248 run_lib.py:152] step: 98350, training_loss: 3.20942e+01
I0514 18:42:20.616011 140128494741248 run_lib.py:152] step: 98400, training_loss: 5.87935e+01
I0514 18:42:20.665345 140128494741248 run_lib.py:165] step: 98400, eval_loss: 3.07564e+01
I0514 18:42:26.908263 140128494741248 run_lib.py:152] step: 98450, training_loss: 3.15776e+01
I0514 18:42:33.378338 140128494741248 run_lib.py:152] step: 98500, training_loss: 2.73129e+01
I0514 18:42:33.431080 140128494741248 run_lib.py:165] step: 98500, eval_loss: 2.44409e+01
I0514 18:42:39.584358 140128494741248 run_lib.py:152] step: 98550, training_loss: 2.86315e+01
I0514 18:42:45.838468 140128494741248 run_lib.py:152] step: 98600, training_loss: 3.13995e+01
I0514 18:42:45.889871 140128494741248 run_lib.py:165] step: 98600, eval_loss: 2.98673e+01
I0514 18:42:52.121955 140128494741248 run_lib.py:152] step: 98650, training_loss: 2.80425e+01
I0514 18:42:58.535035 140128494741248 run_lib.py:152] step: 98700, training_loss: 2.22551e+01
I0514 18:42:58.583305 140128494741248 run_lib.py:165] step: 98700, eval_loss: 3.46769e+01
I0514 18:43:04.750466 140128494741248 run_lib.py:152] step: 98750, training_loss: 4.08913e+01
I0514 18:43:11.052113 140128494741248 run_lib.py:152] step: 98800, training_loss: 2.52841e+01
I0514 18:43:11.103660 140128494741248 run_lib.py:165] step: 98800, eval_loss: 4.62923e+01
I0514 18:43:17.496069 140128494741248 run_lib.py:152] step: 98850, training_loss: 2.31612e+01
I0514 18:43:23.793230 140128494741248 run_lib.py:152] step: 98900, training_loss: 2.49894e+01
I0514 18:43:23.849849 140128494741248 run_lib.py:165] step: 98900, eval_loss: 2.78295e+01
I0514 18:43:30.071290 140128494741248 run_lib.py:152] step: 98950, training_loss: 2.63862e+01
I0514 18:43:36.339404 140128494741248 run_lib.py:152] step: 99000, training_loss: 3.35154e+01
I0514 18:43:36.392279 140128494741248 run_lib.py:165] step: 99000, eval_loss: 3.77720e+01
I0514 18:43:42.875879 140128494741248 run_lib.py:152] step: 99050, training_loss: 4.45098e+01
I0514 18:43:49.215828 140128494741248 run_lib.py:152] step: 99100, training_loss: 3.37319e+01
I0514 18:43:49.266700 140128494741248 run_lib.py:165] step: 99100, eval_loss: 2.53020e+01
I0514 18:43:55.489593 140128494741248 run_lib.py:152] step: 99150, training_loss: 2.86136e+01
I0514 18:44:01.919488 140128494741248 run_lib.py:152] step: 99200, training_loss: 3.06712e+01
I0514 18:44:01.976661 140128494741248 run_lib.py:165] step: 99200, eval_loss: 4.44418e+01
I0514 18:44:08.227411 140128494741248 run_lib.py:152] step: 99250, training_loss: 3.14116e+01
I0514 18:44:14.401497 140128494741248 run_lib.py:152] step: 99300, training_loss: 3.40492e+01
I0514 18:44:14.459852 140128494741248 run_lib.py:165] step: 99300, eval_loss: 2.87316e+01
I0514 18:44:20.665311 140128494741248 run_lib.py:152] step: 99350, training_loss: 3.69766e+01
I0514 18:44:27.175682 140128494741248 run_lib.py:152] step: 99400, training_loss: 2.40591e+01
I0514 18:44:27.227399 140128494741248 run_lib.py:165] step: 99400, eval_loss: 1.22342e+01
I0514 18:44:33.385466 140128494741248 run_lib.py:152] step: 99450, training_loss: 3.35099e+01
I0514 18:44:39.680880 140128494741248 run_lib.py:152] step: 99500, training_loss: 3.78672e+01
I0514 18:44:39.730301 140128494741248 run_lib.py:165] step: 99500, eval_loss: 3.31420e+01
I0514 18:44:46.174458 140128494741248 run_lib.py:152] step: 99550, training_loss: 3.00146e+01
I0514 18:44:52.361330 140128494741248 run_lib.py:152] step: 99600, training_loss: 3.64268e+01
I0514 18:44:52.410351 140128494741248 run_lib.py:165] step: 99600, eval_loss: 4.86362e+01
I0514 18:44:58.726284 140128494741248 run_lib.py:152] step: 99650, training_loss: 2.98970e+01
I0514 18:45:04.975942 140128494741248 run_lib.py:152] step: 99700, training_loss: 3.10468e+01
I0514 18:45:05.026675 140128494741248 run_lib.py:165] step: 99700, eval_loss: 5.10269e+01
I0514 18:45:11.477031 140128494741248 run_lib.py:152] step: 99750, training_loss: 2.36765e+01
I0514 18:45:17.689451 140128494741248 run_lib.py:152] step: 99800, training_loss: 2.75221e+01
I0514 18:45:17.743214 140128494741248 run_lib.py:165] step: 99800, eval_loss: 2.85836e+01
I0514 18:45:24.043967 140128494741248 run_lib.py:152] step: 99850, training_loss: 2.43579e+01
I0514 18:45:30.442615 140128494741248 run_lib.py:152] step: 99900, training_loss: 5.02927e+01
I0514 18:45:30.495800 140128494741248 run_lib.py:165] step: 99900, eval_loss: 3.74319e+01
I0514 18:45:36.761252 140128494741248 run_lib.py:152] step: 99950, training_loss: 2.02432e+01
I0514 18:45:43.048599 140128494741248 run_lib.py:152] step: 100000, training_loss: 2.77428e+01
I0514 18:45:43.259239 140128494741248 run_lib.py:165] step: 100000, eval_loss: 3.79254e+01
I0514 18:47:03.851848 140128494741248 run_lib.py:152] step: 100050, training_loss: 3.85007e+01
I0514 18:47:10.086163 140128494741248 run_lib.py:152] step: 100100, training_loss: 2.26876e+01
I0514 18:47:10.137132 140128494741248 run_lib.py:165] step: 100100, eval_loss: 2.74169e+01
I0514 18:47:16.350799 140128494741248 run_lib.py:152] step: 100150, training_loss: 2.91916e+01
I0514 18:47:22.879569 140128494741248 run_lib.py:152] step: 100200, training_loss: 3.28159e+01
I0514 18:47:22.933245 140128494741248 run_lib.py:165] step: 100200, eval_loss: 3.57460e+01
I0514 18:47:29.134202 140128494741248 run_lib.py:152] step: 100250, training_loss: 3.79479e+01
I0514 18:47:35.307643 140128494741248 run_lib.py:152] step: 100300, training_loss: 3.13072e+01
I0514 18:47:35.362751 140128494741248 run_lib.py:165] step: 100300, eval_loss: 2.96453e+01
I0514 18:47:41.578573 140128494741248 run_lib.py:152] step: 100350, training_loss: 4.31114e+01
I0514 18:47:48.040899 140128494741248 run_lib.py:152] step: 100400, training_loss: 2.22165e+01
I0514 18:47:48.095153 140128494741248 run_lib.py:165] step: 100400, eval_loss: 2.98537e+01
I0514 18:47:54.343289 140128494741248 run_lib.py:152] step: 100450, training_loss: 3.40187e+01
I0514 18:48:00.518652 140128494741248 run_lib.py:152] step: 100500, training_loss: 3.67094e+01
I0514 18:48:00.571954 140128494741248 run_lib.py:165] step: 100500, eval_loss: 3.86594e+01
I0514 18:48:06.814094 140128494741248 run_lib.py:152] step: 100550, training_loss: 2.52124e+01
I0514 18:48:13.233737 140128494741248 run_lib.py:152] step: 100600, training_loss: 2.46858e+01
I0514 18:48:13.295859 140128494741248 run_lib.py:165] step: 100600, eval_loss: 2.88479e+01
I0514 18:48:19.493466 140128494741248 run_lib.py:152] step: 100650, training_loss: 4.97159e+01
I0514 18:48:25.779167 140128494741248 run_lib.py:152] step: 100700, training_loss: 2.53556e+01
I0514 18:48:25.828210 140128494741248 run_lib.py:165] step: 100700, eval_loss: 3.81181e+01
I0514 18:48:32.325838 140128494741248 run_lib.py:152] step: 100750, training_loss: 1.96619e+01
I0514 18:48:38.595740 140128494741248 run_lib.py:152] step: 100800, training_loss: 3.05487e+01
I0514 18:48:38.646344 140128494741248 run_lib.py:165] step: 100800, eval_loss: 2.67940e+01
I0514 18:48:44.877822 140128494741248 run_lib.py:152] step: 100850, training_loss: 3.42669e+01
I0514 18:48:51.318078 140128494741248 run_lib.py:152] step: 100900, training_loss: 3.24821e+01
I0514 18:48:51.371732 140128494741248 run_lib.py:165] step: 100900, eval_loss: 2.41710e+01
I0514 18:48:57.538383 140128494741248 run_lib.py:152] step: 100950, training_loss: 1.90082e+01
I0514 18:49:03.753172 140128494741248 run_lib.py:152] step: 101000, training_loss: 3.31993e+01
I0514 18:49:03.804581 140128494741248 run_lib.py:165] step: 101000, eval_loss: 2.85097e+01
I0514 18:49:10.067231 140128494741248 run_lib.py:152] step: 101050, training_loss: 2.27993e+01
I0514 18:49:16.460065 140128494741248 run_lib.py:152] step: 101100, training_loss: 2.29541e+01
I0514 18:49:16.511830 140128494741248 run_lib.py:165] step: 101100, eval_loss: 2.23820e+01
I0514 18:49:22.694271 140128494741248 run_lib.py:152] step: 101150, training_loss: 1.48238e+01
I0514 18:49:28.937226 140128494741248 run_lib.py:152] step: 101200, training_loss: 3.78190e+01
I0514 18:49:28.995561 140128494741248 run_lib.py:165] step: 101200, eval_loss: 4.34860e+01
I0514 18:49:35.431081 140128494741248 run_lib.py:152] step: 101250, training_loss: 3.21013e+01
I0514 18:49:41.596294 140128494741248 run_lib.py:152] step: 101300, training_loss: 3.04967e+01
I0514 18:49:41.654522 140128494741248 run_lib.py:165] step: 101300, eval_loss: 1.76510e+01
I0514 18:49:47.825949 140128494741248 run_lib.py:152] step: 101350, training_loss: 4.03920e+01
I0514 18:49:54.119513 140128494741248 run_lib.py:152] step: 101400, training_loss: 3.25290e+01
I0514 18:49:54.176271 140128494741248 run_lib.py:165] step: 101400, eval_loss: 3.03523e+01
I0514 18:50:00.618399 140128494741248 run_lib.py:152] step: 101450, training_loss: 3.59114e+01
I0514 18:50:06.962136 140128494741248 run_lib.py:152] step: 101500, training_loss: 4.00962e+01
I0514 18:50:07.021067 140128494741248 run_lib.py:165] step: 101500, eval_loss: 3.79083e+01
I0514 18:50:13.233381 140128494741248 run_lib.py:152] step: 101550, training_loss: 3.22272e+01
I0514 18:50:19.436845 140128494741248 run_lib.py:152] step: 101600, training_loss: 3.23003e+01
I0514 18:50:19.709720 140128494741248 run_lib.py:165] step: 101600, eval_loss: 3.16941e+01
I0514 18:50:26.003610 140128494741248 run_lib.py:152] step: 101650, training_loss: 2.47429e+01
I0514 18:50:32.297331 140128494741248 run_lib.py:152] step: 101700, training_loss: 2.33469e+01
I0514 18:50:32.357325 140128494741248 run_lib.py:165] step: 101700, eval_loss: 3.29783e+01
I0514 18:50:38.478004 140128494741248 run_lib.py:152] step: 101750, training_loss: 2.06497e+01
I0514 18:50:44.901470 140128494741248 run_lib.py:152] step: 101800, training_loss: 2.83798e+01
I0514 18:50:44.954986 140128494741248 run_lib.py:165] step: 101800, eval_loss: 3.04068e+01
I0514 18:50:51.228187 140128494741248 run_lib.py:152] step: 101850, training_loss: 1.59808e+01
I0514 18:50:57.420431 140128494741248 run_lib.py:152] step: 101900, training_loss: 2.95256e+01
I0514 18:50:57.471768 140128494741248 run_lib.py:165] step: 101900, eval_loss: 2.71590e+01
I0514 18:51:03.891189 140128494741248 run_lib.py:152] step: 101950, training_loss: 3.43395e+01
I0514 18:51:10.079613 140128494741248 run_lib.py:152] step: 102000, training_loss: 4.59061e+01
I0514 18:51:10.129576 140128494741248 run_lib.py:165] step: 102000, eval_loss: 2.42596e+01
I0514 18:51:16.269731 140128494741248 run_lib.py:152] step: 102050, training_loss: 3.28962e+01
I0514 18:51:22.441343 140128494741248 run_lib.py:152] step: 102100, training_loss: 3.19035e+01
I0514 18:51:22.492295 140128494741248 run_lib.py:165] step: 102100, eval_loss: 3.20430e+01
I0514 18:51:28.961709 140128494741248 run_lib.py:152] step: 102150, training_loss: 1.58303e+01
I0514 18:51:35.123138 140128494741248 run_lib.py:152] step: 102200, training_loss: 2.53310e+01
I0514 18:51:35.171052 140128494741248 run_lib.py:165] step: 102200, eval_loss: 3.73033e+01
I0514 18:51:41.342977 140128494741248 run_lib.py:152] step: 102250, training_loss: 2.60422e+01
I0514 18:51:47.844728 140128494741248 run_lib.py:152] step: 102300, training_loss: 2.83973e+01
I0514 18:51:47.893702 140128494741248 run_lib.py:165] step: 102300, eval_loss: 3.45558e+01
I0514 18:51:54.122520 140128494741248 run_lib.py:152] step: 102350, training_loss: 3.18315e+01
I0514 18:52:00.470082 140128494741248 run_lib.py:152] step: 102400, training_loss: 2.99281e+01
I0514 18:52:00.522573 140128494741248 run_lib.py:165] step: 102400, eval_loss: 3.29103e+01
I0514 18:52:06.768502 140128494741248 run_lib.py:152] step: 102450, training_loss: 1.46592e+01
I0514 18:52:13.225647 140128494741248 run_lib.py:152] step: 102500, training_loss: 3.40210e+01
I0514 18:52:13.278099 140128494741248 run_lib.py:165] step: 102500, eval_loss: 2.35593e+01
I0514 18:52:19.469676 140128494741248 run_lib.py:152] step: 102550, training_loss: 2.79148e+01
I0514 18:52:25.705905 140128494741248 run_lib.py:152] step: 102600, training_loss: 2.14121e+01
I0514 18:52:25.751267 140128494741248 run_lib.py:165] step: 102600, eval_loss: 3.17921e+01
I0514 18:52:32.297680 140128494741248 run_lib.py:152] step: 102650, training_loss: 4.84671e+01
I0514 18:52:38.459824 140128494741248 run_lib.py:152] step: 102700, training_loss: 2.80871e+01
I0514 18:52:38.513964 140128494741248 run_lib.py:165] step: 102700, eval_loss: 2.79088e+01
I0514 18:52:44.823532 140128494741248 run_lib.py:152] step: 102750, training_loss: 3.88286e+01
I0514 18:52:51.087051 140128494741248 run_lib.py:152] step: 102800, training_loss: 3.68748e+01
I0514 18:52:51.139943 140128494741248 run_lib.py:165] step: 102800, eval_loss: 2.92276e+01
I0514 18:52:57.560769 140128494741248 run_lib.py:152] step: 102850, training_loss: 3.11439e+01
I0514 18:53:03.795352 140128494741248 run_lib.py:152] step: 102900, training_loss: 3.10284e+01
I0514 18:53:03.844480 140128494741248 run_lib.py:165] step: 102900, eval_loss: 2.70397e+01
I0514 18:53:10.068692 140128494741248 run_lib.py:152] step: 102950, training_loss: 2.48292e+01
I0514 18:53:16.482610 140128494741248 run_lib.py:152] step: 103000, training_loss: 2.91577e+01
I0514 18:53:16.534045 140128494741248 run_lib.py:165] step: 103000, eval_loss: 4.04101e+01
I0514 18:53:22.674131 140128494741248 run_lib.py:152] step: 103050, training_loss: 1.85609e+01
I0514 18:53:28.906065 140128494741248 run_lib.py:152] step: 103100, training_loss: 3.80502e+01
I0514 18:53:28.964688 140128494741248 run_lib.py:165] step: 103100, eval_loss: 3.22466e+01
I0514 18:53:35.148097 140128494741248 run_lib.py:152] step: 103150, training_loss: 2.48416e+01
I0514 18:53:41.576541 140128494741248 run_lib.py:152] step: 103200, training_loss: 2.40659e+01
I0514 18:53:41.622630 140128494741248 run_lib.py:165] step: 103200, eval_loss: 2.18148e+01
I0514 18:53:47.837708 140128494741248 run_lib.py:152] step: 103250, training_loss: 1.70971e+01
I0514 18:53:54.061282 140128494741248 run_lib.py:152] step: 103300, training_loss: 3.43783e+01
I0514 18:53:54.110677 140128494741248 run_lib.py:165] step: 103300, eval_loss: 1.49609e+01
I0514 18:54:00.585454 140128494741248 run_lib.py:152] step: 103350, training_loss: 1.34440e+01
I0514 18:54:06.898814 140128494741248 run_lib.py:152] step: 103400, training_loss: 4.56137e+01
I0514 18:54:06.949595 140128494741248 run_lib.py:165] step: 103400, eval_loss: 1.57220e+01
I0514 18:54:13.188913 140128494741248 run_lib.py:152] step: 103450, training_loss: 2.46773e+01
I0514 18:54:19.400059 140128494741248 run_lib.py:152] step: 103500, training_loss: 3.88905e+01
I0514 18:54:19.450880 140128494741248 run_lib.py:165] step: 103500, eval_loss: 2.64446e+01
I0514 18:54:25.812602 140128494741248 run_lib.py:152] step: 103550, training_loss: 3.58104e+01
I0514 18:54:32.047492 140128494741248 run_lib.py:152] step: 103600, training_loss: 2.61507e+01
I0514 18:54:32.098242 140128494741248 run_lib.py:165] step: 103600, eval_loss: 4.15506e+01
I0514 18:54:38.260059 140128494741248 run_lib.py:152] step: 103650, training_loss: 2.65630e+01
I0514 18:54:44.624831 140128494741248 run_lib.py:152] step: 103700, training_loss: 3.91366e+01
I0514 18:54:44.675369 140128494741248 run_lib.py:165] step: 103700, eval_loss: 3.14000e+01
I0514 18:54:50.926597 140128494741248 run_lib.py:152] step: 103750, training_loss: 3.30479e+01
I0514 18:54:57.109011 140128494741248 run_lib.py:152] step: 103800, training_loss: 1.75642e+01
I0514 18:54:57.166187 140128494741248 run_lib.py:165] step: 103800, eval_loss: 2.23198e+01
I0514 18:55:03.311580 140128494741248 run_lib.py:152] step: 103850, training_loss: 2.26264e+01
I0514 18:55:09.799815 140128494741248 run_lib.py:152] step: 103900, training_loss: 3.47651e+01
I0514 18:55:09.850466 140128494741248 run_lib.py:165] step: 103900, eval_loss: 3.44455e+01
I0514 18:55:16.048580 140128494741248 run_lib.py:152] step: 103950, training_loss: 2.81436e+01
I0514 18:55:22.246425 140128494741248 run_lib.py:152] step: 104000, training_loss: 2.52579e+01
I0514 18:55:22.298564 140128494741248 run_lib.py:165] step: 104000, eval_loss: 4.92829e+01
I0514 18:55:28.750832 140128494741248 run_lib.py:152] step: 104050, training_loss: 3.44563e+01
I0514 18:55:34.937332 140128494741248 run_lib.py:152] step: 104100, training_loss: 2.06785e+01
I0514 18:55:34.986449 140128494741248 run_lib.py:165] step: 104100, eval_loss: 2.09613e+01
I0514 18:55:41.166182 140128494741248 run_lib.py:152] step: 104150, training_loss: 2.55163e+01
I0514 18:55:47.451539 140128494741248 run_lib.py:152] step: 104200, training_loss: 4.76928e+01
I0514 18:55:47.501515 140128494741248 run_lib.py:165] step: 104200, eval_loss: 2.83214e+01
I0514 18:55:53.876590 140128494741248 run_lib.py:152] step: 104250, training_loss: 3.71365e+01
I0514 18:56:00.140065 140128494741248 run_lib.py:152] step: 104300, training_loss: 2.38477e+01
I0514 18:56:00.189953 140128494741248 run_lib.py:165] step: 104300, eval_loss: 3.48040e+01
I0514 18:56:06.334606 140128494741248 run_lib.py:152] step: 104350, training_loss: 3.37194e+01
I0514 18:56:12.780587 140128494741248 run_lib.py:152] step: 104400, training_loss: 1.49955e+01
I0514 18:56:12.831436 140128494741248 run_lib.py:165] step: 104400, eval_loss: 4.40056e+01
I0514 18:56:19.066431 140128494741248 run_lib.py:152] step: 104450, training_loss: 3.69647e+01
I0514 18:56:25.345160 140128494741248 run_lib.py:152] step: 104500, training_loss: 3.88294e+01
I0514 18:56:25.393974 140128494741248 run_lib.py:165] step: 104500, eval_loss: 2.13609e+01
I0514 18:56:31.642345 140128494741248 run_lib.py:152] step: 104550, training_loss: 3.39107e+01
I0514 18:56:38.088029 140128494741248 run_lib.py:152] step: 104600, training_loss: 3.39739e+01
I0514 18:56:38.141090 140128494741248 run_lib.py:165] step: 104600, eval_loss: 4.28103e+01
I0514 18:56:44.315076 140128494741248 run_lib.py:152] step: 104650, training_loss: 2.45748e+01
I0514 18:56:50.589648 140128494741248 run_lib.py:152] step: 104700, training_loss: 3.08636e+01
I0514 18:56:50.643862 140128494741248 run_lib.py:165] step: 104700, eval_loss: 4.41084e+01
I0514 18:56:57.127308 140128494741248 run_lib.py:152] step: 104750, training_loss: 2.53823e+01
I0514 18:57:03.440211 140128494741248 run_lib.py:152] step: 104800, training_loss: 2.43025e+01
I0514 18:57:03.493527 140128494741248 run_lib.py:165] step: 104800, eval_loss: 3.53076e+01
I0514 18:57:09.730693 140128494741248 run_lib.py:152] step: 104850, training_loss: 3.51725e+01
I0514 18:57:15.951782 140128494741248 run_lib.py:152] step: 104900, training_loss: 3.88665e+01
I0514 18:57:16.003161 140128494741248 run_lib.py:165] step: 104900, eval_loss: 2.52476e+01
I0514 18:57:22.429178 140128494741248 run_lib.py:152] step: 104950, training_loss: 5.46285e+01
I0514 18:57:28.730535 140128494741248 run_lib.py:152] step: 105000, training_loss: 3.82092e+01
I0514 18:57:28.785407 140128494741248 run_lib.py:165] step: 105000, eval_loss: 1.76138e+01
I0514 18:57:34.905770 140128494741248 run_lib.py:152] step: 105050, training_loss: 2.96163e+01
I0514 18:57:41.102551 140128494741248 run_lib.py:152] step: 105100, training_loss: 4.29116e+01
I0514 18:57:41.392097 140128494741248 run_lib.py:165] step: 105100, eval_loss: 2.05494e+01
I0514 18:57:47.599339 140128494741248 run_lib.py:152] step: 105150, training_loss: 3.41678e+01
I0514 18:57:53.806276 140128494741248 run_lib.py:152] step: 105200, training_loss: 4.34211e+01
I0514 18:57:53.859721 140128494741248 run_lib.py:165] step: 105200, eval_loss: 1.23425e+01
I0514 18:58:00.064857 140128494741248 run_lib.py:152] step: 105250, training_loss: 3.70719e+01
I0514 18:58:06.557756 140128494741248 run_lib.py:152] step: 105300, training_loss: 3.42903e+01
I0514 18:58:06.614156 140128494741248 run_lib.py:165] step: 105300, eval_loss: 4.18959e+01
I0514 18:58:12.789327 140128494741248 run_lib.py:152] step: 105350, training_loss: 3.53213e+01
I0514 18:58:19.004060 140128494741248 run_lib.py:152] step: 105400, training_loss: 3.19922e+01
I0514 18:58:19.056882 140128494741248 run_lib.py:165] step: 105400, eval_loss: 2.23684e+01
I0514 18:58:25.532247 140128494741248 run_lib.py:152] step: 105450, training_loss: 4.58384e+01
I0514 18:58:31.786889 140128494741248 run_lib.py:152] step: 105500, training_loss: 2.52995e+01
I0514 18:58:31.835309 140128494741248 run_lib.py:165] step: 105500, eval_loss: 2.53851e+01
I0514 18:58:38.094802 140128494741248 run_lib.py:152] step: 105550, training_loss: 3.67249e+01
I0514 18:58:44.353319 140128494741248 run_lib.py:152] step: 105600, training_loss: 4.15494e+01
I0514 18:58:44.406695 140128494741248 run_lib.py:165] step: 105600, eval_loss: 3.40150e+01
I0514 18:58:50.950562 140128494741248 run_lib.py:152] step: 105650, training_loss: 3.59427e+01
I0514 18:58:57.165615 140128494741248 run_lib.py:152] step: 105700, training_loss: 3.12201e+01
I0514 18:58:57.225396 140128494741248 run_lib.py:165] step: 105700, eval_loss: 2.91021e+01
I0514 18:59:03.362655 140128494741248 run_lib.py:152] step: 105750, training_loss: 1.34067e+01
I0514 18:59:09.863927 140128494741248 run_lib.py:152] step: 105800, training_loss: 3.79732e+01
I0514 18:59:09.912872 140128494741248 run_lib.py:165] step: 105800, eval_loss: 2.72602e+01
I0514 18:59:16.139346 140128494741248 run_lib.py:152] step: 105850, training_loss: 2.88265e+01
I0514 18:59:22.291651 140128494741248 run_lib.py:152] step: 105900, training_loss: 2.29590e+01
I0514 18:59:22.341853 140128494741248 run_lib.py:165] step: 105900, eval_loss: 4.60787e+01
I0514 18:59:28.622770 140128494741248 run_lib.py:152] step: 105950, training_loss: 3.30535e+01
I0514 18:59:35.138255 140128494741248 run_lib.py:152] step: 106000, training_loss: 4.75552e+01
I0514 18:59:35.190343 140128494741248 run_lib.py:165] step: 106000, eval_loss: 3.77645e+01
I0514 18:59:41.330670 140128494741248 run_lib.py:152] step: 106050, training_loss: 3.75973e+01
I0514 18:59:47.674457 140128494741248 run_lib.py:152] step: 106100, training_loss: 4.05097e+01
I0514 18:59:47.730695 140128494741248 run_lib.py:165] step: 106100, eval_loss: 3.96212e+01
I0514 18:59:54.189799 140128494741248 run_lib.py:152] step: 106150, training_loss: 2.60944e+01
I0514 19:00:00.399734 140128494741248 run_lib.py:152] step: 106200, training_loss: 2.95946e+01
I0514 19:00:00.450930 140128494741248 run_lib.py:165] step: 106200, eval_loss: 3.92338e+01
I0514 19:00:06.823744 140128494741248 run_lib.py:152] step: 106250, training_loss: 4.48048e+01
I0514 19:00:13.033869 140128494741248 run_lib.py:152] step: 106300, training_loss: 1.27661e+01
I0514 19:00:13.086775 140128494741248 run_lib.py:165] step: 106300, eval_loss: 2.84971e+01
I0514 19:00:19.492464 140128494741248 run_lib.py:152] step: 106350, training_loss: 2.58884e+01
I0514 19:00:25.694125 140128494741248 run_lib.py:152] step: 106400, training_loss: 5.33723e+01
I0514 19:00:25.748878 140128494741248 run_lib.py:165] step: 106400, eval_loss: 2.04324e+01
I0514 19:00:32.011122 140128494741248 run_lib.py:152] step: 106450, training_loss: 4.08013e+01
I0514 19:00:38.457740 140128494741248 run_lib.py:152] step: 106500, training_loss: 4.13547e+01
I0514 19:00:38.516086 140128494741248 run_lib.py:165] step: 106500, eval_loss: 1.86756e+01
I0514 19:00:44.760410 140128494741248 run_lib.py:152] step: 106550, training_loss: 2.90504e+01
I0514 19:00:50.933431 140128494741248 run_lib.py:152] step: 106600, training_loss: 3.81324e+01
I0514 19:00:50.982372 140128494741248 run_lib.py:165] step: 106600, eval_loss: 3.73948e+01
I0514 19:00:57.203292 140128494741248 run_lib.py:152] step: 106650, training_loss: 3.57681e+01
I0514 19:01:03.711536 140128494741248 run_lib.py:152] step: 106700, training_loss: 2.63341e+01
I0514 19:01:03.761387 140128494741248 run_lib.py:165] step: 106700, eval_loss: 1.31377e+01
I0514 19:01:10.083764 140128494741248 run_lib.py:152] step: 106750, training_loss: 2.55625e+01
I0514 19:01:16.404985 140128494741248 run_lib.py:152] step: 106800, training_loss: 3.99338e+01
I0514 19:01:16.458123 140128494741248 run_lib.py:165] step: 106800, eval_loss: 3.36674e+01
I0514 19:01:22.943729 140128494741248 run_lib.py:152] step: 106850, training_loss: 1.63115e+01
I0514 19:01:29.213033 140128494741248 run_lib.py:152] step: 106900, training_loss: 3.33747e+01
I0514 19:01:29.263424 140128494741248 run_lib.py:165] step: 106900, eval_loss: 3.37044e+01
I0514 19:01:35.475424 140128494741248 run_lib.py:152] step: 106950, training_loss: 2.62644e+01
I0514 19:01:41.621575 140128494741248 run_lib.py:152] step: 107000, training_loss: 4.43361e+01
I0514 19:01:41.672277 140128494741248 run_lib.py:165] step: 107000, eval_loss: 3.14191e+01
I0514 19:01:48.283885 140128494741248 run_lib.py:152] step: 107050, training_loss: 3.95030e+01
I0514 19:01:54.403579 140128494741248 run_lib.py:152] step: 107100, training_loss: 3.91735e+01
I0514 19:01:54.453456 140128494741248 run_lib.py:165] step: 107100, eval_loss: 2.57096e+01
I0514 19:02:00.712588 140128494741248 run_lib.py:152] step: 107150, training_loss: 3.98391e+01
I0514 19:02:07.155817 140128494741248 run_lib.py:152] step: 107200, training_loss: 2.68056e+01
I0514 19:02:07.209277 140128494741248 run_lib.py:165] step: 107200, eval_loss: 2.72792e+01
I0514 19:02:13.396318 140128494741248 run_lib.py:152] step: 107250, training_loss: 3.29120e+01
I0514 19:02:19.578843 140128494741248 run_lib.py:152] step: 107300, training_loss: 3.97309e+01
I0514 19:02:19.632174 140128494741248 run_lib.py:165] step: 107300, eval_loss: 2.17434e+01
I0514 19:02:25.905888 140128494741248 run_lib.py:152] step: 107350, training_loss: 5.32380e+01
I0514 19:02:32.259819 140128494741248 run_lib.py:152] step: 107400, training_loss: 3.43478e+01
I0514 19:02:32.310026 140128494741248 run_lib.py:165] step: 107400, eval_loss: 2.92378e+01
I0514 19:02:38.578143 140128494741248 run_lib.py:152] step: 107450, training_loss: 2.79048e+01
I0514 19:02:44.802933 140128494741248 run_lib.py:152] step: 107500, training_loss: 2.26011e+01
I0514 19:02:44.852725 140128494741248 run_lib.py:165] step: 107500, eval_loss: 2.04859e+01
I0514 19:02:51.387539 140128494741248 run_lib.py:152] step: 107550, training_loss: 3.17261e+01
I0514 19:02:57.520398 140128494741248 run_lib.py:152] step: 107600, training_loss: 3.70439e+01
I0514 19:02:57.571642 140128494741248 run_lib.py:165] step: 107600, eval_loss: 3.86165e+01
I0514 19:03:03.774132 140128494741248 run_lib.py:152] step: 107650, training_loss: 3.44758e+01
I0514 19:03:09.996679 140128494741248 run_lib.py:152] step: 107700, training_loss: 2.29962e+01
I0514 19:03:10.046961 140128494741248 run_lib.py:165] step: 107700, eval_loss: 2.73441e+01
I0514 19:03:16.634259 140128494741248 run_lib.py:152] step: 107750, training_loss: 2.56871e+01
I0514 19:03:22.904076 140128494741248 run_lib.py:152] step: 107800, training_loss: 3.54981e+01
I0514 19:03:22.957415 140128494741248 run_lib.py:165] step: 107800, eval_loss: 3.05949e+01
I0514 19:03:29.254147 140128494741248 run_lib.py:152] step: 107850, training_loss: 2.89246e+01
I0514 19:03:35.802284 140128494741248 run_lib.py:152] step: 107900, training_loss: 2.11938e+01
I0514 19:03:35.855926 140128494741248 run_lib.py:165] step: 107900, eval_loss: 3.79986e+01
I0514 19:03:41.990942 140128494741248 run_lib.py:152] step: 107950, training_loss: 3.92950e+01
I0514 19:03:48.277016 140128494741248 run_lib.py:152] step: 108000, training_loss: 4.31649e+01
I0514 19:03:48.333353 140128494741248 run_lib.py:165] step: 108000, eval_loss: 1.92524e+01
I0514 19:03:54.586786 140128494741248 run_lib.py:152] step: 108050, training_loss: 2.59620e+01
I0514 19:04:00.964994 140128494741248 run_lib.py:152] step: 108100, training_loss: 3.31852e+01
I0514 19:04:01.021116 140128494741248 run_lib.py:165] step: 108100, eval_loss: 4.28913e+01
I0514 19:04:07.356015 140128494741248 run_lib.py:152] step: 108150, training_loss: 3.06570e+01
I0514 19:04:13.539502 140128494741248 run_lib.py:152] step: 108200, training_loss: 2.74756e+01
I0514 19:04:13.588485 140128494741248 run_lib.py:165] step: 108200, eval_loss: 3.96646e+01
I0514 19:04:20.072187 140128494741248 run_lib.py:152] step: 108250, training_loss: 2.45510e+01
I0514 19:04:26.320238 140128494741248 run_lib.py:152] step: 108300, training_loss: 3.53618e+01
I0514 19:04:26.376265 140128494741248 run_lib.py:165] step: 108300, eval_loss: 3.41554e+01
I0514 19:04:32.811695 140128494741248 run_lib.py:152] step: 108350, training_loss: 1.99055e+01
I0514 19:04:38.965968 140128494741248 run_lib.py:152] step: 108400, training_loss: 2.44717e+01
I0514 19:04:39.019109 140128494741248 run_lib.py:165] step: 108400, eval_loss: 4.01627e+01
I0514 19:04:45.442105 140128494741248 run_lib.py:152] step: 108450, training_loss: 4.26786e+01
I0514 19:04:51.576987 140128494741248 run_lib.py:152] step: 108500, training_loss: 2.66497e+01
I0514 19:04:51.632178 140128494741248 run_lib.py:165] step: 108500, eval_loss: 3.69818e+01
I0514 19:04:57.956582 140128494741248 run_lib.py:152] step: 108550, training_loss: 2.80365e+01
I0514 19:05:04.136462 140128494741248 run_lib.py:152] step: 108600, training_loss: 2.18480e+01
I0514 19:05:04.429727 140128494741248 run_lib.py:165] step: 108600, eval_loss: 3.82238e+01
I0514 19:05:10.634933 140128494741248 run_lib.py:152] step: 108650, training_loss: 3.14281e+01
I0514 19:05:16.764729 140128494741248 run_lib.py:152] step: 108700, training_loss: 3.26942e+01
I0514 19:05:16.820610 140128494741248 run_lib.py:165] step: 108700, eval_loss: 4.28838e+01
I0514 19:05:23.024584 140128494741248 run_lib.py:152] step: 108750, training_loss: 2.52559e+01
I0514 19:05:29.460439 140128494741248 run_lib.py:152] step: 108800, training_loss: 3.50902e+01
I0514 19:05:29.507485 140128494741248 run_lib.py:165] step: 108800, eval_loss: 3.35286e+01
I0514 19:05:35.839387 140128494741248 run_lib.py:152] step: 108850, training_loss: 4.95315e+01
I0514 19:05:42.052892 140128494741248 run_lib.py:152] step: 108900, training_loss: 4.11649e+01
I0514 19:05:42.104364 140128494741248 run_lib.py:165] step: 108900, eval_loss: 4.16683e+01
I0514 19:05:48.604999 140128494741248 run_lib.py:152] step: 108950, training_loss: 2.56002e+01
I0514 19:05:54.750876 140128494741248 run_lib.py:152] step: 109000, training_loss: 2.78014e+01
I0514 19:05:54.807764 140128494741248 run_lib.py:165] step: 109000, eval_loss: 4.04615e+01
I0514 19:06:01.073448 140128494741248 run_lib.py:152] step: 109050, training_loss: 3.94458e+01
I0514 19:06:07.244791 140128494741248 run_lib.py:152] step: 109100, training_loss: 5.31402e+01
I0514 19:06:07.294384 140128494741248 run_lib.py:165] step: 109100, eval_loss: 3.16697e+01
I0514 19:06:13.807085 140128494741248 run_lib.py:152] step: 109150, training_loss: 3.44245e+01
I0514 19:06:19.949765 140128494741248 run_lib.py:152] step: 109200, training_loss: 3.86221e+01
I0514 19:06:20.001511 140128494741248 run_lib.py:165] step: 109200, eval_loss: 1.92637e+01
I0514 19:06:26.298671 140128494741248 run_lib.py:152] step: 109250, training_loss: 3.21776e+01
I0514 19:06:32.792126 140128494741248 run_lib.py:152] step: 109300, training_loss: 3.75666e+01
I0514 19:06:32.841851 140128494741248 run_lib.py:165] step: 109300, eval_loss: 2.94601e+01
I0514 19:06:39.046452 140128494741248 run_lib.py:152] step: 109350, training_loss: 3.57508e+01
I0514 19:06:45.280769 140128494741248 run_lib.py:152] step: 109400, training_loss: 3.16733e+01
I0514 19:06:45.329879 140128494741248 run_lib.py:165] step: 109400, eval_loss: 2.62766e+01
I0514 19:06:51.611314 140128494741248 run_lib.py:152] step: 109450, training_loss: 4.59467e+01
I0514 19:06:58.007102 140128494741248 run_lib.py:152] step: 109500, training_loss: 3.74885e+01
I0514 19:06:58.063237 140128494741248 run_lib.py:165] step: 109500, eval_loss: 2.41112e+01
I0514 19:07:04.342438 140128494741248 run_lib.py:152] step: 109550, training_loss: 2.07589e+01
I0514 19:07:10.642011 140128494741248 run_lib.py:152] step: 109600, training_loss: 3.97843e+01
I0514 19:07:10.691831 140128494741248 run_lib.py:165] step: 109600, eval_loss: 4.09370e+01
I0514 19:07:17.121019 140128494741248 run_lib.py:152] step: 109650, training_loss: 3.51983e+01
I0514 19:07:23.286004 140128494741248 run_lib.py:152] step: 109700, training_loss: 2.50663e+01
I0514 19:07:23.337307 140128494741248 run_lib.py:165] step: 109700, eval_loss: 2.50229e+01
I0514 19:07:29.665431 140128494741248 run_lib.py:152] step: 109750, training_loss: 2.87322e+01
I0514 19:07:35.903153 140128494741248 run_lib.py:152] step: 109800, training_loss: 3.48474e+01
I0514 19:07:35.955582 140128494741248 run_lib.py:165] step: 109800, eval_loss: 3.30980e+01
I0514 19:07:42.522547 140128494741248 run_lib.py:152] step: 109850, training_loss: 3.93025e+01
I0514 19:07:48.805462 140128494741248 run_lib.py:152] step: 109900, training_loss: 2.51434e+01
I0514 19:07:48.862093 140128494741248 run_lib.py:165] step: 109900, eval_loss: 4.30212e+01
I0514 19:07:55.059792 140128494741248 run_lib.py:152] step: 109950, training_loss: 3.71194e+01
I0514 19:08:01.568556 140128494741248 run_lib.py:152] step: 110000, training_loss: 4.00880e+01
I0514 19:08:01.774830 140128494741248 run_lib.py:165] step: 110000, eval_loss: 3.79113e+01
I0514 19:08:07.981964 140128494741248 run_lib.py:152] step: 110050, training_loss: 3.97843e+01
I0514 19:08:14.196401 140128494741248 run_lib.py:152] step: 110100, training_loss: 2.78781e+01
I0514 19:08:14.245669 140128494741248 run_lib.py:165] step: 110100, eval_loss: 2.86796e+01
I0514 19:08:20.571022 140128494741248 run_lib.py:152] step: 110150, training_loss: 1.89462e+01
I0514 19:08:27.081588 140128494741248 run_lib.py:152] step: 110200, training_loss: 3.68822e+01
I0514 19:08:27.128977 140128494741248 run_lib.py:165] step: 110200, eval_loss: 2.85056e+01
I0514 19:08:33.375102 140128494741248 run_lib.py:152] step: 110250, training_loss: 2.22948e+01
I0514 19:08:39.535353 140128494741248 run_lib.py:152] step: 110300, training_loss: 3.46199e+01
I0514 19:08:39.586269 140128494741248 run_lib.py:165] step: 110300, eval_loss: 2.61283e+01
I0514 19:08:46.012341 140128494741248 run_lib.py:152] step: 110350, training_loss: 3.51091e+01
I0514 19:08:52.267175 140128494741248 run_lib.py:152] step: 110400, training_loss: 2.52232e+01
I0514 19:08:52.327225 140128494741248 run_lib.py:165] step: 110400, eval_loss: 1.78174e+01
I0514 19:08:58.548585 140128494741248 run_lib.py:152] step: 110450, training_loss: 3.58120e+01
I0514 19:09:04.682265 140128494741248 run_lib.py:152] step: 110500, training_loss: 3.45317e+01
I0514 19:09:04.730042 140128494741248 run_lib.py:165] step: 110500, eval_loss: 2.67619e+01
I0514 19:09:11.241910 140128494741248 run_lib.py:152] step: 110550, training_loss: 4.30180e+01
I0514 19:09:17.445301 140128494741248 run_lib.py:152] step: 110600, training_loss: 2.14305e+01
I0514 19:09:17.496796 140128494741248 run_lib.py:165] step: 110600, eval_loss: 2.11493e+01
I0514 19:09:23.713370 140128494741248 run_lib.py:152] step: 110650, training_loss: 4.83984e+01
I0514 19:09:30.241033 140128494741248 run_lib.py:152] step: 110700, training_loss: 3.08602e+01
I0514 19:09:30.297572 140128494741248 run_lib.py:165] step: 110700, eval_loss: 3.13466e+01
I0514 19:09:36.520629 140128494741248 run_lib.py:152] step: 110750, training_loss: 2.59364e+01
I0514 19:09:42.800773 140128494741248 run_lib.py:152] step: 110800, training_loss: 3.17544e+01
I0514 19:09:42.852725 140128494741248 run_lib.py:165] step: 110800, eval_loss: 2.22520e+01
I0514 19:09:49.051815 140128494741248 run_lib.py:152] step: 110850, training_loss: 3.18597e+01
I0514 19:09:55.507418 140128494741248 run_lib.py:152] step: 110900, training_loss: 3.67567e+01
I0514 19:09:55.560021 140128494741248 run_lib.py:165] step: 110900, eval_loss: 2.15609e+01
I0514 19:10:01.836693 140128494741248 run_lib.py:152] step: 110950, training_loss: 1.79701e+01
I0514 19:10:08.059983 140128494741248 run_lib.py:152] step: 111000, training_loss: 2.91712e+01
I0514 19:10:08.108023 140128494741248 run_lib.py:165] step: 111000, eval_loss: 2.67316e+01
I0514 19:10:14.550267 140128494741248 run_lib.py:152] step: 111050, training_loss: 4.59285e+01
I0514 19:10:20.689399 140128494741248 run_lib.py:152] step: 111100, training_loss: 3.89055e+01
I0514 19:10:20.745239 140128494741248 run_lib.py:165] step: 111100, eval_loss: 3.14436e+01
I0514 19:10:26.933872 140128494741248 run_lib.py:152] step: 111150, training_loss: 4.02126e+01
I0514 19:10:33.137056 140128494741248 run_lib.py:152] step: 111200, training_loss: 2.54342e+01
I0514 19:10:33.193105 140128494741248 run_lib.py:165] step: 111200, eval_loss: 2.70578e+01
I0514 19:10:39.650313 140128494741248 run_lib.py:152] step: 111250, training_loss: 3.25256e+01
I0514 19:10:45.918249 140128494741248 run_lib.py:152] step: 111300, training_loss: 2.47176e+01
I0514 19:10:45.973021 140128494741248 run_lib.py:165] step: 111300, eval_loss: 3.99475e+01
I0514 19:10:52.116628 140128494741248 run_lib.py:152] step: 111350, training_loss: 3.48772e+01
I0514 19:10:58.582771 140128494741248 run_lib.py:152] step: 111400, training_loss: 2.53141e+01
I0514 19:10:58.639710 140128494741248 run_lib.py:165] step: 111400, eval_loss: 1.94274e+01
I0514 19:11:04.808458 140128494741248 run_lib.py:152] step: 111450, training_loss: 2.92746e+01
I0514 19:11:11.060727 140128494741248 run_lib.py:152] step: 111500, training_loss: 2.56717e+01
I0514 19:11:11.118072 140128494741248 run_lib.py:165] step: 111500, eval_loss: 3.52813e+01
I0514 19:11:17.238726 140128494741248 run_lib.py:152] step: 111550, training_loss: 3.51585e+01
I0514 19:11:23.772712 140128494741248 run_lib.py:152] step: 111600, training_loss: 3.94427e+01
I0514 19:11:23.821105 140128494741248 run_lib.py:165] step: 111600, eval_loss: 1.45674e+01
I0514 19:11:29.969452 140128494741248 run_lib.py:152] step: 111650, training_loss: 3.39999e+01
I0514 19:11:36.197517 140128494741248 run_lib.py:152] step: 111700, training_loss: 2.70624e+01
I0514 19:11:36.251296 140128494741248 run_lib.py:165] step: 111700, eval_loss: 2.78969e+01
I0514 19:11:42.652023 140128494741248 run_lib.py:152] step: 111750, training_loss: 2.11547e+01
I0514 19:11:48.875238 140128494741248 run_lib.py:152] step: 111800, training_loss: 2.21600e+01
I0514 19:11:48.930765 140128494741248 run_lib.py:165] step: 111800, eval_loss: 2.42540e+01
I0514 19:11:55.121620 140128494741248 run_lib.py:152] step: 111850, training_loss: 1.67668e+01
I0514 19:12:01.298972 140128494741248 run_lib.py:152] step: 111900, training_loss: 3.78464e+01
I0514 19:12:01.351257 140128494741248 run_lib.py:165] step: 111900, eval_loss: 3.63320e+01
I0514 19:12:07.886534 140128494741248 run_lib.py:152] step: 111950, training_loss: 4.13418e+01
I0514 19:12:14.148066 140128494741248 run_lib.py:152] step: 112000, training_loss: 2.87075e+01
I0514 19:12:14.195861 140128494741248 run_lib.py:165] step: 112000, eval_loss: 3.69881e+01
I0514 19:12:20.440270 140128494741248 run_lib.py:152] step: 112050, training_loss: 2.82637e+01
I0514 19:12:26.963840 140128494741248 run_lib.py:152] step: 112100, training_loss: 1.86460e+01
I0514 19:12:27.016268 140128494741248 run_lib.py:165] step: 112100, eval_loss: 1.99112e+01
I0514 19:12:33.176820 140128494741248 run_lib.py:152] step: 112150, training_loss: 1.90085e+01
I0514 19:12:39.438121 140128494741248 run_lib.py:152] step: 112200, training_loss: 4.70493e+01
I0514 19:12:39.492717 140128494741248 run_lib.py:165] step: 112200, eval_loss: 5.42024e+01
I0514 19:12:45.670368 140128494741248 run_lib.py:152] step: 112250, training_loss: 2.35974e+01
I0514 19:12:52.138973 140128494741248 run_lib.py:152] step: 112300, training_loss: 2.66021e+01
I0514 19:12:52.189671 140128494741248 run_lib.py:165] step: 112300, eval_loss: 2.99667e+01
I0514 19:12:58.324653 140128494741248 run_lib.py:152] step: 112350, training_loss: 3.31890e+01
I0514 19:13:04.576520 140128494741248 run_lib.py:152] step: 112400, training_loss: 2.90227e+01
I0514 19:13:04.630331 140128494741248 run_lib.py:165] step: 112400, eval_loss: 4.23996e+01
I0514 19:13:11.053431 140128494741248 run_lib.py:152] step: 112450, training_loss: 1.82205e+01
I0514 19:13:17.289685 140128494741248 run_lib.py:152] step: 112500, training_loss: 3.68204e+01
I0514 19:13:17.348443 140128494741248 run_lib.py:165] step: 112500, eval_loss: 1.99797e+01
I0514 19:13:23.535708 140128494741248 run_lib.py:152] step: 112550, training_loss: 2.22774e+01
I0514 19:13:29.751406 140128494741248 run_lib.py:152] step: 112600, training_loss: 4.28668e+01
I0514 19:13:29.808939 140128494741248 run_lib.py:165] step: 112600, eval_loss: 2.74796e+01
I0514 19:13:36.348635 140128494741248 run_lib.py:152] step: 112650, training_loss: 3.23976e+01
I0514 19:13:42.504703 140128494741248 run_lib.py:152] step: 112700, training_loss: 2.05657e+01
I0514 19:13:42.554865 140128494741248 run_lib.py:165] step: 112700, eval_loss: 2.66863e+01
I0514 19:13:48.886592 140128494741248 run_lib.py:152] step: 112750, training_loss: 2.99919e+01
I0514 19:13:55.070531 140128494741248 run_lib.py:152] step: 112800, training_loss: 3.30505e+01
I0514 19:13:55.346590 140128494741248 run_lib.py:165] step: 112800, eval_loss: 1.93051e+01
I0514 19:14:01.542654 140128494741248 run_lib.py:152] step: 112850, training_loss: 4.17417e+01
I0514 19:14:07.796554 140128494741248 run_lib.py:152] step: 112900, training_loss: 3.30462e+01
I0514 19:14:07.846866 140128494741248 run_lib.py:165] step: 112900, eval_loss: 2.60071e+01
I0514 19:14:14.040825 140128494741248 run_lib.py:152] step: 112950, training_loss: 4.64249e+01
I0514 19:14:20.487815 140128494741248 run_lib.py:152] step: 113000, training_loss: 1.93293e+01
I0514 19:14:20.536673 140128494741248 run_lib.py:165] step: 113000, eval_loss: 2.50974e+01
I0514 19:14:26.705085 140128494741248 run_lib.py:152] step: 113050, training_loss: 2.04736e+01
I0514 19:14:32.940392 140128494741248 run_lib.py:152] step: 113100, training_loss: 3.50341e+01
I0514 19:14:32.996606 140128494741248 run_lib.py:165] step: 113100, eval_loss: 2.51424e+01
I0514 19:14:39.454111 140128494741248 run_lib.py:152] step: 113150, training_loss: 2.99565e+01
I0514 19:14:45.648818 140128494741248 run_lib.py:152] step: 113200, training_loss: 3.46644e+01
I0514 19:14:45.696508 140128494741248 run_lib.py:165] step: 113200, eval_loss: 3.41765e+01
I0514 19:14:51.945482 140128494741248 run_lib.py:152] step: 113250, training_loss: 3.72998e+01
I0514 19:14:58.170592 140128494741248 run_lib.py:152] step: 113300, training_loss: 3.81380e+01
I0514 19:14:58.222279 140128494741248 run_lib.py:165] step: 113300, eval_loss: 2.86635e+01
I0514 19:15:04.714593 140128494741248 run_lib.py:152] step: 113350, training_loss: 3.60716e+01
I0514 19:15:10.871052 140128494741248 run_lib.py:152] step: 113400, training_loss: 3.47306e+01
I0514 19:15:10.926552 140128494741248 run_lib.py:165] step: 113400, eval_loss: 3.68945e+01
I0514 19:15:17.073337 140128494741248 run_lib.py:152] step: 113450, training_loss: 3.04122e+01
I0514 19:15:23.438133 140128494741248 run_lib.py:152] step: 113500, training_loss: 2.43303e+01
I0514 19:15:23.487865 140128494741248 run_lib.py:165] step: 113500, eval_loss: 5.25501e+01
I0514 19:15:29.677629 140128494741248 run_lib.py:152] step: 113550, training_loss: 2.66558e+01
I0514 19:15:35.836864 140128494741248 run_lib.py:152] step: 113600, training_loss: 3.60905e+01
I0514 19:15:35.893836 140128494741248 run_lib.py:165] step: 113600, eval_loss: 4.57532e+01
I0514 19:15:42.083569 140128494741248 run_lib.py:152] step: 113650, training_loss: 3.59981e+01
I0514 19:15:48.633522 140128494741248 run_lib.py:152] step: 113700, training_loss: 3.81676e+01
I0514 19:15:48.683303 140128494741248 run_lib.py:165] step: 113700, eval_loss: 3.63411e+01
I0514 19:15:54.954243 140128494741248 run_lib.py:152] step: 113750, training_loss: 2.59723e+01
I0514 19:16:01.174908 140128494741248 run_lib.py:152] step: 113800, training_loss: 3.44714e+01
I0514 19:16:01.224565 140128494741248 run_lib.py:165] step: 113800, eval_loss: 2.84364e+01
I0514 19:16:07.726384 140128494741248 run_lib.py:152] step: 113850, training_loss: 4.05007e+01
I0514 19:16:13.957313 140128494741248 run_lib.py:152] step: 113900, training_loss: 3.02468e+01
I0514 19:16:14.011085 140128494741248 run_lib.py:165] step: 113900, eval_loss: 2.46836e+01
I0514 19:16:20.146921 140128494741248 run_lib.py:152] step: 113950, training_loss: 3.18436e+01
I0514 19:16:26.359593 140128494741248 run_lib.py:152] step: 114000, training_loss: 3.72127e+01
I0514 19:16:26.414358 140128494741248 run_lib.py:165] step: 114000, eval_loss: 3.38067e+01
I0514 19:16:32.852826 140128494741248 run_lib.py:152] step: 114050, training_loss: 3.05499e+01
I0514 19:16:38.955643 140128494741248 run_lib.py:152] step: 114100, training_loss: 3.04530e+01
I0514 19:16:39.006880 140128494741248 run_lib.py:165] step: 114100, eval_loss: 1.84056e+01
I0514 19:16:45.212865 140128494741248 run_lib.py:152] step: 114150, training_loss: 1.99589e+01
I0514 19:16:51.624832 140128494741248 run_lib.py:152] step: 114200, training_loss: 2.82322e+01
I0514 19:16:51.685886 140128494741248 run_lib.py:165] step: 114200, eval_loss: 3.93957e+01
I0514 19:16:57.881236 140128494741248 run_lib.py:152] step: 114250, training_loss: 2.90865e+01
I0514 19:17:04.129268 140128494741248 run_lib.py:152] step: 114300, training_loss: 2.75242e+01
I0514 19:17:04.183324 140128494741248 run_lib.py:165] step: 114300, eval_loss: 3.43453e+01
I0514 19:17:10.414070 140128494741248 run_lib.py:152] step: 114350, training_loss: 3.02398e+01
I0514 19:17:16.942122 140128494741248 run_lib.py:152] step: 114400, training_loss: 3.31965e+01
I0514 19:17:16.990948 140128494741248 run_lib.py:165] step: 114400, eval_loss: 3.21143e+01
I0514 19:17:23.100761 140128494741248 run_lib.py:152] step: 114450, training_loss: 4.63545e+01
I0514 19:17:29.358152 140128494741248 run_lib.py:152] step: 114500, training_loss: 2.57358e+01
I0514 19:17:29.411326 140128494741248 run_lib.py:165] step: 114500, eval_loss: 3.66861e+01
I0514 19:17:35.722753 140128494741248 run_lib.py:152] step: 114550, training_loss: 3.48133e+01
I0514 19:17:41.965684 140128494741248 run_lib.py:152] step: 114600, training_loss: 3.74644e+01
I0514 19:17:42.024126 140128494741248 run_lib.py:165] step: 114600, eval_loss: 3.72622e+01
I0514 19:17:48.300799 140128494741248 run_lib.py:152] step: 114650, training_loss: 4.21207e+01
I0514 19:17:54.558350 140128494741248 run_lib.py:152] step: 114700, training_loss: 2.21666e+01
I0514 19:17:54.612049 140128494741248 run_lib.py:165] step: 114700, eval_loss: 3.57340e+01
I0514 19:18:01.116276 140128494741248 run_lib.py:152] step: 114750, training_loss: 3.21844e+01
I0514 19:18:07.309496 140128494741248 run_lib.py:152] step: 114800, training_loss: 3.03842e+01
I0514 19:18:07.358084 140128494741248 run_lib.py:165] step: 114800, eval_loss: 3.53067e+01
I0514 19:18:13.558778 140128494741248 run_lib.py:152] step: 114850, training_loss: 1.92626e+01
I0514 19:18:19.946412 140128494741248 run_lib.py:152] step: 114900, training_loss: 2.74931e+01
I0514 19:18:20.000652 140128494741248 run_lib.py:165] step: 114900, eval_loss: 5.46909e+01
I0514 19:18:26.234736 140128494741248 run_lib.py:152] step: 114950, training_loss: 3.01245e+01
I0514 19:18:32.435189 140128494741248 run_lib.py:152] step: 115000, training_loss: 3.78275e+01
I0514 19:18:32.488032 140128494741248 run_lib.py:165] step: 115000, eval_loss: 3.53306e+01
I0514 19:18:38.657965 140128494741248 run_lib.py:152] step: 115050, training_loss: 3.52217e+01
I0514 19:18:45.053282 140128494741248 run_lib.py:152] step: 115100, training_loss: 4.10414e+01
I0514 19:18:45.101630 140128494741248 run_lib.py:165] step: 115100, eval_loss: 2.77021e+01
I0514 19:18:51.301473 140128494741248 run_lib.py:152] step: 115150, training_loss: 3.60860e+01
I0514 19:18:57.477483 140128494741248 run_lib.py:152] step: 115200, training_loss: 2.42488e+01
I0514 19:18:57.530364 140128494741248 run_lib.py:165] step: 115200, eval_loss: 2.09989e+01
I0514 19:19:04.072116 140128494741248 run_lib.py:152] step: 115250, training_loss: 2.97191e+01
I0514 19:19:10.300956 140128494741248 run_lib.py:152] step: 115300, training_loss: 1.36209e+01
I0514 19:19:10.352335 140128494741248 run_lib.py:165] step: 115300, eval_loss: 4.00605e+01
I0514 19:19:16.606814 140128494741248 run_lib.py:152] step: 115350, training_loss: 2.10890e+01
I0514 19:19:22.767389 140128494741248 run_lib.py:152] step: 115400, training_loss: 4.03120e+01
I0514 19:19:22.823069 140128494741248 run_lib.py:165] step: 115400, eval_loss: 1.92943e+01
I0514 19:19:29.297160 140128494741248 run_lib.py:152] step: 115450, training_loss: 4.17851e+01
I0514 19:19:35.593828 140128494741248 run_lib.py:152] step: 115500, training_loss: 3.89904e+01
I0514 19:19:35.648329 140128494741248 run_lib.py:165] step: 115500, eval_loss: 3.28329e+01
I0514 19:19:41.797091 140128494741248 run_lib.py:152] step: 115550, training_loss: 4.77602e+01
I0514 19:19:48.247430 140128494741248 run_lib.py:152] step: 115600, training_loss: 3.41165e+01
I0514 19:19:48.302628 140128494741248 run_lib.py:165] step: 115600, eval_loss: 2.38340e+01
I0514 19:19:54.396127 140128494741248 run_lib.py:152] step: 115650, training_loss: 2.98890e+01
I0514 19:20:00.626326 140128494741248 run_lib.py:152] step: 115700, training_loss: 3.24180e+01
I0514 19:20:00.679670 140128494741248 run_lib.py:165] step: 115700, eval_loss: 3.32687e+01
I0514 19:20:06.956171 140128494741248 run_lib.py:152] step: 115750, training_loss: 3.24643e+01
I0514 19:20:13.369273 140128494741248 run_lib.py:152] step: 115800, training_loss: 1.81827e+01
I0514 19:20:13.418823 140128494741248 run_lib.py:165] step: 115800, eval_loss: 2.73284e+01
I0514 19:20:19.632277 140128494741248 run_lib.py:152] step: 115850, training_loss: 3.21891e+01
I0514 19:20:25.857522 140128494741248 run_lib.py:152] step: 115900, training_loss: 3.87050e+01
I0514 19:20:25.907850 140128494741248 run_lib.py:165] step: 115900, eval_loss: 2.21563e+01
I0514 19:20:32.390280 140128494741248 run_lib.py:152] step: 115950, training_loss: 4.51594e+01
I0514 19:20:38.610735 140128494741248 run_lib.py:152] step: 116000, training_loss: 2.29059e+01
I0514 19:20:38.666804 140128494741248 run_lib.py:165] step: 116000, eval_loss: 2.70236e+01
I0514 19:20:44.930349 140128494741248 run_lib.py:152] step: 116050, training_loss: 3.47119e+01
I0514 19:20:51.190021 140128494741248 run_lib.py:152] step: 116100, training_loss: 4.16358e+01
I0514 19:20:51.246741 140128494741248 run_lib.py:165] step: 116100, eval_loss: 3.89612e+01
I0514 19:20:57.606449 140128494741248 run_lib.py:152] step: 116150, training_loss: 4.51610e+01
I0514 19:21:03.773200 140128494741248 run_lib.py:152] step: 116200, training_loss: 4.43237e+01
I0514 19:21:03.823328 140128494741248 run_lib.py:165] step: 116200, eval_loss: 4.13257e+01
I0514 19:21:10.086740 140128494741248 run_lib.py:152] step: 116250, training_loss: 2.71420e+01
I0514 19:21:16.225079 140128494741248 run_lib.py:152] step: 116300, training_loss: 4.03774e+01
I0514 19:21:16.507506 140128494741248 run_lib.py:165] step: 116300, eval_loss: 2.71648e+01
I0514 19:21:22.813713 140128494741248 run_lib.py:152] step: 116350, training_loss: 3.65761e+01
I0514 19:21:29.117840 140128494741248 run_lib.py:152] step: 116400, training_loss: 3.00871e+01
I0514 19:21:29.171049 140128494741248 run_lib.py:165] step: 116400, eval_loss: 4.13013e+01
I0514 19:21:35.422972 140128494741248 run_lib.py:152] step: 116450, training_loss: 5.07552e+01
I0514 19:21:41.915419 140128494741248 run_lib.py:152] step: 116500, training_loss: 3.39638e+01
I0514 19:21:41.967952 140128494741248 run_lib.py:165] step: 116500, eval_loss: 2.38938e+01
I0514 19:21:48.160170 140128494741248 run_lib.py:152] step: 116550, training_loss: 2.20596e+01
I0514 19:21:54.350108 140128494741248 run_lib.py:152] step: 116600, training_loss: 3.04325e+01
I0514 19:21:54.400667 140128494741248 run_lib.py:165] step: 116600, eval_loss: 2.87738e+01
I0514 19:22:00.828427 140128494741248 run_lib.py:152] step: 116650, training_loss: 4.65838e+01
I0514 19:22:07.095318 140128494741248 run_lib.py:152] step: 116700, training_loss: 3.88081e+01
I0514 19:22:07.153774 140128494741248 run_lib.py:165] step: 116700, eval_loss: 3.29931e+01
I0514 19:22:13.409049 140128494741248 run_lib.py:152] step: 116750, training_loss: 2.65532e+01
I0514 19:22:19.605556 140128494741248 run_lib.py:152] step: 116800, training_loss: 1.73861e+01
I0514 19:22:19.656306 140128494741248 run_lib.py:165] step: 116800, eval_loss: 3.01986e+01
I0514 19:22:26.132452 140128494741248 run_lib.py:152] step: 116850, training_loss: 2.79493e+01
I0514 19:22:32.356453 140128494741248 run_lib.py:152] step: 116900, training_loss: 4.66673e+01
I0514 19:22:32.410236 140128494741248 run_lib.py:165] step: 116900, eval_loss: 3.88870e+01
I0514 19:22:38.555863 140128494741248 run_lib.py:152] step: 116950, training_loss: 3.01140e+01
I0514 19:22:45.079953 140128494741248 run_lib.py:152] step: 117000, training_loss: 3.20074e+01
I0514 19:22:45.129726 140128494741248 run_lib.py:165] step: 117000, eval_loss: 3.88625e+01
I0514 19:22:51.203617 140128494741248 run_lib.py:152] step: 117050, training_loss: 3.26534e+01
I0514 19:22:57.441371 140128494741248 run_lib.py:152] step: 117100, training_loss: 4.24323e+01
I0514 19:22:57.489920 140128494741248 run_lib.py:165] step: 117100, eval_loss: 4.04493e+01
I0514 19:23:03.791397 140128494741248 run_lib.py:152] step: 117150, training_loss: 3.35280e+01
I0514 19:23:10.327595 140128494741248 run_lib.py:152] step: 117200, training_loss: 4.32863e+01
I0514 19:23:10.378393 140128494741248 run_lib.py:165] step: 117200, eval_loss: 3.35059e+01
I0514 19:23:16.683568 140128494741248 run_lib.py:152] step: 117250, training_loss: 2.16093e+01
I0514 19:23:22.889897 140128494741248 run_lib.py:152] step: 117300, training_loss: 3.39505e+01
I0514 19:23:22.947803 140128494741248 run_lib.py:165] step: 117300, eval_loss: 2.29126e+01
I0514 19:23:29.412088 140128494741248 run_lib.py:152] step: 117350, training_loss: 3.94569e+01
I0514 19:23:35.550613 140128494741248 run_lib.py:152] step: 117400, training_loss: 3.74335e+01
I0514 19:23:35.602015 140128494741248 run_lib.py:165] step: 117400, eval_loss: 4.22987e+01
I0514 19:23:41.793843 140128494741248 run_lib.py:152] step: 117450, training_loss: 3.07498e+01
I0514 19:23:47.993003 140128494741248 run_lib.py:152] step: 117500, training_loss: 2.22879e+01
I0514 19:23:48.039878 140128494741248 run_lib.py:165] step: 117500, eval_loss: 2.93155e+01
I0514 19:23:54.442934 140128494741248 run_lib.py:152] step: 117550, training_loss: 2.53982e+01
I0514 19:24:00.554661 140128494741248 run_lib.py:152] step: 117600, training_loss: 3.51828e+01
I0514 19:24:00.607065 140128494741248 run_lib.py:165] step: 117600, eval_loss: 3.12699e+01
I0514 19:24:06.882555 140128494741248 run_lib.py:152] step: 117650, training_loss: 4.46386e+01
I0514 19:24:13.261737 140128494741248 run_lib.py:152] step: 117700, training_loss: 2.47218e+01
I0514 19:24:13.312423 140128494741248 run_lib.py:165] step: 117700, eval_loss: 2.72091e+01
I0514 19:24:19.455263 140128494741248 run_lib.py:152] step: 117750, training_loss: 2.21600e+01
I0514 19:24:25.623011 140128494741248 run_lib.py:152] step: 117800, training_loss: 3.85102e+01
I0514 19:24:25.674093 140128494741248 run_lib.py:165] step: 117800, eval_loss: 3.97177e+01
I0514 19:24:31.876092 140128494741248 run_lib.py:152] step: 117850, training_loss: 3.53665e+01
I0514 19:24:38.277522 140128494741248 run_lib.py:152] step: 117900, training_loss: 2.92532e+01
I0514 19:24:38.335863 140128494741248 run_lib.py:165] step: 117900, eval_loss: 3.35974e+01
I0514 19:24:44.474384 140128494741248 run_lib.py:152] step: 117950, training_loss: 3.70006e+01
I0514 19:24:50.674965 140128494741248 run_lib.py:152] step: 118000, training_loss: 4.36275e+01
I0514 19:24:50.734220 140128494741248 run_lib.py:165] step: 118000, eval_loss: 2.15056e+01
I0514 19:24:57.166013 140128494741248 run_lib.py:152] step: 118050, training_loss: 1.76272e+01
I0514 19:25:03.425327 140128494741248 run_lib.py:152] step: 118100, training_loss: 3.64576e+01
I0514 19:25:03.479986 140128494741248 run_lib.py:165] step: 118100, eval_loss: 2.16025e+01
I0514 19:25:09.696681 140128494741248 run_lib.py:152] step: 118150, training_loss: 3.01938e+01
I0514 19:25:15.902000 140128494741248 run_lib.py:152] step: 118200, training_loss: 5.10013e+01
I0514 19:25:15.955583 140128494741248 run_lib.py:165] step: 118200, eval_loss: 2.64781e+01
I0514 19:25:22.426805 140128494741248 run_lib.py:152] step: 118250, training_loss: 3.95026e+01
I0514 19:25:28.651132 140128494741248 run_lib.py:152] step: 118300, training_loss: 3.37323e+01
I0514 19:25:28.703255 140128494741248 run_lib.py:165] step: 118300, eval_loss: 2.59770e+01
I0514 19:25:34.880198 140128494741248 run_lib.py:152] step: 118350, training_loss: 3.21016e+01
I0514 19:25:41.376342 140128494741248 run_lib.py:152] step: 118400, training_loss: 2.74705e+01
I0514 19:25:41.430465 140128494741248 run_lib.py:165] step: 118400, eval_loss: 3.82983e+01
I0514 19:25:47.556080 140128494741248 run_lib.py:152] step: 118450, training_loss: 3.11108e+01
I0514 19:25:53.728713 140128494741248 run_lib.py:152] step: 118500, training_loss: 3.71506e+01
I0514 19:25:53.782659 140128494741248 run_lib.py:165] step: 118500, eval_loss: 2.76828e+01
I0514 19:25:59.916134 140128494741248 run_lib.py:152] step: 118550, training_loss: 2.58148e+01
I0514 19:26:06.353159 140128494741248 run_lib.py:152] step: 118600, training_loss: 2.28914e+01
I0514 19:26:06.401224 140128494741248 run_lib.py:165] step: 118600, eval_loss: 4.48656e+01
I0514 19:26:12.651167 140128494741248 run_lib.py:152] step: 118650, training_loss: 3.01078e+01
I0514 19:26:18.900560 140128494741248 run_lib.py:152] step: 118700, training_loss: 4.02529e+01
I0514 19:26:18.956534 140128494741248 run_lib.py:165] step: 118700, eval_loss: 1.95892e+01
I0514 19:26:25.510464 140128494741248 run_lib.py:152] step: 118750, training_loss: 3.62473e+01
I0514 19:26:31.722648 140128494741248 run_lib.py:152] step: 118800, training_loss: 3.94125e+01
I0514 19:26:31.776192 140128494741248 run_lib.py:165] step: 118800, eval_loss: 3.75987e+01
I0514 19:26:37.991327 140128494741248 run_lib.py:152] step: 118850, training_loss: 4.30564e+01
I0514 19:26:44.284582 140128494741248 run_lib.py:152] step: 118900, training_loss: 3.84432e+01
I0514 19:26:44.333735 140128494741248 run_lib.py:165] step: 118900, eval_loss: 2.56017e+01
I0514 19:26:50.702301 140128494741248 run_lib.py:152] step: 118950, training_loss: 4.39279e+01
I0514 19:26:57.024570 140128494741248 run_lib.py:152] step: 119000, training_loss: 1.98336e+01
I0514 19:26:57.081316 140128494741248 run_lib.py:165] step: 119000, eval_loss: 3.35848e+01
I0514 19:27:03.270334 140128494741248 run_lib.py:152] step: 119050, training_loss: 3.51032e+01
I0514 19:27:09.746034 140128494741248 run_lib.py:152] step: 119100, training_loss: 3.27196e+01
I0514 19:27:09.800742 140128494741248 run_lib.py:165] step: 119100, eval_loss: 3.17480e+01
I0514 19:27:15.977097 140128494741248 run_lib.py:152] step: 119150, training_loss: 2.43227e+01
I0514 19:27:22.186316 140128494741248 run_lib.py:152] step: 119200, training_loss: 2.42114e+01
I0514 19:27:22.241541 140128494741248 run_lib.py:165] step: 119200, eval_loss: 3.97361e+01
I0514 19:27:28.470619 140128494741248 run_lib.py:152] step: 119250, training_loss: 3.27773e+01
I0514 19:27:34.923280 140128494741248 run_lib.py:152] step: 119300, training_loss: 3.27500e+01
I0514 19:27:34.979924 140128494741248 run_lib.py:165] step: 119300, eval_loss: 5.63022e+01
I0514 19:27:41.259666 140128494741248 run_lib.py:152] step: 119350, training_loss: 2.29574e+01
I0514 19:27:47.592655 140128494741248 run_lib.py:152] step: 119400, training_loss: 3.30278e+01
I0514 19:27:47.645575 140128494741248 run_lib.py:165] step: 119400, eval_loss: 4.34206e+01
I0514 19:27:54.079170 140128494741248 run_lib.py:152] step: 119450, training_loss: 4.16594e+01
I0514 19:28:00.322112 140128494741248 run_lib.py:152] step: 119500, training_loss: 1.94350e+01
I0514 19:28:00.377460 140128494741248 run_lib.py:165] step: 119500, eval_loss: 3.42990e+01
I0514 19:28:06.643793 140128494741248 run_lib.py:152] step: 119550, training_loss: 2.31811e+01
I0514 19:28:12.765196 140128494741248 run_lib.py:152] step: 119600, training_loss: 3.28331e+01
I0514 19:28:12.813506 140128494741248 run_lib.py:165] step: 119600, eval_loss: 2.67004e+01
I0514 19:28:19.253036 140128494741248 run_lib.py:152] step: 119650, training_loss: 2.87144e+01
I0514 19:28:25.453460 140128494741248 run_lib.py:152] step: 119700, training_loss: 3.66654e+01
I0514 19:28:25.502234 140128494741248 run_lib.py:165] step: 119700, eval_loss: 4.61371e+01
I0514 19:28:31.750717 140128494741248 run_lib.py:152] step: 119750, training_loss: 2.93579e+01
I0514 19:28:38.010442 140128494741248 run_lib.py:152] step: 119800, training_loss: 4.61909e+01
I0514 19:28:38.293552 140128494741248 run_lib.py:165] step: 119800, eval_loss: 5.00714e+01
I0514 19:28:44.473329 140128494741248 run_lib.py:152] step: 119850, training_loss: 2.43632e+01
I0514 19:28:50.728294 140128494741248 run_lib.py:152] step: 119900, training_loss: 3.27412e+01
I0514 19:28:50.781960 140128494741248 run_lib.py:165] step: 119900, eval_loss: 2.44937e+01
I0514 19:28:56.965624 140128494741248 run_lib.py:152] step: 119950, training_loss: 2.88452e+01
I0514 19:29:03.399273 140128494741248 run_lib.py:152] step: 120000, training_loss: 2.39898e+01
I0514 19:29:03.601785 140128494741248 run_lib.py:165] step: 120000, eval_loss: 4.69531e+01
I0514 19:29:09.827440 140128494741248 run_lib.py:152] step: 120050, training_loss: 2.21421e+01
I0514 19:29:16.091426 140128494741248 run_lib.py:152] step: 120100, training_loss: 2.28714e+01
I0514 19:29:16.145626 140128494741248 run_lib.py:165] step: 120100, eval_loss: 5.13930e+01
I0514 19:29:22.613792 140128494741248 run_lib.py:152] step: 120150, training_loss: 3.05059e+01
I0514 19:29:28.839893 140128494741248 run_lib.py:152] step: 120200, training_loss: 4.55850e+01
I0514 19:29:28.894980 140128494741248 run_lib.py:165] step: 120200, eval_loss: 2.30662e+01
I0514 19:29:35.092260 140128494741248 run_lib.py:152] step: 120250, training_loss: 5.29522e+01
I0514 19:29:41.397032 140128494741248 run_lib.py:152] step: 120300, training_loss: 4.55251e+01
I0514 19:29:41.453759 140128494741248 run_lib.py:165] step: 120300, eval_loss: 4.27853e+01
I0514 19:29:47.892324 140128494741248 run_lib.py:152] step: 120350, training_loss: 3.07621e+01
I0514 19:29:54.113096 140128494741248 run_lib.py:152] step: 120400, training_loss: 2.03971e+01
I0514 19:29:54.160331 140128494741248 run_lib.py:165] step: 120400, eval_loss: 3.46012e+01
I0514 19:30:00.418845 140128494741248 run_lib.py:152] step: 120450, training_loss: 3.20190e+01
I0514 19:30:06.806941 140128494741248 run_lib.py:152] step: 120500, training_loss: 3.65552e+01
I0514 19:30:06.862763 140128494741248 run_lib.py:165] step: 120500, eval_loss: 3.91779e+01
I0514 19:30:13.056503 140128494741248 run_lib.py:152] step: 120550, training_loss: 2.94777e+01
I0514 19:30:19.227238 140128494741248 run_lib.py:152] step: 120600, training_loss: 3.82083e+01
I0514 19:30:19.278184 140128494741248 run_lib.py:165] step: 120600, eval_loss: 4.00073e+01
I0514 19:30:25.545698 140128494741248 run_lib.py:152] step: 120650, training_loss: 4.13949e+01
I0514 19:30:31.906259 140128494741248 run_lib.py:152] step: 120700, training_loss: 3.37747e+01
I0514 19:30:31.958881 140128494741248 run_lib.py:165] step: 120700, eval_loss: 4.20664e+01
I0514 19:30:38.197842 140128494741248 run_lib.py:152] step: 120750, training_loss: 3.19057e+01
I0514 19:30:44.396940 140128494741248 run_lib.py:152] step: 120800, training_loss: 1.78996e+01
I0514 19:30:44.449475 140128494741248 run_lib.py:165] step: 120800, eval_loss: 4.90527e+01
I0514 19:30:50.953801 140128494741248 run_lib.py:152] step: 120850, training_loss: 3.75801e+01
I0514 19:30:57.103262 140128494741248 run_lib.py:152] step: 120900, training_loss: 3.74189e+01
I0514 19:30:57.158142 140128494741248 run_lib.py:165] step: 120900, eval_loss: 3.46946e+01
I0514 19:31:03.432634 140128494741248 run_lib.py:152] step: 120950, training_loss: 3.13459e+01
I0514 19:31:09.609985 140128494741248 run_lib.py:152] step: 121000, training_loss: 2.05553e+01
I0514 19:31:09.667659 140128494741248 run_lib.py:165] step: 121000, eval_loss: 3.21410e+01
I0514 19:31:16.132074 140128494741248 run_lib.py:152] step: 121050, training_loss: 3.55890e+01
I0514 19:31:22.366055 140128494741248 run_lib.py:152] step: 121100, training_loss: 3.52848e+01
I0514 19:31:22.417152 140128494741248 run_lib.py:165] step: 121100, eval_loss: 3.01514e+01
I0514 19:31:28.692315 140128494741248 run_lib.py:152] step: 121150, training_loss: 3.10386e+01
I0514 19:31:35.105559 140128494741248 run_lib.py:152] step: 121200, training_loss: 2.00880e+01
I0514 19:31:35.154514 140128494741248 run_lib.py:165] step: 121200, eval_loss: 2.81936e+01
I0514 19:31:41.355538 140128494741248 run_lib.py:152] step: 121250, training_loss: 4.02398e+01
I0514 19:31:47.570348 140128494741248 run_lib.py:152] step: 121300, training_loss: 3.43909e+01
I0514 19:31:47.625018 140128494741248 run_lib.py:165] step: 121300, eval_loss: 2.04925e+01
I0514 19:31:53.848671 140128494741248 run_lib.py:152] step: 121350, training_loss: 3.34945e+01
I0514 19:32:00.257690 140128494741248 run_lib.py:152] step: 121400, training_loss: 4.29493e+01
I0514 19:32:00.309721 140128494741248 run_lib.py:165] step: 121400, eval_loss: 4.17048e+01
I0514 19:32:06.520785 140128494741248 run_lib.py:152] step: 121450, training_loss: 4.13142e+01
I0514 19:32:12.738105 140128494741248 run_lib.py:152] step: 121500, training_loss: 3.70237e+01
I0514 19:32:12.793282 140128494741248 run_lib.py:165] step: 121500, eval_loss: 2.96936e+01
I0514 19:32:19.346638 140128494741248 run_lib.py:152] step: 121550, training_loss: 3.17337e+01
I0514 19:32:25.534867 140128494741248 run_lib.py:152] step: 121600, training_loss: 3.22004e+01
I0514 19:32:25.589583 140128494741248 run_lib.py:165] step: 121600, eval_loss: 1.75061e+01
I0514 19:32:31.817336 140128494741248 run_lib.py:152] step: 121650, training_loss: 2.80618e+01
I0514 19:32:38.018846 140128494741248 run_lib.py:152] step: 121700, training_loss: 3.33022e+01
I0514 19:32:38.071727 140128494741248 run_lib.py:165] step: 121700, eval_loss: 1.55464e+01
I0514 19:32:44.548020 140128494741248 run_lib.py:152] step: 121750, training_loss: 3.19945e+01
I0514 19:32:50.702643 140128494741248 run_lib.py:152] step: 121800, training_loss: 2.61910e+01
I0514 19:32:50.749686 140128494741248 run_lib.py:165] step: 121800, eval_loss: 4.22925e+01
I0514 19:32:56.982000 140128494741248 run_lib.py:152] step: 121850, training_loss: 2.27950e+01
I0514 19:33:03.484863 140128494741248 run_lib.py:152] step: 121900, training_loss: 3.31060e+01
I0514 19:33:03.535814 140128494741248 run_lib.py:165] step: 121900, eval_loss: 4.22982e+01
I0514 19:33:09.734726 140128494741248 run_lib.py:152] step: 121950, training_loss: 4.19100e+01
I0514 19:33:15.950654 140128494741248 run_lib.py:152] step: 122000, training_loss: 2.94667e+01
I0514 19:33:16.002075 140128494741248 run_lib.py:165] step: 122000, eval_loss: 2.34233e+01
I0514 19:33:22.134196 140128494741248 run_lib.py:152] step: 122050, training_loss: 2.91183e+01
I0514 19:33:28.536137 140128494741248 run_lib.py:152] step: 122100, training_loss: 3.29024e+01
I0514 19:33:28.585407 140128494741248 run_lib.py:165] step: 122100, eval_loss: 3.39210e+01
I0514 19:33:34.823264 140128494741248 run_lib.py:152] step: 122150, training_loss: 2.45269e+01
I0514 19:33:41.020452 140128494741248 run_lib.py:152] step: 122200, training_loss: 2.85570e+01
I0514 19:33:41.074143 140128494741248 run_lib.py:165] step: 122200, eval_loss: 3.87110e+01
I0514 19:33:47.575667 140128494741248 run_lib.py:152] step: 122250, training_loss: 3.34677e+01
I0514 19:33:53.833884 140128494741248 run_lib.py:152] step: 122300, training_loss: 4.27318e+01
I0514 19:33:53.886267 140128494741248 run_lib.py:165] step: 122300, eval_loss: 4.19895e+01
I0514 19:34:00.117470 140128494741248 run_lib.py:152] step: 122350, training_loss: 2.32821e+01
I0514 19:34:06.396954 140128494741248 run_lib.py:152] step: 122400, training_loss: 4.03632e+01
I0514 19:34:06.446053 140128494741248 run_lib.py:165] step: 122400, eval_loss: 2.55029e+01
I0514 19:34:12.889837 140128494741248 run_lib.py:152] step: 122450, training_loss: 3.16328e+01
I0514 19:34:19.118661 140128494741248 run_lib.py:152] step: 122500, training_loss: 2.97822e+01
I0514 19:34:19.176108 140128494741248 run_lib.py:165] step: 122500, eval_loss: 3.96750e+01
I0514 19:34:25.401805 140128494741248 run_lib.py:152] step: 122550, training_loss: 2.85512e+01
I0514 19:34:31.849760 140128494741248 run_lib.py:152] step: 122600, training_loss: 4.24725e+01
I0514 19:34:31.904528 140128494741248 run_lib.py:165] step: 122600, eval_loss: 3.80816e+01
I0514 19:34:38.018708 140128494741248 run_lib.py:152] step: 122650, training_loss: 2.57393e+01
I0514 19:34:44.210540 140128494741248 run_lib.py:152] step: 122700, training_loss: 2.63265e+01
I0514 19:34:44.259537 140128494741248 run_lib.py:165] step: 122700, eval_loss: 3.23063e+01
I0514 19:34:50.483229 140128494741248 run_lib.py:152] step: 122750, training_loss: 2.72374e+01
I0514 19:34:56.825881 140128494741248 run_lib.py:152] step: 122800, training_loss: 3.29007e+01
I0514 19:34:56.876805 140128494741248 run_lib.py:165] step: 122800, eval_loss: 2.33216e+01
I0514 19:35:03.053560 140128494741248 run_lib.py:152] step: 122850, training_loss: 2.43381e+01
I0514 19:35:09.266103 140128494741248 run_lib.py:152] step: 122900, training_loss: 3.62458e+01
I0514 19:35:09.321753 140128494741248 run_lib.py:165] step: 122900, eval_loss: 2.41815e+01
I0514 19:35:15.735265 140128494741248 run_lib.py:152] step: 122950, training_loss: 3.10315e+01
I0514 19:35:21.979654 140128494741248 run_lib.py:152] step: 123000, training_loss: 2.50415e+01
I0514 19:35:22.033100 140128494741248 run_lib.py:165] step: 123000, eval_loss: 3.62249e+01
I0514 19:35:28.220817 140128494741248 run_lib.py:152] step: 123050, training_loss: 3.60070e+01
I0514 19:35:34.449058 140128494741248 run_lib.py:152] step: 123100, training_loss: 2.04925e+01
I0514 19:35:34.498329 140128494741248 run_lib.py:165] step: 123100, eval_loss: 5.42204e+01
I0514 19:35:40.911015 140128494741248 run_lib.py:152] step: 123150, training_loss: 1.57766e+01
I0514 19:35:47.058409 140128494741248 run_lib.py:152] step: 123200, training_loss: 2.65182e+01
I0514 19:35:47.109426 140128494741248 run_lib.py:165] step: 123200, eval_loss: 3.16997e+01
I0514 19:35:53.306306 140128494741248 run_lib.py:152] step: 123250, training_loss: 1.45360e+01
I0514 19:35:59.697865 140128494741248 run_lib.py:152] step: 123300, training_loss: 3.30917e+01
I0514 19:35:59.749917 140128494741248 run_lib.py:165] step: 123300, eval_loss: 2.53685e+01
I0514 19:36:05.911721 140128494741248 run_lib.py:152] step: 123350, training_loss: 2.20327e+01
I0514 19:36:12.234809 140128494741248 run_lib.py:152] step: 123400, training_loss: 6.18841e+01
I0514 19:36:12.290170 140128494741248 run_lib.py:165] step: 123400, eval_loss: 1.90938e+01
I0514 19:36:18.448211 140128494741248 run_lib.py:152] step: 123450, training_loss: 2.44101e+01
I0514 19:36:24.890161 140128494741248 run_lib.py:152] step: 123500, training_loss: 2.29142e+01
I0514 19:36:24.941764 140128494741248 run_lib.py:165] step: 123500, eval_loss: 3.45326e+01
I0514 19:36:31.158773 140128494741248 run_lib.py:152] step: 123550, training_loss: 2.01861e+01
I0514 19:36:37.329075 140128494741248 run_lib.py:152] step: 123600, training_loss: 3.04349e+01
I0514 19:36:37.382202 140128494741248 run_lib.py:165] step: 123600, eval_loss: 2.84924e+01
I0514 19:36:43.787888 140128494741248 run_lib.py:152] step: 123650, training_loss: 3.13869e+01
I0514 19:36:50.054189 140128494741248 run_lib.py:152] step: 123700, training_loss: 3.33605e+01
I0514 19:36:50.114705 140128494741248 run_lib.py:165] step: 123700, eval_loss: 2.39538e+01
I0514 19:36:56.274310 140128494741248 run_lib.py:152] step: 123750, training_loss: 3.30138e+01
I0514 19:37:02.585500 140128494741248 run_lib.py:152] step: 123800, training_loss: 3.63893e+01
I0514 19:37:02.641560 140128494741248 run_lib.py:165] step: 123800, eval_loss: 2.53617e+01
I0514 19:37:09.203164 140128494741248 run_lib.py:152] step: 123850, training_loss: 3.46198e+01
I0514 19:37:15.370991 140128494741248 run_lib.py:152] step: 123900, training_loss: 3.95321e+01
I0514 19:37:15.422559 140128494741248 run_lib.py:165] step: 123900, eval_loss: 2.13676e+01
I0514 19:37:21.602884 140128494741248 run_lib.py:152] step: 123950, training_loss: 3.21037e+01
I0514 19:37:28.078431 140128494741248 run_lib.py:152] step: 124000, training_loss: 2.77084e+01
I0514 19:37:28.130217 140128494741248 run_lib.py:165] step: 124000, eval_loss: 2.30601e+01
I0514 19:37:34.357830 140128494741248 run_lib.py:152] step: 124050, training_loss: 4.93866e+01
I0514 19:37:40.500228 140128494741248 run_lib.py:152] step: 124100, training_loss: 2.72674e+01
I0514 19:37:40.550493 140128494741248 run_lib.py:165] step: 124100, eval_loss: 2.17103e+01
I0514 19:37:46.885374 140128494741248 run_lib.py:152] step: 124150, training_loss: 2.75665e+01
I0514 19:37:53.316184 140128494741248 run_lib.py:152] step: 124200, training_loss: 4.50696e+01
I0514 19:37:53.367693 140128494741248 run_lib.py:165] step: 124200, eval_loss: 3.06968e+01
I0514 19:37:59.587506 140128494741248 run_lib.py:152] step: 124250, training_loss: 1.70315e+01
I0514 19:38:05.726617 140128494741248 run_lib.py:152] step: 124300, training_loss: 4.52757e+01
I0514 19:38:05.774585 140128494741248 run_lib.py:165] step: 124300, eval_loss: 3.34814e+01
I0514 19:38:12.194924 140128494741248 run_lib.py:152] step: 124350, training_loss: 3.96951e+01
I0514 19:38:18.344876 140128494741248 run_lib.py:152] step: 124400, training_loss: 1.94708e+01
I0514 19:38:18.397881 140128494741248 run_lib.py:165] step: 124400, eval_loss: 3.12566e+01
I0514 19:38:24.512766 140128494741248 run_lib.py:152] step: 124450, training_loss: 2.22184e+01
I0514 19:38:30.805355 140128494741248 run_lib.py:152] step: 124500, training_loss: 2.11275e+01
I0514 19:38:30.861633 140128494741248 run_lib.py:165] step: 124500, eval_loss: 3.13149e+01
I0514 19:38:37.393102 140128494741248 run_lib.py:152] step: 124550, training_loss: 3.19046e+01
I0514 19:38:43.610368 140128494741248 run_lib.py:152] step: 124600, training_loss: 2.02680e+01
I0514 19:38:43.660142 140128494741248 run_lib.py:165] step: 124600, eval_loss: 1.67179e+01
I0514 19:38:49.971062 140128494741248 run_lib.py:152] step: 124650, training_loss: 3.05151e+01
I0514 19:38:56.489202 140128494741248 run_lib.py:152] step: 124700, training_loss: 2.36933e+01
I0514 19:38:56.548232 140128494741248 run_lib.py:165] step: 124700, eval_loss: 4.27351e+01
I0514 19:39:02.866362 140128494741248 run_lib.py:152] step: 124750, training_loss: 4.59699e+01
I0514 19:39:09.074127 140128494741248 run_lib.py:152] step: 124800, training_loss: 1.84185e+01
I0514 19:39:09.122591 140128494741248 run_lib.py:165] step: 124800, eval_loss: 2.42728e+01
I0514 19:39:15.403076 140128494741248 run_lib.py:152] step: 124850, training_loss: 4.15794e+01
I0514 19:39:21.792141 140128494741248 run_lib.py:152] step: 124900, training_loss: 2.54712e+01
I0514 19:39:21.849671 140128494741248 run_lib.py:165] step: 124900, eval_loss: 2.97891e+01
I0514 19:39:27.985822 140128494741248 run_lib.py:152] step: 124950, training_loss: 2.13632e+01
I0514 19:39:34.201364 140128494741248 run_lib.py:152] step: 125000, training_loss: 2.66497e+01
I0514 19:39:34.262025 140128494741248 run_lib.py:165] step: 125000, eval_loss: 2.97213e+01
I0514 19:39:40.627453 140128494741248 run_lib.py:152] step: 125050, training_loss: 2.90638e+01
I0514 19:39:46.902630 140128494741248 run_lib.py:152] step: 125100, training_loss: 3.03777e+01
I0514 19:39:46.955981 140128494741248 run_lib.py:165] step: 125100, eval_loss: 1.85069e+01
I0514 19:39:53.171005 140128494741248 run_lib.py:152] step: 125150, training_loss: 3.83675e+01
I0514 19:39:59.356986 140128494741248 run_lib.py:152] step: 125200, training_loss: 3.35137e+01
I0514 19:39:59.407935 140128494741248 run_lib.py:165] step: 125200, eval_loss: 1.53507e+01
I0514 19:40:05.838053 140128494741248 run_lib.py:152] step: 125250, training_loss: 2.74912e+01
I0514 19:40:12.033993 140128494741248 run_lib.py:152] step: 125300, training_loss: 4.08544e+01
I0514 19:40:12.095413 140128494741248 run_lib.py:165] step: 125300, eval_loss: 2.74225e+01
I0514 19:40:18.213724 140128494741248 run_lib.py:152] step: 125350, training_loss: 1.99547e+01
I0514 19:40:24.726755 140128494741248 run_lib.py:152] step: 125400, training_loss: 3.35751e+01
I0514 19:40:24.777859 140128494741248 run_lib.py:165] step: 125400, eval_loss: 3.88391e+01
I0514 19:40:30.962658 140128494741248 run_lib.py:152] step: 125450, training_loss: 2.46356e+01
I0514 19:40:37.245692 140128494741248 run_lib.py:152] step: 125500, training_loss: 2.50505e+01
I0514 19:40:37.298974 140128494741248 run_lib.py:165] step: 125500, eval_loss: 2.32714e+01
I0514 19:40:43.413231 140128494741248 run_lib.py:152] step: 125550, training_loss: 3.58122e+01
I0514 19:40:49.868448 140128494741248 run_lib.py:152] step: 125600, training_loss: 3.47965e+01
I0514 19:40:49.916877 140128494741248 run_lib.py:165] step: 125600, eval_loss: 3.96148e+01
I0514 19:40:56.197407 140128494741248 run_lib.py:152] step: 125650, training_loss: 4.31420e+01
I0514 19:41:02.476952 140128494741248 run_lib.py:152] step: 125700, training_loss: 1.48457e+01
I0514 19:41:02.527701 140128494741248 run_lib.py:165] step: 125700, eval_loss: 4.89781e+01
I0514 19:41:08.976632 140128494741248 run_lib.py:152] step: 125750, training_loss: 3.50821e+01
I0514 19:41:15.203809 140128494741248 run_lib.py:152] step: 125800, training_loss: 3.58268e+01
I0514 19:41:15.261647 140128494741248 run_lib.py:165] step: 125800, eval_loss: 3.80044e+01
I0514 19:41:21.443343 140128494741248 run_lib.py:152] step: 125850, training_loss: 3.64366e+01
I0514 19:41:27.631679 140128494741248 run_lib.py:152] step: 125900, training_loss: 4.43465e+01
I0514 19:41:27.687187 140128494741248 run_lib.py:165] step: 125900, eval_loss: 3.14219e+01
I0514 19:41:34.202055 140128494741248 run_lib.py:152] step: 125950, training_loss: 3.73198e+01
I0514 19:41:40.442338 140128494741248 run_lib.py:152] step: 126000, training_loss: 3.38478e+01
I0514 19:41:40.495050 140128494741248 run_lib.py:165] step: 126000, eval_loss: 3.71120e+01
I0514 19:41:46.724261 140128494741248 run_lib.py:152] step: 126050, training_loss: 2.97753e+01
I0514 19:41:53.157918 140128494741248 run_lib.py:152] step: 126100, training_loss: 1.87829e+01
I0514 19:41:53.210384 140128494741248 run_lib.py:165] step: 126100, eval_loss: 3.09341e+01
I0514 19:41:59.373851 140128494741248 run_lib.py:152] step: 126150, training_loss: 3.51013e+01
I0514 19:42:05.654648 140128494741248 run_lib.py:152] step: 126200, training_loss: 4.42726e+01
I0514 19:42:05.713005 140128494741248 run_lib.py:165] step: 126200, eval_loss: 2.77822e+01
I0514 19:42:11.922523 140128494741248 run_lib.py:152] step: 126250, training_loss: 2.40498e+01
I0514 19:42:18.391905 140128494741248 run_lib.py:152] step: 126300, training_loss: 2.25265e+01
I0514 19:42:18.443122 140128494741248 run_lib.py:165] step: 126300, eval_loss: 3.12477e+01
I0514 19:42:24.769998 140128494741248 run_lib.py:152] step: 126350, training_loss: 4.38852e+01
I0514 19:42:30.997660 140128494741248 run_lib.py:152] step: 126400, training_loss: 4.74169e+01
I0514 19:42:31.051524 140128494741248 run_lib.py:165] step: 126400, eval_loss: 2.43204e+01
I0514 19:42:37.459373 140128494741248 run_lib.py:152] step: 126450, training_loss: 3.82332e+01
I0514 19:42:43.652517 140128494741248 run_lib.py:152] step: 126500, training_loss: 4.21400e+01
I0514 19:42:43.702373 140128494741248 run_lib.py:165] step: 126500, eval_loss: 1.65713e+01
I0514 19:42:49.972080 140128494741248 run_lib.py:152] step: 126550, training_loss: 2.97143e+01
I0514 19:42:56.256475 140128494741248 run_lib.py:152] step: 126600, training_loss: 1.89272e+01
I0514 19:42:56.308250 140128494741248 run_lib.py:165] step: 126600, eval_loss: 3.48822e+01
I0514 19:43:02.658619 140128494741248 run_lib.py:152] step: 126650, training_loss: 4.59438e+01
I0514 19:43:08.861223 140128494741248 run_lib.py:152] step: 126700, training_loss: 2.43267e+01
I0514 19:43:08.914063 140128494741248 run_lib.py:165] step: 126700, eval_loss: 2.92375e+01
I0514 19:43:15.120691 140128494741248 run_lib.py:152] step: 126750, training_loss: 2.69273e+01
I0514 19:43:21.540136 140128494741248 run_lib.py:152] step: 126800, training_loss: 4.83786e+01
I0514 19:43:21.591337 140128494741248 run_lib.py:165] step: 126800, eval_loss: 3.06051e+01
I0514 19:43:27.873315 140128494741248 run_lib.py:152] step: 126850, training_loss: 3.51121e+01
I0514 19:43:34.070742 140128494741248 run_lib.py:152] step: 126900, training_loss: 2.16448e+01
I0514 19:43:34.123830 140128494741248 run_lib.py:165] step: 126900, eval_loss: 2.57450e+01
I0514 19:43:40.335960 140128494741248 run_lib.py:152] step: 126950, training_loss: 1.79854e+01
I0514 19:43:46.795346 140128494741248 run_lib.py:152] step: 127000, training_loss: 3.84310e+01
I0514 19:43:46.845495 140128494741248 run_lib.py:165] step: 127000, eval_loss: 2.31435e+01
I0514 19:43:52.964477 140128494741248 run_lib.py:152] step: 127050, training_loss: 3.51827e+01
I0514 19:43:59.162814 140128494741248 run_lib.py:152] step: 127100, training_loss: 3.83349e+01
I0514 19:43:59.215188 140128494741248 run_lib.py:165] step: 127100, eval_loss: 3.17182e+01
I0514 19:44:05.721820 140128494741248 run_lib.py:152] step: 127150, training_loss: 3.85010e+01
I0514 19:44:11.853378 140128494741248 run_lib.py:152] step: 127200, training_loss: 2.56097e+01
I0514 19:44:11.909433 140128494741248 run_lib.py:165] step: 127200, eval_loss: 2.37769e+01
I0514 19:44:18.172052 140128494741248 run_lib.py:152] step: 127250, training_loss: 2.95190e+01
I0514 19:44:24.348280 140128494741248 run_lib.py:152] step: 127300, training_loss: 3.64200e+01
I0514 19:44:24.398144 140128494741248 run_lib.py:165] step: 127300, eval_loss: 3.58685e+01
I0514 19:44:30.838917 140128494741248 run_lib.py:152] step: 127350, training_loss: 3.64050e+01
I0514 19:44:37.097392 140128494741248 run_lib.py:152] step: 127400, training_loss: 3.08019e+01
I0514 19:44:37.147693 140128494741248 run_lib.py:165] step: 127400, eval_loss: 4.54162e+01
I0514 19:44:43.286971 140128494741248 run_lib.py:152] step: 127450, training_loss: 1.05769e+01
I0514 19:44:49.794284 140128494741248 run_lib.py:152] step: 127500, training_loss: 2.89111e+01
I0514 19:44:49.858633 140128494741248 run_lib.py:165] step: 127500, eval_loss: 3.21861e+01
I0514 19:44:56.009811 140128494741248 run_lib.py:152] step: 127550, training_loss: 1.86174e+01
I0514 19:45:02.193047 140128494741248 run_lib.py:152] step: 127600, training_loss: 2.63090e+01
I0514 19:45:02.243431 140128494741248 run_lib.py:165] step: 127600, eval_loss: 2.81366e+01
I0514 19:45:08.470675 140128494741248 run_lib.py:152] step: 127650, training_loss: 3.11096e+01
I0514 19:45:14.899065 140128494741248 run_lib.py:152] step: 127700, training_loss: 3.46675e+01
I0514 19:45:14.950683 140128494741248 run_lib.py:165] step: 127700, eval_loss: 3.88303e+01
I0514 19:45:21.068354 140128494741248 run_lib.py:152] step: 127750, training_loss: 3.99194e+01
I0514 19:45:27.312230 140128494741248 run_lib.py:152] step: 127800, training_loss: 3.29848e+01
I0514 19:45:27.366862 140128494741248 run_lib.py:165] step: 127800, eval_loss: 3.42815e+01
I0514 19:45:33.769927 140128494741248 run_lib.py:152] step: 127850, training_loss: 3.32519e+01
I0514 19:45:40.025900 140128494741248 run_lib.py:152] step: 127900, training_loss: 2.31714e+01
I0514 19:45:40.080577 140128494741248 run_lib.py:165] step: 127900, eval_loss: 3.81515e+01
I0514 19:45:46.382698 140128494741248 run_lib.py:152] step: 127950, training_loss: 1.97570e+01
I0514 19:45:52.516632 140128494741248 run_lib.py:152] step: 128000, training_loss: 2.46146e+01
I0514 19:45:52.566694 140128494741248 run_lib.py:165] step: 128000, eval_loss: 1.90279e+01
I0514 19:45:59.040246 140128494741248 run_lib.py:152] step: 128050, training_loss: 4.16531e+01
I0514 19:46:05.204001 140128494741248 run_lib.py:152] step: 128100, training_loss: 3.79823e+01
I0514 19:46:05.256747 140128494741248 run_lib.py:165] step: 128100, eval_loss: 3.16190e+01
I0514 19:46:11.467119 140128494741248 run_lib.py:152] step: 128150, training_loss: 3.99527e+01
I0514 19:46:17.920656 140128494741248 run_lib.py:152] step: 128200, training_loss: 4.03130e+01
I0514 19:46:17.973093 140128494741248 run_lib.py:165] step: 128200, eval_loss: 3.98978e+01
I0514 19:46:24.160204 140128494741248 run_lib.py:152] step: 128250, training_loss: 4.96731e+01
I0514 19:46:30.358196 140128494741248 run_lib.py:152] step: 128300, training_loss: 4.46936e+01
I0514 19:46:30.407590 140128494741248 run_lib.py:165] step: 128300, eval_loss: 1.80070e+01
I0514 19:46:36.606025 140128494741248 run_lib.py:152] step: 128350, training_loss: 3.24242e+01
I0514 19:46:42.968005 140128494741248 run_lib.py:152] step: 128400, training_loss: 4.49000e+01
I0514 19:46:43.021734 140128494741248 run_lib.py:165] step: 128400, eval_loss: 3.48765e+01
I0514 19:46:49.189895 140128494741248 run_lib.py:152] step: 128450, training_loss: 4.15047e+01
I0514 19:46:55.430183 140128494741248 run_lib.py:152] step: 128500, training_loss: 2.93589e+01
I0514 19:46:55.486605 140128494741248 run_lib.py:165] step: 128500, eval_loss: 3.71048e+01
I0514 19:47:01.852663 140128494741248 run_lib.py:152] step: 128550, training_loss: 3.49403e+01
I0514 19:47:08.051932 140128494741248 run_lib.py:152] step: 128600, training_loss: 2.36097e+01
I0514 19:47:08.105919 140128494741248 run_lib.py:165] step: 128600, eval_loss: 2.95414e+01
I0514 19:47:14.303397 140128494741248 run_lib.py:152] step: 128650, training_loss: 3.16974e+01
I0514 19:47:20.488628 140128494741248 run_lib.py:152] step: 128700, training_loss: 1.23700e+01
I0514 19:47:20.541974 140128494741248 run_lib.py:165] step: 128700, eval_loss: 3.13432e+01
I0514 19:47:27.020994 140128494741248 run_lib.py:152] step: 128750, training_loss: 2.15736e+01
I0514 19:47:33.193386 140128494741248 run_lib.py:152] step: 128800, training_loss: 2.82607e+01
I0514 19:47:33.242815 140128494741248 run_lib.py:165] step: 128800, eval_loss: 1.64472e+01
I0514 19:47:39.432155 140128494741248 run_lib.py:152] step: 128850, training_loss: 4.10487e+01
I0514 19:47:45.962341 140128494741248 run_lib.py:152] step: 128900, training_loss: 4.28819e+01
I0514 19:47:46.012429 140128494741248 run_lib.py:165] step: 128900, eval_loss: 3.51394e+01
I0514 19:47:52.201537 140128494741248 run_lib.py:152] step: 128950, training_loss: 2.64346e+01
I0514 19:47:58.409724 140128494741248 run_lib.py:152] step: 129000, training_loss: 3.59890e+01
I0514 19:47:58.466619 140128494741248 run_lib.py:165] step: 129000, eval_loss: 4.02338e+01
I0514 19:48:04.706513 140128494741248 run_lib.py:152] step: 129050, training_loss: 3.81576e+01
I0514 19:48:11.208584 140128494741248 run_lib.py:152] step: 129100, training_loss: 3.40073e+01
I0514 19:48:11.265435 140128494741248 run_lib.py:165] step: 129100, eval_loss: 3.61439e+01
I0514 19:48:17.429769 140128494741248 run_lib.py:152] step: 129150, training_loss: 2.44211e+01
I0514 19:48:23.606214 140128494741248 run_lib.py:152] step: 129200, training_loss: 3.52877e+01
I0514 19:48:23.657883 140128494741248 run_lib.py:165] step: 129200, eval_loss: 3.23418e+01
I0514 19:48:30.094154 140128494741248 run_lib.py:152] step: 129250, training_loss: 2.83495e+01
I0514 19:48:36.358193 140128494741248 run_lib.py:152] step: 129300, training_loss: 3.05981e+01
I0514 19:48:36.408984 140128494741248 run_lib.py:165] step: 129300, eval_loss: 3.75457e+01
I0514 19:48:42.592047 140128494741248 run_lib.py:152] step: 129350, training_loss: 3.17381e+01
I0514 19:48:48.804531 140128494741248 run_lib.py:152] step: 129400, training_loss: 3.71608e+01
I0514 19:48:48.852923 140128494741248 run_lib.py:165] step: 129400, eval_loss: 3.97778e+01
I0514 19:48:55.339837 140128494741248 run_lib.py:152] step: 129450, training_loss: 3.15750e+01
I0514 19:49:01.547985 140128494741248 run_lib.py:152] step: 129500, training_loss: 3.29550e+01
I0514 19:49:01.602869 140128494741248 run_lib.py:165] step: 129500, eval_loss: 3.59252e+01
I0514 19:49:07.931562 140128494741248 run_lib.py:152] step: 129550, training_loss: 2.73066e+01
I0514 19:49:14.332070 140128494741248 run_lib.py:152] step: 129600, training_loss: 2.99834e+01
I0514 19:49:14.389017 140128494741248 run_lib.py:165] step: 129600, eval_loss: 1.89895e+01
I0514 19:49:20.574939 140128494741248 run_lib.py:152] step: 129650, training_loss: 3.12029e+01
I0514 19:49:27.076114 140128494741248 run_lib.py:152] step: 129700, training_loss: 4.19006e+01
I0514 19:49:27.126248 140128494741248 run_lib.py:165] step: 129700, eval_loss: 2.75029e+01
I0514 19:49:33.313685 140128494741248 run_lib.py:152] step: 129750, training_loss: 1.31437e+01
I0514 19:49:39.809159 140128494741248 run_lib.py:152] step: 129800, training_loss: 1.76426e+01
I0514 19:49:39.862007 140128494741248 run_lib.py:165] step: 129800, eval_loss: 2.30495e+01
I0514 19:49:45.989212 140128494741248 run_lib.py:152] step: 129850, training_loss: 3.84802e+01
I0514 19:49:52.240545 140128494741248 run_lib.py:152] step: 129900, training_loss: 3.79224e+01
I0514 19:49:52.295899 140128494741248 run_lib.py:165] step: 129900, eval_loss: 1.83275e+01
I0514 19:49:58.699899 140128494741248 run_lib.py:152] step: 129950, training_loss: 2.62052e+01
I0514 19:50:04.987030 140128494741248 run_lib.py:152] step: 130000, training_loss: 3.54184e+01
I0514 19:50:05.189944 140128494741248 run_lib.py:165] step: 130000, eval_loss: 3.57164e+01
I0514 19:50:11.427029 140128494741248 run_lib.py:152] step: 130050, training_loss: 2.51557e+01
I0514 19:50:17.677287 140128494741248 run_lib.py:152] step: 130100, training_loss: 3.02515e+01
I0514 19:50:17.732937 140128494741248 run_lib.py:165] step: 130100, eval_loss: 1.48629e+01
I0514 19:50:24.259019 140128494741248 run_lib.py:152] step: 130150, training_loss: 5.33979e+01
I0514 19:50:30.605241 140128494741248 run_lib.py:152] step: 130200, training_loss: 3.61064e+01
I0514 19:50:30.662772 140128494741248 run_lib.py:165] step: 130200, eval_loss: 2.86111e+01
I0514 19:50:36.855779 140128494741248 run_lib.py:152] step: 130250, training_loss: 3.33363e+01
I0514 19:50:43.372357 140128494741248 run_lib.py:152] step: 130300, training_loss: 3.53874e+01
I0514 19:50:43.422171 140128494741248 run_lib.py:165] step: 130300, eval_loss: 2.68102e+01
I0514 19:50:49.736448 140128494741248 run_lib.py:152] step: 130350, training_loss: 2.00329e+01
I0514 19:50:55.974844 140128494741248 run_lib.py:152] step: 130400, training_loss: 2.91843e+01
I0514 19:50:56.025811 140128494741248 run_lib.py:165] step: 130400, eval_loss: 2.68315e+01
I0514 19:51:02.262161 140128494741248 run_lib.py:152] step: 130450, training_loss: 2.98726e+01
I0514 19:51:08.777033 140128494741248 run_lib.py:152] step: 130500, training_loss: 4.16130e+01
I0514 19:51:08.828197 140128494741248 run_lib.py:165] step: 130500, eval_loss: 4.21273e+01
I0514 19:51:15.068223 140128494741248 run_lib.py:152] step: 130550, training_loss: 2.86423e+01
I0514 19:51:21.303309 140128494741248 run_lib.py:152] step: 130600, training_loss: 2.50326e+01
I0514 19:51:21.354554 140128494741248 run_lib.py:165] step: 130600, eval_loss: 1.89447e+01
I0514 19:51:27.853815 140128494741248 run_lib.py:152] step: 130650, training_loss: 2.80280e+01
I0514 19:51:34.086391 140128494741248 run_lib.py:152] step: 130700, training_loss: 3.49164e+01
I0514 19:51:34.141170 140128494741248 run_lib.py:165] step: 130700, eval_loss: 4.18666e+01
I0514 19:51:40.391142 140128494741248 run_lib.py:152] step: 130750, training_loss: 2.86792e+01
I0514 19:51:46.644834 140128494741248 run_lib.py:152] step: 130800, training_loss: 4.19060e+01
I0514 19:51:46.696065 140128494741248 run_lib.py:165] step: 130800, eval_loss: 2.96392e+01
I0514 19:51:53.120476 140128494741248 run_lib.py:152] step: 130850, training_loss: 3.10611e+01
I0514 19:51:59.354889 140128494741248 run_lib.py:152] step: 130900, training_loss: 3.23730e+01
I0514 19:51:59.407077 140128494741248 run_lib.py:165] step: 130900, eval_loss: 2.20698e+01
I0514 19:52:05.617908 140128494741248 run_lib.py:152] step: 130950, training_loss: 4.78566e+01
I0514 19:52:12.146963 140128494741248 run_lib.py:152] step: 131000, training_loss: 2.54599e+01
I0514 19:52:12.206968 140128494741248 run_lib.py:165] step: 131000, eval_loss: 4.99756e+01
I0514 19:52:18.442351 140128494741248 run_lib.py:152] step: 131050, training_loss: 2.32314e+01
I0514 19:52:24.638927 140128494741248 run_lib.py:152] step: 131100, training_loss: 3.44524e+01
I0514 19:52:24.690273 140128494741248 run_lib.py:165] step: 131100, eval_loss: 2.88259e+01
I0514 19:52:30.829967 140128494741248 run_lib.py:152] step: 131150, training_loss: 3.55931e+01
I0514 19:52:37.256607 140128494741248 run_lib.py:152] step: 131200, training_loss: 2.97591e+01
I0514 19:52:37.309123 140128494741248 run_lib.py:165] step: 131200, eval_loss: 2.51506e+01
I0514 19:52:43.546967 140128494741248 run_lib.py:152] step: 131250, training_loss: 3.62212e+01
I0514 19:52:49.829292 140128494741248 run_lib.py:152] step: 131300, training_loss: 1.64840e+01
I0514 19:52:49.884414 140128494741248 run_lib.py:165] step: 131300, eval_loss: 2.41037e+01
I0514 19:52:56.280941 140128494741248 run_lib.py:152] step: 131350, training_loss: 1.61416e+01
I0514 19:53:02.525357 140128494741248 run_lib.py:152] step: 131400, training_loss: 4.09761e+01
I0514 19:53:02.578429 140128494741248 run_lib.py:165] step: 131400, eval_loss: 3.44918e+01
I0514 19:53:08.830958 140128494741248 run_lib.py:152] step: 131450, training_loss: 4.44443e+01
I0514 19:53:15.086330 140128494741248 run_lib.py:152] step: 131500, training_loss: 2.58444e+01
I0514 19:53:15.137920 140128494741248 run_lib.py:165] step: 131500, eval_loss: 1.88750e+01
I0514 19:53:21.605991 140128494741248 run_lib.py:152] step: 131550, training_loss: 2.34983e+01
I0514 19:53:27.800748 140128494741248 run_lib.py:152] step: 131600, training_loss: 3.80536e+01
I0514 19:53:27.850367 140128494741248 run_lib.py:165] step: 131600, eval_loss: 2.47712e+01
I0514 19:53:34.032149 140128494741248 run_lib.py:152] step: 131650, training_loss: 2.92359e+01
I0514 19:53:40.416112 140128494741248 run_lib.py:152] step: 131700, training_loss: 4.02489e+01
I0514 19:53:40.466124 140128494741248 run_lib.py:165] step: 131700, eval_loss: 2.76621e+01
I0514 19:53:46.827606 140128494741248 run_lib.py:152] step: 131750, training_loss: 3.66337e+01
I0514 19:53:53.058239 140128494741248 run_lib.py:152] step: 131800, training_loss: 3.45175e+01
I0514 19:53:53.106270 140128494741248 run_lib.py:165] step: 131800, eval_loss: 2.02841e+01
I0514 19:53:59.436058 140128494741248 run_lib.py:152] step: 131850, training_loss: 3.53033e+01
I0514 19:54:05.824505 140128494741248 run_lib.py:152] step: 131900, training_loss: 3.36147e+01
I0514 19:54:05.875333 140128494741248 run_lib.py:165] step: 131900, eval_loss: 1.95264e+01
I0514 19:54:12.061080 140128494741248 run_lib.py:152] step: 131950, training_loss: 4.66841e+01
I0514 19:54:18.281523 140128494741248 run_lib.py:152] step: 132000, training_loss: 3.53735e+01
I0514 19:54:18.335783 140128494741248 run_lib.py:165] step: 132000, eval_loss: 3.91275e+01
I0514 19:54:24.767725 140128494741248 run_lib.py:152] step: 132050, training_loss: 2.21254e+01
I0514 19:54:30.941918 140128494741248 run_lib.py:152] step: 132100, training_loss: 4.25765e+01
I0514 19:54:31.002840 140128494741248 run_lib.py:165] step: 132100, eval_loss: 4.30007e+01
I0514 19:54:37.193196 140128494741248 run_lib.py:152] step: 132150, training_loss: 4.90994e+01
I0514 19:54:43.487368 140128494741248 run_lib.py:152] step: 132200, training_loss: 3.07563e+01
I0514 19:54:43.539520 140128494741248 run_lib.py:165] step: 132200, eval_loss: 3.01465e+01
I0514 19:54:50.072367 140128494741248 run_lib.py:152] step: 132250, training_loss: 4.74655e+01
I0514 19:54:56.260687 140128494741248 run_lib.py:152] step: 132300, training_loss: 3.21562e+01
I0514 19:54:56.314521 140128494741248 run_lib.py:165] step: 132300, eval_loss: 2.15169e+01
I0514 19:55:02.494191 140128494741248 run_lib.py:152] step: 132350, training_loss: 2.76547e+01
I0514 19:55:08.933729 140128494741248 run_lib.py:152] step: 132400, training_loss: 3.44803e+01
I0514 19:55:08.987846 140128494741248 run_lib.py:165] step: 132400, eval_loss: 2.18181e+01
I0514 19:55:15.266133 140128494741248 run_lib.py:152] step: 132450, training_loss: 2.36705e+01
I0514 19:55:21.509937 140128494741248 run_lib.py:152] step: 132500, training_loss: 2.22451e+01
I0514 19:55:21.565774 140128494741248 run_lib.py:165] step: 132500, eval_loss: 3.54023e+01
I0514 19:55:27.810387 140128494741248 run_lib.py:152] step: 132550, training_loss: 2.23158e+01
I0514 19:55:34.290684 140128494741248 run_lib.py:152] step: 132600, training_loss: 2.07660e+01
I0514 19:55:34.341509 140128494741248 run_lib.py:165] step: 132600, eval_loss: 2.87044e+01
I0514 19:55:40.542145 140128494741248 run_lib.py:152] step: 132650, training_loss: 2.81604e+01
I0514 19:55:46.696679 140128494741248 run_lib.py:152] step: 132700, training_loss: 4.07734e+01
I0514 19:55:46.748563 140128494741248 run_lib.py:165] step: 132700, eval_loss: 3.46808e+01
I0514 19:55:53.270272 140128494741248 run_lib.py:152] step: 132750, training_loss: 2.44156e+01
I0514 19:55:59.520658 140128494741248 run_lib.py:152] step: 132800, training_loss: 3.68539e+01
I0514 19:55:59.570076 140128494741248 run_lib.py:165] step: 132800, eval_loss: 2.66913e+01
I0514 19:56:05.823212 140128494741248 run_lib.py:152] step: 132850, training_loss: 1.96286e+01
I0514 19:56:12.134941 140128494741248 run_lib.py:152] step: 132900, training_loss: 3.86060e+01
I0514 19:56:12.186753 140128494741248 run_lib.py:165] step: 132900, eval_loss: 3.14997e+01
I0514 19:56:18.559473 140128494741248 run_lib.py:152] step: 132950, training_loss: 2.67951e+01
I0514 19:56:24.814888 140128494741248 run_lib.py:152] step: 133000, training_loss: 3.77122e+01
I0514 19:56:24.872956 140128494741248 run_lib.py:165] step: 133000, eval_loss: 5.09109e+01
I0514 19:56:31.033289 140128494741248 run_lib.py:152] step: 133050, training_loss: 4.17626e+01
I0514 19:56:37.417702 140128494741248 run_lib.py:152] step: 133100, training_loss: 4.17993e+01
I0514 19:56:37.470587 140128494741248 run_lib.py:165] step: 133100, eval_loss: 3.72199e+01
I0514 19:56:43.605442 140128494741248 run_lib.py:152] step: 133150, training_loss: 3.32670e+01
I0514 19:56:49.787290 140128494741248 run_lib.py:152] step: 133200, training_loss: 1.98027e+01
I0514 19:56:49.841827 140128494741248 run_lib.py:165] step: 133200, eval_loss: 4.19886e+01
I0514 19:56:56.026588 140128494741248 run_lib.py:152] step: 133250, training_loss: 3.91670e+01
I0514 19:57:02.386785 140128494741248 run_lib.py:152] step: 133300, training_loss: 2.49675e+01
I0514 19:57:02.437695 140128494741248 run_lib.py:165] step: 133300, eval_loss: 2.77872e+01
I0514 19:57:08.737060 140128494741248 run_lib.py:152] step: 133350, training_loss: 3.36731e+01
I0514 19:57:14.989515 140128494741248 run_lib.py:152] step: 133400, training_loss: 3.24126e+01
I0514 19:57:15.046590 140128494741248 run_lib.py:165] step: 133400, eval_loss: 4.28142e+01
I0514 19:57:21.554134 140128494741248 run_lib.py:152] step: 133450, training_loss: 3.15941e+01
I0514 19:57:27.750973 140128494741248 run_lib.py:152] step: 133500, training_loss: 3.02352e+01
I0514 19:57:27.802369 140128494741248 run_lib.py:165] step: 133500, eval_loss: 2.75940e+01
I0514 19:57:33.997443 140128494741248 run_lib.py:152] step: 133550, training_loss: 2.36296e+01
I0514 19:57:40.217944 140128494741248 run_lib.py:152] step: 133600, training_loss: 4.66046e+01
I0514 19:57:40.270302 140128494741248 run_lib.py:165] step: 133600, eval_loss: 3.85096e+01
I0514 19:57:46.728954 140128494741248 run_lib.py:152] step: 133650, training_loss: 3.38587e+01
I0514 19:57:52.891630 140128494741248 run_lib.py:152] step: 133700, training_loss: 5.03249e+01
I0514 19:57:52.942293 140128494741248 run_lib.py:165] step: 133700, eval_loss: 2.99668e+01
I0514 19:57:59.160469 140128494741248 run_lib.py:152] step: 133750, training_loss: 3.85355e+01
I0514 19:58:05.575644 140128494741248 run_lib.py:152] step: 133800, training_loss: 3.36178e+01
I0514 19:58:05.625611 140128494741248 run_lib.py:165] step: 133800, eval_loss: 2.34459e+01
I0514 19:58:11.800505 140128494741248 run_lib.py:152] step: 133850, training_loss: 3.44470e+01
I0514 19:58:18.013529 140128494741248 run_lib.py:152] step: 133900, training_loss: 1.63907e+01
I0514 19:58:18.069985 140128494741248 run_lib.py:165] step: 133900, eval_loss: 3.94315e+01
I0514 19:58:24.257035 140128494741248 run_lib.py:152] step: 133950, training_loss: 3.93082e+01
I0514 19:58:30.725536 140128494741248 run_lib.py:152] step: 134000, training_loss: 2.22708e+01
I0514 19:58:30.782240 140128494741248 run_lib.py:165] step: 134000, eval_loss: 3.98464e+01
I0514 19:58:36.915882 140128494741248 run_lib.py:152] step: 134050, training_loss: 3.90619e+01
I0514 19:58:43.084888 140128494741248 run_lib.py:152] step: 134100, training_loss: 4.21894e+01
I0514 19:58:43.139322 140128494741248 run_lib.py:165] step: 134100, eval_loss: 2.50855e+01
I0514 19:58:49.585985 140128494741248 run_lib.py:152] step: 134150, training_loss: 2.47490e+01
I0514 19:58:55.679305 140128494741248 run_lib.py:152] step: 134200, training_loss: 3.15794e+01
I0514 19:58:55.729710 140128494741248 run_lib.py:165] step: 134200, eval_loss: 2.92101e+01
I0514 19:59:01.793916 140128494741248 run_lib.py:152] step: 134250, training_loss: 4.60085e+01
I0514 19:59:08.046176 140128494741248 run_lib.py:152] step: 134300, training_loss: 2.39067e+01
I0514 19:59:08.100283 140128494741248 run_lib.py:165] step: 134300, eval_loss: 1.92643e+01
I0514 19:59:14.584624 140128494741248 run_lib.py:152] step: 134350, training_loss: 3.40081e+01
I0514 19:59:20.714693 140128494741248 run_lib.py:152] step: 134400, training_loss: 2.78172e+01
I0514 19:59:20.768805 140128494741248 run_lib.py:165] step: 134400, eval_loss: 2.75484e+01
I0514 19:59:27.075678 140128494741248 run_lib.py:152] step: 134450, training_loss: 3.49760e+01
I0514 19:59:33.568974 140128494741248 run_lib.py:152] step: 134500, training_loss: 2.27258e+01
I0514 19:59:33.626600 140128494741248 run_lib.py:165] step: 134500, eval_loss: 3.84973e+01
I0514 19:59:39.818520 140128494741248 run_lib.py:152] step: 134550, training_loss: 3.32891e+01
I0514 19:59:46.001172 140128494741248 run_lib.py:152] step: 134600, training_loss: 3.16716e+01
I0514 19:59:46.057865 140128494741248 run_lib.py:165] step: 134600, eval_loss: 3.58273e+01
I0514 19:59:52.290078 140128494741248 run_lib.py:152] step: 134650, training_loss: 4.05447e+01
I0514 19:59:58.721472 140128494741248 run_lib.py:152] step: 134700, training_loss: 3.17638e+01
I0514 19:59:58.773413 140128494741248 run_lib.py:165] step: 134700, eval_loss: 1.76342e+01
I0514 20:00:05.035351 140128494741248 run_lib.py:152] step: 134750, training_loss: 4.13067e+01
I0514 20:00:11.308251 140128494741248 run_lib.py:152] step: 134800, training_loss: 2.11093e+01
I0514 20:00:11.357744 140128494741248 run_lib.py:165] step: 134800, eval_loss: 4.54166e+01
I0514 20:00:17.790150 140128494741248 run_lib.py:152] step: 134850, training_loss: 4.10769e+01
I0514 20:00:24.043463 140128494741248 run_lib.py:152] step: 134900, training_loss: 4.58734e+01
I0514 20:00:24.091560 140128494741248 run_lib.py:165] step: 134900, eval_loss: 4.22774e+01
I0514 20:00:30.399841 140128494741248 run_lib.py:152] step: 134950, training_loss: 2.61025e+01
I0514 20:00:36.595503 140128494741248 run_lib.py:152] step: 135000, training_loss: 3.19347e+01
I0514 20:00:36.649716 140128494741248 run_lib.py:165] step: 135000, eval_loss: 3.78935e+01
I0514 20:00:43.086730 140128494741248 run_lib.py:152] step: 135050, training_loss: 2.85465e+01
I0514 20:00:49.309314 140128494741248 run_lib.py:152] step: 135100, training_loss: 3.67180e+01
I0514 20:00:49.364902 140128494741248 run_lib.py:165] step: 135100, eval_loss: 3.36010e+01
I0514 20:00:55.595489 140128494741248 run_lib.py:152] step: 135150, training_loss: 3.05078e+01
I0514 20:01:02.017860 140128494741248 run_lib.py:152] step: 135200, training_loss: 3.62124e+01
I0514 20:01:02.071673 140128494741248 run_lib.py:165] step: 135200, eval_loss: 3.01703e+01
I0514 20:01:08.393132 140128494741248 run_lib.py:152] step: 135250, training_loss: 2.72573e+01
I0514 20:01:14.597960 140128494741248 run_lib.py:152] step: 135300, training_loss: 2.03951e+01
I0514 20:01:14.653491 140128494741248 run_lib.py:165] step: 135300, eval_loss: 2.69731e+01
I0514 20:01:20.760138 140128494741248 run_lib.py:152] step: 135350, training_loss: 2.02462e+01
I0514 20:01:27.227981 140128494741248 run_lib.py:152] step: 135400, training_loss: 2.79146e+01
I0514 20:01:27.279999 140128494741248 run_lib.py:165] step: 135400, eval_loss: 4.15777e+01
I0514 20:01:33.533628 140128494741248 run_lib.py:152] step: 135450, training_loss: 3.80430e+01
I0514 20:01:39.738479 140128494741248 run_lib.py:152] step: 135500, training_loss: 2.39294e+01
I0514 20:01:39.788900 140128494741248 run_lib.py:165] step: 135500, eval_loss: 2.71984e+01
I0514 20:01:46.274798 140128494741248 run_lib.py:152] step: 135550, training_loss: 3.98024e+01
I0514 20:01:52.432305 140128494741248 run_lib.py:152] step: 135600, training_loss: 2.32869e+01
I0514 20:01:52.491528 140128494741248 run_lib.py:165] step: 135600, eval_loss: 2.94967e+01
I0514 20:01:58.716778 140128494741248 run_lib.py:152] step: 135650, training_loss: 4.06814e+01
I0514 20:02:04.939390 140128494741248 run_lib.py:152] step: 135700, training_loss: 2.66220e+01
I0514 20:02:05.002177 140128494741248 run_lib.py:165] step: 135700, eval_loss: 3.30549e+01
I0514 20:02:11.552314 140128494741248 run_lib.py:152] step: 135750, training_loss: 2.89498e+01
I0514 20:02:17.688831 140128494741248 run_lib.py:152] step: 135800, training_loss: 2.78789e+01
I0514 20:02:17.744891 140128494741248 run_lib.py:165] step: 135800, eval_loss: 3.33259e+01
I0514 20:02:23.906246 140128494741248 run_lib.py:152] step: 135850, training_loss: 3.84871e+01
I0514 20:02:30.310121 140128494741248 run_lib.py:152] step: 135900, training_loss: 3.80237e+01
I0514 20:02:30.357825 140128494741248 run_lib.py:165] step: 135900, eval_loss: 3.42911e+01
I0514 20:02:36.614665 140128494741248 run_lib.py:152] step: 135950, training_loss: 3.85189e+01
I0514 20:02:42.815235 140128494741248 run_lib.py:152] step: 136000, training_loss: 2.98305e+01
I0514 20:02:42.867171 140128494741248 run_lib.py:165] step: 136000, eval_loss: 4.07684e+01
I0514 20:02:49.071752 140128494741248 run_lib.py:152] step: 136050, training_loss: 3.25058e+01
I0514 20:02:55.508222 140128494741248 run_lib.py:152] step: 136100, training_loss: 3.17574e+01
I0514 20:02:55.563774 140128494741248 run_lib.py:165] step: 136100, eval_loss: 3.41831e+01
I0514 20:03:01.719843 140128494741248 run_lib.py:152] step: 136150, training_loss: 1.60110e+01
I0514 20:03:07.967112 140128494741248 run_lib.py:152] step: 136200, training_loss: 2.67485e+01
I0514 20:03:08.018952 140128494741248 run_lib.py:165] step: 136200, eval_loss: 4.23848e+01
I0514 20:03:14.399335 140128494741248 run_lib.py:152] step: 136250, training_loss: 3.29694e+01
I0514 20:03:20.588155 140128494741248 run_lib.py:152] step: 136300, training_loss: 2.07148e+01
I0514 20:03:20.637273 140128494741248 run_lib.py:165] step: 136300, eval_loss: 4.32054e+01
I0514 20:03:26.839686 140128494741248 run_lib.py:152] step: 136350, training_loss: 3.51176e+01
I0514 20:03:32.965719 140128494741248 run_lib.py:152] step: 136400, training_loss: 4.05035e+01
I0514 20:03:33.019883 140128494741248 run_lib.py:165] step: 136400, eval_loss: 2.47182e+01
I0514 20:03:39.404032 140128494741248 run_lib.py:152] step: 136450, training_loss: 3.55150e+01
I0514 20:03:45.677383 140128494741248 run_lib.py:152] step: 136500, training_loss: 1.62663e+01
I0514 20:03:45.726100 140128494741248 run_lib.py:165] step: 136500, eval_loss: 2.82316e+01
I0514 20:03:51.963039 140128494741248 run_lib.py:152] step: 136550, training_loss: 2.87206e+01
I0514 20:03:58.391641 140128494741248 run_lib.py:152] step: 136600, training_loss: 2.75930e+01
I0514 20:03:58.443215 140128494741248 run_lib.py:165] step: 136600, eval_loss: 4.70755e+01
I0514 20:04:04.645935 140128494741248 run_lib.py:152] step: 136650, training_loss: 1.60345e+01
I0514 20:04:10.862550 140128494741248 run_lib.py:152] step: 136700, training_loss: 3.95041e+01
I0514 20:04:10.917313 140128494741248 run_lib.py:165] step: 136700, eval_loss: 3.20193e+01
I0514 20:04:17.098210 140128494741248 run_lib.py:152] step: 136750, training_loss: 4.41521e+01
I0514 20:04:23.497112 140128494741248 run_lib.py:152] step: 136800, training_loss: 3.29091e+01
I0514 20:04:23.545870 140128494741248 run_lib.py:165] step: 136800, eval_loss: 2.06024e+01
I0514 20:04:29.765096 140128494741248 run_lib.py:152] step: 136850, training_loss: 1.53629e+01
I0514 20:04:35.934219 140128494741248 run_lib.py:152] step: 136900, training_loss: 1.66352e+01
I0514 20:04:35.986022 140128494741248 run_lib.py:165] step: 136900, eval_loss: 4.68227e+01
I0514 20:04:42.588018 140128494741248 run_lib.py:152] step: 136950, training_loss: 4.42828e+01
I0514 20:04:48.781633 140128494741248 run_lib.py:152] step: 137000, training_loss: 4.59367e+01
I0514 20:04:48.829970 140128494741248 run_lib.py:165] step: 137000, eval_loss: 3.20274e+01
I0514 20:04:55.016280 140128494741248 run_lib.py:152] step: 137050, training_loss: 3.27984e+01
I0514 20:05:01.229748 140128494741248 run_lib.py:152] step: 137100, training_loss: 4.41077e+01
I0514 20:05:01.280637 140128494741248 run_lib.py:165] step: 137100, eval_loss: 3.42630e+01
I0514 20:05:07.771118 140128494741248 run_lib.py:152] step: 137150, training_loss: 3.52402e+01
I0514 20:05:14.042378 140128494741248 run_lib.py:152] step: 137200, training_loss: 3.14876e+01
I0514 20:05:14.098208 140128494741248 run_lib.py:165] step: 137200, eval_loss: 3.00878e+01
I0514 20:05:20.307161 140128494741248 run_lib.py:152] step: 137250, training_loss: 4.69874e+01
I0514 20:05:26.817959 140128494741248 run_lib.py:152] step: 137300, training_loss: 3.68443e+01
I0514 20:05:26.874732 140128494741248 run_lib.py:165] step: 137300, eval_loss: 2.79991e+01
I0514 20:05:33.083597 140128494741248 run_lib.py:152] step: 137350, training_loss: 3.71131e+01
I0514 20:05:39.359510 140128494741248 run_lib.py:152] step: 137400, training_loss: 3.76958e+01
I0514 20:05:39.413121 140128494741248 run_lib.py:165] step: 137400, eval_loss: 4.97191e+01
I0514 20:05:45.629514 140128494741248 run_lib.py:152] step: 137450, training_loss: 3.96954e+01
I0514 20:05:52.072362 140128494741248 run_lib.py:152] step: 137500, training_loss: 3.12150e+01
I0514 20:05:52.126439 140128494741248 run_lib.py:165] step: 137500, eval_loss: 4.56490e+01
I0514 20:05:58.382037 140128494741248 run_lib.py:152] step: 137550, training_loss: 3.53968e+01
I0514 20:06:04.507669 140128494741248 run_lib.py:152] step: 137600, training_loss: 3.97427e+01
I0514 20:06:04.556658 140128494741248 run_lib.py:165] step: 137600, eval_loss: 3.58415e+01
I0514 20:06:11.012318 140128494741248 run_lib.py:152] step: 137650, training_loss: 2.98301e+01
I0514 20:06:17.211510 140128494741248 run_lib.py:152] step: 137700, training_loss: 3.79167e+01
I0514 20:06:17.264633 140128494741248 run_lib.py:165] step: 137700, eval_loss: 2.36454e+01
I0514 20:06:23.466383 140128494741248 run_lib.py:152] step: 137750, training_loss: 3.33666e+01
I0514 20:06:29.744598 140128494741248 run_lib.py:152] step: 137800, training_loss: 3.52513e+01
I0514 20:06:29.796645 140128494741248 run_lib.py:165] step: 137800, eval_loss: 2.65494e+01
I0514 20:06:36.184851 140128494741248 run_lib.py:152] step: 137850, training_loss: 3.58616e+01
I0514 20:06:42.440509 140128494741248 run_lib.py:152] step: 137900, training_loss: 3.12435e+01
I0514 20:06:42.494871 140128494741248 run_lib.py:165] step: 137900, eval_loss: 3.76108e+01
I0514 20:06:48.705861 140128494741248 run_lib.py:152] step: 137950, training_loss: 3.88620e+01
I0514 20:06:55.114377 140128494741248 run_lib.py:152] step: 138000, training_loss: 2.69446e+01
I0514 20:06:55.177546 140128494741248 run_lib.py:165] step: 138000, eval_loss: 2.50567e+01
I0514 20:07:01.431574 140128494741248 run_lib.py:152] step: 138050, training_loss: 3.62604e+01
I0514 20:07:07.685420 140128494741248 run_lib.py:152] step: 138100, training_loss: 3.21933e+01
I0514 20:07:07.738544 140128494741248 run_lib.py:165] step: 138100, eval_loss: 3.72692e+01
I0514 20:07:13.891422 140128494741248 run_lib.py:152] step: 138150, training_loss: 4.48572e+01
I0514 20:07:20.327867 140128494741248 run_lib.py:152] step: 138200, training_loss: 3.74484e+01
I0514 20:07:20.376519 140128494741248 run_lib.py:165] step: 138200, eval_loss: 2.60437e+01
I0514 20:07:26.591415 140128494741248 run_lib.py:152] step: 138250, training_loss: 3.08833e+01
I0514 20:07:32.812614 140128494741248 run_lib.py:152] step: 138300, training_loss: 3.57913e+01
I0514 20:07:32.866980 140128494741248 run_lib.py:165] step: 138300, eval_loss: 2.96818e+01
I0514 20:07:39.258247 140128494741248 run_lib.py:152] step: 138350, training_loss: 4.12148e+01
I0514 20:07:45.530529 140128494741248 run_lib.py:152] step: 138400, training_loss: 2.38428e+01
I0514 20:07:45.587405 140128494741248 run_lib.py:165] step: 138400, eval_loss: 3.47777e+01
I0514 20:07:51.746666 140128494741248 run_lib.py:152] step: 138450, training_loss: 4.42124e+01
I0514 20:07:57.940605 140128494741248 run_lib.py:152] step: 138500, training_loss: 3.35115e+01
I0514 20:07:57.991967 140128494741248 run_lib.py:165] step: 138500, eval_loss: 4.23343e+01
I0514 20:08:04.453778 140128494741248 run_lib.py:152] step: 138550, training_loss: 2.85735e+01
I0514 20:08:10.708296 140128494741248 run_lib.py:152] step: 138600, training_loss: 3.51691e+01
I0514 20:08:10.763601 140128494741248 run_lib.py:165] step: 138600, eval_loss: 4.49430e+01
I0514 20:08:17.017049 140128494741248 run_lib.py:152] step: 138650, training_loss: 2.79229e+01
I0514 20:08:23.464202 140128494741248 run_lib.py:152] step: 138700, training_loss: 2.01978e+01
I0514 20:08:23.512396 140128494741248 run_lib.py:165] step: 138700, eval_loss: 2.78604e+01
I0514 20:08:29.691802 140128494741248 run_lib.py:152] step: 138750, training_loss: 3.25958e+01
I0514 20:08:35.955893 140128494741248 run_lib.py:152] step: 138800, training_loss: 3.14124e+01
I0514 20:08:36.005257 140128494741248 run_lib.py:165] step: 138800, eval_loss: 4.46040e+01
I0514 20:08:42.200602 140128494741248 run_lib.py:152] step: 138850, training_loss: 4.67804e+01
I0514 20:08:48.603922 140128494741248 run_lib.py:152] step: 138900, training_loss: 2.48049e+01
I0514 20:08:48.654461 140128494741248 run_lib.py:165] step: 138900, eval_loss: 3.95922e+01
I0514 20:08:54.840621 140128494741248 run_lib.py:152] step: 138950, training_loss: 3.29077e+01
I0514 20:09:01.070548 140128494741248 run_lib.py:152] step: 139000, training_loss: 2.55831e+01
I0514 20:09:01.127423 140128494741248 run_lib.py:165] step: 139000, eval_loss: 2.60556e+01
I0514 20:09:07.604241 140128494741248 run_lib.py:152] step: 139050, training_loss: 1.55962e+01
I0514 20:09:13.804179 140128494741248 run_lib.py:152] step: 139100, training_loss: 3.58664e+01
I0514 20:09:13.859916 140128494741248 run_lib.py:165] step: 139100, eval_loss: 2.04040e+01
I0514 20:09:20.056177 140128494741248 run_lib.py:152] step: 139150, training_loss: 3.44638e+01
I0514 20:09:26.286912 140128494741248 run_lib.py:152] step: 139200, training_loss: 2.92339e+01
I0514 20:09:26.341696 140128494741248 run_lib.py:165] step: 139200, eval_loss: 4.07482e+01
I0514 20:09:32.939561 140128494741248 run_lib.py:152] step: 139250, training_loss: 3.22335e+01
I0514 20:09:39.092842 140128494741248 run_lib.py:152] step: 139300, training_loss: 3.82908e+01
I0514 20:09:39.143872 140128494741248 run_lib.py:165] step: 139300, eval_loss: 4.28976e+01
I0514 20:09:45.331269 140128494741248 run_lib.py:152] step: 139350, training_loss: 3.64374e+01
I0514 20:09:51.767661 140128494741248 run_lib.py:152] step: 139400, training_loss: 3.90924e+01
I0514 20:09:51.819811 140128494741248 run_lib.py:165] step: 139400, eval_loss: 3.86839e+01
I0514 20:09:58.076491 140128494741248 run_lib.py:152] step: 139450, training_loss: 2.28407e+01
I0514 20:10:04.334940 140128494741248 run_lib.py:152] step: 139500, training_loss: 2.16620e+01
I0514 20:10:04.389128 140128494741248 run_lib.py:165] step: 139500, eval_loss: 3.75447e+01
I0514 20:10:10.567448 140128494741248 run_lib.py:152] step: 139550, training_loss: 3.12375e+01
I0514 20:10:16.956774 140128494741248 run_lib.py:152] step: 139600, training_loss: 4.19718e+01
I0514 20:10:17.006725 140128494741248 run_lib.py:165] step: 139600, eval_loss: 4.08766e+01
I0514 20:10:23.211637 140128494741248 run_lib.py:152] step: 139650, training_loss: 2.45106e+01
I0514 20:10:29.441985 140128494741248 run_lib.py:152] step: 139700, training_loss: 2.84129e+01
I0514 20:10:29.497791 140128494741248 run_lib.py:165] step: 139700, eval_loss: 4.04712e+01
I0514 20:10:35.961517 140128494741248 run_lib.py:152] step: 139750, training_loss: 2.52450e+01
I0514 20:10:42.151397 140128494741248 run_lib.py:152] step: 139800, training_loss: 3.15214e+01
I0514 20:10:42.203617 140128494741248 run_lib.py:165] step: 139800, eval_loss: 2.98633e+01
I0514 20:10:48.480879 140128494741248 run_lib.py:152] step: 139850, training_loss: 3.44452e+01
I0514 20:10:54.708704 140128494741248 run_lib.py:152] step: 139900, training_loss: 3.41924e+01
I0514 20:10:54.761593 140128494741248 run_lib.py:165] step: 139900, eval_loss: 3.43044e+01
I0514 20:11:01.244522 140128494741248 run_lib.py:152] step: 139950, training_loss: 5.68319e+01
I0514 20:11:07.428757 140128494741248 run_lib.py:152] step: 140000, training_loss: 3.47979e+01
I0514 20:11:07.633705 140128494741248 run_lib.py:165] step: 140000, eval_loss: 3.09160e+01
I0514 20:11:13.844748 140128494741248 run_lib.py:152] step: 140050, training_loss: 2.49829e+01
I0514 20:11:20.377637 140128494741248 run_lib.py:152] step: 140100, training_loss: 2.86869e+01
I0514 20:11:20.431886 140128494741248 run_lib.py:165] step: 140100, eval_loss: 3.37681e+01
I0514 20:11:26.647717 140128494741248 run_lib.py:152] step: 140150, training_loss: 2.70035e+01
I0514 20:11:32.765363 140128494741248 run_lib.py:152] step: 140200, training_loss: 2.38344e+01
I0514 20:11:32.822967 140128494741248 run_lib.py:165] step: 140200, eval_loss: 3.65938e+01
I0514 20:11:39.192725 140128494741248 run_lib.py:152] step: 140250, training_loss: 4.01669e+01
I0514 20:11:45.413737 140128494741248 run_lib.py:152] step: 140300, training_loss: 3.01910e+01
I0514 20:11:45.467644 140128494741248 run_lib.py:165] step: 140300, eval_loss: 3.37159e+01
I0514 20:11:51.717522 140128494741248 run_lib.py:152] step: 140350, training_loss: 2.72336e+01
I0514 20:11:57.962146 140128494741248 run_lib.py:152] step: 140400, training_loss: 3.73579e+01
I0514 20:11:58.018718 140128494741248 run_lib.py:165] step: 140400, eval_loss: 2.82439e+01
I0514 20:12:04.465179 140128494741248 run_lib.py:152] step: 140450, training_loss: 2.86120e+01
I0514 20:12:10.742893 140128494741248 run_lib.py:152] step: 140500, training_loss: 4.19816e+01
I0514 20:12:10.802208 140128494741248 run_lib.py:165] step: 140500, eval_loss: 2.43708e+01
I0514 20:12:16.918161 140128494741248 run_lib.py:152] step: 140550, training_loss: 1.19387e+01
I0514 20:12:23.105617 140128494741248 run_lib.py:152] step: 140600, training_loss: 4.50720e+01
I0514 20:12:23.381779 140128494741248 run_lib.py:165] step: 140600, eval_loss: 3.90736e+01
I0514 20:12:29.590336 140128494741248 run_lib.py:152] step: 140650, training_loss: 3.62126e+01
I0514 20:12:35.866203 140128494741248 run_lib.py:152] step: 140700, training_loss: 3.38280e+01
I0514 20:12:35.921460 140128494741248 run_lib.py:165] step: 140700, eval_loss: 3.24985e+01
I0514 20:12:42.172534 140128494741248 run_lib.py:152] step: 140750, training_loss: 1.77311e+01
I0514 20:12:48.651996 140128494741248 run_lib.py:152] step: 140800, training_loss: 3.00210e+01
I0514 20:12:48.703280 140128494741248 run_lib.py:165] step: 140800, eval_loss: 2.39915e+01
I0514 20:12:54.870970 140128494741248 run_lib.py:152] step: 140850, training_loss: 2.46030e+01
I0514 20:13:01.154609 140128494741248 run_lib.py:152] step: 140900, training_loss: 1.51354e+01
I0514 20:13:01.211380 140128494741248 run_lib.py:165] step: 140900, eval_loss: 4.07850e+01
I0514 20:13:07.698520 140128494741248 run_lib.py:152] step: 140950, training_loss: 2.72762e+01
I0514 20:13:13.898699 140128494741248 run_lib.py:152] step: 141000, training_loss: 2.49054e+01
I0514 20:13:13.951828 140128494741248 run_lib.py:165] step: 141000, eval_loss: 3.65636e+01
I0514 20:13:20.166846 140128494741248 run_lib.py:152] step: 141050, training_loss: 3.02697e+01
I0514 20:13:26.352091 140128494741248 run_lib.py:152] step: 141100, training_loss: 3.68489e+01
I0514 20:13:26.406815 140128494741248 run_lib.py:165] step: 141100, eval_loss: 3.17006e+01
I0514 20:13:32.852169 140128494741248 run_lib.py:152] step: 141150, training_loss: 3.11606e+01
I0514 20:13:39.104663 140128494741248 run_lib.py:152] step: 141200, training_loss: 3.00350e+01
I0514 20:13:39.159076 140128494741248 run_lib.py:165] step: 141200, eval_loss: 3.44712e+01
I0514 20:13:45.459579 140128494741248 run_lib.py:152] step: 141250, training_loss: 3.83986e+01
I0514 20:13:51.924804 140128494741248 run_lib.py:152] step: 141300, training_loss: 3.20490e+01
I0514 20:13:51.985641 140128494741248 run_lib.py:165] step: 141300, eval_loss: 4.06163e+01
I0514 20:13:58.161350 140128494741248 run_lib.py:152] step: 141350, training_loss: 2.83807e+01
I0514 20:14:04.364612 140128494741248 run_lib.py:152] step: 141400, training_loss: 2.86400e+01
I0514 20:14:04.415849 140128494741248 run_lib.py:165] step: 141400, eval_loss: 1.80904e+01
I0514 20:14:10.775738 140128494741248 run_lib.py:152] step: 141450, training_loss: 3.62008e+01
I0514 20:14:17.245025 140128494741248 run_lib.py:152] step: 141500, training_loss: 2.91559e+01
I0514 20:14:17.296337 140128494741248 run_lib.py:165] step: 141500, eval_loss: 2.54415e+01
I0514 20:14:23.453724 140128494741248 run_lib.py:152] step: 141550, training_loss: 3.47317e+01
I0514 20:14:29.777277 140128494741248 run_lib.py:152] step: 141600, training_loss: 4.09920e+01
I0514 20:14:29.833418 140128494741248 run_lib.py:165] step: 141600, eval_loss: 3.45110e+01
I0514 20:14:36.195605 140128494741248 run_lib.py:152] step: 141650, training_loss: 3.75116e+01
I0514 20:14:42.430738 140128494741248 run_lib.py:152] step: 141700, training_loss: 2.53346e+01
I0514 20:14:42.481236 140128494741248 run_lib.py:165] step: 141700, eval_loss: 2.85562e+01
I0514 20:14:48.744899 140128494741248 run_lib.py:152] step: 141750, training_loss: 3.49915e+01
I0514 20:14:54.988647 140128494741248 run_lib.py:152] step: 141800, training_loss: 3.43556e+01
I0514 20:14:55.038447 140128494741248 run_lib.py:165] step: 141800, eval_loss: 3.56301e+01
I0514 20:15:01.471112 140128494741248 run_lib.py:152] step: 141850, training_loss: 2.45837e+01
I0514 20:15:07.835721 140128494741248 run_lib.py:152] step: 141900, training_loss: 3.71928e+01
I0514 20:15:07.892067 140128494741248 run_lib.py:165] step: 141900, eval_loss: 3.11928e+01
I0514 20:15:14.064102 140128494741248 run_lib.py:152] step: 141950, training_loss: 3.80967e+01
I0514 20:15:20.521107 140128494741248 run_lib.py:152] step: 142000, training_loss: 3.56671e+01
I0514 20:15:20.575167 140128494741248 run_lib.py:165] step: 142000, eval_loss: 4.29311e+01
I0514 20:15:26.903024 140128494741248 run_lib.py:152] step: 142050, training_loss: 4.31508e+01
I0514 20:15:33.063706 140128494741248 run_lib.py:152] step: 142100, training_loss: 5.20849e+01
I0514 20:15:33.115467 140128494741248 run_lib.py:165] step: 142100, eval_loss: 3.60151e+01
I0514 20:15:39.358174 140128494741248 run_lib.py:152] step: 142150, training_loss: 4.15829e+01
I0514 20:15:45.857742 140128494741248 run_lib.py:152] step: 142200, training_loss: 3.70474e+01
I0514 20:15:45.909396 140128494741248 run_lib.py:165] step: 142200, eval_loss: 3.19925e+01
I0514 20:15:52.114268 140128494741248 run_lib.py:152] step: 142250, training_loss: 3.60789e+01
I0514 20:15:58.394689 140128494741248 run_lib.py:152] step: 142300, training_loss: 3.94011e+01
I0514 20:15:58.452446 140128494741248 run_lib.py:165] step: 142300, eval_loss: 3.69373e+01
I0514 20:16:04.926334 140128494741248 run_lib.py:152] step: 142350, training_loss: 3.59975e+01
I0514 20:16:11.150682 140128494741248 run_lib.py:152] step: 142400, training_loss: 4.05839e+01
I0514 20:16:11.205868 140128494741248 run_lib.py:165] step: 142400, eval_loss: 2.01314e+01
I0514 20:16:17.406223 140128494741248 run_lib.py:152] step: 142450, training_loss: 3.14992e+01
I0514 20:16:23.626685 140128494741248 run_lib.py:152] step: 142500, training_loss: 3.58422e+01
I0514 20:16:23.676848 140128494741248 run_lib.py:165] step: 142500, eval_loss: 3.37662e+01
I0514 20:16:30.197655 140128494741248 run_lib.py:152] step: 142550, training_loss: 3.95470e+01
I0514 20:16:36.436241 140128494741248 run_lib.py:152] step: 142600, training_loss: 2.66193e+01
I0514 20:16:36.487123 140128494741248 run_lib.py:165] step: 142600, eval_loss: 2.45769e+01
I0514 20:16:42.705376 140128494741248 run_lib.py:152] step: 142650, training_loss: 3.12854e+01
I0514 20:16:49.258650 140128494741248 run_lib.py:152] step: 142700, training_loss: 3.32877e+01
I0514 20:16:49.318300 140128494741248 run_lib.py:165] step: 142700, eval_loss: 1.41780e+01
I0514 20:16:55.486224 140128494741248 run_lib.py:152] step: 142750, training_loss: 3.65037e+01
I0514 20:17:01.609682 140128494741248 run_lib.py:152] step: 142800, training_loss: 3.16889e+01
I0514 20:17:01.671346 140128494741248 run_lib.py:165] step: 142800, eval_loss: 3.18922e+01
I0514 20:17:07.834325 140128494741248 run_lib.py:152] step: 142850, training_loss: 2.76891e+01
I0514 20:17:14.366660 140128494741248 run_lib.py:152] step: 142900, training_loss: 3.46397e+01
I0514 20:17:14.427711 140128494741248 run_lib.py:165] step: 142900, eval_loss: 3.74497e+01
I0514 20:17:20.630544 140128494741248 run_lib.py:152] step: 142950, training_loss: 4.34081e+01
I0514 20:17:26.908286 140128494741248 run_lib.py:152] step: 143000, training_loss: 2.04899e+01
I0514 20:17:26.958465 140128494741248 run_lib.py:165] step: 143000, eval_loss: 2.50684e+01
I0514 20:17:33.475053 140128494741248 run_lib.py:152] step: 143050, training_loss: 5.01717e+01
I0514 20:17:39.730839 140128494741248 run_lib.py:152] step: 143100, training_loss: 2.03879e+01
I0514 20:17:39.786439 140128494741248 run_lib.py:165] step: 143100, eval_loss: 3.13981e+01
I0514 20:17:45.989435 140128494741248 run_lib.py:152] step: 143150, training_loss: 5.11637e+01
I0514 20:17:52.250005 140128494741248 run_lib.py:152] step: 143200, training_loss: 3.98522e+01
I0514 20:17:52.302647 140128494741248 run_lib.py:165] step: 143200, eval_loss: 3.75127e+01
I0514 20:17:58.766836 140128494741248 run_lib.py:152] step: 143250, training_loss: 5.34332e+01
I0514 20:18:05.025681 140128494741248 run_lib.py:152] step: 143300, training_loss: 3.28858e+01
I0514 20:18:05.076120 140128494741248 run_lib.py:165] step: 143300, eval_loss: 2.41773e+01
I0514 20:18:11.393522 140128494741248 run_lib.py:152] step: 143350, training_loss: 4.69954e+01
I0514 20:18:17.849701 140128494741248 run_lib.py:152] step: 143400, training_loss: 1.79125e+01
I0514 20:18:17.902873 140128494741248 run_lib.py:165] step: 143400, eval_loss: 2.88613e+01
I0514 20:18:24.093367 140128494741248 run_lib.py:152] step: 143450, training_loss: 3.51744e+01
I0514 20:18:30.309993 140128494741248 run_lib.py:152] step: 143500, training_loss: 3.71805e+01
I0514 20:18:30.358171 140128494741248 run_lib.py:165] step: 143500, eval_loss: 3.39204e+01
I0514 20:18:36.545472 140128494741248 run_lib.py:152] step: 143550, training_loss: 4.42807e+01
I0514 20:18:43.044903 140128494741248 run_lib.py:152] step: 143600, training_loss: 1.99124e+01
I0514 20:18:43.098733 140128494741248 run_lib.py:165] step: 143600, eval_loss: 4.26907e+01
I0514 20:18:49.299367 140128494741248 run_lib.py:152] step: 143650, training_loss: 3.35257e+01
I0514 20:18:55.552098 140128494741248 run_lib.py:152] step: 143700, training_loss: 4.10373e+01
I0514 20:18:55.606884 140128494741248 run_lib.py:165] step: 143700, eval_loss: 3.62751e+01
I0514 20:19:01.978069 140128494741248 run_lib.py:152] step: 143750, training_loss: 5.05940e+01
I0514 20:19:08.247326 140128494741248 run_lib.py:152] step: 143800, training_loss: 2.87361e+01
I0514 20:19:08.303622 140128494741248 run_lib.py:165] step: 143800, eval_loss: 4.29884e+01
I0514 20:19:14.464455 140128494741248 run_lib.py:152] step: 143850, training_loss: 2.58640e+01
I0514 20:19:20.709196 140128494741248 run_lib.py:152] step: 143900, training_loss: 2.02820e+01
I0514 20:19:20.761242 140128494741248 run_lib.py:165] step: 143900, eval_loss: 3.31891e+01
I0514 20:19:27.261193 140128494741248 run_lib.py:152] step: 143950, training_loss: 2.89558e+01
I0514 20:19:33.528109 140128494741248 run_lib.py:152] step: 144000, training_loss: 3.29703e+01
I0514 20:19:33.580632 140128494741248 run_lib.py:165] step: 144000, eval_loss: 4.16709e+01
I0514 20:19:39.806120 140128494741248 run_lib.py:152] step: 144050, training_loss: 3.38674e+01
I0514 20:19:46.039728 140128494741248 run_lib.py:152] step: 144100, training_loss: 4.97360e+01
I0514 20:19:46.312556 140128494741248 run_lib.py:165] step: 144100, eval_loss: 5.23267e+01
I0514 20:19:52.531574 140128494741248 run_lib.py:152] step: 144150, training_loss: 2.90277e+01
I0514 20:19:58.757991 140128494741248 run_lib.py:152] step: 144200, training_loss: 1.93092e+01
I0514 20:19:58.810252 140128494741248 run_lib.py:165] step: 144200, eval_loss: 3.49755e+01
I0514 20:20:04.969829 140128494741248 run_lib.py:152] step: 144250, training_loss: 2.81206e+01
I0514 20:20:11.581486 140128494741248 run_lib.py:152] step: 144300, training_loss: 2.25195e+01
I0514 20:20:11.635113 140128494741248 run_lib.py:165] step: 144300, eval_loss: 2.89656e+01
I0514 20:20:17.849365 140128494741248 run_lib.py:152] step: 144350, training_loss: 2.65615e+01
I0514 20:20:24.006814 140128494741248 run_lib.py:152] step: 144400, training_loss: 4.33940e+01
I0514 20:20:24.058691 140128494741248 run_lib.py:165] step: 144400, eval_loss: 3.64374e+01
I0514 20:20:30.550866 140128494741248 run_lib.py:152] step: 144450, training_loss: 2.73006e+01
I0514 20:20:36.827281 140128494741248 run_lib.py:152] step: 144500, training_loss: 2.35926e+01
I0514 20:20:36.880120 140128494741248 run_lib.py:165] step: 144500, eval_loss: 4.53019e+01
I0514 20:20:43.100286 140128494741248 run_lib.py:152] step: 144550, training_loss: 3.38653e+01
I0514 20:20:49.390603 140128494741248 run_lib.py:152] step: 144600, training_loss: 2.68187e+01
I0514 20:20:49.440861 140128494741248 run_lib.py:165] step: 144600, eval_loss: 2.66559e+01
I0514 20:20:55.876762 140128494741248 run_lib.py:152] step: 144650, training_loss: 3.10219e+01
I0514 20:21:02.052183 140128494741248 run_lib.py:152] step: 144700, training_loss: 3.41586e+01
I0514 20:21:02.103425 140128494741248 run_lib.py:165] step: 144700, eval_loss: 3.99134e+01
I0514 20:21:08.426052 140128494741248 run_lib.py:152] step: 144750, training_loss: 4.90898e+01
I0514 20:21:14.938043 140128494741248 run_lib.py:152] step: 144800, training_loss: 2.64035e+01
I0514 20:21:14.994681 140128494741248 run_lib.py:165] step: 144800, eval_loss: 2.71545e+01
I0514 20:21:21.091532 140128494741248 run_lib.py:152] step: 144850, training_loss: 3.31223e+01
I0514 20:21:27.402044 140128494741248 run_lib.py:152] step: 144900, training_loss: 2.13525e+01
I0514 20:21:27.453982 140128494741248 run_lib.py:165] step: 144900, eval_loss: 2.48094e+01
I0514 20:21:33.634891 140128494741248 run_lib.py:152] step: 144950, training_loss: 4.29238e+01
I0514 20:21:40.177891 140128494741248 run_lib.py:152] step: 145000, training_loss: 2.87254e+01
I0514 20:21:40.231653 140128494741248 run_lib.py:165] step: 145000, eval_loss: 4.02796e+01
I0514 20:21:46.470083 140128494741248 run_lib.py:152] step: 145050, training_loss: 3.56654e+01
I0514 20:21:52.694157 140128494741248 run_lib.py:152] step: 145100, training_loss: 3.01615e+01
I0514 20:21:52.743264 140128494741248 run_lib.py:165] step: 145100, eval_loss: 2.93823e+01
I0514 20:21:59.251827 140128494741248 run_lib.py:152] step: 145150, training_loss: 4.35912e+01
I0514 20:22:05.510965 140128494741248 run_lib.py:152] step: 145200, training_loss: 2.53091e+01
I0514 20:22:05.562359 140128494741248 run_lib.py:165] step: 145200, eval_loss: 3.12431e+01
I0514 20:22:11.759998 140128494741248 run_lib.py:152] step: 145250, training_loss: 2.42993e+01
I0514 20:22:17.963153 140128494741248 run_lib.py:152] step: 145300, training_loss: 4.64447e+01
I0514 20:22:18.013938 140128494741248 run_lib.py:165] step: 145300, eval_loss: 3.07363e+01
I0514 20:22:24.452295 140128494741248 run_lib.py:152] step: 145350, training_loss: 2.19079e+01
I0514 20:22:30.729378 140128494741248 run_lib.py:152] step: 145400, training_loss: 3.04576e+01
I0514 20:22:30.782453 140128494741248 run_lib.py:165] step: 145400, eval_loss: 2.65233e+01
I0514 20:22:37.079025 140128494741248 run_lib.py:152] step: 145450, training_loss: 3.59053e+01
I0514 20:22:43.567648 140128494741248 run_lib.py:152] step: 145500, training_loss: 2.61949e+01
I0514 20:22:43.621106 140128494741248 run_lib.py:165] step: 145500, eval_loss: 3.49497e+01
I0514 20:22:49.806715 140128494741248 run_lib.py:152] step: 145550, training_loss: 4.54264e+01
I0514 20:22:56.099154 140128494741248 run_lib.py:152] step: 145600, training_loss: 2.91659e+01
I0514 20:22:56.149039 140128494741248 run_lib.py:165] step: 145600, eval_loss: 2.91393e+01
I0514 20:23:02.390841 140128494741248 run_lib.py:152] step: 145650, training_loss: 2.24577e+01
I0514 20:23:08.905366 140128494741248 run_lib.py:152] step: 145700, training_loss: 2.17971e+01
I0514 20:23:08.958403 140128494741248 run_lib.py:165] step: 145700, eval_loss: 2.63229e+01
I0514 20:23:15.206009 140128494741248 run_lib.py:152] step: 145750, training_loss: 3.17160e+01
I0514 20:23:21.407752 140128494741248 run_lib.py:152] step: 145800, training_loss: 3.02556e+01
I0514 20:23:21.464115 140128494741248 run_lib.py:165] step: 145800, eval_loss: 3.99142e+01
I0514 20:23:27.713421 140128494741248 run_lib.py:152] step: 145850, training_loss: 2.48969e+01
I0514 20:23:33.814560 140128494741248 run_lib.py:152] step: 145900, training_loss: 3.41298e+01
I0514 20:23:33.866777 140128494741248 run_lib.py:165] step: 145900, eval_loss: 2.82487e+01
I0514 20:23:40.095982 140128494741248 run_lib.py:152] step: 145950, training_loss: 3.37756e+01
I0514 20:23:46.474911 140128494741248 run_lib.py:152] step: 146000, training_loss: 3.78122e+01
I0514 20:23:46.525139 140128494741248 run_lib.py:165] step: 146000, eval_loss: 5.66121e+01
I0514 20:23:52.976266 140128494741248 run_lib.py:152] step: 146050, training_loss: 2.86185e+01
I0514 20:23:59.207999 140128494741248 run_lib.py:152] step: 146100, training_loss: 2.58927e+01
I0514 20:23:59.259998 140128494741248 run_lib.py:165] step: 146100, eval_loss: 3.88209e+01
I0514 20:24:05.507174 140128494741248 run_lib.py:152] step: 146150, training_loss: 2.95059e+01
I0514 20:24:12.109957 140128494741248 run_lib.py:152] step: 146200, training_loss: 2.58420e+01
I0514 20:24:12.160477 140128494741248 run_lib.py:165] step: 146200, eval_loss: 4.16001e+01
I0514 20:24:18.389489 140128494741248 run_lib.py:152] step: 146250, training_loss: 1.52139e+01
I0514 20:24:24.605153 140128494741248 run_lib.py:152] step: 146300, training_loss: 4.65302e+01
I0514 20:24:24.660093 140128494741248 run_lib.py:165] step: 146300, eval_loss: 2.93985e+01
I0514 20:24:30.883480 140128494741248 run_lib.py:152] step: 146350, training_loss: 4.52477e+01
I0514 20:24:37.256638 140128494741248 run_lib.py:152] step: 146400, training_loss: 2.59693e+01
I0514 20:24:37.308604 140128494741248 run_lib.py:165] step: 146400, eval_loss: 2.36870e+01
I0514 20:24:43.604910 140128494741248 run_lib.py:152] step: 146450, training_loss: 3.23751e+01
I0514 20:24:49.877975 140128494741248 run_lib.py:152] step: 146500, training_loss: 2.77799e+01
I0514 20:24:49.932783 140128494741248 run_lib.py:165] step: 146500, eval_loss: 3.29527e+01
I0514 20:24:56.398512 140128494741248 run_lib.py:152] step: 146550, training_loss: 3.24249e+01
I0514 20:25:02.623214 140128494741248 run_lib.py:152] step: 146600, training_loss: 2.91112e+01
I0514 20:25:02.676993 140128494741248 run_lib.py:165] step: 146600, eval_loss: 1.97172e+01
I0514 20:25:08.904254 140128494741248 run_lib.py:152] step: 146650, training_loss: 3.37537e+01
I0514 20:25:15.148614 140128494741248 run_lib.py:152] step: 146700, training_loss: 2.88545e+01
I0514 20:25:15.201224 140128494741248 run_lib.py:165] step: 146700, eval_loss: 2.19806e+01
I0514 20:25:21.685349 140128494741248 run_lib.py:152] step: 146750, training_loss: 2.32834e+01
I0514 20:25:27.982483 140128494741248 run_lib.py:152] step: 146800, training_loss: 3.06951e+01
I0514 20:25:28.038088 140128494741248 run_lib.py:165] step: 146800, eval_loss: 4.05456e+01
I0514 20:25:34.220842 140128494741248 run_lib.py:152] step: 146850, training_loss: 3.74882e+01
I0514 20:25:40.764590 140128494741248 run_lib.py:152] step: 146900, training_loss: 5.56095e+01
I0514 20:25:40.815636 140128494741248 run_lib.py:165] step: 146900, eval_loss: 3.94265e+01
I0514 20:25:47.074791 140128494741248 run_lib.py:152] step: 146950, training_loss: 3.48464e+01
I0514 20:25:53.402326 140128494741248 run_lib.py:152] step: 147000, training_loss: 3.25438e+01
I0514 20:25:53.456417 140128494741248 run_lib.py:165] step: 147000, eval_loss: 2.14956e+01
I0514 20:25:59.699638 140128494741248 run_lib.py:152] step: 147050, training_loss: 3.65948e+01
I0514 20:26:06.258455 140128494741248 run_lib.py:152] step: 147100, training_loss: 2.45655e+01
I0514 20:26:06.305547 140128494741248 run_lib.py:165] step: 147100, eval_loss: 2.13169e+01
I0514 20:26:12.576458 140128494741248 run_lib.py:152] step: 147150, training_loss: 2.44824e+01
I0514 20:26:18.695573 140128494741248 run_lib.py:152] step: 147200, training_loss: 3.83197e+01
I0514 20:26:18.749951 140128494741248 run_lib.py:165] step: 147200, eval_loss: 2.80559e+01
I0514 20:26:25.204542 140128494741248 run_lib.py:152] step: 147250, training_loss: 3.83834e+01
I0514 20:26:31.494984 140128494741248 run_lib.py:152] step: 147300, training_loss: 3.58898e+01
I0514 20:26:31.548696 140128494741248 run_lib.py:165] step: 147300, eval_loss: 2.74148e+01
I0514 20:26:37.868726 140128494741248 run_lib.py:152] step: 147350, training_loss: 3.02711e+01
I0514 20:26:44.127292 140128494741248 run_lib.py:152] step: 147400, training_loss: 2.21564e+01
I0514 20:26:44.180698 140128494741248 run_lib.py:165] step: 147400, eval_loss: 4.34201e+01
I0514 20:26:50.721347 140128494741248 run_lib.py:152] step: 147450, training_loss: 1.59818e+01
I0514 20:26:56.956247 140128494741248 run_lib.py:152] step: 147500, training_loss: 3.75873e+01
I0514 20:26:57.010196 140128494741248 run_lib.py:165] step: 147500, eval_loss: 3.09603e+01
I0514 20:27:03.246650 140128494741248 run_lib.py:152] step: 147550, training_loss: 3.50259e+01
I0514 20:27:09.482683 140128494741248 run_lib.py:152] step: 147600, training_loss: 2.47770e+01
I0514 20:27:09.759803 140128494741248 run_lib.py:165] step: 147600, eval_loss: 3.17743e+01
I0514 20:27:16.073023 140128494741248 run_lib.py:152] step: 147650, training_loss: 3.23927e+01
I0514 20:27:22.355898 140128494741248 run_lib.py:152] step: 147700, training_loss: 3.61899e+01
I0514 20:27:22.408078 140128494741248 run_lib.py:165] step: 147700, eval_loss: 2.62367e+01
I0514 20:27:28.628330 140128494741248 run_lib.py:152] step: 147750, training_loss: 3.78117e+01
I0514 20:27:35.068453 140128494741248 run_lib.py:152] step: 147800, training_loss: 4.53322e+01
I0514 20:27:35.122059 140128494741248 run_lib.py:165] step: 147800, eval_loss: 3.57790e+01
I0514 20:27:41.284499 140128494741248 run_lib.py:152] step: 147850, training_loss: 3.92900e+01
I0514 20:27:47.553513 140128494741248 run_lib.py:152] step: 147900, training_loss: 1.64517e+01
I0514 20:27:47.605693 140128494741248 run_lib.py:165] step: 147900, eval_loss: 2.03616e+01
I0514 20:27:54.063377 140128494741248 run_lib.py:152] step: 147950, training_loss: 4.27809e+01
I0514 20:28:00.339845 140128494741248 run_lib.py:152] step: 148000, training_loss: 4.01125e+01
I0514 20:28:00.395401 140128494741248 run_lib.py:165] step: 148000, eval_loss: 4.89846e+01
I0514 20:28:06.610511 140128494741248 run_lib.py:152] step: 148050, training_loss: 1.77362e+01
I0514 20:28:12.849986 140128494741248 run_lib.py:152] step: 148100, training_loss: 3.39597e+01
I0514 20:28:12.900654 140128494741248 run_lib.py:165] step: 148100, eval_loss: 3.65918e+01
I0514 20:28:19.360766 140128494741248 run_lib.py:152] step: 148150, training_loss: 2.70253e+01
I0514 20:28:25.550198 140128494741248 run_lib.py:152] step: 148200, training_loss: 5.23076e+01
I0514 20:28:25.601820 140128494741248 run_lib.py:165] step: 148200, eval_loss: 2.52506e+01
I0514 20:28:31.816433 140128494741248 run_lib.py:152] step: 148250, training_loss: 2.28078e+01
I0514 20:28:38.271183 140128494741248 run_lib.py:152] step: 148300, training_loss: 3.10710e+01
I0514 20:28:38.326963 140128494741248 run_lib.py:165] step: 148300, eval_loss: 4.84143e+01
I0514 20:28:44.488382 140128494741248 run_lib.py:152] step: 148350, training_loss: 2.88413e+01
I0514 20:28:50.752535 140128494741248 run_lib.py:152] step: 148400, training_loss: 2.72893e+01
I0514 20:28:50.808484 140128494741248 run_lib.py:165] step: 148400, eval_loss: 2.85121e+01
I0514 20:28:57.006848 140128494741248 run_lib.py:152] step: 148450, training_loss: 4.42952e+01
I0514 20:29:03.420068 140128494741248 run_lib.py:152] step: 148500, training_loss: 2.42397e+01
I0514 20:29:03.475484 140128494741248 run_lib.py:165] step: 148500, eval_loss: 2.78873e+01
I0514 20:29:09.687760 140128494741248 run_lib.py:152] step: 148550, training_loss: 2.52824e+01
I0514 20:29:15.969589 140128494741248 run_lib.py:152] step: 148600, training_loss: 3.02480e+01
I0514 20:29:16.029422 140128494741248 run_lib.py:165] step: 148600, eval_loss: 2.14623e+01
I0514 20:29:22.499923 140128494741248 run_lib.py:152] step: 148650, training_loss: 3.25051e+01
I0514 20:29:28.769600 140128494741248 run_lib.py:152] step: 148700, training_loss: 3.24298e+01
I0514 20:29:28.827909 140128494741248 run_lib.py:165] step: 148700, eval_loss: 3.88773e+01
I0514 20:29:35.042666 140128494741248 run_lib.py:152] step: 148750, training_loss: 1.48519e+01
I0514 20:29:41.241252 140128494741248 run_lib.py:152] step: 148800, training_loss: 1.95471e+01
I0514 20:29:41.293761 140128494741248 run_lib.py:165] step: 148800, eval_loss: 2.30672e+01
I0514 20:29:47.753555 140128494741248 run_lib.py:152] step: 148850, training_loss: 2.09881e+01
I0514 20:29:54.049503 140128494741248 run_lib.py:152] step: 148900, training_loss: 2.86113e+01
I0514 20:29:54.102306 140128494741248 run_lib.py:165] step: 148900, eval_loss: 4.08716e+01
I0514 20:30:00.327330 140128494741248 run_lib.py:152] step: 148950, training_loss: 3.53776e+01
I0514 20:30:06.813244 140128494741248 run_lib.py:152] step: 149000, training_loss: 3.96210e+01
I0514 20:30:06.861789 140128494741248 run_lib.py:165] step: 149000, eval_loss: 2.07384e+01
I0514 20:30:13.159688 140128494741248 run_lib.py:152] step: 149050, training_loss: 2.21091e+01
I0514 20:30:19.399486 140128494741248 run_lib.py:152] step: 149100, training_loss: 4.19296e+01
I0514 20:30:19.449343 140128494741248 run_lib.py:165] step: 149100, eval_loss: 2.29073e+01
I0514 20:30:25.734464 140128494741248 run_lib.py:152] step: 149150, training_loss: 3.30130e+01
I0514 20:30:32.180516 140128494741248 run_lib.py:152] step: 149200, training_loss: 3.13128e+01
I0514 20:30:32.233695 140128494741248 run_lib.py:165] step: 149200, eval_loss: 1.91282e+01
I0514 20:30:38.401438 140128494741248 run_lib.py:152] step: 149250, training_loss: 3.85446e+01
I0514 20:30:44.605482 140128494741248 run_lib.py:152] step: 149300, training_loss: 3.84840e+01
I0514 20:30:44.656033 140128494741248 run_lib.py:165] step: 149300, eval_loss: 1.81968e+01
I0514 20:30:51.176698 140128494741248 run_lib.py:152] step: 149350, training_loss: 3.00474e+01
I0514 20:30:57.425070 140128494741248 run_lib.py:152] step: 149400, training_loss: 2.99060e+01
I0514 20:30:57.482797 140128494741248 run_lib.py:165] step: 149400, eval_loss: 4.24149e+01
I0514 20:31:03.754676 140128494741248 run_lib.py:152] step: 149450, training_loss: 4.07335e+01
I0514 20:31:10.023333 140128494741248 run_lib.py:152] step: 149500, training_loss: 2.42743e+01
I0514 20:31:10.074990 140128494741248 run_lib.py:165] step: 149500, eval_loss: 1.98510e+01
I0514 20:31:16.616652 140128494741248 run_lib.py:152] step: 149550, training_loss: 2.61729e+01
I0514 20:31:22.861278 140128494741248 run_lib.py:152] step: 149600, training_loss: 3.68842e+01
I0514 20:31:22.918036 140128494741248 run_lib.py:165] step: 149600, eval_loss: 2.57840e+01
I0514 20:31:29.151367 140128494741248 run_lib.py:152] step: 149650, training_loss: 3.11513e+01
I0514 20:31:35.663395 140128494741248 run_lib.py:152] step: 149700, training_loss: 3.09510e+01
I0514 20:31:35.712974 140128494741248 run_lib.py:165] step: 149700, eval_loss: 1.86410e+01
I0514 20:31:41.953080 140128494741248 run_lib.py:152] step: 149750, training_loss: 2.59393e+01
I0514 20:31:48.227958 140128494741248 run_lib.py:152] step: 149800, training_loss: 3.90528e+01
I0514 20:31:48.285873 140128494741248 run_lib.py:165] step: 149800, eval_loss: 1.90269e+01
I0514 20:31:54.527392 140128494741248 run_lib.py:152] step: 149850, training_loss: 3.82040e+01
I0514 20:32:01.010323 140128494741248 run_lib.py:152] step: 149900, training_loss: 2.82436e+01
I0514 20:32:01.066486 140128494741248 run_lib.py:165] step: 149900, eval_loss: 3.49737e+01
I0514 20:32:07.251648 140128494741248 run_lib.py:152] step: 149950, training_loss: 3.19719e+01
I0514 20:32:13.611669 140128494741248 run_lib.py:152] step: 150000, training_loss: 3.13555e+01
I0514 20:32:13.819581 140128494741248 run_lib.py:165] step: 150000, eval_loss: 3.05309e+01
I0514 20:33:34.742839 140128494741248 run_lib.py:152] step: 150050, training_loss: 2.56306e+01
I0514 20:33:40.957422 140128494741248 run_lib.py:152] step: 150100, training_loss: 3.56581e+01
I0514 20:33:41.006934 140128494741248 run_lib.py:165] step: 150100, eval_loss: 3.40432e+01
I0514 20:33:47.363938 140128494741248 run_lib.py:152] step: 150150, training_loss: 1.40919e+01
I0514 20:33:53.943797 140128494741248 run_lib.py:152] step: 150200, training_loss: 3.63977e+01
I0514 20:33:53.995479 140128494741248 run_lib.py:165] step: 150200, eval_loss: 3.74230e+01
I0514 20:34:00.234077 140128494741248 run_lib.py:152] step: 150250, training_loss: 3.37068e+01
I0514 20:34:06.431021 140128494741248 run_lib.py:152] step: 150300, training_loss: 3.61218e+01
I0514 20:34:06.482267 140128494741248 run_lib.py:165] step: 150300, eval_loss: 3.94555e+01
I0514 20:34:12.788700 140128494741248 run_lib.py:152] step: 150350, training_loss: 2.85443e+01
I0514 20:34:19.350744 140128494741248 run_lib.py:152] step: 150400, training_loss: 2.12960e+01
I0514 20:34:19.401809 140128494741248 run_lib.py:165] step: 150400, eval_loss: 3.50887e+01
I0514 20:34:25.583307 140128494741248 run_lib.py:152] step: 150450, training_loss: 3.30793e+01
I0514 20:34:31.791103 140128494741248 run_lib.py:152] step: 150500, training_loss: 2.36243e+01
I0514 20:34:31.843936 140128494741248 run_lib.py:165] step: 150500, eval_loss: 2.51663e+01
I0514 20:34:38.313439 140128494741248 run_lib.py:152] step: 150550, training_loss: 2.70428e+01
I0514 20:34:44.435172 140128494741248 run_lib.py:152] step: 150600, training_loss: 3.33371e+01
I0514 20:34:44.487921 140128494741248 run_lib.py:165] step: 150600, eval_loss: 4.44237e+01
I0514 20:34:50.721462 140128494741248 run_lib.py:152] step: 150650, training_loss: 3.20083e+01
I0514 20:34:56.963874 140128494741248 run_lib.py:152] step: 150700, training_loss: 2.27100e+01
I0514 20:34:57.016638 140128494741248 run_lib.py:165] step: 150700, eval_loss: 2.46375e+01
I0514 20:35:03.467662 140128494741248 run_lib.py:152] step: 150750, training_loss: 3.82865e+01
I0514 20:35:09.624791 140128494741248 run_lib.py:152] step: 150800, training_loss: 2.29366e+01
I0514 20:35:09.673644 140128494741248 run_lib.py:165] step: 150800, eval_loss: 1.95771e+01
I0514 20:35:15.939607 140128494741248 run_lib.py:152] step: 150850, training_loss: 2.53780e+01
I0514 20:35:22.338521 140128494741248 run_lib.py:152] step: 150900, training_loss: 4.58336e+01
I0514 20:35:22.392495 140128494741248 run_lib.py:165] step: 150900, eval_loss: 2.67678e+01
I0514 20:35:28.614238 140128494741248 run_lib.py:152] step: 150950, training_loss: 4.07376e+01
I0514 20:35:34.837280 140128494741248 run_lib.py:152] step: 151000, training_loss: 5.35502e+01
I0514 20:35:34.885506 140128494741248 run_lib.py:165] step: 151000, eval_loss: 3.43084e+01
I0514 20:35:41.202934 140128494741248 run_lib.py:152] step: 151050, training_loss: 2.92218e+01
I0514 20:35:47.735856 140128494741248 run_lib.py:152] step: 151100, training_loss: 3.13543e+01
I0514 20:35:47.786618 140128494741248 run_lib.py:165] step: 151100, eval_loss: 2.02892e+01
I0514 20:35:54.081154 140128494741248 run_lib.py:152] step: 151150, training_loss: 3.29535e+01
I0514 20:36:00.282095 140128494741248 run_lib.py:152] step: 151200, training_loss: 2.61997e+01
I0514 20:36:00.337944 140128494741248 run_lib.py:165] step: 151200, eval_loss: 3.45877e+01
I0514 20:36:06.746302 140128494741248 run_lib.py:152] step: 151250, training_loss: 2.93329e+01
I0514 20:36:12.983551 140128494741248 run_lib.py:152] step: 151300, training_loss: 4.07767e+01
I0514 20:36:13.036121 140128494741248 run_lib.py:165] step: 151300, eval_loss: 2.61880e+01
I0514 20:36:19.282985 140128494741248 run_lib.py:152] step: 151350, training_loss: 5.57021e+01
I0514 20:36:25.501826 140128494741248 run_lib.py:152] step: 151400, training_loss: 5.65656e+01
I0514 20:36:25.555380 140128494741248 run_lib.py:165] step: 151400, eval_loss: 2.53921e+01
I0514 20:36:32.053629 140128494741248 run_lib.py:152] step: 151450, training_loss: 2.30367e+01
I0514 20:36:38.344329 140128494741248 run_lib.py:152] step: 151500, training_loss: 3.33697e+01
I0514 20:36:38.399283 140128494741248 run_lib.py:165] step: 151500, eval_loss: 2.83317e+01
I0514 20:36:44.714401 140128494741248 run_lib.py:152] step: 151550, training_loss: 2.18802e+01
I0514 20:36:51.127281 140128494741248 run_lib.py:152] step: 151600, training_loss: 4.48201e+01
I0514 20:36:51.187041 140128494741248 run_lib.py:165] step: 151600, eval_loss: 3.14529e+01
I0514 20:36:57.476148 140128494741248 run_lib.py:152] step: 151650, training_loss: 2.30053e+01
I0514 20:37:03.692871 140128494741248 run_lib.py:152] step: 151700, training_loss: 2.24534e+01
I0514 20:37:03.746686 140128494741248 run_lib.py:165] step: 151700, eval_loss: 2.77634e+01
I0514 20:37:09.985092 140128494741248 run_lib.py:152] step: 151750, training_loss: 4.14826e+01
I0514 20:37:16.440141 140128494741248 run_lib.py:152] step: 151800, training_loss: 3.66743e+01
I0514 20:37:16.490154 140128494741248 run_lib.py:165] step: 151800, eval_loss: 2.59672e+01
I0514 20:37:22.654067 140128494741248 run_lib.py:152] step: 151850, training_loss: 4.03610e+01
I0514 20:37:28.952820 140128494741248 run_lib.py:152] step: 151900, training_loss: 3.39800e+01
I0514 20:37:29.006884 140128494741248 run_lib.py:165] step: 151900, eval_loss: 2.48933e+01
I0514 20:37:35.405876 140128494741248 run_lib.py:152] step: 151950, training_loss: 3.61219e+01
I0514 20:37:41.633098 140128494741248 run_lib.py:152] step: 152000, training_loss: 3.44707e+01
I0514 20:37:41.688040 140128494741248 run_lib.py:165] step: 152000, eval_loss: 3.62694e+01
I0514 20:37:47.866322 140128494741248 run_lib.py:152] step: 152050, training_loss: 3.44343e+01
I0514 20:37:54.076137 140128494741248 run_lib.py:152] step: 152100, training_loss: 1.97675e+01
I0514 20:37:54.123668 140128494741248 run_lib.py:165] step: 152100, eval_loss: 3.14630e+01
I0514 20:38:00.516160 140128494741248 run_lib.py:152] step: 152150, training_loss: 3.41773e+01
I0514 20:38:06.790120 140128494741248 run_lib.py:152] step: 152200, training_loss: 2.26616e+01
I0514 20:38:06.844654 140128494741248 run_lib.py:165] step: 152200, eval_loss: 2.30718e+01
I0514 20:38:13.012654 140128494741248 run_lib.py:152] step: 152250, training_loss: 3.79332e+01
I0514 20:38:19.478946 140128494741248 run_lib.py:152] step: 152300, training_loss: 4.12819e+01
I0514 20:38:19.533633 140128494741248 run_lib.py:165] step: 152300, eval_loss: 2.91315e+01
I0514 20:38:25.703948 140128494741248 run_lib.py:152] step: 152350, training_loss: 4.79874e+01
I0514 20:38:31.978902 140128494741248 run_lib.py:152] step: 152400, training_loss: 2.21206e+01
I0514 20:38:32.031559 140128494741248 run_lib.py:165] step: 152400, eval_loss: 3.59195e+01
I0514 20:38:38.283826 140128494741248 run_lib.py:152] step: 152450, training_loss: 4.18712e+01
I0514 20:38:44.708940 140128494741248 run_lib.py:152] step: 152500, training_loss: 3.31759e+01
I0514 20:38:44.763028 140128494741248 run_lib.py:165] step: 152500, eval_loss: 3.04461e+01
I0514 20:38:50.911321 140128494741248 run_lib.py:152] step: 152550, training_loss: 1.42134e+01
I0514 20:38:57.125291 140128494741248 run_lib.py:152] step: 152600, training_loss: 4.07787e+01
I0514 20:38:57.182253 140128494741248 run_lib.py:165] step: 152600, eval_loss: 3.00630e+01
I0514 20:39:03.563873 140128494741248 run_lib.py:152] step: 152650, training_loss: 2.97424e+01
I0514 20:39:09.751519 140128494741248 run_lib.py:152] step: 152700, training_loss: 2.38162e+01
I0514 20:39:09.806191 140128494741248 run_lib.py:165] step: 152700, eval_loss: 3.78970e+01
I0514 20:39:16.061333 140128494741248 run_lib.py:152] step: 152750, training_loss: 3.78955e+01
I0514 20:39:22.342747 140128494741248 run_lib.py:152] step: 152800, training_loss: 3.94720e+01
I0514 20:39:22.395709 140128494741248 run_lib.py:165] step: 152800, eval_loss: 3.19901e+01
I0514 20:39:28.892869 140128494741248 run_lib.py:152] step: 152850, training_loss: 4.75313e+01
I0514 20:39:35.163910 140128494741248 run_lib.py:152] step: 152900, training_loss: 2.89623e+01
I0514 20:39:35.215155 140128494741248 run_lib.py:165] step: 152900, eval_loss: 2.62103e+01
I0514 20:39:41.448629 140128494741248 run_lib.py:152] step: 152950, training_loss: 2.78535e+01
I0514 20:39:47.850259 140128494741248 run_lib.py:152] step: 153000, training_loss: 1.65940e+01
I0514 20:39:47.907706 140128494741248 run_lib.py:165] step: 153000, eval_loss: 4.13138e+01
I0514 20:39:54.110804 140128494741248 run_lib.py:152] step: 153050, training_loss: 3.29952e+01
I0514 20:40:00.255691 140128494741248 run_lib.py:152] step: 153100, training_loss: 1.83969e+01
I0514 20:40:00.307166 140128494741248 run_lib.py:165] step: 153100, eval_loss: 2.30686e+01
I0514 20:40:06.464926 140128494741248 run_lib.py:152] step: 153150, training_loss: 3.42055e+01
I0514 20:40:12.964104 140128494741248 run_lib.py:152] step: 153200, training_loss: 2.87483e+01
I0514 20:40:13.017693 140128494741248 run_lib.py:165] step: 153200, eval_loss: 4.46445e+01
I0514 20:40:19.268090 140128494741248 run_lib.py:152] step: 153250, training_loss: 4.12106e+01
I0514 20:40:25.553144 140128494741248 run_lib.py:152] step: 153300, training_loss: 2.18799e+01
I0514 20:40:25.602981 140128494741248 run_lib.py:165] step: 153300, eval_loss: 3.68539e+01
I0514 20:40:32.114078 140128494741248 run_lib.py:152] step: 153350, training_loss: 3.31678e+01
I0514 20:40:38.314796 140128494741248 run_lib.py:152] step: 153400, training_loss: 3.84756e+01
I0514 20:40:38.369659 140128494741248 run_lib.py:165] step: 153400, eval_loss: 2.37349e+01
I0514 20:40:44.542437 140128494741248 run_lib.py:152] step: 153450, training_loss: 3.23677e+01
I0514 20:40:50.758885 140128494741248 run_lib.py:152] step: 153500, training_loss: 3.01222e+01
I0514 20:40:50.809303 140128494741248 run_lib.py:165] step: 153500, eval_loss: 3.24087e+01
I0514 20:40:57.219477 140128494741248 run_lib.py:152] step: 153550, training_loss: 2.61383e+01
I0514 20:41:03.374952 140128494741248 run_lib.py:152] step: 153600, training_loss: 4.63785e+01
I0514 20:41:03.433670 140128494741248 run_lib.py:165] step: 153600, eval_loss: 8.94237e+00
I0514 20:41:09.548521 140128494741248 run_lib.py:152] step: 153650, training_loss: 3.34502e+01
I0514 20:41:15.915417 140128494741248 run_lib.py:152] step: 153700, training_loss: 3.18515e+01
I0514 20:41:15.970444 140128494741248 run_lib.py:165] step: 153700, eval_loss: 3.35394e+01
I0514 20:41:22.222450 140128494741248 run_lib.py:152] step: 153750, training_loss: 3.87787e+01
I0514 20:41:28.420052 140128494741248 run_lib.py:152] step: 153800, training_loss: 3.11918e+01
I0514 20:41:28.473873 140128494741248 run_lib.py:165] step: 153800, eval_loss: 2.32518e+01
I0514 20:41:34.679321 140128494741248 run_lib.py:152] step: 153850, training_loss: 2.13754e+01
I0514 20:41:41.076900 140128494741248 run_lib.py:152] step: 153900, training_loss: 3.27833e+01
I0514 20:41:41.128286 140128494741248 run_lib.py:165] step: 153900, eval_loss: 2.49859e+01
I0514 20:41:47.374054 140128494741248 run_lib.py:152] step: 153950, training_loss: 3.21251e+01
I0514 20:41:53.591240 140128494741248 run_lib.py:152] step: 154000, training_loss: 2.90001e+01
I0514 20:41:53.647188 140128494741248 run_lib.py:165] step: 154000, eval_loss: 3.58555e+01
I0514 20:42:00.068831 140128494741248 run_lib.py:152] step: 154050, training_loss: 2.72032e+01
I0514 20:42:06.299068 140128494741248 run_lib.py:152] step: 154100, training_loss: 2.27658e+01
I0514 20:42:06.348666 140128494741248 run_lib.py:165] step: 154100, eval_loss: 4.34581e+01
I0514 20:42:12.496612 140128494741248 run_lib.py:152] step: 154150, training_loss: 3.09978e+01
I0514 20:42:18.681252 140128494741248 run_lib.py:152] step: 154200, training_loss: 2.72642e+01
I0514 20:42:18.734161 140128494741248 run_lib.py:165] step: 154200, eval_loss: 2.91680e+01
I0514 20:42:25.047935 140128494741248 run_lib.py:152] step: 154250, training_loss: 5.34536e+01
I0514 20:42:31.292043 140128494741248 run_lib.py:152] step: 154300, training_loss: 3.81054e+01
I0514 20:42:31.348618 140128494741248 run_lib.py:165] step: 154300, eval_loss: 2.17247e+01
I0514 20:42:37.642636 140128494741248 run_lib.py:152] step: 154350, training_loss: 2.95389e+01
I0514 20:42:44.021634 140128494741248 run_lib.py:152] step: 154400, training_loss: 3.11474e+01
I0514 20:42:44.079371 140128494741248 run_lib.py:165] step: 154400, eval_loss: 3.05631e+01
I0514 20:42:50.335103 140128494741248 run_lib.py:152] step: 154450, training_loss: 2.36662e+01
I0514 20:42:56.536451 140128494741248 run_lib.py:152] step: 154500, training_loss: 2.73354e+01
I0514 20:42:56.586592 140128494741248 run_lib.py:165] step: 154500, eval_loss: 3.69331e+01
I0514 20:43:02.799283 140128494741248 run_lib.py:152] step: 154550, training_loss: 2.39427e+01
I0514 20:43:09.312021 140128494741248 run_lib.py:152] step: 154600, training_loss: 3.43094e+01
I0514 20:43:09.364540 140128494741248 run_lib.py:165] step: 154600, eval_loss: 3.08243e+01
I0514 20:43:15.665014 140128494741248 run_lib.py:152] step: 154650, training_loss: 3.94176e+01
I0514 20:43:21.894686 140128494741248 run_lib.py:152] step: 154700, training_loss: 2.82460e+01
I0514 20:43:21.949638 140128494741248 run_lib.py:165] step: 154700, eval_loss: 3.09699e+01
I0514 20:43:28.376498 140128494741248 run_lib.py:152] step: 154750, training_loss: 4.34466e+01
I0514 20:43:34.621227 140128494741248 run_lib.py:152] step: 154800, training_loss: 3.21580e+01
I0514 20:43:34.668680 140128494741248 run_lib.py:165] step: 154800, eval_loss: 3.84163e+01
I0514 20:43:40.853084 140128494741248 run_lib.py:152] step: 154850, training_loss: 2.45861e+01
I0514 20:43:47.081522 140128494741248 run_lib.py:152] step: 154900, training_loss: 2.92820e+01
I0514 20:43:47.133525 140128494741248 run_lib.py:165] step: 154900, eval_loss: 3.11502e+01
I0514 20:43:53.517568 140128494741248 run_lib.py:152] step: 154950, training_loss: 2.70239e+01
I0514 20:43:59.659035 140128494741248 run_lib.py:152] step: 155000, training_loss: 2.08813e+01
I0514 20:43:59.718206 140128494741248 run_lib.py:165] step: 155000, eval_loss: 4.09617e+01
I0514 20:44:05.828859 140128494741248 run_lib.py:152] step: 155050, training_loss: 3.36153e+01
I0514 20:44:12.281818 140128494741248 run_lib.py:152] step: 155100, training_loss: 3.83930e+01
I0514 20:44:12.330721 140128494741248 run_lib.py:165] step: 155100, eval_loss: 3.38810e+01
I0514 20:44:18.583545 140128494741248 run_lib.py:152] step: 155150, training_loss: 3.18287e+01
I0514 20:44:24.902660 140128494741248 run_lib.py:152] step: 155200, training_loss: 3.21882e+01
I0514 20:44:24.957257 140128494741248 run_lib.py:165] step: 155200, eval_loss: 2.97659e+01
I0514 20:44:31.044555 140128494741248 run_lib.py:152] step: 155250, training_loss: 2.48204e+01
I0514 20:44:37.489377 140128494741248 run_lib.py:152] step: 155300, training_loss: 2.54521e+01
I0514 20:44:37.538770 140128494741248 run_lib.py:165] step: 155300, eval_loss: 2.57906e+01
I0514 20:44:43.670946 140128494741248 run_lib.py:152] step: 155350, training_loss: 2.93928e+01
I0514 20:44:49.923242 140128494741248 run_lib.py:152] step: 155400, training_loss: 4.39746e+01
I0514 20:44:49.974184 140128494741248 run_lib.py:165] step: 155400, eval_loss: 3.05931e+01
I0514 20:44:56.336262 140128494741248 run_lib.py:152] step: 155450, training_loss: 2.43466e+01
I0514 20:45:02.625503 140128494741248 run_lib.py:152] step: 155500, training_loss: 4.99101e+01
I0514 20:45:02.679445 140128494741248 run_lib.py:165] step: 155500, eval_loss: 1.91686e+01
I0514 20:45:08.877731 140128494741248 run_lib.py:152] step: 155550, training_loss: 2.30745e+01
I0514 20:45:15.031717 140128494741248 run_lib.py:152] step: 155600, training_loss: 2.85950e+01
I0514 20:45:15.079804 140128494741248 run_lib.py:165] step: 155600, eval_loss: 3.92814e+01
I0514 20:45:21.563277 140128494741248 run_lib.py:152] step: 155650, training_loss: 3.83373e+01
I0514 20:45:27.746311 140128494741248 run_lib.py:152] step: 155700, training_loss: 4.38774e+01
I0514 20:45:27.796587 140128494741248 run_lib.py:165] step: 155700, eval_loss: 2.57798e+01
I0514 20:45:34.072919 140128494741248 run_lib.py:152] step: 155750, training_loss: 3.95704e+01
I0514 20:45:40.448245 140128494741248 run_lib.py:152] step: 155800, training_loss: 3.00988e+01
I0514 20:45:40.497947 140128494741248 run_lib.py:165] step: 155800, eval_loss: 3.82103e+01
I0514 20:45:46.831677 140128494741248 run_lib.py:152] step: 155850, training_loss: 4.09118e+01
I0514 20:45:53.163985 140128494741248 run_lib.py:152] step: 155900, training_loss: 4.08286e+01
I0514 20:45:53.217169 140128494741248 run_lib.py:165] step: 155900, eval_loss: 3.45508e+01
I0514 20:45:59.447067 140128494741248 run_lib.py:152] step: 155950, training_loss: 3.15242e+01
I0514 20:46:05.840697 140128494741248 run_lib.py:152] step: 156000, training_loss: 2.86217e+01
I0514 20:46:05.891217 140128494741248 run_lib.py:165] step: 156000, eval_loss: 2.10579e+01
I0514 20:46:12.156355 140128494741248 run_lib.py:152] step: 156050, training_loss: 3.92075e+01
I0514 20:46:18.385972 140128494741248 run_lib.py:152] step: 156100, training_loss: 3.67474e+01
I0514 20:46:18.445423 140128494741248 run_lib.py:165] step: 156100, eval_loss: 3.73387e+01
I0514 20:46:24.926702 140128494741248 run_lib.py:152] step: 156150, training_loss: 1.49370e+01
I0514 20:46:31.161945 140128494741248 run_lib.py:152] step: 156200, training_loss: 3.17445e+01
I0514 20:46:31.211580 140128494741248 run_lib.py:165] step: 156200, eval_loss: 3.64325e+01
I0514 20:46:37.421289 140128494741248 run_lib.py:152] step: 156250, training_loss: 3.02407e+01
I0514 20:46:43.684677 140128494741248 run_lib.py:152] step: 156300, training_loss: 4.10673e+01
I0514 20:46:43.737344 140128494741248 run_lib.py:165] step: 156300, eval_loss: 2.32095e+01
I0514 20:46:50.131148 140128494741248 run_lib.py:152] step: 156350, training_loss: 3.71795e+01
I0514 20:46:56.370073 140128494741248 run_lib.py:152] step: 156400, training_loss: 3.11648e+01
I0514 20:46:56.426231 140128494741248 run_lib.py:165] step: 156400, eval_loss: 2.95226e+01
I0514 20:47:02.588314 140128494741248 run_lib.py:152] step: 156450, training_loss: 3.20343e+01
I0514 20:47:09.037815 140128494741248 run_lib.py:152] step: 156500, training_loss: 2.21902e+01
I0514 20:47:09.094132 140128494741248 run_lib.py:165] step: 156500, eval_loss: 2.18155e+01
I0514 20:47:15.317882 140128494741248 run_lib.py:152] step: 156550, training_loss: 2.00462e+01
I0514 20:47:21.620769 140128494741248 run_lib.py:152] step: 156600, training_loss: 3.81405e+01
I0514 20:47:21.674908 140128494741248 run_lib.py:165] step: 156600, eval_loss: 2.84589e+01
I0514 20:47:27.825830 140128494741248 run_lib.py:152] step: 156650, training_loss: 3.49075e+01
I0514 20:47:34.262353 140128494741248 run_lib.py:152] step: 156700, training_loss: 2.78202e+01
I0514 20:47:34.318316 140128494741248 run_lib.py:165] step: 156700, eval_loss: 2.59344e+01
I0514 20:47:40.501602 140128494741248 run_lib.py:152] step: 156750, training_loss: 3.07548e+01
I0514 20:47:46.691421 140128494741248 run_lib.py:152] step: 156800, training_loss: 5.07608e+01
I0514 20:47:46.739307 140128494741248 run_lib.py:165] step: 156800, eval_loss: 3.06804e+01
I0514 20:47:53.128059 140128494741248 run_lib.py:152] step: 156850, training_loss: 3.35105e+01
I0514 20:47:59.375201 140128494741248 run_lib.py:152] step: 156900, training_loss: 2.97383e+01
I0514 20:47:59.427432 140128494741248 run_lib.py:165] step: 156900, eval_loss: 3.61951e+01
I0514 20:48:05.592375 140128494741248 run_lib.py:152] step: 156950, training_loss: 3.88452e+01
I0514 20:48:11.745213 140128494741248 run_lib.py:152] step: 157000, training_loss: 2.92985e+01
I0514 20:48:11.791489 140128494741248 run_lib.py:165] step: 157000, eval_loss: 1.86147e+01
I0514 20:48:18.325136 140128494741248 run_lib.py:152] step: 157050, training_loss: 4.00917e+01
I0514 20:48:24.462303 140128494741248 run_lib.py:152] step: 157100, training_loss: 4.36610e+01
I0514 20:48:24.517321 140128494741248 run_lib.py:165] step: 157100, eval_loss: 4.49940e+01
I0514 20:48:30.706395 140128494741248 run_lib.py:152] step: 157150, training_loss: 3.30187e+01
I0514 20:48:37.191097 140128494741248 run_lib.py:152] step: 157200, training_loss: 2.04914e+01
I0514 20:48:37.243772 140128494741248 run_lib.py:165] step: 157200, eval_loss: 2.13483e+01
I0514 20:48:43.501604 140128494741248 run_lib.py:152] step: 157250, training_loss: 3.45896e+01
I0514 20:48:49.734604 140128494741248 run_lib.py:152] step: 157300, training_loss: 2.82617e+01
I0514 20:48:49.788163 140128494741248 run_lib.py:165] step: 157300, eval_loss: 2.99782e+01
I0514 20:48:56.028698 140128494741248 run_lib.py:152] step: 157350, training_loss: 3.87598e+01
I0514 20:49:02.494302 140128494741248 run_lib.py:152] step: 157400, training_loss: 2.95903e+01
I0514 20:49:02.544113 140128494741248 run_lib.py:165] step: 157400, eval_loss: 2.24572e+01
I0514 20:49:08.683344 140128494741248 run_lib.py:152] step: 157450, training_loss: 3.88302e+01
I0514 20:49:14.973036 140128494741248 run_lib.py:152] step: 157500, training_loss: 4.93929e+01
I0514 20:49:15.022535 140128494741248 run_lib.py:165] step: 157500, eval_loss: 2.66936e+01
I0514 20:49:21.411595 140128494741248 run_lib.py:152] step: 157550, training_loss: 3.82818e+01
I0514 20:49:27.673096 140128494741248 run_lib.py:152] step: 157600, training_loss: 3.87988e+01
I0514 20:49:27.722908 140128494741248 run_lib.py:165] step: 157600, eval_loss: 1.63810e+01
I0514 20:49:33.963225 140128494741248 run_lib.py:152] step: 157650, training_loss: 2.38428e+01
I0514 20:49:40.192321 140128494741248 run_lib.py:152] step: 157700, training_loss: 2.28283e+01
I0514 20:49:40.240564 140128494741248 run_lib.py:165] step: 157700, eval_loss: 1.42941e+01
I0514 20:49:46.673001 140128494741248 run_lib.py:152] step: 157750, training_loss: 2.99654e+01
I0514 20:49:52.902090 140128494741248 run_lib.py:152] step: 157800, training_loss: 2.17582e+01
I0514 20:49:52.958926 140128494741248 run_lib.py:165] step: 157800, eval_loss: 3.44229e+01
I0514 20:49:59.240558 140128494741248 run_lib.py:152] step: 157850, training_loss: 4.30563e+01
I0514 20:50:05.799494 140128494741248 run_lib.py:152] step: 157900, training_loss: 2.68742e+01
I0514 20:50:05.851893 140128494741248 run_lib.py:165] step: 157900, eval_loss: 2.54472e+01
I0514 20:50:12.022046 140128494741248 run_lib.py:152] step: 157950, training_loss: 3.33804e+01
I0514 20:50:18.282546 140128494741248 run_lib.py:152] step: 158000, training_loss: 2.65432e+01
I0514 20:50:18.332381 140128494741248 run_lib.py:165] step: 158000, eval_loss: 2.95320e+01
I0514 20:50:24.602020 140128494741248 run_lib.py:152] step: 158050, training_loss: 2.68054e+01
I0514 20:50:31.068260 140128494741248 run_lib.py:152] step: 158100, training_loss: 2.53123e+01
I0514 20:50:31.118432 140128494741248 run_lib.py:165] step: 158100, eval_loss: 2.06483e+01
I0514 20:50:37.420854 140128494741248 run_lib.py:152] step: 158150, training_loss: 5.08571e+01
I0514 20:50:43.646604 140128494741248 run_lib.py:152] step: 158200, training_loss: 2.66260e+01
I0514 20:50:43.701328 140128494741248 run_lib.py:165] step: 158200, eval_loss: 2.25839e+01
I0514 20:50:50.168370 140128494741248 run_lib.py:152] step: 158250, training_loss: 2.93271e+01
I0514 20:50:56.469050 140128494741248 run_lib.py:152] step: 158300, training_loss: 2.15853e+01
I0514 20:50:56.520622 140128494741248 run_lib.py:165] step: 158300, eval_loss: 3.24075e+01
I0514 20:51:02.712851 140128494741248 run_lib.py:152] step: 158350, training_loss: 2.28455e+01
I0514 20:51:08.910216 140128494741248 run_lib.py:152] step: 158400, training_loss: 2.84394e+01
I0514 20:51:08.962315 140128494741248 run_lib.py:165] step: 158400, eval_loss: 3.94258e+01
I0514 20:51:15.393119 140128494741248 run_lib.py:152] step: 158450, training_loss: 3.59086e+01
I0514 20:51:21.603721 140128494741248 run_lib.py:152] step: 158500, training_loss: 3.79169e+01
I0514 20:51:21.659244 140128494741248 run_lib.py:165] step: 158500, eval_loss: 3.08298e+01
I0514 20:51:27.819346 140128494741248 run_lib.py:152] step: 158550, training_loss: 3.59532e+01
I0514 20:51:34.219171 140128494741248 run_lib.py:152] step: 158600, training_loss: 2.14562e+01
I0514 20:51:34.269984 140128494741248 run_lib.py:165] step: 158600, eval_loss: 3.03468e+01
I0514 20:51:40.467385 140128494741248 run_lib.py:152] step: 158650, training_loss: 3.06328e+01
I0514 20:51:46.722254 140128494741248 run_lib.py:152] step: 158700, training_loss: 3.11402e+01
I0514 20:51:46.773543 140128494741248 run_lib.py:165] step: 158700, eval_loss: 2.80382e+01
I0514 20:51:53.013313 140128494741248 run_lib.py:152] step: 158750, training_loss: 3.54089e+01
I0514 20:51:59.526769 140128494741248 run_lib.py:152] step: 158800, training_loss: 1.67041e+01
I0514 20:51:59.581012 140128494741248 run_lib.py:165] step: 158800, eval_loss: 2.36161e+01
I0514 20:52:05.805596 140128494741248 run_lib.py:152] step: 158850, training_loss: 2.30831e+01
I0514 20:52:12.060995 140128494741248 run_lib.py:152] step: 158900, training_loss: 2.39113e+01
I0514 20:52:12.110399 140128494741248 run_lib.py:165] step: 158900, eval_loss: 2.59531e+01
I0514 20:52:18.659888 140128494741248 run_lib.py:152] step: 158950, training_loss: 2.61144e+01
I0514 20:52:24.774804 140128494741248 run_lib.py:152] step: 159000, training_loss: 2.61434e+01
I0514 20:52:24.825857 140128494741248 run_lib.py:165] step: 159000, eval_loss: 2.36113e+01
I0514 20:52:31.095142 140128494741248 run_lib.py:152] step: 159050, training_loss: 3.81181e+01
I0514 20:52:37.305870 140128494741248 run_lib.py:152] step: 159100, training_loss: 3.27561e+01
I0514 20:52:37.364714 140128494741248 run_lib.py:165] step: 159100, eval_loss: 1.80048e+01
I0514 20:52:43.821010 140128494741248 run_lib.py:152] step: 159150, training_loss: 3.12892e+01
I0514 20:52:50.046629 140128494741248 run_lib.py:152] step: 159200, training_loss: 2.96847e+01
I0514 20:52:50.098298 140128494741248 run_lib.py:165] step: 159200, eval_loss: 3.15278e+01
I0514 20:52:56.400507 140128494741248 run_lib.py:152] step: 159250, training_loss: 3.23701e+01
I0514 20:53:02.806064 140128494741248 run_lib.py:152] step: 159300, training_loss: 2.66044e+01
I0514 20:53:02.857710 140128494741248 run_lib.py:165] step: 159300, eval_loss: 2.32252e+01
I0514 20:53:09.085000 140128494741248 run_lib.py:152] step: 159350, training_loss: 1.85936e+01
I0514 20:53:15.295709 140128494741248 run_lib.py:152] step: 159400, training_loss: 3.33670e+01
I0514 20:53:15.346588 140128494741248 run_lib.py:165] step: 159400, eval_loss: 2.40647e+01
I0514 20:53:21.589982 140128494741248 run_lib.py:152] step: 159450, training_loss: 3.28022e+01
I0514 20:53:27.995154 140128494741248 run_lib.py:152] step: 159500, training_loss: 2.80697e+01
I0514 20:53:28.048434 140128494741248 run_lib.py:165] step: 159500, eval_loss: 2.63905e+01
I0514 20:53:34.275286 140128494741248 run_lib.py:152] step: 159550, training_loss: 2.70962e+01
I0514 20:53:40.538784 140128494741248 run_lib.py:152] step: 159600, training_loss: 4.40449e+01
I0514 20:53:40.590250 140128494741248 run_lib.py:165] step: 159600, eval_loss: 3.80544e+01
I0514 20:53:47.054178 140128494741248 run_lib.py:152] step: 159650, training_loss: 2.88416e+01
I0514 20:53:53.253652 140128494741248 run_lib.py:152] step: 159700, training_loss: 2.26268e+01
I0514 20:53:53.302800 140128494741248 run_lib.py:165] step: 159700, eval_loss: 3.15032e+01
I0514 20:53:59.546555 140128494741248 run_lib.py:152] step: 159750, training_loss: 3.57983e+01
I0514 20:54:05.759478 140128494741248 run_lib.py:152] step: 159800, training_loss: 3.65742e+01
I0514 20:54:05.812014 140128494741248 run_lib.py:165] step: 159800, eval_loss: 3.45781e+01
I0514 20:54:12.260208 140128494741248 run_lib.py:152] step: 159850, training_loss: 3.21175e+01
I0514 20:54:18.522941 140128494741248 run_lib.py:152] step: 159900, training_loss: 1.92825e+01
I0514 20:54:18.574892 140128494741248 run_lib.py:165] step: 159900, eval_loss: 4.21647e+01
I0514 20:54:24.746588 140128494741248 run_lib.py:152] step: 159950, training_loss: 3.07049e+01
I0514 20:54:31.238286 140128494741248 run_lib.py:152] step: 160000, training_loss: 2.75476e+01
I0514 20:54:31.447505 140128494741248 run_lib.py:165] step: 160000, eval_loss: 2.59019e+01
I0514 20:54:37.640462 140128494741248 run_lib.py:152] step: 160050, training_loss: 3.80407e+01
I0514 20:54:43.907647 140128494741248 run_lib.py:152] step: 160100, training_loss: 4.76343e+01
I0514 20:54:43.964544 140128494741248 run_lib.py:165] step: 160100, eval_loss: 3.96217e+01
I0514 20:54:50.181345 140128494741248 run_lib.py:152] step: 160150, training_loss: 4.87432e+01
I0514 20:54:56.540076 140128494741248 run_lib.py:152] step: 160200, training_loss: 4.30596e+01
I0514 20:54:56.591844 140128494741248 run_lib.py:165] step: 160200, eval_loss: 3.75173e+01
I0514 20:55:02.838032 140128494741248 run_lib.py:152] step: 160250, training_loss: 2.41409e+01
I0514 20:55:09.022486 140128494741248 run_lib.py:152] step: 160300, training_loss: 3.83452e+01
I0514 20:55:09.073153 140128494741248 run_lib.py:165] step: 160300, eval_loss: 3.39425e+01
I0514 20:55:15.565742 140128494741248 run_lib.py:152] step: 160350, training_loss: 5.37077e+01
I0514 20:55:21.750185 140128494741248 run_lib.py:152] step: 160400, training_loss: 4.35918e+01
I0514 20:55:21.801717 140128494741248 run_lib.py:165] step: 160400, eval_loss: 1.85675e+01
I0514 20:55:28.001563 140128494741248 run_lib.py:152] step: 160450, training_loss: 3.39966e+01
I0514 20:55:34.245872 140128494741248 run_lib.py:152] step: 160500, training_loss: 2.93732e+01
I0514 20:55:34.303085 140128494741248 run_lib.py:165] step: 160500, eval_loss: 2.67623e+01
I0514 20:55:40.720245 140128494741248 run_lib.py:152] step: 160550, training_loss: 1.81688e+01
I0514 20:55:46.867571 140128494741248 run_lib.py:152] step: 160600, training_loss: 2.81478e+01
I0514 20:55:46.921045 140128494741248 run_lib.py:165] step: 160600, eval_loss: 1.84335e+01
I0514 20:55:53.126417 140128494741248 run_lib.py:152] step: 160650, training_loss: 4.43292e+01
I0514 20:55:59.555547 140128494741248 run_lib.py:152] step: 160700, training_loss: 4.18746e+01
I0514 20:55:59.607305 140128494741248 run_lib.py:165] step: 160700, eval_loss: 1.91628e+01
I0514 20:56:05.845031 140128494741248 run_lib.py:152] step: 160750, training_loss: 3.16732e+01
I0514 20:56:12.073740 140128494741248 run_lib.py:152] step: 160800, training_loss: 4.54463e+01
I0514 20:56:12.122285 140128494741248 run_lib.py:165] step: 160800, eval_loss: 3.77010e+01
I0514 20:56:18.424273 140128494741248 run_lib.py:152] step: 160850, training_loss: 1.85433e+01
I0514 20:56:24.852232 140128494741248 run_lib.py:152] step: 160900, training_loss: 4.08904e+01
I0514 20:56:24.902601 140128494741248 run_lib.py:165] step: 160900, eval_loss: 4.02166e+01
I0514 20:56:31.092123 140128494741248 run_lib.py:152] step: 160950, training_loss: 2.58796e+01
I0514 20:56:37.353597 140128494741248 run_lib.py:152] step: 161000, training_loss: 3.11780e+01
I0514 20:56:37.407093 140128494741248 run_lib.py:165] step: 161000, eval_loss: 2.86300e+01
I0514 20:56:43.768426 140128494741248 run_lib.py:152] step: 161050, training_loss: 3.21464e+01
I0514 20:56:49.985789 140128494741248 run_lib.py:152] step: 161100, training_loss: 4.24731e+01
I0514 20:56:50.038174 140128494741248 run_lib.py:165] step: 161100, eval_loss: 2.98239e+01
I0514 20:56:56.267324 140128494741248 run_lib.py:152] step: 161150, training_loss: 2.64260e+01
I0514 20:57:02.396888 140128494741248 run_lib.py:152] step: 161200, training_loss: 3.47859e+01
I0514 20:57:02.450152 140128494741248 run_lib.py:165] step: 161200, eval_loss: 3.48484e+01
I0514 20:57:08.927292 140128494741248 run_lib.py:152] step: 161250, training_loss: 4.56193e+01
I0514 20:57:15.235320 140128494741248 run_lib.py:152] step: 161300, training_loss: 3.17132e+01
I0514 20:57:15.285511 140128494741248 run_lib.py:165] step: 161300, eval_loss: 2.83823e+01
I0514 20:57:21.531244 140128494741248 run_lib.py:152] step: 161350, training_loss: 3.07403e+01
I0514 20:57:27.973038 140128494741248 run_lib.py:152] step: 161400, training_loss: 5.05690e+01
I0514 20:57:28.027344 140128494741248 run_lib.py:165] step: 161400, eval_loss: 2.95428e+01
I0514 20:57:34.244085 140128494741248 run_lib.py:152] step: 161450, training_loss: 3.22937e+01
I0514 20:57:40.467590 140128494741248 run_lib.py:152] step: 161500, training_loss: 3.00142e+01
I0514 20:57:40.519182 140128494741248 run_lib.py:165] step: 161500, eval_loss: 1.90758e+01
I0514 20:57:46.865639 140128494741248 run_lib.py:152] step: 161550, training_loss: 3.69085e+01
I0514 20:57:53.285908 140128494741248 run_lib.py:152] step: 161600, training_loss: 3.54307e+01
I0514 20:57:53.334218 140128494741248 run_lib.py:165] step: 161600, eval_loss: 2.84136e+01
I0514 20:57:59.583660 140128494741248 run_lib.py:152] step: 161650, training_loss: 4.76587e+01
I0514 20:58:05.760899 140128494741248 run_lib.py:152] step: 161700, training_loss: 4.18376e+01
I0514 20:58:05.813303 140128494741248 run_lib.py:165] step: 161700, eval_loss: 2.92987e+01
I0514 20:58:12.182173 140128494741248 run_lib.py:152] step: 161750, training_loss: 2.38994e+01
I0514 20:58:18.393796 140128494741248 run_lib.py:152] step: 161800, training_loss: 1.70795e+01
I0514 20:58:18.444592 140128494741248 run_lib.py:165] step: 161800, eval_loss: 5.84142e+01
I0514 20:58:24.697986 140128494741248 run_lib.py:152] step: 161850, training_loss: 2.25396e+01
I0514 20:58:30.931020 140128494741248 run_lib.py:152] step: 161900, training_loss: 2.18133e+01
I0514 20:58:30.981843 140128494741248 run_lib.py:165] step: 161900, eval_loss: 3.48579e+01
I0514 20:58:37.456357 140128494741248 run_lib.py:152] step: 161950, training_loss: 3.23943e+01
I0514 20:58:43.642056 140128494741248 run_lib.py:152] step: 162000, training_loss: 3.62087e+01
I0514 20:58:43.695854 140128494741248 run_lib.py:165] step: 162000, eval_loss: 2.30172e+01
I0514 20:58:49.833845 140128494741248 run_lib.py:152] step: 162050, training_loss: 2.98847e+01
I0514 20:58:56.293339 140128494741248 run_lib.py:152] step: 162100, training_loss: 3.42622e+01
I0514 20:58:56.346676 140128494741248 run_lib.py:165] step: 162100, eval_loss: 3.37358e+01
I0514 20:59:02.458287 140128494741248 run_lib.py:152] step: 162150, training_loss: 3.60104e+01
I0514 20:59:08.724870 140128494741248 run_lib.py:152] step: 162200, training_loss: 4.10327e+01
I0514 20:59:08.776122 140128494741248 run_lib.py:165] step: 162200, eval_loss: 3.67996e+01
I0514 20:59:15.002611 140128494741248 run_lib.py:152] step: 162250, training_loss: 3.35883e+01
I0514 20:59:21.536849 140128494741248 run_lib.py:152] step: 162300, training_loss: 3.39881e+01
I0514 20:59:21.594044 140128494741248 run_lib.py:165] step: 162300, eval_loss: 3.07477e+01
I0514 20:59:27.942456 140128494741248 run_lib.py:152] step: 162350, training_loss: 3.35869e+01
I0514 20:59:34.099221 140128494741248 run_lib.py:152] step: 162400, training_loss: 3.30535e+01
I0514 20:59:34.155040 140128494741248 run_lib.py:165] step: 162400, eval_loss: 2.62629e+01
I0514 20:59:40.653390 140128494741248 run_lib.py:152] step: 162450, training_loss: 4.54523e+01
I0514 20:59:46.886778 140128494741248 run_lib.py:152] step: 162500, training_loss: 3.38627e+01
I0514 20:59:46.939707 140128494741248 run_lib.py:165] step: 162500, eval_loss: 2.90292e+01
I0514 20:59:53.144676 140128494741248 run_lib.py:152] step: 162550, training_loss: 2.04034e+01
I0514 20:59:59.435693 140128494741248 run_lib.py:152] step: 162600, training_loss: 4.15495e+01
I0514 20:59:59.485451 140128494741248 run_lib.py:165] step: 162600, eval_loss: 2.88814e+01
I0514 21:00:05.849924 140128494741248 run_lib.py:152] step: 162650, training_loss: 1.87096e+01
I0514 21:00:11.982494 140128494741248 run_lib.py:152] step: 162700, training_loss: 2.74716e+01
I0514 21:00:12.031801 140128494741248 run_lib.py:165] step: 162700, eval_loss: 3.75251e+01
I0514 21:00:18.181673 140128494741248 run_lib.py:152] step: 162750, training_loss: 5.01048e+01
I0514 21:00:24.571227 140128494741248 run_lib.py:152] step: 162800, training_loss: 3.61760e+01
I0514 21:00:24.621894 140128494741248 run_lib.py:165] step: 162800, eval_loss: 3.48330e+01
I0514 21:00:30.841629 140128494741248 run_lib.py:152] step: 162850, training_loss: 2.74365e+01
I0514 21:00:36.981663 140128494741248 run_lib.py:152] step: 162900, training_loss: 3.66666e+01
I0514 21:00:37.032152 140128494741248 run_lib.py:165] step: 162900, eval_loss: 3.95930e+01
I0514 21:00:43.192485 140128494741248 run_lib.py:152] step: 162950, training_loss: 2.53772e+01
I0514 21:00:49.518962 140128494741248 run_lib.py:152] step: 163000, training_loss: 3.32554e+01
I0514 21:00:49.575873 140128494741248 run_lib.py:165] step: 163000, eval_loss: 3.36499e+01
I0514 21:00:55.782422 140128494741248 run_lib.py:152] step: 163050, training_loss: 3.33128e+01
I0514 21:01:01.928375 140128494741248 run_lib.py:152] step: 163100, training_loss: 3.86786e+01
I0514 21:01:01.983281 140128494741248 run_lib.py:165] step: 163100, eval_loss: 3.93876e+01
I0514 21:01:08.424398 140128494741248 run_lib.py:152] step: 163150, training_loss: 2.86666e+01
I0514 21:01:14.632084 140128494741248 run_lib.py:152] step: 163200, training_loss: 4.77608e+01
I0514 21:01:14.680882 140128494741248 run_lib.py:165] step: 163200, eval_loss: 3.72401e+01
I0514 21:01:20.816713 140128494741248 run_lib.py:152] step: 163250, training_loss: 3.52138e+01
I0514 21:01:26.965804 140128494741248 run_lib.py:152] step: 163300, training_loss: 3.86379e+01
I0514 21:01:27.020566 140128494741248 run_lib.py:165] step: 163300, eval_loss: 2.57328e+01
I0514 21:01:33.369615 140128494741248 run_lib.py:152] step: 163350, training_loss: 4.00414e+01
I0514 21:01:39.665413 140128494741248 run_lib.py:152] step: 163400, training_loss: 2.70391e+01
I0514 21:01:39.724323 140128494741248 run_lib.py:165] step: 163400, eval_loss: 3.61235e+01
I0514 21:01:45.939069 140128494741248 run_lib.py:152] step: 163450, training_loss: 4.22633e+01
I0514 21:01:52.291576 140128494741248 run_lib.py:152] step: 163500, training_loss: 3.30278e+01
I0514 21:01:52.343586 140128494741248 run_lib.py:165] step: 163500, eval_loss: 5.00133e+01
I0514 21:01:58.574219 140128494741248 run_lib.py:152] step: 163550, training_loss: 3.15702e+01
I0514 21:02:04.666738 140128494741248 run_lib.py:152] step: 163600, training_loss: 2.67250e+01
I0514 21:02:04.724121 140128494741248 run_lib.py:165] step: 163600, eval_loss: 2.98627e+01
I0514 21:02:10.975927 140128494741248 run_lib.py:152] step: 163650, training_loss: 3.60698e+01
I0514 21:02:17.435087 140128494741248 run_lib.py:152] step: 163700, training_loss: 3.71463e+01
I0514 21:02:17.487326 140128494741248 run_lib.py:165] step: 163700, eval_loss: 3.50129e+01
I0514 21:02:23.655446 140128494741248 run_lib.py:152] step: 163750, training_loss: 3.74132e+01
I0514 21:02:29.913297 140128494741248 run_lib.py:152] step: 163800, training_loss: 1.94327e+01
I0514 21:02:29.966106 140128494741248 run_lib.py:165] step: 163800, eval_loss: 4.19657e+01
I0514 21:02:36.442684 140128494741248 run_lib.py:152] step: 163850, training_loss: 2.93653e+01
I0514 21:02:42.766367 140128494741248 run_lib.py:152] step: 163900, training_loss: 1.64638e+01
I0514 21:02:42.816866 140128494741248 run_lib.py:165] step: 163900, eval_loss: 1.84406e+01
I0514 21:02:48.911624 140128494741248 run_lib.py:152] step: 163950, training_loss: 2.39230e+01
I0514 21:02:55.212238 140128494741248 run_lib.py:152] step: 164000, training_loss: 3.51283e+01
I0514 21:02:55.275473 140128494741248 run_lib.py:165] step: 164000, eval_loss: 3.34312e+01
I0514 21:03:01.698290 140128494741248 run_lib.py:152] step: 164050, training_loss: 3.93700e+01
I0514 21:03:07.822206 140128494741248 run_lib.py:152] step: 164100, training_loss: 4.27990e+01
I0514 21:03:07.869615 140128494741248 run_lib.py:165] step: 164100, eval_loss: 3.03698e+01
I0514 21:03:14.030576 140128494741248 run_lib.py:152] step: 164150, training_loss: 2.57918e+01
I0514 21:03:20.426028 140128494741248 run_lib.py:152] step: 164200, training_loss: 2.39828e+01
I0514 21:03:20.480241 140128494741248 run_lib.py:165] step: 164200, eval_loss: 4.89903e+01
I0514 21:03:26.549991 140128494741248 run_lib.py:152] step: 164250, training_loss: 3.39705e+01
I0514 21:03:32.763687 140128494741248 run_lib.py:152] step: 164300, training_loss: 3.19560e+01
I0514 21:03:32.819627 140128494741248 run_lib.py:165] step: 164300, eval_loss: 4.29697e+01
I0514 21:03:39.006450 140128494741248 run_lib.py:152] step: 164350, training_loss: 2.73306e+01
I0514 21:03:45.376371 140128494741248 run_lib.py:152] step: 164400, training_loss: 3.42271e+01
I0514 21:03:45.432674 140128494741248 run_lib.py:165] step: 164400, eval_loss: 3.63466e+01
I0514 21:03:51.514633 140128494741248 run_lib.py:152] step: 164450, training_loss: 3.38640e+01
I0514 21:03:57.729140 140128494741248 run_lib.py:152] step: 164500, training_loss: 3.92907e+01
I0514 21:03:57.781541 140128494741248 run_lib.py:165] step: 164500, eval_loss: 4.18991e+01
I0514 21:04:04.130829 140128494741248 run_lib.py:152] step: 164550, training_loss: 3.01285e+01
I0514 21:04:10.294068 140128494741248 run_lib.py:152] step: 164600, training_loss: 2.44166e+01
I0514 21:04:10.343917 140128494741248 run_lib.py:165] step: 164600, eval_loss: 4.81165e+01
I0514 21:04:16.597006 140128494741248 run_lib.py:152] step: 164650, training_loss: 3.77214e+01
I0514 21:04:22.708798 140128494741248 run_lib.py:152] step: 164700, training_loss: 4.16743e+01
I0514 21:04:22.759813 140128494741248 run_lib.py:165] step: 164700, eval_loss: 3.89249e+01
I0514 21:04:29.251456 140128494741248 run_lib.py:152] step: 164750, training_loss: 4.00673e+01
I0514 21:04:35.390546 140128494741248 run_lib.py:152] step: 164800, training_loss: 3.42337e+01
I0514 21:04:35.439398 140128494741248 run_lib.py:165] step: 164800, eval_loss: 2.95046e+01
I0514 21:04:41.598897 140128494741248 run_lib.py:152] step: 164850, training_loss: 2.61109e+01
I0514 21:04:48.093569 140128494741248 run_lib.py:152] step: 164900, training_loss: 3.18689e+01
I0514 21:04:48.141278 140128494741248 run_lib.py:165] step: 164900, eval_loss: 5.38662e+01
I0514 21:04:54.272346 140128494741248 run_lib.py:152] step: 164950, training_loss: 4.67672e+01
I0514 21:05:00.476284 140128494741248 run_lib.py:152] step: 165000, training_loss: 2.69773e+01
I0514 21:05:00.527298 140128494741248 run_lib.py:165] step: 165000, eval_loss: 4.05859e+01
I0514 21:05:06.641724 140128494741248 run_lib.py:152] step: 165050, training_loss: 3.56693e+01
I0514 21:05:13.138288 140128494741248 run_lib.py:152] step: 165100, training_loss: 4.15502e+01
I0514 21:05:13.194680 140128494741248 run_lib.py:165] step: 165100, eval_loss: 3.93249e+01
I0514 21:05:19.465444 140128494741248 run_lib.py:152] step: 165150, training_loss: 4.20645e+01
I0514 21:05:25.641973 140128494741248 run_lib.py:152] step: 165200, training_loss: 3.16423e+01
I0514 21:05:25.691871 140128494741248 run_lib.py:165] step: 165200, eval_loss: 2.76931e+01
I0514 21:05:32.085670 140128494741248 run_lib.py:152] step: 165250, training_loss: 4.09265e+01
I0514 21:05:38.296708 140128494741248 run_lib.py:152] step: 165300, training_loss: 2.97166e+01
I0514 21:05:38.353930 140128494741248 run_lib.py:165] step: 165300, eval_loss: 4.79388e+01
I0514 21:05:44.570803 140128494741248 run_lib.py:152] step: 165350, training_loss: 2.72946e+01
I0514 21:05:50.676719 140128494741248 run_lib.py:152] step: 165400, training_loss: 1.84683e+01
I0514 21:05:50.727404 140128494741248 run_lib.py:165] step: 165400, eval_loss: 4.83718e+01
I0514 21:05:57.113200 140128494741248 run_lib.py:152] step: 165450, training_loss: 1.87051e+01
I0514 21:06:03.302187 140128494741248 run_lib.py:152] step: 165500, training_loss: 2.71547e+01
I0514 21:06:03.354979 140128494741248 run_lib.py:165] step: 165500, eval_loss: 3.00431e+01
I0514 21:06:09.509263 140128494741248 run_lib.py:152] step: 165550, training_loss: 3.29551e+01
I0514 21:06:15.892561 140128494741248 run_lib.py:152] step: 165600, training_loss: 3.14317e+01
I0514 21:06:15.942122 140128494741248 run_lib.py:165] step: 165600, eval_loss: 2.23280e+01
I0514 21:06:22.198354 140128494741248 run_lib.py:152] step: 165650, training_loss: 2.27976e+01
I0514 21:06:28.337124 140128494741248 run_lib.py:152] step: 165700, training_loss: 2.05584e+01
I0514 21:06:28.388375 140128494741248 run_lib.py:165] step: 165700, eval_loss: 3.00303e+01
I0514 21:06:34.526062 140128494741248 run_lib.py:152] step: 165750, training_loss: 3.18675e+01
I0514 21:06:40.917309 140128494741248 run_lib.py:152] step: 165800, training_loss: 4.70579e+01
I0514 21:06:40.970330 140128494741248 run_lib.py:165] step: 165800, eval_loss: 3.56968e+01
I0514 21:06:47.155438 140128494741248 run_lib.py:152] step: 165850, training_loss: 2.57466e+01
I0514 21:06:53.477330 140128494741248 run_lib.py:152] step: 165900, training_loss: 2.76071e+01
I0514 21:06:53.529708 140128494741248 run_lib.py:165] step: 165900, eval_loss: 3.49528e+01
I0514 21:06:59.951350 140128494741248 run_lib.py:152] step: 165950, training_loss: 4.50845e+01
I0514 21:07:06.092590 140128494741248 run_lib.py:152] step: 166000, training_loss: 2.88176e+01
I0514 21:07:06.143340 140128494741248 run_lib.py:165] step: 166000, eval_loss: 3.45921e+01
I0514 21:07:12.419507 140128494741248 run_lib.py:152] step: 166050, training_loss: 3.70300e+01
I0514 21:07:18.752578 140128494741248 run_lib.py:152] step: 166100, training_loss: 3.62370e+01
I0514 21:07:18.807732 140128494741248 run_lib.py:165] step: 166100, eval_loss: 3.94287e+01
I0514 21:07:25.203402 140128494741248 run_lib.py:152] step: 166150, training_loss: 2.31867e+01
I0514 21:07:31.399640 140128494741248 run_lib.py:152] step: 166200, training_loss: 2.78646e+01
I0514 21:07:31.449235 140128494741248 run_lib.py:165] step: 166200, eval_loss: 3.12285e+01
I0514 21:07:37.748020 140128494741248 run_lib.py:152] step: 166250, training_loss: 3.34082e+01
I0514 21:07:44.172134 140128494741248 run_lib.py:152] step: 166300, training_loss: 2.59972e+01
I0514 21:07:44.221620 140128494741248 run_lib.py:165] step: 166300, eval_loss: 3.62011e+01
I0514 21:07:50.404844 140128494741248 run_lib.py:152] step: 166350, training_loss: 3.03307e+01
I0514 21:07:56.583843 140128494741248 run_lib.py:152] step: 166400, training_loss: 3.51710e+01
I0514 21:07:56.637549 140128494741248 run_lib.py:165] step: 166400, eval_loss: 3.35430e+01
I0514 21:08:02.803565 140128494741248 run_lib.py:152] step: 166450, training_loss: 2.34196e+01
I0514 21:08:09.256515 140128494741248 run_lib.py:152] step: 166500, training_loss: 3.72672e+01
I0514 21:08:09.303775 140128494741248 run_lib.py:165] step: 166500, eval_loss: 3.21473e+01
I0514 21:08:15.502463 140128494741248 run_lib.py:152] step: 166550, training_loss: 2.95941e+01
I0514 21:08:21.604458 140128494741248 run_lib.py:152] step: 166600, training_loss: 2.76535e+01
I0514 21:08:21.656141 140128494741248 run_lib.py:165] step: 166600, eval_loss: 3.84093e+01
I0514 21:08:28.093289 140128494741248 run_lib.py:152] step: 166650, training_loss: 4.27592e+01
I0514 21:08:34.374736 140128494741248 run_lib.py:152] step: 166700, training_loss: 3.52963e+01
I0514 21:08:34.425356 140128494741248 run_lib.py:165] step: 166700, eval_loss: 2.65797e+01
I0514 21:08:40.601567 140128494741248 run_lib.py:152] step: 166750, training_loss: 5.10500e+01
I0514 21:08:46.806268 140128494741248 run_lib.py:152] step: 166800, training_loss: 3.91832e+01
I0514 21:08:46.863478 140128494741248 run_lib.py:165] step: 166800, eval_loss: 2.05565e+01
I0514 21:08:53.313237 140128494741248 run_lib.py:152] step: 166850, training_loss: 3.52841e+01
I0514 21:08:59.541134 140128494741248 run_lib.py:152] step: 166900, training_loss: 2.97623e+01
I0514 21:08:59.601159 140128494741248 run_lib.py:165] step: 166900, eval_loss: 3.73019e+01
I0514 21:09:05.750794 140128494741248 run_lib.py:152] step: 166950, training_loss: 4.59542e+01
I0514 21:09:12.243066 140128494741248 run_lib.py:152] step: 167000, training_loss: 2.91407e+01
I0514 21:09:12.298590 140128494741248 run_lib.py:165] step: 167000, eval_loss: 4.23539e+01
I0514 21:09:18.434933 140128494741248 run_lib.py:152] step: 167050, training_loss: 3.04457e+01
I0514 21:09:24.690058 140128494741248 run_lib.py:152] step: 167100, training_loss: 2.91852e+01
I0514 21:09:24.741700 140128494741248 run_lib.py:165] step: 167100, eval_loss: 2.76841e+01
I0514 21:09:30.926819 140128494741248 run_lib.py:152] step: 167150, training_loss: 3.18946e+01
I0514 21:09:37.401771 140128494741248 run_lib.py:152] step: 167200, training_loss: 2.91949e+01
I0514 21:09:37.456550 140128494741248 run_lib.py:165] step: 167200, eval_loss: 5.34269e+01
I0514 21:09:43.563758 140128494741248 run_lib.py:152] step: 167250, training_loss: 3.42175e+01
I0514 21:09:49.766877 140128494741248 run_lib.py:152] step: 167300, training_loss: 2.95177e+01
I0514 21:09:49.817660 140128494741248 run_lib.py:165] step: 167300, eval_loss: 2.83913e+01
I0514 21:09:56.307973 140128494741248 run_lib.py:152] step: 167350, training_loss: 3.30660e+01
I0514 21:10:02.453597 140128494741248 run_lib.py:152] step: 167400, training_loss: 4.59635e+01
I0514 21:10:02.505705 140128494741248 run_lib.py:165] step: 167400, eval_loss: 3.81444e+01
I0514 21:10:08.734613 140128494741248 run_lib.py:152] step: 167450, training_loss: 2.24955e+01
I0514 21:10:15.035670 140128494741248 run_lib.py:152] step: 167500, training_loss: 4.86331e+01
I0514 21:10:15.091166 140128494741248 run_lib.py:165] step: 167500, eval_loss: 4.35707e+01
I0514 21:10:21.503609 140128494741248 run_lib.py:152] step: 167550, training_loss: 1.80091e+01
I0514 21:10:27.677422 140128494741248 run_lib.py:152] step: 167600, training_loss: 4.35135e+01
I0514 21:10:27.726508 140128494741248 run_lib.py:165] step: 167600, eval_loss: 3.79302e+01
I0514 21:10:33.921505 140128494741248 run_lib.py:152] step: 167650, training_loss: 4.13471e+01
I0514 21:10:40.311703 140128494741248 run_lib.py:152] step: 167700, training_loss: 3.68242e+01
I0514 21:10:40.364121 140128494741248 run_lib.py:165] step: 167700, eval_loss: 3.61330e+01
I0514 21:10:46.553848 140128494741248 run_lib.py:152] step: 167750, training_loss: 4.53625e+01
I0514 21:10:52.738443 140128494741248 run_lib.py:152] step: 167800, training_loss: 2.16126e+01
I0514 21:10:52.794705 140128494741248 run_lib.py:165] step: 167800, eval_loss: 2.87030e+01
I0514 21:10:58.935264 140128494741248 run_lib.py:152] step: 167850, training_loss: 4.84088e+01
I0514 21:11:05.325328 140128494741248 run_lib.py:152] step: 167900, training_loss: 4.14695e+01
I0514 21:11:05.376417 140128494741248 run_lib.py:165] step: 167900, eval_loss: 1.90280e+01
I0514 21:11:11.574944 140128494741248 run_lib.py:152] step: 167950, training_loss: 3.70572e+01
I0514 21:11:17.800168 140128494741248 run_lib.py:152] step: 168000, training_loss: 4.55608e+01
I0514 21:11:17.853986 140128494741248 run_lib.py:165] step: 168000, eval_loss: 3.23393e+01
I0514 21:11:24.164629 140128494741248 run_lib.py:152] step: 168050, training_loss: 2.66645e+01
I0514 21:11:30.434650 140128494741248 run_lib.py:152] step: 168100, training_loss: 4.23740e+01
I0514 21:11:30.491671 140128494741248 run_lib.py:165] step: 168100, eval_loss: 4.30183e+01
I0514 21:11:36.741421 140128494741248 run_lib.py:152] step: 168150, training_loss: 4.72020e+01
I0514 21:11:42.908109 140128494741248 run_lib.py:152] step: 168200, training_loss: 2.65087e+01
I0514 21:11:42.958300 140128494741248 run_lib.py:165] step: 168200, eval_loss: 2.95304e+01
I0514 21:11:49.397739 140128494741248 run_lib.py:152] step: 168250, training_loss: 3.13171e+01
I0514 21:11:55.543853 140128494741248 run_lib.py:152] step: 168300, training_loss: 2.26629e+01
I0514 21:11:55.597496 140128494741248 run_lib.py:165] step: 168300, eval_loss: 3.25297e+01
I0514 21:12:01.861550 140128494741248 run_lib.py:152] step: 168350, training_loss: 2.59009e+01
I0514 21:12:08.223783 140128494741248 run_lib.py:152] step: 168400, training_loss: 2.72146e+01
I0514 21:12:08.277759 140128494741248 run_lib.py:165] step: 168400, eval_loss: 2.54672e+01
I0514 21:12:14.483450 140128494741248 run_lib.py:152] step: 168450, training_loss: 2.37258e+01
I0514 21:12:20.693431 140128494741248 run_lib.py:152] step: 168500, training_loss: 2.24421e+01
I0514 21:12:20.749375 140128494741248 run_lib.py:165] step: 168500, eval_loss: 2.85119e+01
I0514 21:12:26.947539 140128494741248 run_lib.py:152] step: 168550, training_loss: 3.32235e+01
I0514 21:12:33.350617 140128494741248 run_lib.py:152] step: 168600, training_loss: 4.69924e+01
I0514 21:12:33.403000 140128494741248 run_lib.py:165] step: 168600, eval_loss: 2.87111e+01
I0514 21:12:39.484370 140128494741248 run_lib.py:152] step: 168650, training_loss: 5.12128e+01
I0514 21:12:45.654962 140128494741248 run_lib.py:152] step: 168700, training_loss: 3.70603e+01
I0514 21:12:45.705658 140128494741248 run_lib.py:165] step: 168700, eval_loss: 2.95572e+01
I0514 21:12:52.217175 140128494741248 run_lib.py:152] step: 168750, training_loss: 3.79434e+01
I0514 21:12:58.371537 140128494741248 run_lib.py:152] step: 168800, training_loss: 3.06280e+01
I0514 21:12:58.421904 140128494741248 run_lib.py:165] step: 168800, eval_loss: 2.38549e+01
I0514 21:13:04.644180 140128494741248 run_lib.py:152] step: 168850, training_loss: 2.87800e+01
I0514 21:13:10.901699 140128494741248 run_lib.py:152] step: 168900, training_loss: 2.66374e+01
I0514 21:13:10.953795 140128494741248 run_lib.py:165] step: 168900, eval_loss: 4.34214e+01
I0514 21:13:17.332888 140128494741248 run_lib.py:152] step: 168950, training_loss: 1.86897e+01
I0514 21:13:23.514209 140128494741248 run_lib.py:152] step: 169000, training_loss: 3.12371e+01
I0514 21:13:23.571584 140128494741248 run_lib.py:165] step: 169000, eval_loss: 3.39680e+01
I0514 21:13:29.655381 140128494741248 run_lib.py:152] step: 169050, training_loss: 2.35416e+01
I0514 21:13:36.098330 140128494741248 run_lib.py:152] step: 169100, training_loss: 3.82700e+01
I0514 21:13:36.154579 140128494741248 run_lib.py:165] step: 169100, eval_loss: 2.69754e+01
I0514 21:13:42.326402 140128494741248 run_lib.py:152] step: 169150, training_loss: 4.96847e+01
I0514 21:13:48.473390 140128494741248 run_lib.py:152] step: 169200, training_loss: 2.95867e+01
I0514 21:13:48.527229 140128494741248 run_lib.py:165] step: 169200, eval_loss: 2.46978e+01
I0514 21:13:54.631242 140128494741248 run_lib.py:152] step: 169250, training_loss: 3.05321e+01
I0514 21:14:01.027354 140128494741248 run_lib.py:152] step: 169300, training_loss: 2.35590e+01
I0514 21:14:01.077687 140128494741248 run_lib.py:165] step: 169300, eval_loss: 2.33905e+01
I0514 21:14:07.189309 140128494741248 run_lib.py:152] step: 169350, training_loss: 2.61704e+01
I0514 21:14:13.395805 140128494741248 run_lib.py:152] step: 169400, training_loss: 3.95205e+01
I0514 21:14:13.449909 140128494741248 run_lib.py:165] step: 169400, eval_loss: 2.49166e+01
I0514 21:14:19.834871 140128494741248 run_lib.py:152] step: 169450, training_loss: 1.98314e+01
I0514 21:14:26.036687 140128494741248 run_lib.py:152] step: 169500, training_loss: 1.86762e+01
I0514 21:14:26.090115 140128494741248 run_lib.py:165] step: 169500, eval_loss: 2.63874e+01
I0514 21:14:32.288444 140128494741248 run_lib.py:152] step: 169550, training_loss: 4.04455e+01
I0514 21:14:38.499398 140128494741248 run_lib.py:152] step: 169600, training_loss: 2.47579e+01
I0514 21:14:38.551077 140128494741248 run_lib.py:165] step: 169600, eval_loss: 2.48592e+01
I0514 21:14:44.951570 140128494741248 run_lib.py:152] step: 169650, training_loss: 3.80996e+01
I0514 21:14:51.185987 140128494741248 run_lib.py:152] step: 169700, training_loss: 4.98705e+01
I0514 21:14:51.240694 140128494741248 run_lib.py:165] step: 169700, eval_loss: 2.25255e+01
I0514 21:14:57.394252 140128494741248 run_lib.py:152] step: 169750, training_loss: 3.60269e+01
I0514 21:15:03.972179 140128494741248 run_lib.py:152] step: 169800, training_loss: 2.94301e+01
I0514 21:15:04.023262 140128494741248 run_lib.py:165] step: 169800, eval_loss: 5.31660e+01
I0514 21:15:10.241050 140128494741248 run_lib.py:152] step: 169850, training_loss: 3.78488e+01
I0514 21:15:16.410199 140128494741248 run_lib.py:152] step: 169900, training_loss: 3.00990e+01
I0514 21:15:16.467575 140128494741248 run_lib.py:165] step: 169900, eval_loss: 3.11751e+01
I0514 21:15:22.663281 140128494741248 run_lib.py:152] step: 169950, training_loss: 4.06410e+01
I0514 21:15:29.073691 140128494741248 run_lib.py:152] step: 170000, training_loss: 4.71265e+01
I0514 21:15:29.275191 140128494741248 run_lib.py:165] step: 170000, eval_loss: 2.75250e+01
I0514 21:15:35.397372 140128494741248 run_lib.py:152] step: 170050, training_loss: 2.57895e+01
I0514 21:15:41.602828 140128494741248 run_lib.py:152] step: 170100, training_loss: 1.93078e+01
I0514 21:15:41.651993 140128494741248 run_lib.py:165] step: 170100, eval_loss: 2.86280e+01
I0514 21:15:48.049052 140128494741248 run_lib.py:152] step: 170150, training_loss: 3.45894e+01
I0514 21:15:54.307857 140128494741248 run_lib.py:152] step: 170200, training_loss: 4.68269e+01
I0514 21:15:54.359603 140128494741248 run_lib.py:165] step: 170200, eval_loss: 3.25248e+01
I0514 21:16:00.473401 140128494741248 run_lib.py:152] step: 170250, training_loss: 2.73426e+01
I0514 21:16:06.685865 140128494741248 run_lib.py:152] step: 170300, training_loss: 4.41392e+01
I0514 21:16:06.741741 140128494741248 run_lib.py:165] step: 170300, eval_loss: 3.76405e+01
I0514 21:16:13.068199 140128494741248 run_lib.py:152] step: 170350, training_loss: 4.18732e+01
I0514 21:16:19.287657 140128494741248 run_lib.py:152] step: 170400, training_loss: 3.34568e+01
I0514 21:16:19.340552 140128494741248 run_lib.py:165] step: 170400, eval_loss: 3.02107e+01
I0514 21:16:25.482884 140128494741248 run_lib.py:152] step: 170450, training_loss: 2.52424e+01
I0514 21:16:31.955011 140128494741248 run_lib.py:152] step: 170500, training_loss: 4.80717e+01
I0514 21:16:32.007048 140128494741248 run_lib.py:165] step: 170500, eval_loss: 3.88610e+01
I0514 21:16:38.075434 140128494741248 run_lib.py:152] step: 170550, training_loss: 4.82541e+01
I0514 21:16:44.276519 140128494741248 run_lib.py:152] step: 170600, training_loss: 2.87951e+01
I0514 21:16:44.327459 140128494741248 run_lib.py:165] step: 170600, eval_loss: 2.78929e+01
I0514 21:16:50.591964 140128494741248 run_lib.py:152] step: 170650, training_loss: 2.75094e+01
I0514 21:16:56.980291 140128494741248 run_lib.py:152] step: 170700, training_loss: 2.79153e+01
I0514 21:16:57.033671 140128494741248 run_lib.py:165] step: 170700, eval_loss: 4.32855e+01
I0514 21:17:03.179793 140128494741248 run_lib.py:152] step: 170750, training_loss: 3.21578e+01
I0514 21:17:09.457769 140128494741248 run_lib.py:152] step: 170800, training_loss: 4.09226e+01
I0514 21:17:09.515220 140128494741248 run_lib.py:165] step: 170800, eval_loss: 2.68474e+01
I0514 21:17:15.911568 140128494741248 run_lib.py:152] step: 170850, training_loss: 3.38307e+01
I0514 21:17:22.069195 140128494741248 run_lib.py:152] step: 170900, training_loss: 2.90067e+01
I0514 21:17:22.123800 140128494741248 run_lib.py:165] step: 170900, eval_loss: 3.11470e+01
I0514 21:17:28.279056 140128494741248 run_lib.py:152] step: 170950, training_loss: 3.14985e+01
I0514 21:17:34.513093 140128494741248 run_lib.py:152] step: 171000, training_loss: 2.79661e+01
I0514 21:17:34.564197 140128494741248 run_lib.py:165] step: 171000, eval_loss: 2.67491e+01
I0514 21:17:40.974053 140128494741248 run_lib.py:152] step: 171050, training_loss: 3.26726e+01
I0514 21:17:47.100323 140128494741248 run_lib.py:152] step: 171100, training_loss: 3.46605e+01
I0514 21:17:47.148432 140128494741248 run_lib.py:165] step: 171100, eval_loss: 2.88983e+01
I0514 21:17:53.377960 140128494741248 run_lib.py:152] step: 171150, training_loss: 2.65966e+01
I0514 21:17:59.800451 140128494741248 run_lib.py:152] step: 171200, training_loss: 4.02423e+01
I0514 21:17:59.856624 140128494741248 run_lib.py:165] step: 171200, eval_loss: 3.62927e+01
I0514 21:18:05.941386 140128494741248 run_lib.py:152] step: 171250, training_loss: 4.06573e+01
I0514 21:18:12.169372 140128494741248 run_lib.py:152] step: 171300, training_loss: 2.16395e+01
I0514 21:18:12.222284 140128494741248 run_lib.py:165] step: 171300, eval_loss: 2.15121e+01
I0514 21:18:18.347202 140128494741248 run_lib.py:152] step: 171350, training_loss: 5.32382e+01
I0514 21:18:24.805686 140128494741248 run_lib.py:152] step: 171400, training_loss: 3.15464e+01
I0514 21:18:24.859201 140128494741248 run_lib.py:165] step: 171400, eval_loss: 2.82594e+01
I0514 21:18:31.097798 140128494741248 run_lib.py:152] step: 171450, training_loss: 3.29601e+01
I0514 21:18:37.245646 140128494741248 run_lib.py:152] step: 171500, training_loss: 4.36788e+01
I0514 21:18:37.299341 140128494741248 run_lib.py:165] step: 171500, eval_loss: 2.25225e+01
I0514 21:18:43.765910 140128494741248 run_lib.py:152] step: 171550, training_loss: 2.90717e+01
I0514 21:18:50.023000 140128494741248 run_lib.py:152] step: 171600, training_loss: 2.87888e+01
I0514 21:18:50.074135 140128494741248 run_lib.py:165] step: 171600, eval_loss: 6.23157e+01
I0514 21:18:56.348704 140128494741248 run_lib.py:152] step: 171650, training_loss: 2.72236e+01
I0514 21:19:02.524245 140128494741248 run_lib.py:152] step: 171700, training_loss: 2.69197e+01
I0514 21:19:02.576947 140128494741248 run_lib.py:165] step: 171700, eval_loss: 4.50868e+01
I0514 21:19:09.176559 140128494741248 run_lib.py:152] step: 171750, training_loss: 2.65966e+01
I0514 21:19:15.307606 140128494741248 run_lib.py:152] step: 171800, training_loss: 3.96922e+01
I0514 21:19:15.357578 140128494741248 run_lib.py:165] step: 171800, eval_loss: 1.82864e+01
I0514 21:19:21.509798 140128494741248 run_lib.py:152] step: 171850, training_loss: 3.71390e+01
I0514 21:19:28.015701 140128494741248 run_lib.py:152] step: 171900, training_loss: 3.07815e+01
I0514 21:19:28.065540 140128494741248 run_lib.py:165] step: 171900, eval_loss: 2.51746e+01
I0514 21:19:34.353360 140128494741248 run_lib.py:152] step: 171950, training_loss: 2.59951e+01
I0514 21:19:40.462728 140128494741248 run_lib.py:152] step: 172000, training_loss: 3.46278e+01
I0514 21:19:40.515211 140128494741248 run_lib.py:165] step: 172000, eval_loss: 3.62677e+01
I0514 21:19:46.812463 140128494741248 run_lib.py:152] step: 172050, training_loss: 3.43977e+01
I0514 21:19:53.156960 140128494741248 run_lib.py:152] step: 172100, training_loss: 2.96137e+01
I0514 21:19:53.207802 140128494741248 run_lib.py:165] step: 172100, eval_loss: 2.95410e+01
I0514 21:19:59.436015 140128494741248 run_lib.py:152] step: 172150, training_loss: 3.03500e+01
I0514 21:20:05.668118 140128494741248 run_lib.py:152] step: 172200, training_loss: 3.31468e+01
I0514 21:20:05.718310 140128494741248 run_lib.py:165] step: 172200, eval_loss: 2.89433e+01
I0514 21:20:12.121824 140128494741248 run_lib.py:152] step: 172250, training_loss: 4.75914e+01
I0514 21:20:18.307886 140128494741248 run_lib.py:152] step: 172300, training_loss: 1.91429e+01
I0514 21:20:18.357657 140128494741248 run_lib.py:165] step: 172300, eval_loss: 3.48794e+01
I0514 21:20:24.526468 140128494741248 run_lib.py:152] step: 172350, training_loss: 2.23265e+01
I0514 21:20:30.921608 140128494741248 run_lib.py:152] step: 172400, training_loss: 4.86770e+01
I0514 21:20:30.973966 140128494741248 run_lib.py:165] step: 172400, eval_loss: 2.58980e+01
I0514 21:20:37.415667 140128494741248 run_lib.py:152] step: 172450, training_loss: 3.15299e+01
I0514 21:20:43.551491 140128494741248 run_lib.py:152] step: 172500, training_loss: 3.55734e+01
I0514 21:20:43.603388 140128494741248 run_lib.py:165] step: 172500, eval_loss: 9.86150e+00
I0514 21:20:49.812949 140128494741248 run_lib.py:152] step: 172550, training_loss: 2.76579e+01
I0514 21:20:56.264428 140128494741248 run_lib.py:152] step: 172600, training_loss: 2.71941e+01
I0514 21:20:56.314637 140128494741248 run_lib.py:165] step: 172600, eval_loss: 3.54980e+01
I0514 21:21:02.539227 140128494741248 run_lib.py:152] step: 172650, training_loss: 2.22625e+01
I0514 21:21:08.674845 140128494741248 run_lib.py:152] step: 172700, training_loss: 2.75314e+01
I0514 21:21:08.732635 140128494741248 run_lib.py:165] step: 172700, eval_loss: 4.79015e+01
I0514 21:21:14.954344 140128494741248 run_lib.py:152] step: 172750, training_loss: 3.38102e+01
I0514 21:21:21.366385 140128494741248 run_lib.py:152] step: 172800, training_loss: 1.53685e+01
I0514 21:21:21.415433 140128494741248 run_lib.py:165] step: 172800, eval_loss: 4.08620e+01
I0514 21:21:27.562029 140128494741248 run_lib.py:152] step: 172850, training_loss: 1.76578e+01
I0514 21:21:33.847781 140128494741248 run_lib.py:152] step: 172900, training_loss: 3.34204e+01
I0514 21:21:33.901568 140128494741248 run_lib.py:165] step: 172900, eval_loss: 3.36659e+01
I0514 21:21:40.230988 140128494741248 run_lib.py:152] step: 172950, training_loss: 2.90656e+01
I0514 21:21:46.331160 140128494741248 run_lib.py:152] step: 173000, training_loss: 2.93219e+01
I0514 21:21:46.382932 140128494741248 run_lib.py:165] step: 173000, eval_loss: 3.25942e+01
I0514 21:21:52.668555 140128494741248 run_lib.py:152] step: 173050, training_loss: 3.88099e+01
I0514 21:21:58.814844 140128494741248 run_lib.py:152] step: 173100, training_loss: 2.13744e+01
I0514 21:21:58.867724 140128494741248 run_lib.py:165] step: 173100, eval_loss: 2.37707e+01
I0514 21:22:05.261925 140128494741248 run_lib.py:152] step: 173150, training_loss: 3.16518e+01
I0514 21:22:11.423739 140128494741248 run_lib.py:152] step: 173200, training_loss: 2.30027e+01
I0514 21:22:11.476043 140128494741248 run_lib.py:165] step: 173200, eval_loss: 3.91391e+01
I0514 21:22:17.589169 140128494741248 run_lib.py:152] step: 173250, training_loss: 3.82958e+01
I0514 21:22:24.056181 140128494741248 run_lib.py:152] step: 173300, training_loss: 3.55792e+01
I0514 21:22:24.109426 140128494741248 run_lib.py:165] step: 173300, eval_loss: 2.45364e+01
I0514 21:22:30.282780 140128494741248 run_lib.py:152] step: 173350, training_loss: 2.58210e+01
I0514 21:22:36.474550 140128494741248 run_lib.py:152] step: 173400, training_loss: 2.37432e+01
I0514 21:22:36.526483 140128494741248 run_lib.py:165] step: 173400, eval_loss: 2.25711e+01
I0514 21:22:42.684835 140128494741248 run_lib.py:152] step: 173450, training_loss: 4.11822e+01
I0514 21:22:49.179833 140128494741248 run_lib.py:152] step: 173500, training_loss: 2.55017e+01
I0514 21:22:49.227826 140128494741248 run_lib.py:165] step: 173500, eval_loss: 3.00679e+01
I0514 21:22:55.525763 140128494741248 run_lib.py:152] step: 173550, training_loss: 3.04350e+01
I0514 21:23:01.713411 140128494741248 run_lib.py:152] step: 173600, training_loss: 3.50493e+01
I0514 21:23:01.767998 140128494741248 run_lib.py:165] step: 173600, eval_loss: 2.79370e+01
I0514 21:23:08.218464 140128494741248 run_lib.py:152] step: 173650, training_loss: 4.03857e+01
I0514 21:23:14.350796 140128494741248 run_lib.py:152] step: 173700, training_loss: 4.10176e+01
I0514 21:23:14.402158 140128494741248 run_lib.py:165] step: 173700, eval_loss: 2.47352e+01
I0514 21:23:20.601872 140128494741248 run_lib.py:152] step: 173750, training_loss: 2.20281e+01
I0514 21:23:26.861860 140128494741248 run_lib.py:152] step: 173800, training_loss: 2.32670e+01
I0514 21:23:26.914912 140128494741248 run_lib.py:165] step: 173800, eval_loss: 2.73642e+01
I0514 21:23:33.370898 140128494741248 run_lib.py:152] step: 173850, training_loss: 2.08090e+01
I0514 21:23:39.533924 140128494741248 run_lib.py:152] step: 173900, training_loss: 3.64278e+01
I0514 21:23:39.586802 140128494741248 run_lib.py:165] step: 173900, eval_loss: 4.63876e+01
I0514 21:23:45.841532 140128494741248 run_lib.py:152] step: 173950, training_loss: 3.08775e+01
I0514 21:23:52.300911 140128494741248 run_lib.py:152] step: 174000, training_loss: 2.42440e+01
I0514 21:23:52.349739 140128494741248 run_lib.py:165] step: 174000, eval_loss: 1.98292e+01
I0514 21:23:58.581773 140128494741248 run_lib.py:152] step: 174050, training_loss: 4.07474e+01
I0514 21:24:04.723218 140128494741248 run_lib.py:152] step: 174100, training_loss: 4.67412e+01
I0514 21:24:04.774283 140128494741248 run_lib.py:165] step: 174100, eval_loss: 3.07952e+01
I0514 21:24:10.951820 140128494741248 run_lib.py:152] step: 174150, training_loss: 3.94287e+01
I0514 21:24:17.265631 140128494741248 run_lib.py:152] step: 174200, training_loss: 4.36014e+01
I0514 21:24:17.320142 140128494741248 run_lib.py:165] step: 174200, eval_loss: 2.23863e+01
I0514 21:24:23.586615 140128494741248 run_lib.py:152] step: 174250, training_loss: 4.48121e+01
I0514 21:24:29.771962 140128494741248 run_lib.py:152] step: 174300, training_loss: 4.70595e+01
I0514 21:24:29.827727 140128494741248 run_lib.py:165] step: 174300, eval_loss: 3.71262e+01
I0514 21:24:36.133487 140128494741248 run_lib.py:152] step: 174350, training_loss: 2.95376e+01
I0514 21:24:42.343239 140128494741248 run_lib.py:152] step: 174400, training_loss: 5.07114e+01
I0514 21:24:42.396128 140128494741248 run_lib.py:165] step: 174400, eval_loss: 1.77414e+01
I0514 21:24:48.545229 140128494741248 run_lib.py:152] step: 174450, training_loss: 2.96710e+01
I0514 21:24:54.725030 140128494741248 run_lib.py:152] step: 174500, training_loss: 2.61639e+01
I0514 21:24:54.779158 140128494741248 run_lib.py:165] step: 174500, eval_loss: 4.21385e+01
I0514 21:25:01.248575 140128494741248 run_lib.py:152] step: 174550, training_loss: 3.88524e+01
I0514 21:25:07.497033 140128494741248 run_lib.py:152] step: 174600, training_loss: 5.89183e+01
I0514 21:25:07.545488 140128494741248 run_lib.py:165] step: 174600, eval_loss: 4.89771e+01
I0514 21:25:13.680846 140128494741248 run_lib.py:152] step: 174650, training_loss: 4.02243e+01
I0514 21:25:20.162274 140128494741248 run_lib.py:152] step: 174700, training_loss: 4.08929e+01
I0514 21:25:20.215892 140128494741248 run_lib.py:165] step: 174700, eval_loss: 4.73875e+01
I0514 21:25:26.490619 140128494741248 run_lib.py:152] step: 174750, training_loss: 2.74028e+01
I0514 21:25:32.685885 140128494741248 run_lib.py:152] step: 174800, training_loss: 3.83766e+01
I0514 21:25:32.737888 140128494741248 run_lib.py:165] step: 174800, eval_loss: 3.24120e+01
I0514 21:25:38.931496 140128494741248 run_lib.py:152] step: 174850, training_loss: 2.24171e+01
I0514 21:25:45.427541 140128494741248 run_lib.py:152] step: 174900, training_loss: 3.11207e+01
I0514 21:25:45.478925 140128494741248 run_lib.py:165] step: 174900, eval_loss: 1.91153e+01
I0514 21:25:51.573587 140128494741248 run_lib.py:152] step: 174950, training_loss: 2.55844e+01
I0514 21:25:57.797162 140128494741248 run_lib.py:152] step: 175000, training_loss: 4.48101e+01
I0514 21:25:57.846931 140128494741248 run_lib.py:165] step: 175000, eval_loss: 4.07782e+01
I0514 21:26:04.227597 140128494741248 run_lib.py:152] step: 175050, training_loss: 3.21168e+01
I0514 21:26:10.421621 140128494741248 run_lib.py:152] step: 175100, training_loss: 5.59351e+01
I0514 21:26:10.481638 140128494741248 run_lib.py:165] step: 175100, eval_loss: 3.04351e+01
I0514 21:26:16.639512 140128494741248 run_lib.py:152] step: 175150, training_loss: 3.74355e+01
I0514 21:26:22.844869 140128494741248 run_lib.py:152] step: 175200, training_loss: 3.65806e+01
I0514 21:26:22.903939 140128494741248 run_lib.py:165] step: 175200, eval_loss: 3.48047e+01
I0514 21:26:29.351578 140128494741248 run_lib.py:152] step: 175250, training_loss: 2.39209e+01
I0514 21:26:35.551293 140128494741248 run_lib.py:152] step: 175300, training_loss: 2.81630e+01
I0514 21:26:35.608442 140128494741248 run_lib.py:165] step: 175300, eval_loss: 4.40980e+01
I0514 21:26:41.821507 140128494741248 run_lib.py:152] step: 175350, training_loss: 1.99610e+01
I0514 21:26:48.310142 140128494741248 run_lib.py:152] step: 175400, training_loss: 2.83600e+01
I0514 21:26:48.361828 140128494741248 run_lib.py:165] step: 175400, eval_loss: 2.98020e+01
I0514 21:26:54.584317 140128494741248 run_lib.py:152] step: 175450, training_loss: 4.57805e+01
I0514 21:27:00.723594 140128494741248 run_lib.py:152] step: 175500, training_loss: 2.64341e+01
I0514 21:27:00.774834 140128494741248 run_lib.py:165] step: 175500, eval_loss: 3.64850e+01
I0514 21:27:06.949232 140128494741248 run_lib.py:152] step: 175550, training_loss: 3.63129e+01
I0514 21:27:13.411249 140128494741248 run_lib.py:152] step: 175600, training_loss: 2.27733e+01
I0514 21:27:13.472650 140128494741248 run_lib.py:165] step: 175600, eval_loss: 2.79219e+01
I0514 21:27:19.651558 140128494741248 run_lib.py:152] step: 175650, training_loss: 3.24695e+01
I0514 21:27:25.741471 140128494741248 run_lib.py:152] step: 175700, training_loss: 1.93955e+01
I0514 21:27:25.787250 140128494741248 run_lib.py:165] step: 175700, eval_loss: 2.46712e+01
I0514 21:27:32.256656 140128494741248 run_lib.py:152] step: 175750, training_loss: 2.14615e+01
I0514 21:27:38.476699 140128494741248 run_lib.py:152] step: 175800, training_loss: 1.42198e+01
I0514 21:27:38.528264 140128494741248 run_lib.py:165] step: 175800, eval_loss: 2.04447e+01
I0514 21:27:44.714855 140128494741248 run_lib.py:152] step: 175850, training_loss: 2.26419e+01
I0514 21:27:50.966599 140128494741248 run_lib.py:152] step: 175900, training_loss: 3.58001e+01
I0514 21:27:51.018776 140128494741248 run_lib.py:165] step: 175900, eval_loss: 3.30335e+01
I0514 21:27:57.550459 140128494741248 run_lib.py:152] step: 175950, training_loss: 3.54821e+01
I0514 21:28:03.771147 140128494741248 run_lib.py:152] step: 176000, training_loss: 3.15340e+01
I0514 21:28:03.824023 140128494741248 run_lib.py:165] step: 176000, eval_loss: 3.39220e+01
I0514 21:28:09.998755 140128494741248 run_lib.py:152] step: 176050, training_loss: 2.31738e+01
I0514 21:28:16.429377 140128494741248 run_lib.py:152] step: 176100, training_loss: 3.81783e+01
I0514 21:28:16.482547 140128494741248 run_lib.py:165] step: 176100, eval_loss: 2.10524e+01
I0514 21:28:22.636501 140128494741248 run_lib.py:152] step: 176150, training_loss: 3.21842e+01
I0514 21:28:28.850844 140128494741248 run_lib.py:152] step: 176200, training_loss: 3.13132e+01
I0514 21:28:28.904078 140128494741248 run_lib.py:165] step: 176200, eval_loss: 2.40333e+01
I0514 21:28:35.062268 140128494741248 run_lib.py:152] step: 176250, training_loss: 2.65288e+01
I0514 21:28:41.582789 140128494741248 run_lib.py:152] step: 176300, training_loss: 3.87074e+01
I0514 21:28:41.637710 140128494741248 run_lib.py:165] step: 176300, eval_loss: 2.66349e+01
I0514 21:28:47.788067 140128494741248 run_lib.py:152] step: 176350, training_loss: 2.77406e+01
I0514 21:28:54.002557 140128494741248 run_lib.py:152] step: 176400, training_loss: 3.53521e+01
I0514 21:28:54.054146 140128494741248 run_lib.py:165] step: 176400, eval_loss: 2.19224e+01
I0514 21:29:00.535545 140128494741248 run_lib.py:152] step: 176450, training_loss: 3.44682e+01
I0514 21:29:06.714326 140128494741248 run_lib.py:152] step: 176500, training_loss: 3.00223e+01
I0514 21:29:06.767499 140128494741248 run_lib.py:165] step: 176500, eval_loss: 1.99836e+01
I0514 21:29:12.990586 140128494741248 run_lib.py:152] step: 176550, training_loss: 4.97426e+01
I0514 21:29:19.148312 140128494741248 run_lib.py:152] step: 176600, training_loss: 3.59334e+01
I0514 21:29:19.197639 140128494741248 run_lib.py:165] step: 176600, eval_loss: 2.93296e+01
I0514 21:29:25.676156 140128494741248 run_lib.py:152] step: 176650, training_loss: 3.26497e+01
I0514 21:29:31.874040 140128494741248 run_lib.py:152] step: 176700, training_loss: 1.89516e+01
I0514 21:29:31.932204 140128494741248 run_lib.py:165] step: 176700, eval_loss: 2.51055e+01
I0514 21:29:38.097152 140128494741248 run_lib.py:152] step: 176750, training_loss: 3.42266e+01
I0514 21:29:44.551177 140128494741248 run_lib.py:152] step: 176800, training_loss: 3.41687e+01
I0514 21:29:44.608435 140128494741248 run_lib.py:165] step: 176800, eval_loss: 2.83382e+01
I0514 21:29:50.923806 140128494741248 run_lib.py:152] step: 176850, training_loss: 2.64171e+01
I0514 21:29:57.111118 140128494741248 run_lib.py:152] step: 176900, training_loss: 2.29051e+01
I0514 21:29:57.163690 140128494741248 run_lib.py:165] step: 176900, eval_loss: 3.99260e+01
I0514 21:30:03.429899 140128494741248 run_lib.py:152] step: 176950, training_loss: 3.95672e+01
I0514 21:30:09.910552 140128494741248 run_lib.py:152] step: 177000, training_loss: 3.96329e+01
I0514 21:30:09.962514 140128494741248 run_lib.py:165] step: 177000, eval_loss: 3.37073e+01
I0514 21:30:16.133147 140128494741248 run_lib.py:152] step: 177050, training_loss: 3.99964e+01
I0514 21:30:22.449311 140128494741248 run_lib.py:152] step: 177100, training_loss: 2.65826e+01
I0514 21:30:22.500227 140128494741248 run_lib.py:165] step: 177100, eval_loss: 3.55003e+01
I0514 21:30:28.999797 140128494741248 run_lib.py:152] step: 177150, training_loss: 2.18227e+01
I0514 21:30:35.246314 140128494741248 run_lib.py:152] step: 177200, training_loss: 2.59330e+01
I0514 21:30:35.298970 140128494741248 run_lib.py:165] step: 177200, eval_loss: 3.62364e+01
I0514 21:30:41.365339 140128494741248 run_lib.py:152] step: 177250, training_loss: 3.57774e+01
I0514 21:30:47.525630 140128494741248 run_lib.py:152] step: 177300, training_loss: 5.31974e+01
I0514 21:30:47.593955 140128494741248 run_lib.py:165] step: 177300, eval_loss: 4.31757e+01
I0514 21:30:53.963892 140128494741248 run_lib.py:152] step: 177350, training_loss: 2.50405e+01
I0514 21:31:00.200692 140128494741248 run_lib.py:152] step: 177400, training_loss: 3.35597e+01
I0514 21:31:00.251366 140128494741248 run_lib.py:165] step: 177400, eval_loss: 3.42323e+01
I0514 21:31:06.465040 140128494741248 run_lib.py:152] step: 177450, training_loss: 4.23065e+01
I0514 21:31:12.918245 140128494741248 run_lib.py:152] step: 177500, training_loss: 4.01312e+01
I0514 21:31:12.972882 140128494741248 run_lib.py:165] step: 177500, eval_loss: 3.39585e+01
I0514 21:31:19.128437 140128494741248 run_lib.py:152] step: 177550, training_loss: 2.70356e+01
I0514 21:31:25.445425 140128494741248 run_lib.py:152] step: 177600, training_loss: 4.30727e+01
I0514 21:31:25.495981 140128494741248 run_lib.py:165] step: 177600, eval_loss: 2.37553e+01
I0514 21:31:31.714583 140128494741248 run_lib.py:152] step: 177650, training_loss: 3.36312e+01
I0514 21:31:38.129587 140128494741248 run_lib.py:152] step: 177700, training_loss: 3.49421e+01
I0514 21:31:38.179764 140128494741248 run_lib.py:165] step: 177700, eval_loss: 2.92576e+01
I0514 21:31:44.355962 140128494741248 run_lib.py:152] step: 177750, training_loss: 3.91988e+01
I0514 21:31:50.553623 140128494741248 run_lib.py:152] step: 177800, training_loss: 2.46258e+01
I0514 21:31:50.602663 140128494741248 run_lib.py:165] step: 177800, eval_loss: 2.98593e+01
I0514 21:31:57.021521 140128494741248 run_lib.py:152] step: 177850, training_loss: 2.43071e+01
I0514 21:32:03.149168 140128494741248 run_lib.py:152] step: 177900, training_loss: 4.63110e+01
I0514 21:32:03.199405 140128494741248 run_lib.py:165] step: 177900, eval_loss: 2.79131e+01
I0514 21:32:09.435209 140128494741248 run_lib.py:152] step: 177950, training_loss: 3.03227e+01
I0514 21:32:15.635325 140128494741248 run_lib.py:152] step: 178000, training_loss: 5.17994e+01
I0514 21:32:15.691575 140128494741248 run_lib.py:165] step: 178000, eval_loss: 2.28433e+01
I0514 21:32:22.147761 140128494741248 run_lib.py:152] step: 178050, training_loss: 2.15938e+01
I0514 21:32:28.438371 140128494741248 run_lib.py:152] step: 178100, training_loss: 3.49777e+01
I0514 21:32:28.499087 140128494741248 run_lib.py:165] step: 178100, eval_loss: 3.22867e+01
I0514 21:32:34.637335 140128494741248 run_lib.py:152] step: 178150, training_loss: 4.16703e+01
I0514 21:32:41.056797 140128494741248 run_lib.py:152] step: 178200, training_loss: 3.16176e+01
I0514 21:32:41.107379 140128494741248 run_lib.py:165] step: 178200, eval_loss: 2.90996e+01
I0514 21:32:47.251838 140128494741248 run_lib.py:152] step: 178250, training_loss: 3.80079e+01
I0514 21:32:53.515492 140128494741248 run_lib.py:152] step: 178300, training_loss: 3.19841e+01
I0514 21:32:53.566963 140128494741248 run_lib.py:165] step: 178300, eval_loss: 3.76086e+01
I0514 21:32:59.767729 140128494741248 run_lib.py:152] step: 178350, training_loss: 3.55144e+01
I0514 21:33:06.071109 140128494741248 run_lib.py:152] step: 178400, training_loss: 3.55674e+01
I0514 21:33:06.119316 140128494741248 run_lib.py:165] step: 178400, eval_loss: 2.62809e+01
I0514 21:33:12.332405 140128494741248 run_lib.py:152] step: 178450, training_loss: 4.42372e+01
I0514 21:33:18.447262 140128494741248 run_lib.py:152] step: 178500, training_loss: 1.86174e+01
I0514 21:33:18.499176 140128494741248 run_lib.py:165] step: 178500, eval_loss: 2.16048e+01
I0514 21:33:24.839352 140128494741248 run_lib.py:152] step: 178550, training_loss: 1.83916e+01
I0514 21:33:31.024754 140128494741248 run_lib.py:152] step: 178600, training_loss: 2.85955e+01
I0514 21:33:31.071729 140128494741248 run_lib.py:165] step: 178600, eval_loss: 2.02726e+01
I0514 21:33:37.261471 140128494741248 run_lib.py:152] step: 178650, training_loss: 2.82658e+01
I0514 21:33:43.451263 140128494741248 run_lib.py:152] step: 178700, training_loss: 4.84697e+01
I0514 21:33:43.506375 140128494741248 run_lib.py:165] step: 178700, eval_loss: 2.74867e+01
I0514 21:33:50.006691 140128494741248 run_lib.py:152] step: 178750, training_loss: 3.10349e+01
I0514 21:33:56.253538 140128494741248 run_lib.py:152] step: 178800, training_loss: 3.18177e+01
I0514 21:33:56.309352 140128494741248 run_lib.py:165] step: 178800, eval_loss: 2.32987e+01
I0514 21:34:02.401842 140128494741248 run_lib.py:152] step: 178850, training_loss: 2.83855e+01
I0514 21:34:08.856147 140128494741248 run_lib.py:152] step: 178900, training_loss: 2.72887e+01
I0514 21:34:08.911083 140128494741248 run_lib.py:165] step: 178900, eval_loss: 2.67738e+01
I0514 21:34:15.068235 140128494741248 run_lib.py:152] step: 178950, training_loss: 4.76040e+01
I0514 21:34:21.281810 140128494741248 run_lib.py:152] step: 179000, training_loss: 2.75146e+01
I0514 21:34:21.333042 140128494741248 run_lib.py:165] step: 179000, eval_loss: 3.45192e+01
I0514 21:34:27.494726 140128494741248 run_lib.py:152] step: 179050, training_loss: 3.81862e+01
I0514 21:34:33.855746 140128494741248 run_lib.py:152] step: 179100, training_loss: 3.71707e+01
I0514 21:34:33.908846 140128494741248 run_lib.py:165] step: 179100, eval_loss: 3.62795e+01
I0514 21:34:40.142735 140128494741248 run_lib.py:152] step: 179150, training_loss: 2.80055e+01
I0514 21:34:46.410844 140128494741248 run_lib.py:152] step: 179200, training_loss: 4.03477e+01
I0514 21:34:46.463872 140128494741248 run_lib.py:165] step: 179200, eval_loss: 3.58658e+01
I0514 21:34:52.918062 140128494741248 run_lib.py:152] step: 179250, training_loss: 3.11580e+01
I0514 21:34:59.107011 140128494741248 run_lib.py:152] step: 179300, training_loss: 3.14986e+01
I0514 21:34:59.157851 140128494741248 run_lib.py:165] step: 179300, eval_loss: 2.47340e+01
I0514 21:35:05.375338 140128494741248 run_lib.py:152] step: 179350, training_loss: 2.94689e+01
I0514 21:35:11.573040 140128494741248 run_lib.py:152] step: 179400, training_loss: 2.54250e+01
I0514 21:35:11.623652 140128494741248 run_lib.py:165] step: 179400, eval_loss: 2.27654e+01
I0514 21:35:18.008507 140128494741248 run_lib.py:152] step: 179450, training_loss: 3.79306e+01
I0514 21:35:24.093751 140128494741248 run_lib.py:152] step: 179500, training_loss: 2.63345e+01
I0514 21:35:24.144012 140128494741248 run_lib.py:165] step: 179500, eval_loss: 2.86224e+01
I0514 21:35:30.448328 140128494741248 run_lib.py:152] step: 179550, training_loss: 3.00285e+01
I0514 21:35:36.861146 140128494741248 run_lib.py:152] step: 179600, training_loss: 4.44102e+01
I0514 21:35:36.912791 140128494741248 run_lib.py:165] step: 179600, eval_loss: 4.71182e+01
I0514 21:35:43.079352 140128494741248 run_lib.py:152] step: 179650, training_loss: 3.21337e+01
I0514 21:35:49.312439 140128494741248 run_lib.py:152] step: 179700, training_loss: 3.33418e+01
I0514 21:35:49.363626 140128494741248 run_lib.py:165] step: 179700, eval_loss: 3.97789e+01
I0514 21:35:55.593945 140128494741248 run_lib.py:152] step: 179750, training_loss: 1.99018e+01
I0514 21:36:01.998427 140128494741248 run_lib.py:152] step: 179800, training_loss: 4.37973e+01
I0514 21:36:02.053260 140128494741248 run_lib.py:165] step: 179800, eval_loss: 1.47365e+01
I0514 21:36:08.262255 140128494741248 run_lib.py:152] step: 179850, training_loss: 3.43174e+01
I0514 21:36:14.443144 140128494741248 run_lib.py:152] step: 179900, training_loss: 3.07650e+01
I0514 21:36:14.502533 140128494741248 run_lib.py:165] step: 179900, eval_loss: 3.37076e+01
I0514 21:36:20.927408 140128494741248 run_lib.py:152] step: 179950, training_loss: 4.10291e+01
I0514 21:36:27.061947 140128494741248 run_lib.py:152] step: 180000, training_loss: 2.97722e+01
I0514 21:36:27.267539 140128494741248 run_lib.py:165] step: 180000, eval_loss: 2.75834e+01
I0514 21:36:33.471683 140128494741248 run_lib.py:152] step: 180050, training_loss: 3.21728e+01
I0514 21:36:39.575260 140128494741248 run_lib.py:152] step: 180100, training_loss: 5.22423e+01
I0514 21:36:39.630388 140128494741248 run_lib.py:165] step: 180100, eval_loss: 3.42844e+01
I0514 21:36:46.085599 140128494741248 run_lib.py:152] step: 180150, training_loss: 3.22794e+01
I0514 21:36:52.294611 140128494741248 run_lib.py:152] step: 180200, training_loss: 3.27634e+01
I0514 21:36:52.349587 140128494741248 run_lib.py:165] step: 180200, eval_loss: 3.20752e+01
I0514 21:36:58.482575 140128494741248 run_lib.py:152] step: 180250, training_loss: 3.86406e+01
I0514 21:37:04.932185 140128494741248 run_lib.py:152] step: 180300, training_loss: 3.28252e+01
I0514 21:37:04.979342 140128494741248 run_lib.py:165] step: 180300, eval_loss: 4.59277e+01
I0514 21:37:11.126943 140128494741248 run_lib.py:152] step: 180350, training_loss: 2.82733e+01
I0514 21:37:17.290424 140128494741248 run_lib.py:152] step: 180400, training_loss: 2.35250e+01
I0514 21:37:17.342206 140128494741248 run_lib.py:165] step: 180400, eval_loss: 2.99124e+01
I0514 21:37:23.483336 140128494741248 run_lib.py:152] step: 180450, training_loss: 3.95458e+01
I0514 21:37:29.948834 140128494741248 run_lib.py:152] step: 180500, training_loss: 3.04552e+01
I0514 21:37:29.999758 140128494741248 run_lib.py:165] step: 180500, eval_loss: 2.41779e+01
I0514 21:37:36.170995 140128494741248 run_lib.py:152] step: 180550, training_loss: 2.43989e+01
I0514 21:37:42.323710 140128494741248 run_lib.py:152] step: 180600, training_loss: 3.03344e+01
I0514 21:37:42.380643 140128494741248 run_lib.py:165] step: 180600, eval_loss: 3.78001e+01
I0514 21:37:48.834430 140128494741248 run_lib.py:152] step: 180650, training_loss: 3.01187e+01
I0514 21:37:54.993647 140128494741248 run_lib.py:152] step: 180700, training_loss: 2.00778e+01
I0514 21:37:55.046706 140128494741248 run_lib.py:165] step: 180700, eval_loss: 3.10809e+01
I0514 21:38:01.232858 140128494741248 run_lib.py:152] step: 180750, training_loss: 2.34926e+01
I0514 21:38:07.523827 140128494741248 run_lib.py:152] step: 180800, training_loss: 2.36885e+01
I0514 21:38:07.576584 140128494741248 run_lib.py:165] step: 180800, eval_loss: 2.82164e+01
I0514 21:38:14.034411 140128494741248 run_lib.py:152] step: 180850, training_loss: 3.56419e+01
I0514 21:38:20.276846 140128494741248 run_lib.py:152] step: 180900, training_loss: 3.05614e+01
I0514 21:38:20.327236 140128494741248 run_lib.py:165] step: 180900, eval_loss: 1.96331e+01
I0514 21:38:26.654879 140128494741248 run_lib.py:152] step: 180950, training_loss: 1.87998e+01
I0514 21:38:33.114276 140128494741248 run_lib.py:152] step: 181000, training_loss: 3.42446e+01
I0514 21:38:33.166097 140128494741248 run_lib.py:165] step: 181000, eval_loss: 4.59450e+01
I0514 21:38:39.373054 140128494741248 run_lib.py:152] step: 181050, training_loss: 2.07636e+01
I0514 21:38:45.631083 140128494741248 run_lib.py:152] step: 181100, training_loss: 3.38610e+01
I0514 21:38:45.685552 140128494741248 run_lib.py:165] step: 181100, eval_loss: 4.47238e+01
I0514 21:38:52.034106 140128494741248 run_lib.py:152] step: 181150, training_loss: 2.69171e+01
I0514 21:38:58.305472 140128494741248 run_lib.py:152] step: 181200, training_loss: 3.01290e+01
I0514 21:38:58.362201 140128494741248 run_lib.py:165] step: 181200, eval_loss: 3.29240e+01
I0514 21:39:04.580137 140128494741248 run_lib.py:152] step: 181250, training_loss: 3.33396e+01
I0514 21:39:10.822156 140128494741248 run_lib.py:152] step: 181300, training_loss: 3.72236e+01
I0514 21:39:10.878920 140128494741248 run_lib.py:165] step: 181300, eval_loss: 3.13377e+01
I0514 21:39:17.218789 140128494741248 run_lib.py:152] step: 181350, training_loss: 3.44195e+01
I0514 21:39:23.482010 140128494741248 run_lib.py:152] step: 181400, training_loss: 3.81505e+01
I0514 21:39:23.531746 140128494741248 run_lib.py:165] step: 181400, eval_loss: 2.02486e+01
I0514 21:39:29.697630 140128494741248 run_lib.py:152] step: 181450, training_loss: 2.88328e+01
I0514 21:39:36.122976 140128494741248 run_lib.py:152] step: 181500, training_loss: 3.47993e+01
I0514 21:39:36.174171 140128494741248 run_lib.py:165] step: 181500, eval_loss: 3.57120e+01
I0514 21:39:42.269183 140128494741248 run_lib.py:152] step: 181550, training_loss: 2.87633e+01
I0514 21:39:48.447590 140128494741248 run_lib.py:152] step: 181600, training_loss: 3.66208e+01
I0514 21:39:48.498252 140128494741248 run_lib.py:165] step: 181600, eval_loss: 2.27471e+01
I0514 21:39:54.787512 140128494741248 run_lib.py:152] step: 181650, training_loss: 4.46542e+01
I0514 21:40:01.227918 140128494741248 run_lib.py:152] step: 181700, training_loss: 3.00363e+01
I0514 21:40:01.278403 140128494741248 run_lib.py:165] step: 181700, eval_loss: 3.65018e+01
I0514 21:40:07.419080 140128494741248 run_lib.py:152] step: 181750, training_loss: 2.69018e+01
I0514 21:40:13.647393 140128494741248 run_lib.py:152] step: 181800, training_loss: 2.84351e+01
I0514 21:40:13.701210 140128494741248 run_lib.py:165] step: 181800, eval_loss: 1.89360e+01
I0514 21:40:20.116096 140128494741248 run_lib.py:152] step: 181850, training_loss: 3.29005e+01
I0514 21:40:26.358983 140128494741248 run_lib.py:152] step: 181900, training_loss: 3.92534e+01
I0514 21:40:26.411679 140128494741248 run_lib.py:165] step: 181900, eval_loss: 2.66486e+01
I0514 21:40:32.527684 140128494741248 run_lib.py:152] step: 181950, training_loss: 3.39777e+01
I0514 21:40:38.756538 140128494741248 run_lib.py:152] step: 182000, training_loss: 2.81224e+01
I0514 21:40:38.807677 140128494741248 run_lib.py:165] step: 182000, eval_loss: 2.12220e+01
I0514 21:40:45.253389 140128494741248 run_lib.py:152] step: 182050, training_loss: 2.38147e+01
I0514 21:40:51.503097 140128494741248 run_lib.py:152] step: 182100, training_loss: 3.50535e+01
I0514 21:40:51.559277 140128494741248 run_lib.py:165] step: 182100, eval_loss: 2.30835e+01
I0514 21:40:57.713755 140128494741248 run_lib.py:152] step: 182150, training_loss: 2.78154e+01
I0514 21:41:04.180706 140128494741248 run_lib.py:152] step: 182200, training_loss: 3.51546e+01
I0514 21:41:04.231699 140128494741248 run_lib.py:165] step: 182200, eval_loss: 5.33661e+01
I0514 21:41:10.340910 140128494741248 run_lib.py:152] step: 182250, training_loss: 3.14513e+01
I0514 21:41:16.549589 140128494741248 run_lib.py:152] step: 182300, training_loss: 3.62328e+01
I0514 21:41:16.602356 140128494741248 run_lib.py:165] step: 182300, eval_loss: 1.58462e+01
I0514 21:41:22.811374 140128494741248 run_lib.py:152] step: 182350, training_loss: 4.24873e+01
I0514 21:41:29.236125 140128494741248 run_lib.py:152] step: 182400, training_loss: 2.19507e+01
I0514 21:41:29.287361 140128494741248 run_lib.py:165] step: 182400, eval_loss: 3.10212e+01
I0514 21:41:35.461073 140128494741248 run_lib.py:152] step: 182450, training_loss: 3.69708e+01
I0514 21:41:41.606785 140128494741248 run_lib.py:152] step: 182500, training_loss: 2.14611e+01
I0514 21:41:41.655189 140128494741248 run_lib.py:165] step: 182500, eval_loss: 3.60332e+01
I0514 21:41:48.207329 140128494741248 run_lib.py:152] step: 182550, training_loss: 3.68262e+01
I0514 21:41:54.319745 140128494741248 run_lib.py:152] step: 182600, training_loss: 2.58559e+01
I0514 21:41:54.369472 140128494741248 run_lib.py:165] step: 182600, eval_loss: 3.33022e+01
I0514 21:42:00.558955 140128494741248 run_lib.py:152] step: 182650, training_loss: 3.06621e+01
I0514 21:42:06.849969 140128494741248 run_lib.py:152] step: 182700, training_loss: 3.55861e+01
I0514 21:42:06.904686 140128494741248 run_lib.py:165] step: 182700, eval_loss: 2.35269e+01
I0514 21:42:13.251394 140128494741248 run_lib.py:152] step: 182750, training_loss: 4.30961e+01
I0514 21:42:19.445134 140128494741248 run_lib.py:152] step: 182800, training_loss: 2.83946e+01
I0514 21:42:19.499711 140128494741248 run_lib.py:165] step: 182800, eval_loss: 2.48485e+01
I0514 21:42:25.701252 140128494741248 run_lib.py:152] step: 182850, training_loss: 1.64712e+01
I0514 21:42:32.065321 140128494741248 run_lib.py:152] step: 182900, training_loss: 2.10349e+01
I0514 21:42:32.116230 140128494741248 run_lib.py:165] step: 182900, eval_loss: 4.52690e+01
I0514 21:42:38.355083 140128494741248 run_lib.py:152] step: 182950, training_loss: 3.11505e+01
I0514 21:42:44.566229 140128494741248 run_lib.py:152] step: 183000, training_loss: 2.86607e+01
I0514 21:42:44.622577 140128494741248 run_lib.py:165] step: 183000, eval_loss: 3.78399e+01
I0514 21:42:50.838759 140128494741248 run_lib.py:152] step: 183050, training_loss: 4.55862e+01
I0514 21:42:57.364722 140128494741248 run_lib.py:152] step: 183100, training_loss: 3.96956e+01
I0514 21:42:57.417050 140128494741248 run_lib.py:165] step: 183100, eval_loss: 3.79607e+01
I0514 21:43:03.583742 140128494741248 run_lib.py:152] step: 183150, training_loss: 4.47061e+01
I0514 21:43:09.837638 140128494741248 run_lib.py:152] step: 183200, training_loss: 4.63673e+01
I0514 21:43:09.889048 140128494741248 run_lib.py:165] step: 183200, eval_loss: 2.66215e+01
I0514 21:43:16.348593 140128494741248 run_lib.py:152] step: 183250, training_loss: 3.32278e+01
I0514 21:43:22.542734 140128494741248 run_lib.py:152] step: 183300, training_loss: 4.73861e+01
I0514 21:43:22.595729 140128494741248 run_lib.py:165] step: 183300, eval_loss: 3.03334e+01
I0514 21:43:28.795695 140128494741248 run_lib.py:152] step: 183350, training_loss: 1.36934e+01
I0514 21:43:34.981912 140128494741248 run_lib.py:152] step: 183400, training_loss: 2.54469e+01
I0514 21:43:35.030199 140128494741248 run_lib.py:165] step: 183400, eval_loss: 3.97265e+01
I0514 21:43:41.523789 140128494741248 run_lib.py:152] step: 183450, training_loss: 4.12702e+01
I0514 21:43:47.713302 140128494741248 run_lib.py:152] step: 183500, training_loss: 5.36692e+01
I0514 21:43:47.761594 140128494741248 run_lib.py:165] step: 183500, eval_loss: 3.98483e+01
I0514 21:43:53.932502 140128494741248 run_lib.py:152] step: 183550, training_loss: 4.26142e+01
I0514 21:44:00.203879 140128494741248 run_lib.py:152] step: 183600, training_loss: 2.89828e+01
I0514 21:44:00.480852 140128494741248 run_lib.py:165] step: 183600, eval_loss: 3.29513e+01
I0514 21:44:06.687997 140128494741248 run_lib.py:152] step: 183650, training_loss: 2.37344e+01
I0514 21:44:12.848440 140128494741248 run_lib.py:152] step: 183700, training_loss: 2.64854e+01
I0514 21:44:12.899745 140128494741248 run_lib.py:165] step: 183700, eval_loss: 3.67259e+01
I0514 21:44:19.103720 140128494741248 run_lib.py:152] step: 183750, training_loss: 2.94026e+01
I0514 21:44:25.490474 140128494741248 run_lib.py:152] step: 183800, training_loss: 3.63634e+01
I0514 21:44:25.541584 140128494741248 run_lib.py:165] step: 183800, eval_loss: 3.18980e+01
I0514 21:44:31.683110 140128494741248 run_lib.py:152] step: 183850, training_loss: 3.28398e+01
I0514 21:44:37.858013 140128494741248 run_lib.py:152] step: 183900, training_loss: 3.41100e+01
I0514 21:44:37.909838 140128494741248 run_lib.py:165] step: 183900, eval_loss: 1.58261e+01
I0514 21:44:44.350454 140128494741248 run_lib.py:152] step: 183950, training_loss: 3.31016e+01
I0514 21:44:50.513597 140128494741248 run_lib.py:152] step: 184000, training_loss: 2.54442e+01
I0514 21:44:50.564846 140128494741248 run_lib.py:165] step: 184000, eval_loss: 2.35599e+01
I0514 21:44:56.656526 140128494741248 run_lib.py:152] step: 184050, training_loss: 3.71278e+01
I0514 21:45:02.825219 140128494741248 run_lib.py:152] step: 184100, training_loss: 3.50878e+01
I0514 21:45:02.876041 140128494741248 run_lib.py:165] step: 184100, eval_loss: 3.03890e+01
I0514 21:45:09.320106 140128494741248 run_lib.py:152] step: 184150, training_loss: 3.07616e+01
I0514 21:45:15.526051 140128494741248 run_lib.py:152] step: 184200, training_loss: 1.76666e+01
I0514 21:45:15.576865 140128494741248 run_lib.py:165] step: 184200, eval_loss: 3.71981e+01
I0514 21:45:21.825521 140128494741248 run_lib.py:152] step: 184250, training_loss: 5.89220e+01
I0514 21:45:28.275052 140128494741248 run_lib.py:152] step: 184300, training_loss: 2.36032e+01
I0514 21:45:28.328226 140128494741248 run_lib.py:165] step: 184300, eval_loss: 2.87506e+01
I0514 21:45:34.535479 140128494741248 run_lib.py:152] step: 184350, training_loss: 3.20041e+01
I0514 21:45:40.760567 140128494741248 run_lib.py:152] step: 184400, training_loss: 3.59861e+01
I0514 21:45:40.809595 140128494741248 run_lib.py:165] step: 184400, eval_loss: 2.66613e+01
I0514 21:45:47.091443 140128494741248 run_lib.py:152] step: 184450, training_loss: 2.67583e+01
I0514 21:45:53.528739 140128494741248 run_lib.py:152] step: 184500, training_loss: 2.89932e+01
I0514 21:45:53.580956 140128494741248 run_lib.py:165] step: 184500, eval_loss: 2.57724e+01
I0514 21:45:59.782114 140128494741248 run_lib.py:152] step: 184550, training_loss: 3.07586e+01
I0514 21:46:05.898357 140128494741248 run_lib.py:152] step: 184600, training_loss: 2.21491e+01
I0514 21:46:05.949783 140128494741248 run_lib.py:165] step: 184600, eval_loss: 3.33400e+01
I0514 21:46:12.332318 140128494741248 run_lib.py:152] step: 184650, training_loss: 1.91690e+01
I0514 21:46:18.521348 140128494741248 run_lib.py:152] step: 184700, training_loss: 2.74842e+01
I0514 21:46:18.575042 140128494741248 run_lib.py:165] step: 184700, eval_loss: 3.01950e+01
I0514 21:46:24.781770 140128494741248 run_lib.py:152] step: 184750, training_loss: 3.86690e+01
I0514 21:46:30.890599 140128494741248 run_lib.py:152] step: 184800, training_loss: 3.24920e+01
I0514 21:46:30.942503 140128494741248 run_lib.py:165] step: 184800, eval_loss: 1.69678e+01
I0514 21:46:37.355105 140128494741248 run_lib.py:152] step: 184850, training_loss: 3.38030e+01
I0514 21:46:43.664586 140128494741248 run_lib.py:152] step: 184900, training_loss: 3.33676e+01
I0514 21:46:43.713144 140128494741248 run_lib.py:165] step: 184900, eval_loss: 4.34341e+01
I0514 21:46:49.857606 140128494741248 run_lib.py:152] step: 184950, training_loss: 1.75181e+01
I0514 21:46:56.288458 140128494741248 run_lib.py:152] step: 185000, training_loss: 2.98728e+01
I0514 21:46:56.340112 140128494741248 run_lib.py:165] step: 185000, eval_loss: 2.74688e+01
I0514 21:47:02.690790 140128494741248 run_lib.py:152] step: 185050, training_loss: 2.14185e+01
I0514 21:47:08.871802 140128494741248 run_lib.py:152] step: 185100, training_loss: 5.17702e+01
I0514 21:47:08.924390 140128494741248 run_lib.py:165] step: 185100, eval_loss: 4.23094e+01
I0514 21:47:15.133394 140128494741248 run_lib.py:152] step: 185150, training_loss: 2.07018e+01
I0514 21:47:21.464216 140128494741248 run_lib.py:152] step: 185200, training_loss: 3.30026e+01
I0514 21:47:21.516955 140128494741248 run_lib.py:165] step: 185200, eval_loss: 3.14744e+01
I0514 21:47:27.748625 140128494741248 run_lib.py:152] step: 185250, training_loss: 2.56654e+01
I0514 21:47:33.915869 140128494741248 run_lib.py:152] step: 185300, training_loss: 3.03622e+01
I0514 21:47:33.968420 140128494741248 run_lib.py:165] step: 185300, eval_loss: 3.96313e+01
I0514 21:47:40.422317 140128494741248 run_lib.py:152] step: 185350, training_loss: 3.13065e+01
I0514 21:47:46.614146 140128494741248 run_lib.py:152] step: 185400, training_loss: 3.41541e+01
I0514 21:47:46.668277 140128494741248 run_lib.py:165] step: 185400, eval_loss: 2.45974e+01
I0514 21:47:52.852896 140128494741248 run_lib.py:152] step: 185450, training_loss: 2.71827e+01
I0514 21:47:59.037417 140128494741248 run_lib.py:152] step: 185500, training_loss: 3.38470e+01
I0514 21:47:59.089025 140128494741248 run_lib.py:165] step: 185500, eval_loss: 3.18665e+01
I0514 21:48:05.515281 140128494741248 run_lib.py:152] step: 185550, training_loss: 4.27667e+01
I0514 21:48:11.708331 140128494741248 run_lib.py:152] step: 185600, training_loss: 3.23558e+01
I0514 21:48:11.759309 140128494741248 run_lib.py:165] step: 185600, eval_loss: 2.27069e+01
I0514 21:48:17.991450 140128494741248 run_lib.py:152] step: 185650, training_loss: 3.76434e+01
I0514 21:48:24.387978 140128494741248 run_lib.py:152] step: 185700, training_loss: 2.70774e+01
I0514 21:48:24.438339 140128494741248 run_lib.py:165] step: 185700, eval_loss: 3.07371e+01
I0514 21:48:30.753066 140128494741248 run_lib.py:152] step: 185750, training_loss: 1.61446e+01
I0514 21:48:36.875475 140128494741248 run_lib.py:152] step: 185800, training_loss: 3.07643e+01
I0514 21:48:36.926549 140128494741248 run_lib.py:165] step: 185800, eval_loss: 3.36414e+01
I0514 21:48:43.096429 140128494741248 run_lib.py:152] step: 185850, training_loss: 2.21831e+01
I0514 21:48:49.543056 140128494741248 run_lib.py:152] step: 185900, training_loss: 4.05116e+01
I0514 21:48:49.597878 140128494741248 run_lib.py:165] step: 185900, eval_loss: 5.00378e+01
I0514 21:48:55.761685 140128494741248 run_lib.py:152] step: 185950, training_loss: 2.63211e+01
I0514 21:49:01.893180 140128494741248 run_lib.py:152] step: 186000, training_loss: 3.11008e+01
I0514 21:49:01.944948 140128494741248 run_lib.py:165] step: 186000, eval_loss: 2.15516e+01
I0514 21:49:08.462944 140128494741248 run_lib.py:152] step: 186050, training_loss: 4.71462e+01
I0514 21:49:14.559169 140128494741248 run_lib.py:152] step: 186100, training_loss: 5.09002e+01
I0514 21:49:14.611196 140128494741248 run_lib.py:165] step: 186100, eval_loss: 2.70540e+01
I0514 21:49:20.801927 140128494741248 run_lib.py:152] step: 186150, training_loss: 3.59145e+01
I0514 21:49:26.921186 140128494741248 run_lib.py:152] step: 186200, training_loss: 2.95869e+01
I0514 21:49:26.970993 140128494741248 run_lib.py:165] step: 186200, eval_loss: 3.20818e+01
I0514 21:49:33.353769 140128494741248 run_lib.py:152] step: 186250, training_loss: 2.65616e+01
I0514 21:49:39.552338 140128494741248 run_lib.py:152] step: 186300, training_loss: 5.28670e+01
I0514 21:49:39.601919 140128494741248 run_lib.py:165] step: 186300, eval_loss: 4.19358e+01
I0514 21:49:45.755704 140128494741248 run_lib.py:152] step: 186350, training_loss: 3.05770e+01
I0514 21:49:52.032245 140128494741248 run_lib.py:152] step: 186400, training_loss: 2.31277e+01
I0514 21:49:52.082927 140128494741248 run_lib.py:165] step: 186400, eval_loss: 1.79478e+01
I0514 21:49:58.357734 140128494741248 run_lib.py:152] step: 186450, training_loss: 2.00547e+01
I0514 21:50:04.574422 140128494741248 run_lib.py:152] step: 186500, training_loss: 3.73116e+01
I0514 21:50:04.630598 140128494741248 run_lib.py:165] step: 186500, eval_loss: 3.39612e+01
I0514 21:50:10.851406 140128494741248 run_lib.py:152] step: 186550, training_loss: 2.77537e+01
I0514 21:50:17.260997 140128494741248 run_lib.py:152] step: 186600, training_loss: 4.54700e+01
I0514 21:50:17.316301 140128494741248 run_lib.py:165] step: 186600, eval_loss: 2.08203e+01
I0514 21:50:23.547671 140128494741248 run_lib.py:152] step: 186650, training_loss: 3.71657e+01
I0514 21:50:29.732610 140128494741248 run_lib.py:152] step: 186700, training_loss: 3.83309e+01
I0514 21:50:29.789265 140128494741248 run_lib.py:165] step: 186700, eval_loss: 2.86973e+01
I0514 21:50:36.221559 140128494741248 run_lib.py:152] step: 186750, training_loss: 2.83663e+01
I0514 21:50:42.420224 140128494741248 run_lib.py:152] step: 186800, training_loss: 2.81537e+01
I0514 21:50:42.471454 140128494741248 run_lib.py:165] step: 186800, eval_loss: 3.40107e+01
I0514 21:50:48.625916 140128494741248 run_lib.py:152] step: 186850, training_loss: 4.35898e+01
I0514 21:50:54.761299 140128494741248 run_lib.py:152] step: 186900, training_loss: 2.55793e+01
I0514 21:50:54.813648 140128494741248 run_lib.py:165] step: 186900, eval_loss: 3.67402e+01
I0514 21:51:01.253037 140128494741248 run_lib.py:152] step: 186950, training_loss: 4.34112e+01
I0514 21:51:07.476436 140128494741248 run_lib.py:152] step: 187000, training_loss: 4.16954e+01
I0514 21:51:07.527544 140128494741248 run_lib.py:165] step: 187000, eval_loss: 1.20437e+01
I0514 21:51:13.802779 140128494741248 run_lib.py:152] step: 187050, training_loss: 2.58259e+01
I0514 21:51:19.883510 140128494741248 run_lib.py:152] step: 187100, training_loss: 3.42996e+01
I0514 21:51:20.181302 140128494741248 run_lib.py:165] step: 187100, eval_loss: 2.24964e+01
I0514 21:51:26.465662 140128494741248 run_lib.py:152] step: 187150, training_loss: 1.93105e+01
I0514 21:51:32.650408 140128494741248 run_lib.py:152] step: 187200, training_loss: 5.14246e+01
I0514 21:51:32.702029 140128494741248 run_lib.py:165] step: 187200, eval_loss: 2.48439e+01
I0514 21:51:38.899565 140128494741248 run_lib.py:152] step: 187250, training_loss: 4.34997e+01
I0514 21:51:45.347823 140128494741248 run_lib.py:152] step: 187300, training_loss: 2.79957e+01
I0514 21:51:45.408184 140128494741248 run_lib.py:165] step: 187300, eval_loss: 2.89770e+01
I0514 21:51:51.507896 140128494741248 run_lib.py:152] step: 187350, training_loss: 3.92511e+01
I0514 21:51:57.678666 140128494741248 run_lib.py:152] step: 187400, training_loss: 3.23330e+01
I0514 21:51:57.732621 140128494741248 run_lib.py:165] step: 187400, eval_loss: 3.98829e+01
I0514 21:52:04.167170 140128494741248 run_lib.py:152] step: 187450, training_loss: 3.34634e+01
I0514 21:52:10.403123 140128494741248 run_lib.py:152] step: 187500, training_loss: 2.10013e+01
I0514 21:52:10.452156 140128494741248 run_lib.py:165] step: 187500, eval_loss: 2.52969e+01
I0514 21:52:16.601366 140128494741248 run_lib.py:152] step: 187550, training_loss: 3.65782e+01
I0514 21:52:22.844469 140128494741248 run_lib.py:152] step: 187600, training_loss: 2.88566e+01
I0514 21:52:22.900002 140128494741248 run_lib.py:165] step: 187600, eval_loss: 2.25398e+01
I0514 21:52:29.275131 140128494741248 run_lib.py:152] step: 187650, training_loss: 2.94510e+01
I0514 21:52:35.569766 140128494741248 run_lib.py:152] step: 187700, training_loss: 4.38959e+01
I0514 21:52:35.625586 140128494741248 run_lib.py:165] step: 187700, eval_loss: 2.83761e+01
I0514 21:52:41.841353 140128494741248 run_lib.py:152] step: 187750, training_loss: 3.49989e+01
I0514 21:52:48.258061 140128494741248 run_lib.py:152] step: 187800, training_loss: 2.90036e+01
I0514 21:52:48.309757 140128494741248 run_lib.py:165] step: 187800, eval_loss: 3.09836e+01
I0514 21:52:54.431164 140128494741248 run_lib.py:152] step: 187850, training_loss: 2.05133e+01
I0514 21:53:00.639694 140128494741248 run_lib.py:152] step: 187900, training_loss: 3.66448e+01
I0514 21:53:00.686909 140128494741248 run_lib.py:165] step: 187900, eval_loss: 3.82507e+01
I0514 21:53:06.886651 140128494741248 run_lib.py:152] step: 187950, training_loss: 2.79661e+01
I0514 21:53:13.345988 140128494741248 run_lib.py:152] step: 188000, training_loss: 3.90168e+01
I0514 21:53:13.399750 140128494741248 run_lib.py:165] step: 188000, eval_loss: 3.28160e+01
I0514 21:53:19.610240 140128494741248 run_lib.py:152] step: 188050, training_loss: 3.61439e+01
I0514 21:53:25.847525 140128494741248 run_lib.py:152] step: 188100, training_loss: 3.01485e+01
I0514 21:53:25.898501 140128494741248 run_lib.py:165] step: 188100, eval_loss: 3.20608e+01
I0514 21:53:32.278818 140128494741248 run_lib.py:152] step: 188150, training_loss: 4.85942e+01
I0514 21:53:38.462775 140128494741248 run_lib.py:152] step: 188200, training_loss: 2.76217e+01
I0514 21:53:38.523605 140128494741248 run_lib.py:165] step: 188200, eval_loss: 2.18657e+01
I0514 21:53:44.722490 140128494741248 run_lib.py:152] step: 188250, training_loss: 3.75844e+01
I0514 21:53:50.929957 140128494741248 run_lib.py:152] step: 188300, training_loss: 2.09311e+01
I0514 21:53:50.987186 140128494741248 run_lib.py:165] step: 188300, eval_loss: 2.98945e+01
I0514 21:53:57.466394 140128494741248 run_lib.py:152] step: 188350, training_loss: 2.08274e+01
I0514 21:54:03.715186 140128494741248 run_lib.py:152] step: 188400, training_loss: 3.13694e+01
I0514 21:54:03.767590 140128494741248 run_lib.py:165] step: 188400, eval_loss: 2.68129e+01
I0514 21:54:09.949633 140128494741248 run_lib.py:152] step: 188450, training_loss: 4.10618e+01
I0514 21:54:16.357838 140128494741248 run_lib.py:152] step: 188500, training_loss: 4.09827e+01
I0514 21:54:16.410499 140128494741248 run_lib.py:165] step: 188500, eval_loss: 2.93319e+01
I0514 21:54:22.643949 140128494741248 run_lib.py:152] step: 188550, training_loss: 2.75462e+01
I0514 21:54:28.968495 140128494741248 run_lib.py:152] step: 188600, training_loss: 2.90705e+01
I0514 21:54:29.027714 140128494741248 run_lib.py:165] step: 188600, eval_loss: 2.80281e+01
I0514 21:54:35.136072 140128494741248 run_lib.py:152] step: 188650, training_loss: 2.85318e+01
I0514 21:54:41.594679 140128494741248 run_lib.py:152] step: 188700, training_loss: 2.78144e+01
I0514 21:54:41.651480 140128494741248 run_lib.py:165] step: 188700, eval_loss: 5.40293e+01
I0514 21:54:47.775723 140128494741248 run_lib.py:152] step: 188750, training_loss: 2.44725e+01
I0514 21:54:53.975366 140128494741248 run_lib.py:152] step: 188800, training_loss: 2.96813e+01
I0514 21:54:54.027693 140128494741248 run_lib.py:165] step: 188800, eval_loss: 3.50927e+01
I0514 21:55:00.585697 140128494741248 run_lib.py:152] step: 188850, training_loss: 3.04037e+01
I0514 21:55:06.872751 140128494741248 run_lib.py:152] step: 188900, training_loss: 1.66235e+01
I0514 21:55:06.929572 140128494741248 run_lib.py:165] step: 188900, eval_loss: 4.75300e+01
I0514 21:55:13.138772 140128494741248 run_lib.py:152] step: 188950, training_loss: 4.00739e+01
I0514 21:55:19.238358 140128494741248 run_lib.py:152] step: 189000, training_loss: 4.02595e+01
I0514 21:55:19.287803 140128494741248 run_lib.py:165] step: 189000, eval_loss: 3.24143e+01
I0514 21:55:25.717690 140128494741248 run_lib.py:152] step: 189050, training_loss: 3.47070e+01
I0514 21:55:31.922308 140128494741248 run_lib.py:152] step: 189100, training_loss: 2.37651e+01
I0514 21:55:31.974204 140128494741248 run_lib.py:165] step: 189100, eval_loss: 2.64659e+01
I0514 21:55:38.140669 140128494741248 run_lib.py:152] step: 189150, training_loss: 2.86295e+01
I0514 21:55:44.516165 140128494741248 run_lib.py:152] step: 189200, training_loss: 1.87215e+01
I0514 21:55:44.575592 140128494741248 run_lib.py:165] step: 189200, eval_loss: 3.45853e+01
I0514 21:55:50.686972 140128494741248 run_lib.py:152] step: 189250, training_loss: 3.02324e+01
I0514 21:55:56.782935 140128494741248 run_lib.py:152] step: 189300, training_loss: 1.81838e+01
I0514 21:55:56.832165 140128494741248 run_lib.py:165] step: 189300, eval_loss: 4.51860e+01
I0514 21:56:03.034410 140128494741248 run_lib.py:152] step: 189350, training_loss: 3.23215e+01
I0514 21:56:09.564915 140128494741248 run_lib.py:152] step: 189400, training_loss: 3.31634e+01
I0514 21:56:09.620166 140128494741248 run_lib.py:165] step: 189400, eval_loss: 1.95642e+01
I0514 21:56:15.832232 140128494741248 run_lib.py:152] step: 189450, training_loss: 2.22985e+01
I0514 21:56:21.992609 140128494741248 run_lib.py:152] step: 189500, training_loss: 2.25983e+01
I0514 21:56:22.042565 140128494741248 run_lib.py:165] step: 189500, eval_loss: 3.13800e+01
I0514 21:56:28.437900 140128494741248 run_lib.py:152] step: 189550, training_loss: 2.93840e+01
I0514 21:56:34.587519 140128494741248 run_lib.py:152] step: 189600, training_loss: 3.93431e+01
I0514 21:56:34.641150 140128494741248 run_lib.py:165] step: 189600, eval_loss: 3.79038e+01
I0514 21:56:40.814701 140128494741248 run_lib.py:152] step: 189650, training_loss: 2.51582e+01
I0514 21:56:46.919599 140128494741248 run_lib.py:152] step: 189700, training_loss: 3.01793e+01
I0514 21:56:46.970671 140128494741248 run_lib.py:165] step: 189700, eval_loss: 2.63891e+01
I0514 21:56:53.476420 140128494741248 run_lib.py:152] step: 189750, training_loss: 2.06489e+01
I0514 21:56:59.632409 140128494741248 run_lib.py:152] step: 189800, training_loss: 3.93102e+01
I0514 21:56:59.682805 140128494741248 run_lib.py:165] step: 189800, eval_loss: 2.43756e+01
I0514 21:57:05.887089 140128494741248 run_lib.py:152] step: 189850, training_loss: 2.77369e+01
I0514 21:57:12.253662 140128494741248 run_lib.py:152] step: 189900, training_loss: 3.23817e+01
I0514 21:57:12.313732 140128494741248 run_lib.py:165] step: 189900, eval_loss: 2.59404e+01
I0514 21:57:18.559412 140128494741248 run_lib.py:152] step: 189950, training_loss: 2.42774e+01
I0514 21:57:24.777441 140128494741248 run_lib.py:152] step: 190000, training_loss: 2.98051e+01
I0514 21:57:24.983718 140128494741248 run_lib.py:165] step: 190000, eval_loss: 2.18372e+01
I0514 21:57:31.168521 140128494741248 run_lib.py:152] step: 190050, training_loss: 3.40643e+01
I0514 21:57:37.506627 140128494741248 run_lib.py:152] step: 190100, training_loss: 2.90418e+01
I0514 21:57:37.559793 140128494741248 run_lib.py:165] step: 190100, eval_loss: 1.92849e+01
I0514 21:57:43.778478 140128494741248 run_lib.py:152] step: 190150, training_loss: 2.94716e+01
I0514 21:57:50.035716 140128494741248 run_lib.py:152] step: 190200, training_loss: 5.14537e+01
I0514 21:57:50.095119 140128494741248 run_lib.py:165] step: 190200, eval_loss: 4.29694e+01
I0514 21:57:56.555812 140128494741248 run_lib.py:152] step: 190250, training_loss: 4.08312e+01
I0514 21:58:02.717749 140128494741248 run_lib.py:152] step: 190300, training_loss: 3.27228e+01
I0514 21:58:02.769719 140128494741248 run_lib.py:165] step: 190300, eval_loss: 2.78238e+01
I0514 21:58:08.959480 140128494741248 run_lib.py:152] step: 190350, training_loss: 2.50225e+01
I0514 21:58:15.152057 140128494741248 run_lib.py:152] step: 190400, training_loss: 3.55873e+01
I0514 21:58:15.203513 140128494741248 run_lib.py:165] step: 190400, eval_loss: 3.15746e+01
I0514 21:58:21.679478 140128494741248 run_lib.py:152] step: 190450, training_loss: 3.28027e+01
I0514 21:58:27.904072 140128494741248 run_lib.py:152] step: 190500, training_loss: 3.42702e+01
I0514 21:58:27.959229 140128494741248 run_lib.py:165] step: 190500, eval_loss: 2.07013e+01
I0514 21:58:34.148802 140128494741248 run_lib.py:152] step: 190550, training_loss: 3.49592e+01
I0514 21:58:40.332297 140128494741248 run_lib.py:152] step: 190600, training_loss: 2.52184e+01
I0514 21:58:40.604451 140128494741248 run_lib.py:165] step: 190600, eval_loss: 3.29816e+01
I0514 21:58:46.841593 140128494741248 run_lib.py:152] step: 190650, training_loss: 4.47148e+01
I0514 21:58:52.991668 140128494741248 run_lib.py:152] step: 190700, training_loss: 4.85346e+01
I0514 21:58:53.043048 140128494741248 run_lib.py:165] step: 190700, eval_loss: 8.92054e+00
I0514 21:58:59.228237 140128494741248 run_lib.py:152] step: 190750, training_loss: 3.05439e+01
I0514 21:59:05.802517 140128494741248 run_lib.py:152] step: 190800, training_loss: 2.60368e+01
I0514 21:59:05.856335 140128494741248 run_lib.py:165] step: 190800, eval_loss: 2.46100e+01
I0514 21:59:12.023394 140128494741248 run_lib.py:152] step: 190850, training_loss: 2.13025e+01
I0514 21:59:18.247093 140128494741248 run_lib.py:152] step: 190900, training_loss: 3.88830e+01
I0514 21:59:18.300203 140128494741248 run_lib.py:165] step: 190900, eval_loss: 2.90888e+01
I0514 21:59:24.719200 140128494741248 run_lib.py:152] step: 190950, training_loss: 2.79272e+01
I0514 21:59:30.874625 140128494741248 run_lib.py:152] step: 191000, training_loss: 3.89727e+01
I0514 21:59:30.927752 140128494741248 run_lib.py:165] step: 191000, eval_loss: 4.13512e+01
I0514 21:59:37.155067 140128494741248 run_lib.py:152] step: 191050, training_loss: 2.24803e+01
I0514 21:59:43.293122 140128494741248 run_lib.py:152] step: 191100, training_loss: 5.90835e+01
I0514 21:59:43.341050 140128494741248 run_lib.py:165] step: 191100, eval_loss: 2.89036e+01
I0514 21:59:49.782403 140128494741248 run_lib.py:152] step: 191150, training_loss: 4.34804e+01
I0514 21:59:55.972447 140128494741248 run_lib.py:152] step: 191200, training_loss: 2.56297e+01
I0514 21:59:56.022829 140128494741248 run_lib.py:165] step: 191200, eval_loss: 5.14209e+01
I0514 22:00:02.174551 140128494741248 run_lib.py:152] step: 191250, training_loss: 2.81242e+01
I0514 22:00:08.612679 140128494741248 run_lib.py:152] step: 191300, training_loss: 2.36482e+01
I0514 22:00:08.666659 140128494741248 run_lib.py:165] step: 191300, eval_loss: 2.31526e+01
I0514 22:00:14.848330 140128494741248 run_lib.py:152] step: 191350, training_loss: 3.70698e+01
I0514 22:00:21.117516 140128494741248 run_lib.py:152] step: 191400, training_loss: 3.61460e+01
I0514 22:00:21.168601 140128494741248 run_lib.py:165] step: 191400, eval_loss: 4.19591e+01
I0514 22:00:27.318777 140128494741248 run_lib.py:152] step: 191450, training_loss: 2.65159e+01
I0514 22:00:33.757483 140128494741248 run_lib.py:152] step: 191500, training_loss: 3.91541e+01
I0514 22:00:33.811266 140128494741248 run_lib.py:165] step: 191500, eval_loss: 2.70218e+01
I0514 22:00:40.051699 140128494741248 run_lib.py:152] step: 191550, training_loss: 3.52462e+01
I0514 22:00:46.177603 140128494741248 run_lib.py:152] step: 191600, training_loss: 2.63114e+01
I0514 22:00:46.230761 140128494741248 run_lib.py:165] step: 191600, eval_loss: 2.68818e+01
I0514 22:00:52.715311 140128494741248 run_lib.py:152] step: 191650, training_loss: 3.09708e+01
I0514 22:00:58.983375 140128494741248 run_lib.py:152] step: 191700, training_loss: 2.76304e+01
I0514 22:00:59.036200 140128494741248 run_lib.py:165] step: 191700, eval_loss: 4.26769e+01
I0514 22:01:05.401932 140128494741248 run_lib.py:152] step: 191750, training_loss: 4.60063e+01
I0514 22:01:11.583637 140128494741248 run_lib.py:152] step: 191800, training_loss: 2.68450e+01
I0514 22:01:11.636619 140128494741248 run_lib.py:165] step: 191800, eval_loss: 2.74251e+01
I0514 22:01:18.038404 140128494741248 run_lib.py:152] step: 191850, training_loss: 1.91604e+01
I0514 22:01:24.314979 140128494741248 run_lib.py:152] step: 191900, training_loss: 5.74089e+01
I0514 22:01:24.374095 140128494741248 run_lib.py:165] step: 191900, eval_loss: 2.70538e+01
I0514 22:01:30.650264 140128494741248 run_lib.py:152] step: 191950, training_loss: 3.20645e+01
I0514 22:01:36.975230 140128494741248 run_lib.py:152] step: 192000, training_loss: 2.96714e+01
I0514 22:01:37.031544 140128494741248 run_lib.py:165] step: 192000, eval_loss: 2.77321e+01
I0514 22:01:43.262738 140128494741248 run_lib.py:152] step: 192050, training_loss: 4.91906e+01
I0514 22:01:49.510008 140128494741248 run_lib.py:152] step: 192100, training_loss: 3.02811e+01
I0514 22:01:49.565807 140128494741248 run_lib.py:165] step: 192100, eval_loss: 1.70176e+01
I0514 22:01:55.652715 140128494741248 run_lib.py:152] step: 192150, training_loss: 2.97340e+01
I0514 22:02:02.174961 140128494741248 run_lib.py:152] step: 192200, training_loss: 3.94618e+01
I0514 22:02:02.235221 140128494741248 run_lib.py:165] step: 192200, eval_loss: 3.22522e+01
I0514 22:02:08.494790 140128494741248 run_lib.py:152] step: 192250, training_loss: 3.58874e+01
I0514 22:02:14.639705 140128494741248 run_lib.py:152] step: 192300, training_loss: 3.21282e+01
I0514 22:02:14.688447 140128494741248 run_lib.py:165] step: 192300, eval_loss: 4.31927e+01
I0514 22:02:21.193780 140128494741248 run_lib.py:152] step: 192350, training_loss: 2.81850e+01
I0514 22:02:27.361562 140128494741248 run_lib.py:152] step: 192400, training_loss: 2.39159e+01
I0514 22:02:27.416252 140128494741248 run_lib.py:165] step: 192400, eval_loss: 2.96959e+01
I0514 22:02:33.631180 140128494741248 run_lib.py:152] step: 192450, training_loss: 3.75293e+01
I0514 22:02:39.816171 140128494741248 run_lib.py:152] step: 192500, training_loss: 2.36139e+01
I0514 22:02:39.872471 140128494741248 run_lib.py:165] step: 192500, eval_loss: 2.74826e+01
I0514 22:02:46.312942 140128494741248 run_lib.py:152] step: 192550, training_loss: 2.16612e+01
I0514 22:02:52.530613 140128494741248 run_lib.py:152] step: 192600, training_loss: 2.64505e+01
I0514 22:02:52.581451 140128494741248 run_lib.py:165] step: 192600, eval_loss: 2.99582e+01
I0514 22:02:58.662956 140128494741248 run_lib.py:152] step: 192650, training_loss: 3.32324e+01
I0514 22:03:05.098918 140128494741248 run_lib.py:152] step: 192700, training_loss: 2.58622e+01
I0514 22:03:05.160546 140128494741248 run_lib.py:165] step: 192700, eval_loss: 2.11155e+01
I0514 22:03:11.310184 140128494741248 run_lib.py:152] step: 192750, training_loss: 3.56440e+01
I0514 22:03:17.531203 140128494741248 run_lib.py:152] step: 192800, training_loss: 3.34377e+01
I0514 22:03:17.580613 140128494741248 run_lib.py:165] step: 192800, eval_loss: 3.17899e+01
I0514 22:03:23.778918 140128494741248 run_lib.py:152] step: 192850, training_loss: 3.25379e+01
I0514 22:03:30.300514 140128494741248 run_lib.py:152] step: 192900, training_loss: 1.48798e+01
I0514 22:03:30.346599 140128494741248 run_lib.py:165] step: 192900, eval_loss: 3.47189e+01
I0514 22:03:36.481303 140128494741248 run_lib.py:152] step: 192950, training_loss: 3.48447e+01
I0514 22:03:42.740823 140128494741248 run_lib.py:152] step: 193000, training_loss: 2.85429e+01
I0514 22:03:42.794880 140128494741248 run_lib.py:165] step: 193000, eval_loss: 3.02208e+01
I0514 22:03:49.105338 140128494741248 run_lib.py:152] step: 193050, training_loss: 3.38663e+01
I0514 22:03:55.330737 140128494741248 run_lib.py:152] step: 193100, training_loss: 3.82372e+01
I0514 22:03:55.380199 140128494741248 run_lib.py:165] step: 193100, eval_loss: 3.86566e+01
I0514 22:04:01.634658 140128494741248 run_lib.py:152] step: 193150, training_loss: 2.27302e+01
I0514 22:04:07.739236 140128494741248 run_lib.py:152] step: 193200, training_loss: 2.94140e+01
I0514 22:04:07.791652 140128494741248 run_lib.py:165] step: 193200, eval_loss: 2.59424e+01
I0514 22:04:14.204407 140128494741248 run_lib.py:152] step: 193250, training_loss: 3.76245e+01
I0514 22:04:20.403728 140128494741248 run_lib.py:152] step: 193300, training_loss: 3.39531e+01
I0514 22:04:20.456832 140128494741248 run_lib.py:165] step: 193300, eval_loss: 2.10596e+01
I0514 22:04:26.778551 140128494741248 run_lib.py:152] step: 193350, training_loss: 3.88053e+01
I0514 22:04:33.153020 140128494741248 run_lib.py:152] step: 193400, training_loss: 3.95280e+01
I0514 22:04:33.202410 140128494741248 run_lib.py:165] step: 193400, eval_loss: 3.15943e+01
I0514 22:04:39.529859 140128494741248 run_lib.py:152] step: 193450, training_loss: 3.22440e+01
I0514 22:04:45.741570 140128494741248 run_lib.py:152] step: 193500, training_loss: 3.05742e+01
I0514 22:04:45.798460 140128494741248 run_lib.py:165] step: 193500, eval_loss: 3.01824e+01
I0514 22:04:52.105642 140128494741248 run_lib.py:152] step: 193550, training_loss: 4.77601e+01
I0514 22:04:58.507392 140128494741248 run_lib.py:152] step: 193600, training_loss: 4.33026e+01
I0514 22:04:58.567328 140128494741248 run_lib.py:165] step: 193600, eval_loss: 3.76786e+01
I0514 22:05:04.840873 140128494741248 run_lib.py:152] step: 193650, training_loss: 3.09331e+01
I0514 22:05:10.994064 140128494741248 run_lib.py:152] step: 193700, training_loss: 3.30950e+01
I0514 22:05:11.045222 140128494741248 run_lib.py:165] step: 193700, eval_loss: 2.10007e+01
I0514 22:05:17.425867 140128494741248 run_lib.py:152] step: 193750, training_loss: 3.46050e+01
I0514 22:05:23.632760 140128494741248 run_lib.py:152] step: 193800, training_loss: 3.80020e+01
I0514 22:05:23.689300 140128494741248 run_lib.py:165] step: 193800, eval_loss: 3.35528e+01
I0514 22:05:29.888253 140128494741248 run_lib.py:152] step: 193850, training_loss: 3.91640e+01
I0514 22:05:36.150849 140128494741248 run_lib.py:152] step: 193900, training_loss: 3.12351e+01
I0514 22:05:36.207897 140128494741248 run_lib.py:165] step: 193900, eval_loss: 3.24820e+01
I0514 22:05:42.670647 140128494741248 run_lib.py:152] step: 193950, training_loss: 2.93741e+01
I0514 22:05:48.868143 140128494741248 run_lib.py:152] step: 194000, training_loss: 3.40026e+01
I0514 22:05:48.925998 140128494741248 run_lib.py:165] step: 194000, eval_loss: 3.85783e+01
I0514 22:05:55.083820 140128494741248 run_lib.py:152] step: 194050, training_loss: 4.03984e+01
I0514 22:06:01.333713 140128494741248 run_lib.py:152] step: 194100, training_loss: 2.91431e+01
I0514 22:06:01.602105 140128494741248 run_lib.py:165] step: 194100, eval_loss: 2.65343e+01
I0514 22:06:07.835929 140128494741248 run_lib.py:152] step: 194150, training_loss: 2.51882e+01
I0514 22:06:14.033156 140128494741248 run_lib.py:152] step: 194200, training_loss: 2.52623e+01
I0514 22:06:14.082883 140128494741248 run_lib.py:165] step: 194200, eval_loss: 2.30816e+01
I0514 22:06:20.326399 140128494741248 run_lib.py:152] step: 194250, training_loss: 3.19232e+01
I0514 22:06:26.712329 140128494741248 run_lib.py:152] step: 194300, training_loss: 4.42108e+01
I0514 22:06:26.768164 140128494741248 run_lib.py:165] step: 194300, eval_loss: 4.19071e+01
I0514 22:06:32.972722 140128494741248 run_lib.py:152] step: 194350, training_loss: 2.80441e+01
I0514 22:06:39.071313 140128494741248 run_lib.py:152] step: 194400, training_loss: 1.43801e+01
I0514 22:06:39.121462 140128494741248 run_lib.py:165] step: 194400, eval_loss: 4.24891e+01
I0514 22:06:45.514596 140128494741248 run_lib.py:152] step: 194450, training_loss: 3.89136e+01
I0514 22:06:51.571626 140128494741248 run_lib.py:152] step: 194500, training_loss: 2.14588e+01
I0514 22:06:51.622504 140128494741248 run_lib.py:165] step: 194500, eval_loss: 3.04991e+01
I0514 22:06:57.808717 140128494741248 run_lib.py:152] step: 194550, training_loss: 2.47352e+01
I0514 22:07:04.046977 140128494741248 run_lib.py:152] step: 194600, training_loss: 3.78891e+01
I0514 22:07:04.104494 140128494741248 run_lib.py:165] step: 194600, eval_loss: 4.68081e+01
I0514 22:07:10.500710 140128494741248 run_lib.py:152] step: 194650, training_loss: 2.76378e+01
I0514 22:07:16.614491 140128494741248 run_lib.py:152] step: 194700, training_loss: 2.23590e+01
I0514 22:07:16.667145 140128494741248 run_lib.py:165] step: 194700, eval_loss: 3.06181e+01
I0514 22:07:22.776496 140128494741248 run_lib.py:152] step: 194750, training_loss: 3.55937e+01
I0514 22:07:29.190475 140128494741248 run_lib.py:152] step: 194800, training_loss: 4.21019e+01
I0514 22:07:29.236109 140128494741248 run_lib.py:165] step: 194800, eval_loss: 2.51796e+01
I0514 22:07:35.481896 140128494741248 run_lib.py:152] step: 194850, training_loss: 2.30635e+01
I0514 22:07:41.634234 140128494741248 run_lib.py:152] step: 194900, training_loss: 3.60278e+01
I0514 22:07:41.691045 140128494741248 run_lib.py:165] step: 194900, eval_loss: 2.06995e+01
I0514 22:07:47.913758 140128494741248 run_lib.py:152] step: 194950, training_loss: 2.95224e+01
I0514 22:07:54.351207 140128494741248 run_lib.py:152] step: 195000, training_loss: 2.70746e+01
I0514 22:07:54.404069 140128494741248 run_lib.py:165] step: 195000, eval_loss: 1.87893e+01
I0514 22:08:00.632236 140128494741248 run_lib.py:152] step: 195050, training_loss: 2.38680e+01
I0514 22:08:06.797189 140128494741248 run_lib.py:152] step: 195100, training_loss: 4.07020e+01
I0514 22:08:06.856081 140128494741248 run_lib.py:165] step: 195100, eval_loss: 3.46071e+01
I0514 22:08:13.268632 140128494741248 run_lib.py:152] step: 195150, training_loss: 3.56690e+01
I0514 22:08:19.453994 140128494741248 run_lib.py:152] step: 195200, training_loss: 5.29410e+01
I0514 22:08:19.501648 140128494741248 run_lib.py:165] step: 195200, eval_loss: 4.11762e+01
I0514 22:08:25.731881 140128494741248 run_lib.py:152] step: 195250, training_loss: 3.17841e+01
I0514 22:08:31.970877 140128494741248 run_lib.py:152] step: 195300, training_loss: 2.49877e+01
I0514 22:08:32.023484 140128494741248 run_lib.py:165] step: 195300, eval_loss: 3.10807e+01
I0514 22:08:38.425302 140128494741248 run_lib.py:152] step: 195350, training_loss: 2.45417e+01
I0514 22:08:44.656162 140128494741248 run_lib.py:152] step: 195400, training_loss: 2.45857e+01
I0514 22:08:44.713488 140128494741248 run_lib.py:165] step: 195400, eval_loss: 3.05533e+01
I0514 22:08:50.847532 140128494741248 run_lib.py:152] step: 195450, training_loss: 2.38443e+01
I0514 22:08:57.262959 140128494741248 run_lib.py:152] step: 195500, training_loss: 4.02666e+01
I0514 22:08:57.313152 140128494741248 run_lib.py:165] step: 195500, eval_loss: 3.63318e+01
I0514 22:09:03.570602 140128494741248 run_lib.py:152] step: 195550, training_loss: 3.03984e+01
I0514 22:09:09.788833 140128494741248 run_lib.py:152] step: 195600, training_loss: 2.38810e+01
I0514 22:09:09.838530 140128494741248 run_lib.py:165] step: 195600, eval_loss: 3.45721e+01
I0514 22:09:16.054676 140128494741248 run_lib.py:152] step: 195650, training_loss: 3.98552e+01
I0514 22:09:22.494533 140128494741248 run_lib.py:152] step: 195700, training_loss: 2.38413e+01
I0514 22:09:22.547867 140128494741248 run_lib.py:165] step: 195700, eval_loss: 4.02758e+01
I0514 22:09:28.725706 140128494741248 run_lib.py:152] step: 195750, training_loss: 3.40630e+01
I0514 22:09:34.972994 140128494741248 run_lib.py:152] step: 195800, training_loss: 2.74966e+01
I0514 22:09:35.024091 140128494741248 run_lib.py:165] step: 195800, eval_loss: 3.07481e+01
I0514 22:09:41.432915 140128494741248 run_lib.py:152] step: 195850, training_loss: 3.88342e+01
I0514 22:09:47.655673 140128494741248 run_lib.py:152] step: 195900, training_loss: 2.91413e+01
I0514 22:09:47.710395 140128494741248 run_lib.py:165] step: 195900, eval_loss: 3.84436e+01
I0514 22:09:53.891569 140128494741248 run_lib.py:152] step: 195950, training_loss: 3.08581e+01
I0514 22:10:00.084370 140128494741248 run_lib.py:152] step: 196000, training_loss: 3.27015e+01
I0514 22:10:00.141883 140128494741248 run_lib.py:165] step: 196000, eval_loss: 2.71697e+01
I0514 22:10:06.572620 140128494741248 run_lib.py:152] step: 196050, training_loss: 3.21545e+01
I0514 22:10:12.713262 140128494741248 run_lib.py:152] step: 196100, training_loss: 4.45914e+01
I0514 22:10:12.762586 140128494741248 run_lib.py:165] step: 196100, eval_loss: 1.53761e+01
I0514 22:10:18.954512 140128494741248 run_lib.py:152] step: 196150, training_loss: 3.02854e+01
I0514 22:10:25.351965 140128494741248 run_lib.py:152] step: 196200, training_loss: 2.32693e+01
I0514 22:10:25.403919 140128494741248 run_lib.py:165] step: 196200, eval_loss: 3.46784e+01
I0514 22:10:31.619741 140128494741248 run_lib.py:152] step: 196250, training_loss: 2.86612e+01
I0514 22:10:37.868306 140128494741248 run_lib.py:152] step: 196300, training_loss: 3.03501e+01
I0514 22:10:37.918126 140128494741248 run_lib.py:165] step: 196300, eval_loss: 5.16322e+01
I0514 22:10:44.138987 140128494741248 run_lib.py:152] step: 196350, training_loss: 1.60271e+01
I0514 22:10:50.598700 140128494741248 run_lib.py:152] step: 196400, training_loss: 3.35644e+01
I0514 22:10:50.651062 140128494741248 run_lib.py:165] step: 196400, eval_loss: 3.69349e+01
I0514 22:10:56.796405 140128494741248 run_lib.py:152] step: 196450, training_loss: 2.83696e+01
I0514 22:11:03.011060 140128494741248 run_lib.py:152] step: 196500, training_loss: 2.56101e+01
I0514 22:11:03.061025 140128494741248 run_lib.py:165] step: 196500, eval_loss: 1.72556e+01
I0514 22:11:09.448828 140128494741248 run_lib.py:152] step: 196550, training_loss: 4.32947e+01
I0514 22:11:15.618356 140128494741248 run_lib.py:152] step: 196600, training_loss: 2.69611e+01
I0514 22:11:15.671503 140128494741248 run_lib.py:165] step: 196600, eval_loss: 2.42812e+01
I0514 22:11:21.902386 140128494741248 run_lib.py:152] step: 196650, training_loss: 2.91328e+01
I0514 22:11:28.106593 140128494741248 run_lib.py:152] step: 196700, training_loss: 2.83638e+01
I0514 22:11:28.163407 140128494741248 run_lib.py:165] step: 196700, eval_loss: 3.97199e+01
I0514 22:11:34.582005 140128494741248 run_lib.py:152] step: 196750, training_loss: 4.72088e+01
I0514 22:11:40.836960 140128494741248 run_lib.py:152] step: 196800, training_loss: 3.01647e+01
I0514 22:11:40.885841 140128494741248 run_lib.py:165] step: 196800, eval_loss: 3.45893e+01
I0514 22:11:47.089588 140128494741248 run_lib.py:152] step: 196850, training_loss: 3.38544e+01
I0514 22:11:53.568845 140128494741248 run_lib.py:152] step: 196900, training_loss: 3.24142e+01
I0514 22:11:53.620549 140128494741248 run_lib.py:165] step: 196900, eval_loss: 4.55765e+01
I0514 22:11:59.773065 140128494741248 run_lib.py:152] step: 196950, training_loss: 5.50058e+01
I0514 22:12:06.026025 140128494741248 run_lib.py:152] step: 197000, training_loss: 4.00222e+01
I0514 22:12:06.078898 140128494741248 run_lib.py:165] step: 197000, eval_loss: 3.96073e+01
I0514 22:12:12.213393 140128494741248 run_lib.py:152] step: 197050, training_loss: 3.43206e+01
I0514 22:12:18.628587 140128494741248 run_lib.py:152] step: 197100, training_loss: 3.18037e+01
I0514 22:12:18.681558 140128494741248 run_lib.py:165] step: 197100, eval_loss: 3.59986e+01
I0514 22:12:24.839154 140128494741248 run_lib.py:152] step: 197150, training_loss: 3.16143e+01
I0514 22:12:30.941931 140128494741248 run_lib.py:152] step: 197200, training_loss: 3.12020e+01
I0514 22:12:30.992944 140128494741248 run_lib.py:165] step: 197200, eval_loss: 2.13670e+01
I0514 22:12:37.486227 140128494741248 run_lib.py:152] step: 197250, training_loss: 3.74472e+01
I0514 22:12:43.667414 140128494741248 run_lib.py:152] step: 197300, training_loss: 3.21172e+01
I0514 22:12:43.720133 140128494741248 run_lib.py:165] step: 197300, eval_loss: 3.86693e+01
I0514 22:12:49.940251 140128494741248 run_lib.py:152] step: 197350, training_loss: 2.81898e+01
I0514 22:12:56.081539 140128494741248 run_lib.py:152] step: 197400, training_loss: 1.70731e+01
I0514 22:12:56.133367 140128494741248 run_lib.py:165] step: 197400, eval_loss: 2.79095e+01
I0514 22:13:02.578102 140128494741248 run_lib.py:152] step: 197450, training_loss: 3.84925e+01
I0514 22:13:08.745083 140128494741248 run_lib.py:152] step: 197500, training_loss: 2.87742e+01
I0514 22:13:08.799872 140128494741248 run_lib.py:165] step: 197500, eval_loss: 2.25316e+01
I0514 22:13:14.981851 140128494741248 run_lib.py:152] step: 197550, training_loss: 3.57267e+01
I0514 22:13:21.305210 140128494741248 run_lib.py:152] step: 197600, training_loss: 2.58439e+01
I0514 22:13:21.585243 140128494741248 run_lib.py:165] step: 197600, eval_loss: 3.05398e+01
I0514 22:13:27.837668 140128494741248 run_lib.py:152] step: 197650, training_loss: 3.09861e+01
I0514 22:13:33.983212 140128494741248 run_lib.py:152] step: 197700, training_loss: 2.40256e+01
I0514 22:13:34.041893 140128494741248 run_lib.py:165] step: 197700, eval_loss: 2.77395e+01
I0514 22:13:40.227239 140128494741248 run_lib.py:152] step: 197750, training_loss: 2.03064e+01
I0514 22:13:46.681563 140128494741248 run_lib.py:152] step: 197800, training_loss: 2.46764e+01
I0514 22:13:46.739404 140128494741248 run_lib.py:165] step: 197800, eval_loss: 2.28069e+01
I0514 22:13:52.880064 140128494741248 run_lib.py:152] step: 197850, training_loss: 4.16452e+01
I0514 22:13:59.051602 140128494741248 run_lib.py:152] step: 197900, training_loss: 3.83805e+01
I0514 22:13:59.100313 140128494741248 run_lib.py:165] step: 197900, eval_loss: 4.00853e+01
I0514 22:14:05.508438 140128494741248 run_lib.py:152] step: 197950, training_loss: 1.87767e+01
I0514 22:14:11.733221 140128494741248 run_lib.py:152] step: 198000, training_loss: 2.37157e+01
I0514 22:14:11.790229 140128494741248 run_lib.py:165] step: 198000, eval_loss: 4.41958e+01
I0514 22:14:18.024623 140128494741248 run_lib.py:152] step: 198050, training_loss: 2.63030e+01
I0514 22:14:24.235061 140128494741248 run_lib.py:152] step: 198100, training_loss: 2.90228e+01
I0514 22:14:24.287446 140128494741248 run_lib.py:165] step: 198100, eval_loss: 3.95959e+01
I0514 22:14:30.741633 140128494741248 run_lib.py:152] step: 198150, training_loss: 2.72275e+01
I0514 22:14:36.949703 140128494741248 run_lib.py:152] step: 198200, training_loss: 3.25937e+01
I0514 22:14:37.002518 140128494741248 run_lib.py:165] step: 198200, eval_loss: 4.58155e+01
I0514 22:14:43.175821 140128494741248 run_lib.py:152] step: 198250, training_loss: 4.16403e+01
I0514 22:14:49.670919 140128494741248 run_lib.py:152] step: 198300, training_loss: 3.77617e+01
I0514 22:14:49.725347 140128494741248 run_lib.py:165] step: 198300, eval_loss: 1.95745e+01
I0514 22:14:55.954950 140128494741248 run_lib.py:152] step: 198350, training_loss: 3.20024e+01
I0514 22:15:02.225001 140128494741248 run_lib.py:152] step: 198400, training_loss: 4.28043e+01
I0514 22:15:02.275021 140128494741248 run_lib.py:165] step: 198400, eval_loss: 2.53332e+01
I0514 22:15:08.561775 140128494741248 run_lib.py:152] step: 198450, training_loss: 4.28219e+01
I0514 22:15:15.036508 140128494741248 run_lib.py:152] step: 198500, training_loss: 2.69096e+01
I0514 22:15:15.084894 140128494741248 run_lib.py:165] step: 198500, eval_loss: 3.48056e+01
I0514 22:15:21.273049 140128494741248 run_lib.py:152] step: 198550, training_loss: 2.48291e+01
I0514 22:15:27.403571 140128494741248 run_lib.py:152] step: 198600, training_loss: 3.25499e+01
I0514 22:15:27.460003 140128494741248 run_lib.py:165] step: 198600, eval_loss: 5.38191e+01
I0514 22:15:33.951169 140128494741248 run_lib.py:152] step: 198650, training_loss: 4.64878e+01
I0514 22:15:40.192968 140128494741248 run_lib.py:152] step: 198700, training_loss: 2.58443e+01
I0514 22:15:40.248038 140128494741248 run_lib.py:165] step: 198700, eval_loss: 2.27090e+01
I0514 22:15:46.486905 140128494741248 run_lib.py:152] step: 198750, training_loss: 2.24525e+01
I0514 22:15:52.634478 140128494741248 run_lib.py:152] step: 198800, training_loss: 1.91657e+01
I0514 22:15:52.689357 140128494741248 run_lib.py:165] step: 198800, eval_loss: 3.00472e+01
I0514 22:15:59.191795 140128494741248 run_lib.py:152] step: 198850, training_loss: 3.36311e+01
I0514 22:16:05.386908 140128494741248 run_lib.py:152] step: 198900, training_loss: 2.27224e+01
I0514 22:16:05.439862 140128494741248 run_lib.py:165] step: 198900, eval_loss: 2.54004e+01
I0514 22:16:11.579847 140128494741248 run_lib.py:152] step: 198950, training_loss: 2.73937e+01
I0514 22:16:18.060776 140128494741248 run_lib.py:152] step: 199000, training_loss: 2.69218e+01
I0514 22:16:18.108534 140128494741248 run_lib.py:165] step: 199000, eval_loss: 2.39191e+01
I0514 22:16:24.308539 140128494741248 run_lib.py:152] step: 199050, training_loss: 4.04606e+01
I0514 22:16:30.430066 140128494741248 run_lib.py:152] step: 199100, training_loss: 4.55681e+01
I0514 22:16:30.477604 140128494741248 run_lib.py:165] step: 199100, eval_loss: 2.89494e+01
I0514 22:16:36.786677 140128494741248 run_lib.py:152] step: 199150, training_loss: 3.09743e+01
I0514 22:16:43.201028 140128494741248 run_lib.py:152] step: 199200, training_loss: 3.78808e+01
I0514 22:16:43.254790 140128494741248 run_lib.py:165] step: 199200, eval_loss: 3.73945e+01
I0514 22:16:49.473343 140128494741248 run_lib.py:152] step: 199250, training_loss: 4.51918e+01
I0514 22:16:55.595670 140128494741248 run_lib.py:152] step: 199300, training_loss: 2.84294e+01
I0514 22:16:55.650038 140128494741248 run_lib.py:165] step: 199300, eval_loss: 2.36733e+01
I0514 22:17:02.091204 140128494741248 run_lib.py:152] step: 199350, training_loss: 2.96184e+01
I0514 22:17:08.386459 140128494741248 run_lib.py:152] step: 199400, training_loss: 3.08766e+01
I0514 22:17:08.442990 140128494741248 run_lib.py:165] step: 199400, eval_loss: 3.17460e+01
I0514 22:17:14.671164 140128494741248 run_lib.py:152] step: 199450, training_loss: 5.02849e+01
I0514 22:17:20.910700 140128494741248 run_lib.py:152] step: 199500, training_loss: 1.99295e+01
I0514 22:17:20.966996 140128494741248 run_lib.py:165] step: 199500, eval_loss: 4.72708e+01
I0514 22:17:27.399611 140128494741248 run_lib.py:152] step: 199550, training_loss: 2.00910e+01
I0514 22:17:33.549656 140128494741248 run_lib.py:152] step: 199600, training_loss: 4.17906e+01
I0514 22:17:33.600807 140128494741248 run_lib.py:165] step: 199600, eval_loss: 3.43052e+01
I0514 22:17:39.822837 140128494741248 run_lib.py:152] step: 199650, training_loss: 4.10838e+01
I0514 22:17:46.170904 140128494741248 run_lib.py:152] step: 199700, training_loss: 2.70667e+01
I0514 22:17:46.230509 140128494741248 run_lib.py:165] step: 199700, eval_loss: 1.91260e+01
I0514 22:17:52.514472 140128494741248 run_lib.py:152] step: 199750, training_loss: 2.27178e+01
I0514 22:17:58.706587 140128494741248 run_lib.py:152] step: 199800, training_loss: 4.47311e+01
I0514 22:17:58.761174 140128494741248 run_lib.py:165] step: 199800, eval_loss: 4.92679e+01
I0514 22:18:05.034821 140128494741248 run_lib.py:152] step: 199850, training_loss: 3.75028e+01
I0514 22:18:11.393608 140128494741248 run_lib.py:152] step: 199900, training_loss: 2.48445e+01
I0514 22:18:11.449037 140128494741248 run_lib.py:165] step: 199900, eval_loss: 4.30977e+01
I0514 22:18:17.699952 140128494741248 run_lib.py:152] step: 199950, training_loss: 2.51487e+01
I0514 22:18:23.917943 140128494741248 run_lib.py:152] step: 200000, training_loss: 3.47346e+01
I0514 22:18:24.127553 140128494741248 run_lib.py:165] step: 200000, eval_loss: 2.63382e+01
I0514 22:19:44.510501 140128494741248 run_lib.py:152] step: 200050, training_loss: 3.92778e+01
I0514 22:19:50.701398 140128494741248 run_lib.py:152] step: 200100, training_loss: 2.20851e+01
I0514 22:19:50.757479 140128494741248 run_lib.py:165] step: 200100, eval_loss: 4.14889e+01
I0514 22:19:56.945661 140128494741248 run_lib.py:152] step: 200150, training_loss: 3.59218e+01
I0514 22:20:03.357865 140128494741248 run_lib.py:152] step: 200200, training_loss: 2.81019e+01
I0514 22:20:03.406059 140128494741248 run_lib.py:165] step: 200200, eval_loss: 1.86783e+01
I0514 22:20:09.652508 140128494741248 run_lib.py:152] step: 200250, training_loss: 2.09583e+01
I0514 22:20:15.802175 140128494741248 run_lib.py:152] step: 200300, training_loss: 2.39059e+01
I0514 22:20:15.853156 140128494741248 run_lib.py:165] step: 200300, eval_loss: 4.22355e+01
I0514 22:20:22.034553 140128494741248 run_lib.py:152] step: 200350, training_loss: 3.38911e+01
I0514 22:20:28.515298 140128494741248 run_lib.py:152] step: 200400, training_loss: 4.33588e+01
I0514 22:20:28.567102 140128494741248 run_lib.py:165] step: 200400, eval_loss: 2.92394e+01
I0514 22:20:34.787719 140128494741248 run_lib.py:152] step: 200450, training_loss: 2.20263e+01
I0514 22:20:40.897449 140128494741248 run_lib.py:152] step: 200500, training_loss: 2.84305e+01
I0514 22:20:40.947528 140128494741248 run_lib.py:165] step: 200500, eval_loss: 2.02090e+01
I0514 22:20:47.464896 140128494741248 run_lib.py:152] step: 200550, training_loss: 2.33488e+01
I0514 22:20:53.713640 140128494741248 run_lib.py:152] step: 200600, training_loss: 3.14103e+01
I0514 22:20:53.764406 140128494741248 run_lib.py:165] step: 200600, eval_loss: 3.71843e+01
I0514 22:20:59.965832 140128494741248 run_lib.py:152] step: 200650, training_loss: 3.24963e+01
I0514 22:21:06.154123 140128494741248 run_lib.py:152] step: 200700, training_loss: 3.77174e+01
I0514 22:21:06.211117 140128494741248 run_lib.py:165] step: 200700, eval_loss: 2.23707e+01
I0514 22:21:12.631500 140128494741248 run_lib.py:152] step: 200750, training_loss: 5.04091e+01
I0514 22:21:18.888355 140128494741248 run_lib.py:152] step: 200800, training_loss: 4.25798e+01
I0514 22:21:18.940345 140128494741248 run_lib.py:165] step: 200800, eval_loss: 4.43164e+01
I0514 22:21:25.080086 140128494741248 run_lib.py:152] step: 200850, training_loss: 3.50334e+01
I0514 22:21:31.565642 140128494741248 run_lib.py:152] step: 200900, training_loss: 1.53544e+01
I0514 22:21:31.617033 140128494741248 run_lib.py:165] step: 200900, eval_loss: 3.82155e+01
I0514 22:21:37.837509 140128494741248 run_lib.py:152] step: 200950, training_loss: 3.43955e+01
I0514 22:21:44.090903 140128494741248 run_lib.py:152] step: 201000, training_loss: 3.29917e+01
I0514 22:21:44.151787 140128494741248 run_lib.py:165] step: 201000, eval_loss: 4.30695e+01
I0514 22:21:50.332245 140128494741248 run_lib.py:152] step: 201050, training_loss: 3.54007e+01
I0514 22:21:56.702316 140128494741248 run_lib.py:152] step: 201100, training_loss: 3.69367e+01
I0514 22:21:56.753960 140128494741248 run_lib.py:165] step: 201100, eval_loss: 3.63794e+01
I0514 22:22:03.003663 140128494741248 run_lib.py:152] step: 201150, training_loss: 4.20015e+01
I0514 22:22:09.137652 140128494741248 run_lib.py:152] step: 201200, training_loss: 2.88451e+01
I0514 22:22:09.189789 140128494741248 run_lib.py:165] step: 201200, eval_loss: 2.30010e+01
I0514 22:22:15.661257 140128494741248 run_lib.py:152] step: 201250, training_loss: 3.18244e+01
I0514 22:22:21.938519 140128494741248 run_lib.py:152] step: 201300, training_loss: 2.78236e+01
I0514 22:22:21.990164 140128494741248 run_lib.py:165] step: 201300, eval_loss: 3.79129e+01
I0514 22:22:28.156218 140128494741248 run_lib.py:152] step: 201350, training_loss: 1.41813e+01
I0514 22:22:34.337525 140128494741248 run_lib.py:152] step: 201400, training_loss: 3.04318e+01
I0514 22:22:34.390546 140128494741248 run_lib.py:165] step: 201400, eval_loss: 3.10868e+01
I0514 22:22:40.700358 140128494741248 run_lib.py:152] step: 201450, training_loss: 2.55326e+01
I0514 22:22:46.926842 140128494741248 run_lib.py:152] step: 201500, training_loss: 2.91280e+01
I0514 22:22:46.986638 140128494741248 run_lib.py:165] step: 201500, eval_loss: 2.93918e+01
I0514 22:22:53.136841 140128494741248 run_lib.py:152] step: 201550, training_loss: 4.04555e+01
I0514 22:22:59.512010 140128494741248 run_lib.py:152] step: 201600, training_loss: 1.97307e+01
I0514 22:22:59.565831 140128494741248 run_lib.py:165] step: 201600, eval_loss: 3.20653e+01
I0514 22:23:05.777984 140128494741248 run_lib.py:152] step: 201650, training_loss: 2.42133e+01
I0514 22:23:12.001746 140128494741248 run_lib.py:152] step: 201700, training_loss: 2.51971e+01
I0514 22:23:12.053622 140128494741248 run_lib.py:165] step: 201700, eval_loss: 4.57841e+01
I0514 22:23:18.197015 140128494741248 run_lib.py:152] step: 201750, training_loss: 4.34291e+01
I0514 22:23:24.640914 140128494741248 run_lib.py:152] step: 201800, training_loss: 3.57290e+01
I0514 22:23:24.700708 140128494741248 run_lib.py:165] step: 201800, eval_loss: 3.71295e+01
I0514 22:23:30.807116 140128494741248 run_lib.py:152] step: 201850, training_loss: 2.59587e+01
I0514 22:23:37.082137 140128494741248 run_lib.py:152] step: 201900, training_loss: 4.19853e+01
I0514 22:23:37.137093 140128494741248 run_lib.py:165] step: 201900, eval_loss: 3.21180e+01
I0514 22:23:43.648922 140128494741248 run_lib.py:152] step: 201950, training_loss: 2.50282e+01
I0514 22:23:49.802473 140128494741248 run_lib.py:152] step: 202000, training_loss: 4.07373e+01
I0514 22:23:49.860654 140128494741248 run_lib.py:165] step: 202000, eval_loss: 3.44215e+01
I0514 22:23:56.185162 140128494741248 run_lib.py:152] step: 202050, training_loss: 3.66029e+01
I0514 22:24:02.412875 140128494741248 run_lib.py:152] step: 202100, training_loss: 4.26383e+01
I0514 22:24:02.465870 140128494741248 run_lib.py:165] step: 202100, eval_loss: 3.55606e+01
I0514 22:24:08.904890 140128494741248 run_lib.py:152] step: 202150, training_loss: 4.15266e+01
I0514 22:24:15.063589 140128494741248 run_lib.py:152] step: 202200, training_loss: 2.10922e+01
I0514 22:24:15.111701 140128494741248 run_lib.py:165] step: 202200, eval_loss: 3.53344e+01
I0514 22:24:21.430729 140128494741248 run_lib.py:152] step: 202250, training_loss: 3.96938e+01
I0514 22:24:27.907587 140128494741248 run_lib.py:152] step: 202300, training_loss: 3.95504e+01
I0514 22:24:27.959835 140128494741248 run_lib.py:165] step: 202300, eval_loss: 2.88242e+01
I0514 22:24:34.108011 140128494741248 run_lib.py:152] step: 202350, training_loss: 3.32136e+01
I0514 22:24:40.409870 140128494741248 run_lib.py:152] step: 202400, training_loss: 3.50754e+01
I0514 22:24:40.459969 140128494741248 run_lib.py:165] step: 202400, eval_loss: 2.87864e+01
I0514 22:24:46.668593 140128494741248 run_lib.py:152] step: 202450, training_loss: 2.59680e+01
I0514 22:24:53.059755 140128494741248 run_lib.py:152] step: 202500, training_loss: 3.94838e+01
I0514 22:24:53.111047 140128494741248 run_lib.py:165] step: 202500, eval_loss: 2.37917e+01
I0514 22:24:59.358528 140128494741248 run_lib.py:152] step: 202550, training_loss: 3.40431e+01
I0514 22:25:05.514702 140128494741248 run_lib.py:152] step: 202600, training_loss: 3.97279e+01
I0514 22:25:05.565577 140128494741248 run_lib.py:165] step: 202600, eval_loss: 4.11519e+01
I0514 22:25:12.018501 140128494741248 run_lib.py:152] step: 202650, training_loss: 2.32012e+01
I0514 22:25:18.248793 140128494741248 run_lib.py:152] step: 202700, training_loss: 3.30186e+01
I0514 22:25:18.298922 140128494741248 run_lib.py:165] step: 202700, eval_loss: 2.59276e+01
I0514 22:25:24.563679 140128494741248 run_lib.py:152] step: 202750, training_loss: 2.77351e+01
I0514 22:25:30.672966 140128494741248 run_lib.py:152] step: 202800, training_loss: 2.03456e+01
I0514 22:25:30.722794 140128494741248 run_lib.py:165] step: 202800, eval_loss: 4.06078e+01
I0514 22:25:37.215002 140128494741248 run_lib.py:152] step: 202850, training_loss: 3.14709e+01
I0514 22:25:43.424642 140128494741248 run_lib.py:152] step: 202900, training_loss: 2.62888e+01
I0514 22:25:43.475627 140128494741248 run_lib.py:165] step: 202900, eval_loss: 3.98497e+01
I0514 22:25:49.702394 140128494741248 run_lib.py:152] step: 202950, training_loss: 1.95653e+01
I0514 22:25:56.163976 140128494741248 run_lib.py:152] step: 203000, training_loss: 2.28269e+01
I0514 22:25:56.215673 140128494741248 run_lib.py:165] step: 203000, eval_loss: 4.36996e+01
I0514 22:26:02.402017 140128494741248 run_lib.py:152] step: 203050, training_loss: 3.93746e+01
I0514 22:26:08.448215 140128494741248 run_lib.py:152] step: 203100, training_loss: 3.03356e+01
I0514 22:26:08.497783 140128494741248 run_lib.py:165] step: 203100, eval_loss: 3.26894e+01
I0514 22:26:14.714347 140128494741248 run_lib.py:152] step: 203150, training_loss: 2.28195e+01
I0514 22:26:21.113914 140128494741248 run_lib.py:152] step: 203200, training_loss: 2.66666e+01
I0514 22:26:21.163495 140128494741248 run_lib.py:165] step: 203200, eval_loss: 4.86979e+01
I0514 22:26:27.326391 140128494741248 run_lib.py:152] step: 203250, training_loss: 1.82480e+01
I0514 22:26:33.545924 140128494741248 run_lib.py:152] step: 203300, training_loss: 2.35513e+01
I0514 22:26:33.599725 140128494741248 run_lib.py:165] step: 203300, eval_loss: 2.89223e+01
I0514 22:26:40.034295 140128494741248 run_lib.py:152] step: 203350, training_loss: 3.19639e+01
I0514 22:26:46.250390 140128494741248 run_lib.py:152] step: 203400, training_loss: 5.12524e+01
I0514 22:26:46.302504 140128494741248 run_lib.py:165] step: 203400, eval_loss: 1.64147e+01
I0514 22:26:52.436121 140128494741248 run_lib.py:152] step: 203450, training_loss: 3.56665e+01
I0514 22:26:58.622835 140128494741248 run_lib.py:152] step: 203500, training_loss: 3.40038e+01
I0514 22:26:58.678121 140128494741248 run_lib.py:165] step: 203500, eval_loss: 2.88321e+01
I0514 22:27:05.117751 140128494741248 run_lib.py:152] step: 203550, training_loss: 4.61096e+01
I0514 22:27:11.330991 140128494741248 run_lib.py:152] step: 203600, training_loss: 2.90747e+01
I0514 22:27:11.383342 140128494741248 run_lib.py:165] step: 203600, eval_loss: 2.76157e+01
I0514 22:27:17.591855 140128494741248 run_lib.py:152] step: 203650, training_loss: 1.91844e+01
I0514 22:27:23.985103 140128494741248 run_lib.py:152] step: 203700, training_loss: 3.01558e+01
I0514 22:27:24.035023 140128494741248 run_lib.py:165] step: 203700, eval_loss: 1.80184e+01
I0514 22:27:30.255469 140128494741248 run_lib.py:152] step: 203750, training_loss: 2.99513e+01
I0514 22:27:36.400807 140128494741248 run_lib.py:152] step: 203800, training_loss: 3.08153e+01
I0514 22:27:36.453528 140128494741248 run_lib.py:165] step: 203800, eval_loss: 3.66830e+01
I0514 22:27:42.781357 140128494741248 run_lib.py:152] step: 203850, training_loss: 4.05832e+01
I0514 22:27:49.290544 140128494741248 run_lib.py:152] step: 203900, training_loss: 2.27835e+01
I0514 22:27:49.340776 140128494741248 run_lib.py:165] step: 203900, eval_loss: 3.51083e+01
I0514 22:27:55.603738 140128494741248 run_lib.py:152] step: 203950, training_loss: 3.79349e+01
I0514 22:28:01.819742 140128494741248 run_lib.py:152] step: 204000, training_loss: 4.54502e+01
I0514 22:28:01.868623 140128494741248 run_lib.py:165] step: 204000, eval_loss: 3.24506e+01
I0514 22:28:08.265537 140128494741248 run_lib.py:152] step: 204050, training_loss: 4.47698e+01
I0514 22:28:14.450412 140128494741248 run_lib.py:152] step: 204100, training_loss: 3.43471e+01
I0514 22:28:14.503438 140128494741248 run_lib.py:165] step: 204100, eval_loss: 2.02325e+01
I0514 22:28:20.740797 140128494741248 run_lib.py:152] step: 204150, training_loss: 3.99192e+01
I0514 22:28:26.919730 140128494741248 run_lib.py:152] step: 204200, training_loss: 2.90931e+01
I0514 22:28:26.974282 140128494741248 run_lib.py:165] step: 204200, eval_loss: 2.78562e+01
I0514 22:28:33.327182 140128494741248 run_lib.py:152] step: 204250, training_loss: 4.62357e+01
I0514 22:28:39.503433 140128494741248 run_lib.py:152] step: 204300, training_loss: 3.74381e+01
I0514 22:28:39.555259 140128494741248 run_lib.py:165] step: 204300, eval_loss: 1.98832e+01
I0514 22:28:45.845231 140128494741248 run_lib.py:152] step: 204350, training_loss: 3.41935e+01
I0514 22:28:52.334690 140128494741248 run_lib.py:152] step: 204400, training_loss: 2.63920e+01
I0514 22:28:52.390206 140128494741248 run_lib.py:165] step: 204400, eval_loss: 4.05770e+01
I0514 22:28:58.536200 140128494741248 run_lib.py:152] step: 204450, training_loss: 4.01219e+01
I0514 22:29:04.781367 140128494741248 run_lib.py:152] step: 204500, training_loss: 2.02008e+01
I0514 22:29:04.836047 140128494741248 run_lib.py:165] step: 204500, eval_loss: 5.15835e+01
I0514 22:29:11.020302 140128494741248 run_lib.py:152] step: 204550, training_loss: 3.62699e+01
I0514 22:29:17.439261 140128494741248 run_lib.py:152] step: 204600, training_loss: 3.72584e+01
I0514 22:29:17.488259 140128494741248 run_lib.py:165] step: 204600, eval_loss: 2.67091e+01
I0514 22:29:23.768921 140128494741248 run_lib.py:152] step: 204650, training_loss: 2.96048e+01
I0514 22:29:29.983272 140128494741248 run_lib.py:152] step: 204700, training_loss: 4.19975e+01
I0514 22:29:30.037141 140128494741248 run_lib.py:165] step: 204700, eval_loss: 3.55623e+01
I0514 22:29:36.499977 140128494741248 run_lib.py:152] step: 204750, training_loss: 3.06885e+01
I0514 22:29:42.714987 140128494741248 run_lib.py:152] step: 204800, training_loss: 2.96318e+01
I0514 22:29:42.770267 140128494741248 run_lib.py:165] step: 204800, eval_loss: 3.87807e+01
I0514 22:29:48.974510 140128494741248 run_lib.py:152] step: 204850, training_loss: 2.37741e+01
I0514 22:29:55.233933 140128494741248 run_lib.py:152] step: 204900, training_loss: 3.42462e+01
I0514 22:29:55.287828 140128494741248 run_lib.py:165] step: 204900, eval_loss: 3.01786e+01
I0514 22:30:01.666958 140128494741248 run_lib.py:152] step: 204950, training_loss: 2.40267e+01
I0514 22:30:07.853470 140128494741248 run_lib.py:152] step: 205000, training_loss: 3.22001e+01
I0514 22:30:07.908693 140128494741248 run_lib.py:165] step: 205000, eval_loss: 2.96061e+01
I0514 22:30:14.117888 140128494741248 run_lib.py:152] step: 205050, training_loss: 3.50842e+01
I0514 22:30:20.648652 140128494741248 run_lib.py:152] step: 205100, training_loss: 4.43650e+01
I0514 22:30:20.702577 140128494741248 run_lib.py:165] step: 205100, eval_loss: 2.24538e+01
I0514 22:30:26.858985 140128494741248 run_lib.py:152] step: 205150, training_loss: 3.47150e+01
I0514 22:30:33.024426 140128494741248 run_lib.py:152] step: 205200, training_loss: 3.92980e+01
I0514 22:30:33.081445 140128494741248 run_lib.py:165] step: 205200, eval_loss: 3.55597e+01
I0514 22:30:39.281664 140128494741248 run_lib.py:152] step: 205250, training_loss: 2.43390e+01
I0514 22:30:45.739364 140128494741248 run_lib.py:152] step: 205300, training_loss: 3.36876e+01
I0514 22:30:45.793179 140128494741248 run_lib.py:165] step: 205300, eval_loss: 3.02572e+01
I0514 22:30:51.913745 140128494741248 run_lib.py:152] step: 205350, training_loss: 5.48358e+01
I0514 22:30:58.048751 140128494741248 run_lib.py:152] step: 205400, training_loss: 2.67557e+01
I0514 22:30:58.101635 140128494741248 run_lib.py:165] step: 205400, eval_loss: 2.95266e+01
I0514 22:31:04.564249 140128494741248 run_lib.py:152] step: 205450, training_loss: 2.11443e+01
I0514 22:31:10.783194 140128494741248 run_lib.py:152] step: 205500, training_loss: 4.40779e+01
I0514 22:31:10.835577 140128494741248 run_lib.py:165] step: 205500, eval_loss: 2.49019e+01
I0514 22:31:17.071979 140128494741248 run_lib.py:152] step: 205550, training_loss: 4.41941e+01
I0514 22:31:23.177598 140128494741248 run_lib.py:152] step: 205600, training_loss: 2.42918e+01
I0514 22:31:23.231312 140128494741248 run_lib.py:165] step: 205600, eval_loss: 4.50247e+01
I0514 22:31:29.706671 140128494741248 run_lib.py:152] step: 205650, training_loss: 2.50827e+01
I0514 22:31:35.887846 140128494741248 run_lib.py:152] step: 205700, training_loss: 3.62656e+01
I0514 22:31:35.940544 140128494741248 run_lib.py:165] step: 205700, eval_loss: 2.80096e+01
I0514 22:31:42.147393 140128494741248 run_lib.py:152] step: 205750, training_loss: 3.73012e+01
I0514 22:31:48.637797 140128494741248 run_lib.py:152] step: 205800, training_loss: 2.83300e+01
I0514 22:31:48.694468 140128494741248 run_lib.py:165] step: 205800, eval_loss: 2.08245e+01
I0514 22:31:54.903338 140128494741248 run_lib.py:152] step: 205850, training_loss: 3.31396e+01
I0514 22:32:01.125332 140128494741248 run_lib.py:152] step: 205900, training_loss: 2.12188e+01
I0514 22:32:01.188053 140128494741248 run_lib.py:165] step: 205900, eval_loss: 2.75048e+01
I0514 22:32:07.310155 140128494741248 run_lib.py:152] step: 205950, training_loss: 2.95756e+01
I0514 22:32:13.753487 140128494741248 run_lib.py:152] step: 206000, training_loss: 2.93076e+01
I0514 22:32:13.808035 140128494741248 run_lib.py:165] step: 206000, eval_loss: 2.46977e+01
I0514 22:32:19.948317 140128494741248 run_lib.py:152] step: 206050, training_loss: 4.11762e+01
I0514 22:32:26.114523 140128494741248 run_lib.py:152] step: 206100, training_loss: 2.96722e+01
I0514 22:32:26.170027 140128494741248 run_lib.py:165] step: 206100, eval_loss: 3.77878e+01
I0514 22:32:32.596966 140128494741248 run_lib.py:152] step: 206150, training_loss: 3.73160e+01
I0514 22:32:38.822956 140128494741248 run_lib.py:152] step: 206200, training_loss: 3.62880e+01
I0514 22:32:38.873979 140128494741248 run_lib.py:165] step: 206200, eval_loss: 2.26555e+01
I0514 22:32:45.069208 140128494741248 run_lib.py:152] step: 206250, training_loss: 2.31237e+01
I0514 22:32:51.254352 140128494741248 run_lib.py:152] step: 206300, training_loss: 3.46322e+01
I0514 22:32:51.312063 140128494741248 run_lib.py:165] step: 206300, eval_loss: 1.96009e+01
I0514 22:32:57.792322 140128494741248 run_lib.py:152] step: 206350, training_loss: 5.32249e+01
I0514 22:33:04.093113 140128494741248 run_lib.py:152] step: 206400, training_loss: 4.35588e+01
I0514 22:33:04.152938 140128494741248 run_lib.py:165] step: 206400, eval_loss: 4.21139e+01
I0514 22:33:10.432263 140128494741248 run_lib.py:152] step: 206450, training_loss: 3.04834e+01
I0514 22:33:16.915461 140128494741248 run_lib.py:152] step: 206500, training_loss: 4.05822e+01
I0514 22:33:16.968144 140128494741248 run_lib.py:165] step: 206500, eval_loss: 4.82247e+01
I0514 22:33:23.211240 140128494741248 run_lib.py:152] step: 206550, training_loss: 2.53448e+01
I0514 22:33:29.272746 140128494741248 run_lib.py:152] step: 206600, training_loss: 4.22278e+01
I0514 22:33:29.323646 140128494741248 run_lib.py:165] step: 206600, eval_loss: 3.70695e+01
I0514 22:33:35.556192 140128494741248 run_lib.py:152] step: 206650, training_loss: 2.97087e+01
I0514 22:33:42.038296 140128494741248 run_lib.py:152] step: 206700, training_loss: 2.38397e+01
I0514 22:33:42.092281 140128494741248 run_lib.py:165] step: 206700, eval_loss: 2.19430e+01
I0514 22:33:48.282503 140128494741248 run_lib.py:152] step: 206750, training_loss: 4.05405e+01
I0514 22:33:54.444575 140128494741248 run_lib.py:152] step: 206800, training_loss: 3.23303e+01
I0514 22:33:54.496423 140128494741248 run_lib.py:165] step: 206800, eval_loss: 2.87091e+01
I0514 22:34:00.842074 140128494741248 run_lib.py:152] step: 206850, training_loss: 3.98986e+01
I0514 22:34:06.957265 140128494741248 run_lib.py:152] step: 206900, training_loss: 4.44527e+01
I0514 22:34:07.011660 140128494741248 run_lib.py:165] step: 206900, eval_loss: 5.59856e+01
I0514 22:34:13.144422 140128494741248 run_lib.py:152] step: 206950, training_loss: 3.13850e+01
I0514 22:34:19.397701 140128494741248 run_lib.py:152] step: 207000, training_loss: 4.42031e+01
I0514 22:34:19.447429 140128494741248 run_lib.py:165] step: 207000, eval_loss: 2.57136e+01
I0514 22:34:25.824298 140128494741248 run_lib.py:152] step: 207050, training_loss: 5.06307e+01
I0514 22:34:31.974825 140128494741248 run_lib.py:152] step: 207100, training_loss: 3.35211e+01
I0514 22:34:32.024096 140128494741248 run_lib.py:165] step: 207100, eval_loss: 2.20479e+01
I0514 22:34:38.286135 140128494741248 run_lib.py:152] step: 207150, training_loss: 3.55046e+01
I0514 22:34:44.717780 140128494741248 run_lib.py:152] step: 207200, training_loss: 3.26637e+01
I0514 22:34:44.772670 140128494741248 run_lib.py:165] step: 207200, eval_loss: 4.41599e+01
I0514 22:34:50.950304 140128494741248 run_lib.py:152] step: 207250, training_loss: 2.95633e+01
I0514 22:34:57.147762 140128494741248 run_lib.py:152] step: 207300, training_loss: 3.03217e+01
I0514 22:34:57.196600 140128494741248 run_lib.py:165] step: 207300, eval_loss: 3.83728e+01
I0514 22:35:03.386159 140128494741248 run_lib.py:152] step: 207350, training_loss: 2.96370e+01
I0514 22:35:09.773457 140128494741248 run_lib.py:152] step: 207400, training_loss: 4.62339e+01
I0514 22:35:09.827333 140128494741248 run_lib.py:165] step: 207400, eval_loss: 3.19842e+01
I0514 22:35:15.949763 140128494741248 run_lib.py:152] step: 207450, training_loss: 2.67210e+01
I0514 22:35:22.191091 140128494741248 run_lib.py:152] step: 207500, training_loss: 2.35160e+01
I0514 22:35:22.244892 140128494741248 run_lib.py:165] step: 207500, eval_loss: 3.76165e+01
I0514 22:35:28.586939 140128494741248 run_lib.py:152] step: 207550, training_loss: 4.50569e+01
I0514 22:35:34.901922 140128494741248 run_lib.py:152] step: 207600, training_loss: 3.28511e+01
I0514 22:35:34.953916 140128494741248 run_lib.py:165] step: 207600, eval_loss: 2.70846e+01
I0514 22:35:41.130652 140128494741248 run_lib.py:152] step: 207650, training_loss: 5.30711e+01
I0514 22:35:47.294350 140128494741248 run_lib.py:152] step: 207700, training_loss: 4.09049e+01
I0514 22:35:47.352267 140128494741248 run_lib.py:165] step: 207700, eval_loss: 3.37663e+01
I0514 22:35:53.742549 140128494741248 run_lib.py:152] step: 207750, training_loss: 2.94063e+01
I0514 22:35:59.930408 140128494741248 run_lib.py:152] step: 207800, training_loss: 2.69532e+01
I0514 22:35:59.983077 140128494741248 run_lib.py:165] step: 207800, eval_loss: 2.53227e+01
I0514 22:36:06.085224 140128494741248 run_lib.py:152] step: 207850, training_loss: 4.23547e+01
I0514 22:36:12.501774 140128494741248 run_lib.py:152] step: 207900, training_loss: 2.85837e+01
I0514 22:36:12.550796 140128494741248 run_lib.py:165] step: 207900, eval_loss: 2.46254e+01
I0514 22:36:18.760403 140128494741248 run_lib.py:152] step: 207950, training_loss: 3.71586e+01
I0514 22:36:24.900921 140128494741248 run_lib.py:152] step: 208000, training_loss: 3.44634e+01
I0514 22:36:24.952064 140128494741248 run_lib.py:165] step: 208000, eval_loss: 1.62392e+01
I0514 22:36:31.179161 140128494741248 run_lib.py:152] step: 208050, training_loss: 2.70579e+01
I0514 22:36:37.595896 140128494741248 run_lib.py:152] step: 208100, training_loss: 3.18991e+01
I0514 22:36:37.647276 140128494741248 run_lib.py:165] step: 208100, eval_loss: 2.13151e+01
I0514 22:36:43.898959 140128494741248 run_lib.py:152] step: 208150, training_loss: 3.21341e+01
I0514 22:36:50.196817 140128494741248 run_lib.py:152] step: 208200, training_loss: 3.69778e+01
I0514 22:36:50.251050 140128494741248 run_lib.py:165] step: 208200, eval_loss: 4.53038e+01
I0514 22:36:56.662161 140128494741248 run_lib.py:152] step: 208250, training_loss: 2.79924e+01
I0514 22:37:02.874124 140128494741248 run_lib.py:152] step: 208300, training_loss: 4.24790e+01
I0514 22:37:02.927765 140128494741248 run_lib.py:165] step: 208300, eval_loss: 3.22948e+01
I0514 22:37:09.114169 140128494741248 run_lib.py:152] step: 208350, training_loss: 2.87534e+01
I0514 22:37:15.337086 140128494741248 run_lib.py:152] step: 208400, training_loss: 3.67209e+01
I0514 22:37:15.388351 140128494741248 run_lib.py:165] step: 208400, eval_loss: 3.01938e+01
I0514 22:37:21.782076 140128494741248 run_lib.py:152] step: 208450, training_loss: 1.31721e+01
I0514 22:37:27.988840 140128494741248 run_lib.py:152] step: 208500, training_loss: 2.54661e+01
I0514 22:37:28.047119 140128494741248 run_lib.py:165] step: 208500, eval_loss: 2.82726e+01
I0514 22:37:34.214521 140128494741248 run_lib.py:152] step: 208550, training_loss: 3.31791e+01
I0514 22:37:40.667690 140128494741248 run_lib.py:152] step: 208600, training_loss: 2.82162e+01
I0514 22:37:40.719655 140128494741248 run_lib.py:165] step: 208600, eval_loss: 2.43396e+01
I0514 22:37:46.986092 140128494741248 run_lib.py:152] step: 208650, training_loss: 2.87756e+01
I0514 22:37:53.269146 140128494741248 run_lib.py:152] step: 208700, training_loss: 3.60823e+01
I0514 22:37:53.321585 140128494741248 run_lib.py:165] step: 208700, eval_loss: 2.99352e+01
I0514 22:37:59.455591 140128494741248 run_lib.py:152] step: 208750, training_loss: 3.10253e+01
I0514 22:38:05.869509 140128494741248 run_lib.py:152] step: 208800, training_loss: 3.46925e+01
I0514 22:38:05.923597 140128494741248 run_lib.py:165] step: 208800, eval_loss: 2.50359e+01
I0514 22:38:12.182344 140128494741248 run_lib.py:152] step: 208850, training_loss: 2.77723e+01
I0514 22:38:18.387169 140128494741248 run_lib.py:152] step: 208900, training_loss: 2.49036e+01
I0514 22:38:18.439793 140128494741248 run_lib.py:165] step: 208900, eval_loss: 3.69969e+01
I0514 22:38:24.914292 140128494741248 run_lib.py:152] step: 208950, training_loss: 1.80878e+01
I0514 22:38:31.000528 140128494741248 run_lib.py:152] step: 209000, training_loss: 3.79043e+01
I0514 22:38:31.052710 140128494741248 run_lib.py:165] step: 209000, eval_loss: 2.89467e+01
I0514 22:38:37.258207 140128494741248 run_lib.py:152] step: 209050, training_loss: 3.74016e+01
I0514 22:38:43.433337 140128494741248 run_lib.py:152] step: 209100, training_loss: 3.07902e+01
I0514 22:38:43.480490 140128494741248 run_lib.py:165] step: 209100, eval_loss: 2.75535e+01
I0514 22:38:49.844162 140128494741248 run_lib.py:152] step: 209150, training_loss: 2.18873e+01
I0514 22:38:55.984086 140128494741248 run_lib.py:152] step: 209200, training_loss: 2.79178e+01
I0514 22:38:56.030056 140128494741248 run_lib.py:165] step: 209200, eval_loss: 1.97685e+01
I0514 22:39:02.241348 140128494741248 run_lib.py:152] step: 209250, training_loss: 3.13856e+01
I0514 22:39:08.600244 140128494741248 run_lib.py:152] step: 209300, training_loss: 2.34353e+01
I0514 22:39:08.651311 140128494741248 run_lib.py:165] step: 209300, eval_loss: 3.56122e+01
I0514 22:39:14.757570 140128494741248 run_lib.py:152] step: 209350, training_loss: 4.41756e+01
I0514 22:39:20.953858 140128494741248 run_lib.py:152] step: 209400, training_loss: 2.92520e+01
I0514 22:39:21.009368 140128494741248 run_lib.py:165] step: 209400, eval_loss: 3.44266e+01
I0514 22:39:27.181681 140128494741248 run_lib.py:152] step: 209450, training_loss: 3.65307e+01
I0514 22:39:33.663167 140128494741248 run_lib.py:152] step: 209500, training_loss: 3.36729e+01
I0514 22:39:33.715466 140128494741248 run_lib.py:165] step: 209500, eval_loss: 3.59573e+01
I0514 22:39:39.957959 140128494741248 run_lib.py:152] step: 209550, training_loss: 2.45476e+01
I0514 22:39:46.060880 140128494741248 run_lib.py:152] step: 209600, training_loss: 3.73648e+01
I0514 22:39:46.111914 140128494741248 run_lib.py:165] step: 209600, eval_loss: 4.02777e+01
I0514 22:39:52.602265 140128494741248 run_lib.py:152] step: 209650, training_loss: 2.57377e+01
I0514 22:39:58.813821 140128494741248 run_lib.py:152] step: 209700, training_loss: 4.76620e+01
I0514 22:39:58.870517 140128494741248 run_lib.py:165] step: 209700, eval_loss: 2.80567e+01
I0514 22:40:05.115170 140128494741248 run_lib.py:152] step: 209750, training_loss: 3.55332e+01
I0514 22:40:11.307899 140128494741248 run_lib.py:152] step: 209800, training_loss: 4.40667e+01
I0514 22:40:11.359841 140128494741248 run_lib.py:165] step: 209800, eval_loss: 2.47550e+01
I0514 22:40:17.779433 140128494741248 run_lib.py:152] step: 209850, training_loss: 2.26633e+01
I0514 22:40:23.963011 140128494741248 run_lib.py:152] step: 209900, training_loss: 2.49909e+01
I0514 22:40:24.014487 140128494741248 run_lib.py:165] step: 209900, eval_loss: 3.49819e+01
I0514 22:40:30.256352 140128494741248 run_lib.py:152] step: 209950, training_loss: 2.33995e+01
I0514 22:40:36.705697 140128494741248 run_lib.py:152] step: 210000, training_loss: 1.93357e+01
I0514 22:40:36.911065 140128494741248 run_lib.py:165] step: 210000, eval_loss: 2.91585e+01
I0514 22:40:43.207510 140128494741248 run_lib.py:152] step: 210050, training_loss: 3.25410e+01
I0514 22:40:49.351823 140128494741248 run_lib.py:152] step: 210100, training_loss: 1.81449e+01
I0514 22:40:49.403964 140128494741248 run_lib.py:165] step: 210100, eval_loss: 2.10337e+01
I0514 22:40:55.653922 140128494741248 run_lib.py:152] step: 210150, training_loss: 3.86059e+01
I0514 22:41:02.198913 140128494741248 run_lib.py:152] step: 210200, training_loss: 3.48948e+01
I0514 22:41:02.251320 140128494741248 run_lib.py:165] step: 210200, eval_loss: 3.38644e+01
I0514 22:41:08.456100 140128494741248 run_lib.py:152] step: 210250, training_loss: 1.82404e+01
I0514 22:41:14.722099 140128494741248 run_lib.py:152] step: 210300, training_loss: 4.31070e+01
I0514 22:41:14.773027 140128494741248 run_lib.py:165] step: 210300, eval_loss: 4.01999e+01
I0514 22:41:21.131392 140128494741248 run_lib.py:152] step: 210350, training_loss: 2.92585e+01
I0514 22:41:27.351998 140128494741248 run_lib.py:152] step: 210400, training_loss: 3.44656e+01
I0514 22:41:27.407469 140128494741248 run_lib.py:165] step: 210400, eval_loss: 1.76927e+01
I0514 22:41:33.626335 140128494741248 run_lib.py:152] step: 210450, training_loss: 2.88093e+01
I0514 22:41:39.856732 140128494741248 run_lib.py:152] step: 210500, training_loss: 2.50087e+01
I0514 22:41:39.903948 140128494741248 run_lib.py:165] step: 210500, eval_loss: 3.11916e+01
I0514 22:41:46.283599 140128494741248 run_lib.py:152] step: 210550, training_loss: 3.42112e+01
I0514 22:41:52.440111 140128494741248 run_lib.py:152] step: 210600, training_loss: 3.15162e+01
I0514 22:41:52.492281 140128494741248 run_lib.py:165] step: 210600, eval_loss: 3.57778e+01
I0514 22:41:58.606606 140128494741248 run_lib.py:152] step: 210650, training_loss: 5.71296e+01
I0514 22:42:05.032826 140128494741248 run_lib.py:152] step: 210700, training_loss: 2.66905e+01
I0514 22:42:05.085161 140128494741248 run_lib.py:165] step: 210700, eval_loss: 2.73093e+01
I0514 22:42:11.202667 140128494741248 run_lib.py:152] step: 210750, training_loss: 3.39527e+01
I0514 22:42:17.390442 140128494741248 run_lib.py:152] step: 210800, training_loss: 3.93729e+01
I0514 22:42:17.440191 140128494741248 run_lib.py:165] step: 210800, eval_loss: 3.59112e+01
I0514 22:42:23.622247 140128494741248 run_lib.py:152] step: 210850, training_loss: 4.56306e+01
I0514 22:42:29.993427 140128494741248 run_lib.py:152] step: 210900, training_loss: 3.77105e+01
I0514 22:42:30.045643 140128494741248 run_lib.py:165] step: 210900, eval_loss: 3.59190e+01
I0514 22:42:36.224265 140128494741248 run_lib.py:152] step: 210950, training_loss: 2.75056e+01
I0514 22:42:42.406008 140128494741248 run_lib.py:152] step: 211000, training_loss: 3.91169e+01
I0514 22:42:42.457286 140128494741248 run_lib.py:165] step: 211000, eval_loss: 3.07367e+01
I0514 22:42:48.951020 140128494741248 run_lib.py:152] step: 211050, training_loss: 3.02962e+01
I0514 22:42:55.097816 140128494741248 run_lib.py:152] step: 211100, training_loss: 3.36329e+01
I0514 22:42:55.144006 140128494741248 run_lib.py:165] step: 211100, eval_loss: 3.31412e+01
I0514 22:43:01.293084 140128494741248 run_lib.py:152] step: 211150, training_loss: 2.53911e+01
I0514 22:43:07.475781 140128494741248 run_lib.py:152] step: 211200, training_loss: 2.73323e+01
I0514 22:43:07.525516 140128494741248 run_lib.py:165] step: 211200, eval_loss: 1.63559e+01
I0514 22:43:13.922209 140128494741248 run_lib.py:152] step: 211250, training_loss: 2.70915e+01
I0514 22:43:20.147473 140128494741248 run_lib.py:152] step: 211300, training_loss: 3.00005e+01
I0514 22:43:20.205012 140128494741248 run_lib.py:165] step: 211300, eval_loss: 3.02387e+01
I0514 22:43:26.402292 140128494741248 run_lib.py:152] step: 211350, training_loss: 2.85589e+01
I0514 22:43:32.829877 140128494741248 run_lib.py:152] step: 211400, training_loss: 4.19056e+01
I0514 22:43:32.881761 140128494741248 run_lib.py:165] step: 211400, eval_loss: 2.31073e+01
I0514 22:43:39.098974 140128494741248 run_lib.py:152] step: 211450, training_loss: 2.45406e+01
I0514 22:43:45.277259 140128494741248 run_lib.py:152] step: 211500, training_loss: 1.99390e+01
I0514 22:43:45.331682 140128494741248 run_lib.py:165] step: 211500, eval_loss: 3.08539e+01
I0514 22:43:51.484566 140128494741248 run_lib.py:152] step: 211550, training_loss: 2.35783e+01
I0514 22:43:57.838579 140128494741248 run_lib.py:152] step: 211600, training_loss: 2.60863e+01
I0514 22:43:57.889953 140128494741248 run_lib.py:165] step: 211600, eval_loss: 3.46669e+01
I0514 22:44:04.034471 140128494741248 run_lib.py:152] step: 211650, training_loss: 3.45984e+01
I0514 22:44:10.146647 140128494741248 run_lib.py:152] step: 211700, training_loss: 4.52643e+01
I0514 22:44:10.196846 140128494741248 run_lib.py:165] step: 211700, eval_loss: 2.54149e+01
I0514 22:44:16.616495 140128494741248 run_lib.py:152] step: 211750, training_loss: 2.07326e+01
I0514 22:44:22.835891 140128494741248 run_lib.py:152] step: 211800, training_loss: 3.13340e+01
I0514 22:44:22.886542 140128494741248 run_lib.py:165] step: 211800, eval_loss: 3.40892e+01
I0514 22:44:29.083963 140128494741248 run_lib.py:152] step: 211850, training_loss: 3.16328e+01
I0514 22:44:35.318536 140128494741248 run_lib.py:152] step: 211900, training_loss: 4.31228e+01
I0514 22:44:35.370048 140128494741248 run_lib.py:165] step: 211900, eval_loss: 2.89638e+01
I0514 22:44:41.748993 140128494741248 run_lib.py:152] step: 211950, training_loss: 3.53236e+01
I0514 22:44:47.880517 140128494741248 run_lib.py:152] step: 212000, training_loss: 3.29470e+01
I0514 22:44:47.937763 140128494741248 run_lib.py:165] step: 212000, eval_loss: 3.78386e+01
I0514 22:44:54.133152 140128494741248 run_lib.py:152] step: 212050, training_loss: 3.47567e+01
I0514 22:45:00.514992 140128494741248 run_lib.py:152] step: 212100, training_loss: 3.64867e+01
I0514 22:45:00.571716 140128494741248 run_lib.py:165] step: 212100, eval_loss: 3.22527e+01
I0514 22:45:06.787327 140128494741248 run_lib.py:152] step: 212150, training_loss: 3.61678e+01
I0514 22:45:12.975912 140128494741248 run_lib.py:152] step: 212200, training_loss: 1.69616e+01
I0514 22:45:13.026034 140128494741248 run_lib.py:165] step: 212200, eval_loss: 3.19523e+01
I0514 22:45:19.173896 140128494741248 run_lib.py:152] step: 212250, training_loss: 2.36339e+01
I0514 22:45:25.603820 140128494741248 run_lib.py:152] step: 212300, training_loss: 3.23203e+01
I0514 22:45:25.654900 140128494741248 run_lib.py:165] step: 212300, eval_loss: 3.42320e+01
I0514 22:45:31.678247 140128494741248 run_lib.py:152] step: 212350, training_loss: 2.51410e+01
I0514 22:45:37.827534 140128494741248 run_lib.py:152] step: 212400, training_loss: 4.39698e+01
I0514 22:45:37.890390 140128494741248 run_lib.py:165] step: 212400, eval_loss: 2.59307e+01
I0514 22:45:44.267406 140128494741248 run_lib.py:152] step: 212450, training_loss: 4.42505e+01
I0514 22:45:50.393578 140128494741248 run_lib.py:152] step: 212500, training_loss: 3.26156e+01
I0514 22:45:50.444423 140128494741248 run_lib.py:165] step: 212500, eval_loss: 2.93503e+01
I0514 22:45:56.641971 140128494741248 run_lib.py:152] step: 212550, training_loss: 2.89459e+01
I0514 22:46:02.815107 140128494741248 run_lib.py:152] step: 212600, training_loss: 2.85083e+01
I0514 22:46:02.870523 140128494741248 run_lib.py:165] step: 212600, eval_loss: 3.82913e+01
I0514 22:46:09.212977 140128494741248 run_lib.py:152] step: 212650, training_loss: 4.61264e+01
I0514 22:46:15.455685 140128494741248 run_lib.py:152] step: 212700, training_loss: 4.32274e+01
I0514 22:46:15.515411 140128494741248 run_lib.py:165] step: 212700, eval_loss: 2.26260e+01
I0514 22:46:21.696344 140128494741248 run_lib.py:152] step: 212750, training_loss: 4.77614e+01
I0514 22:46:28.024308 140128494741248 run_lib.py:152] step: 212800, training_loss: 1.96632e+01
I0514 22:46:28.075343 140128494741248 run_lib.py:165] step: 212800, eval_loss: 3.06976e+01
I0514 22:46:34.266330 140128494741248 run_lib.py:152] step: 212850, training_loss: 2.26072e+01
I0514 22:46:40.501971 140128494741248 run_lib.py:152] step: 212900, training_loss: 2.16705e+01
I0514 22:46:40.559663 140128494741248 run_lib.py:165] step: 212900, eval_loss: 3.33019e+01
I0514 22:46:46.772604 140128494741248 run_lib.py:152] step: 212950, training_loss: 4.27752e+01
I0514 22:46:53.203837 140128494741248 run_lib.py:152] step: 213000, training_loss: 1.33562e+01
I0514 22:46:53.256904 140128494741248 run_lib.py:165] step: 213000, eval_loss: 3.41329e+01
I0514 22:46:59.448009 140128494741248 run_lib.py:152] step: 213050, training_loss: 3.03578e+01
I0514 22:47:05.582473 140128494741248 run_lib.py:152] step: 213100, training_loss: 3.29882e+01
I0514 22:47:05.636179 140128494741248 run_lib.py:165] step: 213100, eval_loss: 3.35182e+01
I0514 22:47:12.136240 140128494741248 run_lib.py:152] step: 213150, training_loss: 3.22186e+01
I0514 22:47:18.277509 140128494741248 run_lib.py:152] step: 213200, training_loss: 2.31893e+01
I0514 22:47:18.325191 140128494741248 run_lib.py:165] step: 213200, eval_loss: 2.63950e+01
I0514 22:47:24.502341 140128494741248 run_lib.py:152] step: 213250, training_loss: 3.30861e+01
I0514 22:47:30.748707 140128494741248 run_lib.py:152] step: 213300, training_loss: 3.96409e+01
I0514 22:47:30.800353 140128494741248 run_lib.py:165] step: 213300, eval_loss: 3.28373e+01
I0514 22:47:37.359423 140128494741248 run_lib.py:152] step: 213350, training_loss: 3.91882e+01
I0514 22:47:43.534860 140128494741248 run_lib.py:152] step: 213400, training_loss: 3.51799e+01
I0514 22:47:43.590232 140128494741248 run_lib.py:165] step: 213400, eval_loss: 4.21376e+01
I0514 22:47:49.802892 140128494741248 run_lib.py:152] step: 213450, training_loss: 2.39740e+01
I0514 22:47:56.197458 140128494741248 run_lib.py:152] step: 213500, training_loss: 2.72451e+01
I0514 22:47:56.247926 140128494741248 run_lib.py:165] step: 213500, eval_loss: 2.24162e+01
I0514 22:48:02.427621 140128494741248 run_lib.py:152] step: 213550, training_loss: 2.75085e+01
I0514 22:48:08.618761 140128494741248 run_lib.py:152] step: 213600, training_loss: 2.39502e+01
I0514 22:48:08.670487 140128494741248 run_lib.py:165] step: 213600, eval_loss: 2.79034e+01
I0514 22:48:14.916411 140128494741248 run_lib.py:152] step: 213650, training_loss: 3.26286e+01
I0514 22:48:21.339571 140128494741248 run_lib.py:152] step: 213700, training_loss: 3.57359e+01
I0514 22:48:21.389564 140128494741248 run_lib.py:165] step: 213700, eval_loss: 3.73130e+01
I0514 22:48:27.603845 140128494741248 run_lib.py:152] step: 213750, training_loss: 2.40563e+01
I0514 22:48:33.847206 140128494741248 run_lib.py:152] step: 213800, training_loss: 2.67295e+01
I0514 22:48:33.900572 140128494741248 run_lib.py:165] step: 213800, eval_loss: 2.71334e+01
I0514 22:48:40.344675 140128494741248 run_lib.py:152] step: 213850, training_loss: 3.64990e+01
I0514 22:48:46.588813 140128494741248 run_lib.py:152] step: 213900, training_loss: 3.51336e+01
I0514 22:48:46.644124 140128494741248 run_lib.py:165] step: 213900, eval_loss: 4.26579e+01
I0514 22:48:52.876559 140128494741248 run_lib.py:152] step: 213950, training_loss: 5.58354e+01
I0514 22:48:59.136005 140128494741248 run_lib.py:152] step: 214000, training_loss: 2.28489e+01
I0514 22:48:59.187972 140128494741248 run_lib.py:165] step: 214000, eval_loss: 2.47885e+01
I0514 22:49:05.480226 140128494741248 run_lib.py:152] step: 214050, training_loss: 2.68676e+01
I0514 22:49:11.715790 140128494741248 run_lib.py:152] step: 214100, training_loss: 2.95889e+01
I0514 22:49:11.766600 140128494741248 run_lib.py:165] step: 214100, eval_loss: 3.36003e+01
I0514 22:49:17.907171 140128494741248 run_lib.py:152] step: 214150, training_loss: 4.10013e+01
I0514 22:49:24.295722 140128494741248 run_lib.py:152] step: 214200, training_loss: 3.83473e+01
I0514 22:49:24.346424 140128494741248 run_lib.py:165] step: 214200, eval_loss: 2.76958e+01
I0514 22:49:30.528844 140128494741248 run_lib.py:152] step: 214250, training_loss: 3.78952e+01
I0514 22:49:36.687864 140128494741248 run_lib.py:152] step: 214300, training_loss: 1.87266e+01
I0514 22:49:36.738041 140128494741248 run_lib.py:165] step: 214300, eval_loss: 2.27101e+01
I0514 22:49:42.971226 140128494741248 run_lib.py:152] step: 214350, training_loss: 3.22037e+01
I0514 22:49:49.371376 140128494741248 run_lib.py:152] step: 214400, training_loss: 2.97465e+01
I0514 22:49:49.421168 140128494741248 run_lib.py:165] step: 214400, eval_loss: 3.40223e+01
I0514 22:49:55.615329 140128494741248 run_lib.py:152] step: 214450, training_loss: 3.78267e+01
I0514 22:50:01.810759 140128494741248 run_lib.py:152] step: 214500, training_loss: 2.83985e+01
I0514 22:50:01.863132 140128494741248 run_lib.py:165] step: 214500, eval_loss: 3.89228e+01
I0514 22:50:08.342558 140128494741248 run_lib.py:152] step: 214550, training_loss: 3.88064e+01
I0514 22:50:14.623387 140128494741248 run_lib.py:152] step: 214600, training_loss: 3.59081e+01
I0514 22:50:14.675094 140128494741248 run_lib.py:165] step: 214600, eval_loss: 2.22269e+01
I0514 22:50:20.922446 140128494741248 run_lib.py:152] step: 214650, training_loss: 1.40636e+01
I0514 22:50:27.160277 140128494741248 run_lib.py:152] step: 214700, training_loss: 4.06323e+01
I0514 22:50:27.212511 140128494741248 run_lib.py:165] step: 214700, eval_loss: 3.61829e+01
I0514 22:50:33.577830 140128494741248 run_lib.py:152] step: 214750, training_loss: 4.19803e+01
I0514 22:50:39.859663 140128494741248 run_lib.py:152] step: 214800, training_loss: 3.56431e+01
I0514 22:50:39.911235 140128494741248 run_lib.py:165] step: 214800, eval_loss: 4.10115e+01
I0514 22:50:46.067211 140128494741248 run_lib.py:152] step: 214850, training_loss: 1.65502e+01
I0514 22:50:52.567883 140128494741248 run_lib.py:152] step: 214900, training_loss: 3.38898e+01
I0514 22:50:52.628886 140128494741248 run_lib.py:165] step: 214900, eval_loss: 2.47909e+01
I0514 22:50:58.798394 140128494741248 run_lib.py:152] step: 214950, training_loss: 4.03171e+01
I0514 22:51:05.019996 140128494741248 run_lib.py:152] step: 215000, training_loss: 3.41018e+01
I0514 22:51:05.068572 140128494741248 run_lib.py:165] step: 215000, eval_loss: 3.96837e+01
I0514 22:51:11.246294 140128494741248 run_lib.py:152] step: 215050, training_loss: 2.91591e+01
I0514 22:51:17.716033 140128494741248 run_lib.py:152] step: 215100, training_loss: 3.34194e+01
I0514 22:51:17.762557 140128494741248 run_lib.py:165] step: 215100, eval_loss: 3.24628e+01
I0514 22:51:24.012835 140128494741248 run_lib.py:152] step: 215150, training_loss: 1.35418e+01
I0514 22:51:30.118575 140128494741248 run_lib.py:152] step: 215200, training_loss: 4.43501e+01
I0514 22:51:30.173841 140128494741248 run_lib.py:165] step: 215200, eval_loss: 4.54783e+01
I0514 22:51:36.611641 140128494741248 run_lib.py:152] step: 215250, training_loss: 3.11576e+01
I0514 22:51:42.757917 140128494741248 run_lib.py:152] step: 215300, training_loss: 4.22888e+01
I0514 22:51:42.806142 140128494741248 run_lib.py:165] step: 215300, eval_loss: 3.13171e+01
I0514 22:51:49.049864 140128494741248 run_lib.py:152] step: 215350, training_loss: 3.77574e+01
I0514 22:51:55.248927 140128494741248 run_lib.py:152] step: 215400, training_loss: 2.12146e+01
I0514 22:51:55.306408 140128494741248 run_lib.py:165] step: 215400, eval_loss: 4.10257e+01
I0514 22:52:01.666725 140128494741248 run_lib.py:152] step: 215450, training_loss: 3.17977e+01
I0514 22:52:07.909773 140128494741248 run_lib.py:152] step: 215500, training_loss: 3.30460e+01
I0514 22:52:07.964696 140128494741248 run_lib.py:165] step: 215500, eval_loss: 4.20984e+01
I0514 22:52:14.157660 140128494741248 run_lib.py:152] step: 215550, training_loss: 2.03771e+01
I0514 22:52:20.568299 140128494741248 run_lib.py:152] step: 215600, training_loss: 2.58865e+01
I0514 22:52:20.623673 140128494741248 run_lib.py:165] step: 215600, eval_loss: 4.61630e+01
I0514 22:52:26.836850 140128494741248 run_lib.py:152] step: 215650, training_loss: 3.73486e+01
I0514 22:52:33.024725 140128494741248 run_lib.py:152] step: 215700, training_loss: 3.27621e+01
I0514 22:52:33.076722 140128494741248 run_lib.py:165] step: 215700, eval_loss: 1.51316e+01
I0514 22:52:39.253823 140128494741248 run_lib.py:152] step: 215750, training_loss: 1.75761e+01
I0514 22:52:45.669888 140128494741248 run_lib.py:152] step: 215800, training_loss: 1.76275e+01
I0514 22:52:45.722198 140128494741248 run_lib.py:165] step: 215800, eval_loss: 3.47073e+01
I0514 22:52:52.010146 140128494741248 run_lib.py:152] step: 215850, training_loss: 3.06542e+01
I0514 22:52:58.256557 140128494741248 run_lib.py:152] step: 215900, training_loss: 2.52346e+01
I0514 22:52:58.309310 140128494741248 run_lib.py:165] step: 215900, eval_loss: 4.05001e+01
I0514 22:53:04.742090 140128494741248 run_lib.py:152] step: 215950, training_loss: 4.13918e+01
I0514 22:53:10.974376 140128494741248 run_lib.py:152] step: 216000, training_loss: 3.32716e+01
I0514 22:53:11.025376 140128494741248 run_lib.py:165] step: 216000, eval_loss: 4.52761e+01
I0514 22:53:17.278542 140128494741248 run_lib.py:152] step: 216050, training_loss: 3.10085e+01
I0514 22:53:23.421541 140128494741248 run_lib.py:152] step: 216100, training_loss: 1.70566e+01
I0514 22:53:23.470467 140128494741248 run_lib.py:165] step: 216100, eval_loss: 2.17156e+01
I0514 22:53:29.868142 140128494741248 run_lib.py:152] step: 216150, training_loss: 4.00701e+01
I0514 22:53:36.027352 140128494741248 run_lib.py:152] step: 216200, training_loss: 3.78650e+01
I0514 22:53:36.086946 140128494741248 run_lib.py:165] step: 216200, eval_loss: 4.18673e+01
I0514 22:53:42.208258 140128494741248 run_lib.py:152] step: 216250, training_loss: 3.64780e+01
I0514 22:53:48.542380 140128494741248 run_lib.py:152] step: 216300, training_loss: 3.80680e+01
I0514 22:53:48.600636 140128494741248 run_lib.py:165] step: 216300, eval_loss: 3.61643e+01
I0514 22:53:54.847189 140128494741248 run_lib.py:152] step: 216350, training_loss: 3.50076e+01
I0514 22:54:01.069871 140128494741248 run_lib.py:152] step: 216400, training_loss: 3.20362e+01
I0514 22:54:01.122507 140128494741248 run_lib.py:165] step: 216400, eval_loss: 3.35154e+01
I0514 22:54:07.283728 140128494741248 run_lib.py:152] step: 216450, training_loss: 2.43312e+01
I0514 22:54:13.692849 140128494741248 run_lib.py:152] step: 216500, training_loss: 2.85730e+01
I0514 22:54:13.743724 140128494741248 run_lib.py:165] step: 216500, eval_loss: 3.46031e+01
I0514 22:54:19.905622 140128494741248 run_lib.py:152] step: 216550, training_loss: 3.07958e+01
I0514 22:54:26.114218 140128494741248 run_lib.py:152] step: 216600, training_loss: 4.20482e+01
I0514 22:54:26.167117 140128494741248 run_lib.py:165] step: 216600, eval_loss: 1.89864e+01
I0514 22:54:32.565950 140128494741248 run_lib.py:152] step: 216650, training_loss: 3.12693e+01
I0514 22:54:38.737919 140128494741248 run_lib.py:152] step: 216700, training_loss: 2.49220e+01
I0514 22:54:38.795711 140128494741248 run_lib.py:165] step: 216700, eval_loss: 2.23063e+01
I0514 22:54:44.999536 140128494741248 run_lib.py:152] step: 216750, training_loss: 2.20686e+01
I0514 22:54:51.156794 140128494741248 run_lib.py:152] step: 216800, training_loss: 3.56846e+01
I0514 22:54:51.204846 140128494741248 run_lib.py:165] step: 216800, eval_loss: 4.84529e+01
I0514 22:54:57.659751 140128494741248 run_lib.py:152] step: 216850, training_loss: 2.71057e+01
I0514 22:55:03.770054 140128494741248 run_lib.py:152] step: 216900, training_loss: 5.03410e+01
I0514 22:55:03.823814 140128494741248 run_lib.py:165] step: 216900, eval_loss: 3.38076e+01
I0514 22:55:10.125237 140128494741248 run_lib.py:152] step: 216950, training_loss: 2.44857e+01
I0514 22:55:16.514038 140128494741248 run_lib.py:152] step: 217000, training_loss: 3.20558e+01
I0514 22:55:16.569903 140128494741248 run_lib.py:165] step: 217000, eval_loss: 3.49431e+01
I0514 22:55:22.735639 140128494741248 run_lib.py:152] step: 217050, training_loss: 2.82408e+01
I0514 22:55:28.981815 140128494741248 run_lib.py:152] step: 217100, training_loss: 4.22846e+01
I0514 22:55:29.031937 140128494741248 run_lib.py:165] step: 217100, eval_loss: 1.98773e+01
I0514 22:55:35.238448 140128494741248 run_lib.py:152] step: 217150, training_loss: 3.05773e+01
I0514 22:55:41.680333 140128494741248 run_lib.py:152] step: 217200, training_loss: 3.54762e+01
I0514 22:55:41.727659 140128494741248 run_lib.py:165] step: 217200, eval_loss: 3.47769e+01
I0514 22:55:47.922027 140128494741248 run_lib.py:152] step: 217250, training_loss: 3.39437e+01
I0514 22:55:54.095553 140128494741248 run_lib.py:152] step: 217300, training_loss: 3.85901e+01
I0514 22:55:54.147350 140128494741248 run_lib.py:165] step: 217300, eval_loss: 2.67604e+01
I0514 22:56:00.504441 140128494741248 run_lib.py:152] step: 217350, training_loss: 7.40858e+00
I0514 22:56:06.758245 140128494741248 run_lib.py:152] step: 217400, training_loss: 2.14232e+01
I0514 22:56:06.811461 140128494741248 run_lib.py:165] step: 217400, eval_loss: 3.14741e+01
I0514 22:56:13.033513 140128494741248 run_lib.py:152] step: 217450, training_loss: 9.61432e+00
I0514 22:56:19.203651 140128494741248 run_lib.py:152] step: 217500, training_loss: 3.11688e+01
I0514 22:56:19.255534 140128494741248 run_lib.py:165] step: 217500, eval_loss: 1.93714e+01
I0514 22:56:25.654858 140128494741248 run_lib.py:152] step: 217550, training_loss: 3.75381e+01
I0514 22:56:31.855295 140128494741248 run_lib.py:152] step: 217600, training_loss: 3.82384e+01
I0514 22:56:31.903854 140128494741248 run_lib.py:165] step: 217600, eval_loss: 3.95461e+01
I0514 22:56:38.114908 140128494741248 run_lib.py:152] step: 217650, training_loss: 1.42754e+01
I0514 22:56:44.513765 140128494741248 run_lib.py:152] step: 217700, training_loss: 3.14474e+01
I0514 22:56:44.565605 140128494741248 run_lib.py:165] step: 217700, eval_loss: 2.23842e+01
I0514 22:56:50.800482 140128494741248 run_lib.py:152] step: 217750, training_loss: 1.31961e+01
I0514 22:56:56.968641 140128494741248 run_lib.py:152] step: 217800, training_loss: 2.21746e+01
I0514 22:56:57.020082 140128494741248 run_lib.py:165] step: 217800, eval_loss: 2.87514e+01
I0514 22:57:03.239361 140128494741248 run_lib.py:152] step: 217850, training_loss: 3.62773e+01
I0514 22:57:09.662159 140128494741248 run_lib.py:152] step: 217900, training_loss: 2.91558e+01
I0514 22:57:09.715603 140128494741248 run_lib.py:165] step: 217900, eval_loss: 3.41744e+01
I0514 22:57:15.907046 140128494741248 run_lib.py:152] step: 217950, training_loss: 3.17903e+01
I0514 22:57:22.122008 140128494741248 run_lib.py:152] step: 218000, training_loss: 3.27806e+01
I0514 22:57:22.175606 140128494741248 run_lib.py:165] step: 218000, eval_loss: 2.84324e+01
I0514 22:57:28.551482 140128494741248 run_lib.py:152] step: 218050, training_loss: 2.27139e+01
I0514 22:57:34.746471 140128494741248 run_lib.py:152] step: 218100, training_loss: 2.05818e+01
I0514 22:57:34.797336 140128494741248 run_lib.py:165] step: 218100, eval_loss: 2.08325e+01
I0514 22:57:40.996588 140128494741248 run_lib.py:152] step: 218150, training_loss: 2.33007e+01
I0514 22:57:47.180422 140128494741248 run_lib.py:152] step: 218200, training_loss: 3.30542e+01
I0514 22:57:47.231876 140128494741248 run_lib.py:165] step: 218200, eval_loss: 2.94802e+01
I0514 22:57:53.646909 140128494741248 run_lib.py:152] step: 218250, training_loss: 3.76911e+01
I0514 22:57:59.932724 140128494741248 run_lib.py:152] step: 218300, training_loss: 3.25799e+01
I0514 22:57:59.984167 140128494741248 run_lib.py:165] step: 218300, eval_loss: 3.08319e+01
I0514 22:58:06.128532 140128494741248 run_lib.py:152] step: 218350, training_loss: 2.57666e+01
I0514 22:58:12.586190 140128494741248 run_lib.py:152] step: 218400, training_loss: 3.71047e+01
I0514 22:58:12.636406 140128494741248 run_lib.py:165] step: 218400, eval_loss: 1.70036e+01
I0514 22:58:18.914657 140128494741248 run_lib.py:152] step: 218450, training_loss: 3.87526e+01
I0514 22:58:25.029465 140128494741248 run_lib.py:152] step: 218500, training_loss: 3.04544e+01
I0514 22:58:25.078980 140128494741248 run_lib.py:165] step: 218500, eval_loss: 3.22484e+01
I0514 22:58:31.277338 140128494741248 run_lib.py:152] step: 218550, training_loss: 1.98518e+01
I0514 22:58:37.681852 140128494741248 run_lib.py:152] step: 218600, training_loss: 1.83294e+01
I0514 22:58:37.732647 140128494741248 run_lib.py:165] step: 218600, eval_loss: 3.90062e+01
I0514 22:58:44.008872 140128494741248 run_lib.py:152] step: 218650, training_loss: 2.62419e+01
I0514 22:58:50.119992 140128494741248 run_lib.py:152] step: 218700, training_loss: 1.66243e+01
I0514 22:58:50.167910 140128494741248 run_lib.py:165] step: 218700, eval_loss: 2.24594e+01
I0514 22:58:56.622442 140128494741248 run_lib.py:152] step: 218750, training_loss: 3.52567e+01
I0514 22:59:02.806436 140128494741248 run_lib.py:152] step: 218800, training_loss: 5.06328e+01
I0514 22:59:02.858654 140128494741248 run_lib.py:165] step: 218800, eval_loss: 1.67810e+01
I0514 22:59:08.954030 140128494741248 run_lib.py:152] step: 218850, training_loss: 3.24514e+01
I0514 22:59:15.161449 140128494741248 run_lib.py:152] step: 218900, training_loss: 3.76338e+01
I0514 22:59:15.217281 140128494741248 run_lib.py:165] step: 218900, eval_loss: 2.49573e+01
I0514 22:59:21.586656 140128494741248 run_lib.py:152] step: 218950, training_loss: 2.46830e+01
I0514 22:59:27.778623 140128494741248 run_lib.py:152] step: 219000, training_loss: 2.50808e+01
I0514 22:59:27.832102 140128494741248 run_lib.py:165] step: 219000, eval_loss: 2.18432e+01
I0514 22:59:34.007811 140128494741248 run_lib.py:152] step: 219050, training_loss: 2.70636e+01
I0514 22:59:40.551579 140128494741248 run_lib.py:152] step: 219100, training_loss: 1.90625e+01
I0514 22:59:40.601495 140128494741248 run_lib.py:165] step: 219100, eval_loss: 2.54515e+01
I0514 22:59:46.874871 140128494741248 run_lib.py:152] step: 219150, training_loss: 3.18087e+01
I0514 22:59:53.025629 140128494741248 run_lib.py:152] step: 219200, training_loss: 3.58015e+01
I0514 22:59:53.073486 140128494741248 run_lib.py:165] step: 219200, eval_loss: 3.07485e+01
I0514 22:59:59.289390 140128494741248 run_lib.py:152] step: 219250, training_loss: 4.10176e+01
I0514 23:00:05.740025 140128494741248 run_lib.py:152] step: 219300, training_loss: 3.12501e+01
I0514 23:00:05.791658 140128494741248 run_lib.py:165] step: 219300, eval_loss: 3.10645e+01
I0514 23:00:12.050719 140128494741248 run_lib.py:152] step: 219350, training_loss: 3.41489e+01
I0514 23:00:18.189705 140128494741248 run_lib.py:152] step: 219400, training_loss: 3.28235e+01
I0514 23:00:18.243369 140128494741248 run_lib.py:165] step: 219400, eval_loss: 3.43817e+01
I0514 23:00:24.682296 140128494741248 run_lib.py:152] step: 219450, training_loss: 2.30699e+01
I0514 23:00:30.831021 140128494741248 run_lib.py:152] step: 219500, training_loss: 2.04596e+01
I0514 23:00:30.884131 140128494741248 run_lib.py:165] step: 219500, eval_loss: 3.74945e+01
I0514 23:00:37.095818 140128494741248 run_lib.py:152] step: 219550, training_loss: 4.12420e+01
I0514 23:00:43.300693 140128494741248 run_lib.py:152] step: 219600, training_loss: 4.45715e+01
I0514 23:00:43.352290 140128494741248 run_lib.py:165] step: 219600, eval_loss: 3.03222e+01
I0514 23:00:49.814070 140128494741248 run_lib.py:152] step: 219650, training_loss: 3.91956e+01
I0514 23:00:55.959331 140128494741248 run_lib.py:152] step: 219700, training_loss: 3.84244e+01
I0514 23:00:56.008653 140128494741248 run_lib.py:165] step: 219700, eval_loss: 2.20631e+01
I0514 23:01:02.227428 140128494741248 run_lib.py:152] step: 219750, training_loss: 4.96119e+01
I0514 23:01:08.640478 140128494741248 run_lib.py:152] step: 219800, training_loss: 2.81746e+01
I0514 23:01:08.688616 140128494741248 run_lib.py:165] step: 219800, eval_loss: 3.42402e+01
I0514 23:01:14.869406 140128494741248 run_lib.py:152] step: 219850, training_loss: 2.29554e+01
I0514 23:01:21.022803 140128494741248 run_lib.py:152] step: 219900, training_loss: 1.27619e+01
I0514 23:01:21.079472 140128494741248 run_lib.py:165] step: 219900, eval_loss: 2.78793e+01
I0514 23:01:27.225607 140128494741248 run_lib.py:152] step: 219950, training_loss: 3.55352e+01
I0514 23:01:33.722412 140128494741248 run_lib.py:152] step: 220000, training_loss: 2.94680e+01
I0514 23:01:33.931060 140128494741248 run_lib.py:165] step: 220000, eval_loss: 2.15174e+01
I0514 23:01:40.083443 140128494741248 run_lib.py:152] step: 220050, training_loss: 2.85916e+01
I0514 23:01:46.382804 140128494741248 run_lib.py:152] step: 220100, training_loss: 2.01705e+01
I0514 23:01:46.436525 140128494741248 run_lib.py:165] step: 220100, eval_loss: 4.15181e+01
I0514 23:01:52.871330 140128494741248 run_lib.py:152] step: 220150, training_loss: 3.03116e+01
I0514 23:01:59.090249 140128494741248 run_lib.py:152] step: 220200, training_loss: 3.05756e+01
I0514 23:01:59.142608 140128494741248 run_lib.py:165] step: 220200, eval_loss: 2.00137e+01
I0514 23:02:05.245291 140128494741248 run_lib.py:152] step: 220250, training_loss: 2.54149e+01
I0514 23:02:11.430644 140128494741248 run_lib.py:152] step: 220300, training_loss: 3.81620e+01
I0514 23:02:11.481621 140128494741248 run_lib.py:165] step: 220300, eval_loss: 4.53202e+01
I0514 23:02:17.888492 140128494741248 run_lib.py:152] step: 220350, training_loss: 3.98080e+01
I0514 23:02:24.186256 140128494741248 run_lib.py:152] step: 220400, training_loss: 2.70729e+01
I0514 23:02:24.237795 140128494741248 run_lib.py:165] step: 220400, eval_loss: 3.63031e+01
I0514 23:02:30.442780 140128494741248 run_lib.py:152] step: 220450, training_loss: 2.79763e+01
I0514 23:02:36.774958 140128494741248 run_lib.py:152] step: 220500, training_loss: 3.37927e+01
I0514 23:02:36.831359 140128494741248 run_lib.py:165] step: 220500, eval_loss: 2.34724e+01
I0514 23:02:42.969262 140128494741248 run_lib.py:152] step: 220550, training_loss: 2.30439e+01
I0514 23:02:49.222163 140128494741248 run_lib.py:152] step: 220600, training_loss: 3.78097e+01
I0514 23:02:49.273197 140128494741248 run_lib.py:165] step: 220600, eval_loss: 3.51347e+01
I0514 23:02:55.454660 140128494741248 run_lib.py:152] step: 220650, training_loss: 2.27450e+01
I0514 23:03:01.875658 140128494741248 run_lib.py:152] step: 220700, training_loss: 3.46753e+01
I0514 23:03:01.927590 140128494741248 run_lib.py:165] step: 220700, eval_loss: 2.80039e+01
I0514 23:03:08.035238 140128494741248 run_lib.py:152] step: 220750, training_loss: 2.17350e+01
I0514 23:03:14.263436 140128494741248 run_lib.py:152] step: 220800, training_loss: 2.82354e+01
I0514 23:03:14.313832 140128494741248 run_lib.py:165] step: 220800, eval_loss: 2.73994e+01
I0514 23:03:20.697475 140128494741248 run_lib.py:152] step: 220850, training_loss: 2.74501e+01
I0514 23:03:26.953370 140128494741248 run_lib.py:152] step: 220900, training_loss: 2.52845e+01
I0514 23:03:27.007535 140128494741248 run_lib.py:165] step: 220900, eval_loss: 5.28763e+01
I0514 23:03:33.234390 140128494741248 run_lib.py:152] step: 220950, training_loss: 4.31949e+01
I0514 23:03:39.510654 140128494741248 run_lib.py:152] step: 221000, training_loss: 5.12140e+01
I0514 23:03:39.560057 140128494741248 run_lib.py:165] step: 221000, eval_loss: 2.86113e+01
I0514 23:03:45.962083 140128494741248 run_lib.py:152] step: 221050, training_loss: 2.66888e+01
I0514 23:03:52.097619 140128494741248 run_lib.py:152] step: 221100, training_loss: 3.61496e+01
I0514 23:03:52.151191 140128494741248 run_lib.py:165] step: 221100, eval_loss: 3.46331e+01
I0514 23:03:58.368463 140128494741248 run_lib.py:152] step: 221150, training_loss: 2.05370e+01
I0514 23:04:04.796921 140128494741248 run_lib.py:152] step: 221200, training_loss: 3.20905e+01
I0514 23:04:04.851584 140128494741248 run_lib.py:165] step: 221200, eval_loss: 2.58165e+01
I0514 23:04:10.960123 140128494741248 run_lib.py:152] step: 221250, training_loss: 3.36827e+01
I0514 23:04:17.180068 140128494741248 run_lib.py:152] step: 221300, training_loss: 2.13671e+01
I0514 23:04:17.235818 140128494741248 run_lib.py:165] step: 221300, eval_loss: 4.62654e+01
I0514 23:04:23.386691 140128494741248 run_lib.py:152] step: 221350, training_loss: 4.40196e+01
I0514 23:04:29.840301 140128494741248 run_lib.py:152] step: 221400, training_loss: 2.19793e+01
I0514 23:04:29.886930 140128494741248 run_lib.py:165] step: 221400, eval_loss: 3.13162e+01
I0514 23:04:36.146072 140128494741248 run_lib.py:152] step: 221450, training_loss: 2.69781e+01
I0514 23:04:42.335292 140128494741248 run_lib.py:152] step: 221500, training_loss: 3.29474e+01
I0514 23:04:42.385904 140128494741248 run_lib.py:165] step: 221500, eval_loss: 2.08619e+01
I0514 23:04:48.870730 140128494741248 run_lib.py:152] step: 221550, training_loss: 4.35622e+01
I0514 23:04:55.155516 140128494741248 run_lib.py:152] step: 221600, training_loss: 3.26979e+01
I0514 23:04:55.204563 140128494741248 run_lib.py:165] step: 221600, eval_loss: 2.95177e+01
I0514 23:05:01.360719 140128494741248 run_lib.py:152] step: 221650, training_loss: 3.12724e+01
I0514 23:05:07.534185 140128494741248 run_lib.py:152] step: 221700, training_loss: 3.91303e+01
I0514 23:05:07.587615 140128494741248 run_lib.py:165] step: 221700, eval_loss: 2.08999e+01
I0514 23:05:14.110687 140128494741248 run_lib.py:152] step: 221750, training_loss: 3.85942e+01
I0514 23:05:20.316342 140128494741248 run_lib.py:152] step: 221800, training_loss: 2.81413e+01
I0514 23:05:20.373202 140128494741248 run_lib.py:165] step: 221800, eval_loss: 3.18340e+01
I0514 23:05:26.538858 140128494741248 run_lib.py:152] step: 221850, training_loss: 3.19308e+01
I0514 23:05:33.008832 140128494741248 run_lib.py:152] step: 221900, training_loss: 4.03620e+01
I0514 23:05:33.069727 140128494741248 run_lib.py:165] step: 221900, eval_loss: 2.35573e+01
I0514 23:05:39.200649 140128494741248 run_lib.py:152] step: 221950, training_loss: 1.96061e+01
I0514 23:05:45.354638 140128494741248 run_lib.py:152] step: 222000, training_loss: 3.27532e+01
I0514 23:05:45.406428 140128494741248 run_lib.py:165] step: 222000, eval_loss: 3.33731e+01
I0514 23:05:51.584764 140128494741248 run_lib.py:152] step: 222050, training_loss: 4.56052e+01
I0514 23:05:58.043909 140128494741248 run_lib.py:152] step: 222100, training_loss: 3.32704e+01
I0514 23:05:58.095571 140128494741248 run_lib.py:165] step: 222100, eval_loss: 1.97225e+01
I0514 23:06:04.294423 140128494741248 run_lib.py:152] step: 222150, training_loss: 3.13878e+01
I0514 23:06:10.462035 140128494741248 run_lib.py:152] step: 222200, training_loss: 2.93838e+01
I0514 23:06:10.511370 140128494741248 run_lib.py:165] step: 222200, eval_loss: 2.78571e+01
I0514 23:06:16.976704 140128494741248 run_lib.py:152] step: 222250, training_loss: 2.31442e+01
I0514 23:06:23.080702 140128494741248 run_lib.py:152] step: 222300, training_loss: 2.83455e+01
I0514 23:06:23.133103 140128494741248 run_lib.py:165] step: 222300, eval_loss: 4.08101e+01
I0514 23:06:29.329064 140128494741248 run_lib.py:152] step: 222350, training_loss: 2.94248e+01
I0514 23:06:35.470032 140128494741248 run_lib.py:152] step: 222400, training_loss: 3.49834e+01
I0514 23:06:35.518314 140128494741248 run_lib.py:165] step: 222400, eval_loss: 2.30980e+01
I0514 23:06:41.908337 140128494741248 run_lib.py:152] step: 222450, training_loss: 2.10128e+01
I0514 23:06:48.009941 140128494741248 run_lib.py:152] step: 222500, training_loss: 2.17005e+01
I0514 23:06:48.057719 140128494741248 run_lib.py:165] step: 222500, eval_loss: 2.05917e+01
I0514 23:06:54.336992 140128494741248 run_lib.py:152] step: 222550, training_loss: 2.98032e+01
I0514 23:07:00.742501 140128494741248 run_lib.py:152] step: 222600, training_loss: 3.40832e+01
I0514 23:07:00.797383 140128494741248 run_lib.py:165] step: 222600, eval_loss: 4.01199e+01
I0514 23:07:07.095685 140128494741248 run_lib.py:152] step: 222650, training_loss: 2.78144e+01
I0514 23:07:13.443122 140128494741248 run_lib.py:152] step: 222700, training_loss: 3.16448e+01
I0514 23:07:13.498716 140128494741248 run_lib.py:165] step: 222700, eval_loss: 2.27953e+01
I0514 23:07:19.774698 140128494741248 run_lib.py:152] step: 222750, training_loss: 3.28502e+01
I0514 23:07:26.230747 140128494741248 run_lib.py:152] step: 222800, training_loss: 2.73876e+01
I0514 23:07:26.283015 140128494741248 run_lib.py:165] step: 222800, eval_loss: 2.98503e+01
I0514 23:07:32.464611 140128494741248 run_lib.py:152] step: 222850, training_loss: 3.82571e+01
I0514 23:07:38.631011 140128494741248 run_lib.py:152] step: 222900, training_loss: 2.85571e+01
I0514 23:07:38.682232 140128494741248 run_lib.py:165] step: 222900, eval_loss: 3.10933e+01
I0514 23:07:45.189668 140128494741248 run_lib.py:152] step: 222950, training_loss: 5.87436e+01
I0514 23:07:51.389649 140128494741248 run_lib.py:152] step: 223000, training_loss: 2.53740e+01
I0514 23:07:51.436170 140128494741248 run_lib.py:165] step: 223000, eval_loss: 2.95506e+01
I0514 23:07:57.615580 140128494741248 run_lib.py:152] step: 223050, training_loss: 1.67795e+01
I0514 23:08:03.820721 140128494741248 run_lib.py:152] step: 223100, training_loss: 3.17362e+01
I0514 23:08:03.875999 140128494741248 run_lib.py:165] step: 223100, eval_loss: 2.54630e+01
I0514 23:08:10.273970 140128494741248 run_lib.py:152] step: 223150, training_loss: 2.83477e+01
I0514 23:08:16.493138 140128494741248 run_lib.py:152] step: 223200, training_loss: 4.07412e+01
I0514 23:08:16.548487 140128494741248 run_lib.py:165] step: 223200, eval_loss: 4.04099e+01
I0514 23:08:22.754165 140128494741248 run_lib.py:152] step: 223250, training_loss: 2.43889e+01
I0514 23:08:29.230405 140128494741248 run_lib.py:152] step: 223300, training_loss: 2.75019e+01
I0514 23:08:29.280234 140128494741248 run_lib.py:165] step: 223300, eval_loss: 3.48821e+01
I0514 23:08:35.423320 140128494741248 run_lib.py:152] step: 223350, training_loss: 2.63630e+01
I0514 23:08:41.622122 140128494741248 run_lib.py:152] step: 223400, training_loss: 3.91006e+01
I0514 23:08:41.675767 140128494741248 run_lib.py:165] step: 223400, eval_loss: 4.39725e+01
I0514 23:08:47.825997 140128494741248 run_lib.py:152] step: 223450, training_loss: 2.61004e+01
I0514 23:08:54.305340 140128494741248 run_lib.py:152] step: 223500, training_loss: 3.65168e+01
I0514 23:08:54.357304 140128494741248 run_lib.py:165] step: 223500, eval_loss: 2.51386e+01
I0514 23:09:00.512079 140128494741248 run_lib.py:152] step: 223550, training_loss: 3.07749e+01
I0514 23:09:06.671173 140128494741248 run_lib.py:152] step: 223600, training_loss: 2.63220e+01
I0514 23:09:06.726394 140128494741248 run_lib.py:165] step: 223600, eval_loss: 2.55342e+01
I0514 23:09:13.102765 140128494741248 run_lib.py:152] step: 223650, training_loss: 4.29710e+01
I0514 23:09:19.381232 140128494741248 run_lib.py:152] step: 223700, training_loss: 2.91112e+01
I0514 23:09:19.435793 140128494741248 run_lib.py:165] step: 223700, eval_loss: 2.81753e+01
I0514 23:09:25.580627 140128494741248 run_lib.py:152] step: 223750, training_loss: 2.73548e+01
I0514 23:09:31.863830 140128494741248 run_lib.py:152] step: 223800, training_loss: 3.64330e+01
I0514 23:09:31.914535 140128494741248 run_lib.py:165] step: 223800, eval_loss: 3.24749e+01
I0514 23:09:38.321202 140128494741248 run_lib.py:152] step: 223850, training_loss: 2.63635e+01
I0514 23:09:44.432460 140128494741248 run_lib.py:152] step: 223900, training_loss: 3.25123e+01
I0514 23:09:44.483628 140128494741248 run_lib.py:165] step: 223900, eval_loss: 2.39080e+01
I0514 23:09:50.740839 140128494741248 run_lib.py:152] step: 223950, training_loss: 2.87156e+01
I0514 23:09:57.152338 140128494741248 run_lib.py:152] step: 224000, training_loss: 3.95998e+01
I0514 23:09:57.202393 140128494741248 run_lib.py:165] step: 224000, eval_loss: 3.07306e+01
I0514 23:10:03.461649 140128494741248 run_lib.py:152] step: 224050, training_loss: 3.56847e+01
I0514 23:10:09.593931 140128494741248 run_lib.py:152] step: 224100, training_loss: 3.38585e+01
I0514 23:10:09.640150 140128494741248 run_lib.py:165] step: 224100, eval_loss: 3.61028e+01
I0514 23:10:15.852632 140128494741248 run_lib.py:152] step: 224150, training_loss: 4.05067e+01
I0514 23:10:22.280101 140128494741248 run_lib.py:152] step: 224200, training_loss: 4.07976e+01
I0514 23:10:22.330365 140128494741248 run_lib.py:165] step: 224200, eval_loss: 3.44432e+01
I0514 23:10:28.453469 140128494741248 run_lib.py:152] step: 224250, training_loss: 3.39330e+01
I0514 23:10:34.567626 140128494741248 run_lib.py:152] step: 224300, training_loss: 2.52750e+01
I0514 23:10:34.615295 140128494741248 run_lib.py:165] step: 224300, eval_loss: 2.91141e+01
I0514 23:10:41.125148 140128494741248 run_lib.py:152] step: 224350, training_loss: 3.58018e+01
I0514 23:10:47.390647 140128494741248 run_lib.py:152] step: 224400, training_loss: 4.50038e+01
I0514 23:10:47.443420 140128494741248 run_lib.py:165] step: 224400, eval_loss: 3.62851e+01
I0514 23:10:53.620294 140128494741248 run_lib.py:152] step: 224450, training_loss: 2.58869e+01
I0514 23:10:59.842245 140128494741248 run_lib.py:152] step: 224500, training_loss: 2.59934e+01
I0514 23:10:59.899262 140128494741248 run_lib.py:165] step: 224500, eval_loss: 3.26623e+01
I0514 23:11:06.361108 140128494741248 run_lib.py:152] step: 224550, training_loss: 2.55609e+01
I0514 23:11:12.656179 140128494741248 run_lib.py:152] step: 224600, training_loss: 3.07532e+01
I0514 23:11:12.710425 140128494741248 run_lib.py:165] step: 224600, eval_loss: 5.26813e+01
I0514 23:11:18.861401 140128494741248 run_lib.py:152] step: 224650, training_loss: 4.40175e+01
I0514 23:11:25.301859 140128494741248 run_lib.py:152] step: 224700, training_loss: 3.35242e+01
I0514 23:11:25.353419 140128494741248 run_lib.py:165] step: 224700, eval_loss: 2.27204e+01
I0514 23:11:31.475327 140128494741248 run_lib.py:152] step: 224750, training_loss: 3.53085e+01
I0514 23:11:37.681672 140128494741248 run_lib.py:152] step: 224800, training_loss: 4.96631e+01
I0514 23:11:37.737837 140128494741248 run_lib.py:165] step: 224800, eval_loss: 3.15078e+01
I0514 23:11:43.930739 140128494741248 run_lib.py:152] step: 224850, training_loss: 3.18818e+01
I0514 23:11:50.357342 140128494741248 run_lib.py:152] step: 224900, training_loss: 2.69340e+01
I0514 23:11:50.408799 140128494741248 run_lib.py:165] step: 224900, eval_loss: 2.97029e+01
I0514 23:11:56.575242 140128494741248 run_lib.py:152] step: 224950, training_loss: 4.01287e+01
I0514 23:12:02.733776 140128494741248 run_lib.py:152] step: 225000, training_loss: 2.22732e+01
I0514 23:12:02.790085 140128494741248 run_lib.py:165] step: 225000, eval_loss: 3.30104e+01
I0514 23:12:09.247629 140128494741248 run_lib.py:152] step: 225050, training_loss: 3.40888e+01
I0514 23:12:15.467548 140128494741248 run_lib.py:152] step: 225100, training_loss: 3.66560e+01
I0514 23:12:15.520020 140128494741248 run_lib.py:165] step: 225100, eval_loss: 2.96121e+01
I0514 23:12:21.687235 140128494741248 run_lib.py:152] step: 225150, training_loss: 3.63195e+01
I0514 23:12:27.806801 140128494741248 run_lib.py:152] step: 225200, training_loss: 1.69049e+01
I0514 23:12:27.861831 140128494741248 run_lib.py:165] step: 225200, eval_loss: 3.91978e+01
I0514 23:12:34.295916 140128494741248 run_lib.py:152] step: 225250, training_loss: 2.15439e+01
I0514 23:12:40.498788 140128494741248 run_lib.py:152] step: 225300, training_loss: 2.44914e+01
I0514 23:12:40.549668 140128494741248 run_lib.py:165] step: 225300, eval_loss: 3.98761e+01
I0514 23:12:46.737942 140128494741248 run_lib.py:152] step: 225350, training_loss: 4.48963e+01
I0514 23:12:53.139363 140128494741248 run_lib.py:152] step: 225400, training_loss: 2.45189e+01
I0514 23:12:53.194113 140128494741248 run_lib.py:165] step: 225400, eval_loss: 3.72383e+01
I0514 23:12:59.388903 140128494741248 run_lib.py:152] step: 225450, training_loss: 3.28724e+01
I0514 23:13:05.544243 140128494741248 run_lib.py:152] step: 225500, training_loss: 1.87789e+01
I0514 23:13:05.595453 140128494741248 run_lib.py:165] step: 225500, eval_loss: 1.64486e+01
I0514 23:13:11.801980 140128494741248 run_lib.py:152] step: 225550, training_loss: 2.07468e+01
I0514 23:13:18.138432 140128494741248 run_lib.py:152] step: 225600, training_loss: 3.38221e+01
I0514 23:13:18.197567 140128494741248 run_lib.py:165] step: 225600, eval_loss: 3.92436e+01
I0514 23:13:24.481200 140128494741248 run_lib.py:152] step: 225650, training_loss: 2.46312e+01
I0514 23:13:30.647987 140128494741248 run_lib.py:152] step: 225700, training_loss: 3.12495e+01
I0514 23:13:30.695449 140128494741248 run_lib.py:165] step: 225700, eval_loss: 5.58391e+01
I0514 23:13:37.127391 140128494741248 run_lib.py:152] step: 225750, training_loss: 2.51790e+01
I0514 23:13:43.330094 140128494741248 run_lib.py:152] step: 225800, training_loss: 4.29580e+01
I0514 23:13:43.383726 140128494741248 run_lib.py:165] step: 225800, eval_loss: 3.47632e+01
I0514 23:13:49.533834 140128494741248 run_lib.py:152] step: 225850, training_loss: 3.25495e+01
I0514 23:13:55.808468 140128494741248 run_lib.py:152] step: 225900, training_loss: 3.87972e+01
I0514 23:13:55.862525 140128494741248 run_lib.py:165] step: 225900, eval_loss: 3.25856e+01
I0514 23:14:02.399924 140128494741248 run_lib.py:152] step: 225950, training_loss: 2.56729e+01
I0514 23:14:08.457508 140128494741248 run_lib.py:152] step: 226000, training_loss: 2.78143e+01
I0514 23:14:08.509234 140128494741248 run_lib.py:165] step: 226000, eval_loss: 4.09136e+01
I0514 23:14:14.772275 140128494741248 run_lib.py:152] step: 226050, training_loss: 3.30851e+01
I0514 23:14:21.187676 140128494741248 run_lib.py:152] step: 226100, training_loss: 4.40262e+01
I0514 23:14:21.237348 140128494741248 run_lib.py:165] step: 226100, eval_loss: 2.50264e+01
I0514 23:14:27.378165 140128494741248 run_lib.py:152] step: 226150, training_loss: 2.85242e+01
I0514 23:14:33.592716 140128494741248 run_lib.py:152] step: 226200, training_loss: 4.19009e+01
I0514 23:14:33.643711 140128494741248 run_lib.py:165] step: 226200, eval_loss: 3.63344e+01
I0514 23:14:39.814654 140128494741248 run_lib.py:152] step: 226250, training_loss: 2.36655e+01
I0514 23:14:46.252294 140128494741248 run_lib.py:152] step: 226300, training_loss: 2.17497e+01
I0514 23:14:46.303194 140128494741248 run_lib.py:165] step: 226300, eval_loss: 3.92220e+01
I0514 23:14:52.608456 140128494741248 run_lib.py:152] step: 226350, training_loss: 3.49676e+01
I0514 23:14:58.838450 140128494741248 run_lib.py:152] step: 226400, training_loss: 3.61475e+01
I0514 23:14:58.894318 140128494741248 run_lib.py:165] step: 226400, eval_loss: 2.95918e+01
I0514 23:15:05.332252 140128494741248 run_lib.py:152] step: 226450, training_loss: 1.83102e+01
I0514 23:15:11.659408 140128494741248 run_lib.py:152] step: 226500, training_loss: 1.65706e+01
I0514 23:15:11.716552 140128494741248 run_lib.py:165] step: 226500, eval_loss: 2.53599e+01
I0514 23:15:17.914335 140128494741248 run_lib.py:152] step: 226550, training_loss: 3.11675e+01
I0514 23:15:24.149528 140128494741248 run_lib.py:152] step: 226600, training_loss: 3.05890e+01
I0514 23:15:24.201177 140128494741248 run_lib.py:165] step: 226600, eval_loss: 3.30995e+01
I0514 23:15:30.692981 140128494741248 run_lib.py:152] step: 226650, training_loss: 2.28410e+01
I0514 23:15:36.889371 140128494741248 run_lib.py:152] step: 226700, training_loss: 2.84332e+01
I0514 23:15:36.947294 140128494741248 run_lib.py:165] step: 226700, eval_loss: 2.81211e+01
I0514 23:15:43.067708 140128494741248 run_lib.py:152] step: 226750, training_loss: 2.25928e+01
I0514 23:15:49.550411 140128494741248 run_lib.py:152] step: 226800, training_loss: 2.72765e+01
I0514 23:15:49.597433 140128494741248 run_lib.py:165] step: 226800, eval_loss: 2.41602e+01
I0514 23:15:55.776658 140128494741248 run_lib.py:152] step: 226850, training_loss: 3.23090e+01
I0514 23:16:01.946927 140128494741248 run_lib.py:152] step: 226900, training_loss: 3.37417e+01
I0514 23:16:01.999303 140128494741248 run_lib.py:165] step: 226900, eval_loss: 1.60708e+01
I0514 23:16:08.289754 140128494741248 run_lib.py:152] step: 226950, training_loss: 4.15554e+01
I0514 23:16:14.805643 140128494741248 run_lib.py:152] step: 227000, training_loss: 3.82449e+01
I0514 23:16:14.861274 140128494741248 run_lib.py:165] step: 227000, eval_loss: 2.13700e+01
I0514 23:16:21.058141 140128494741248 run_lib.py:152] step: 227050, training_loss: 2.26976e+01
I0514 23:16:27.242223 140128494741248 run_lib.py:152] step: 227100, training_loss: 2.64349e+01
I0514 23:16:27.291827 140128494741248 run_lib.py:165] step: 227100, eval_loss: 4.77157e+01
I0514 23:16:33.806112 140128494741248 run_lib.py:152] step: 227150, training_loss: 2.48134e+01
I0514 23:16:40.030248 140128494741248 run_lib.py:152] step: 227200, training_loss: 2.53612e+01
I0514 23:16:40.085703 140128494741248 run_lib.py:165] step: 227200, eval_loss: 3.09978e+01
I0514 23:16:46.419778 140128494741248 run_lib.py:152] step: 227250, training_loss: 3.30609e+01
I0514 23:16:52.693908 140128494741248 run_lib.py:152] step: 227300, training_loss: 4.56186e+01
I0514 23:16:52.742777 140128494741248 run_lib.py:165] step: 227300, eval_loss: 3.23758e+01
I0514 23:16:59.166590 140128494741248 run_lib.py:152] step: 227350, training_loss: 2.77451e+01
I0514 23:17:05.253483 140128494741248 run_lib.py:152] step: 227400, training_loss: 2.47209e+01
I0514 23:17:05.302784 140128494741248 run_lib.py:165] step: 227400, eval_loss: 2.44433e+01
I0514 23:17:11.486621 140128494741248 run_lib.py:152] step: 227450, training_loss: 2.89279e+01
I0514 23:17:17.953991 140128494741248 run_lib.py:152] step: 227500, training_loss: 1.90994e+01
I0514 23:17:18.007751 140128494741248 run_lib.py:165] step: 227500, eval_loss: 4.92115e+01
I0514 23:17:24.166289 140128494741248 run_lib.py:152] step: 227550, training_loss: 3.58152e+01
I0514 23:17:30.500492 140128494741248 run_lib.py:152] step: 227600, training_loss: 3.43400e+01
I0514 23:17:30.549900 140128494741248 run_lib.py:165] step: 227600, eval_loss: 3.49163e+01
I0514 23:17:36.872445 140128494741248 run_lib.py:152] step: 227650, training_loss: 6.33753e+01
I0514 23:17:43.308683 140128494741248 run_lib.py:152] step: 227700, training_loss: 1.57114e+01
I0514 23:17:43.359281 140128494741248 run_lib.py:165] step: 227700, eval_loss: 5.64709e+01
I0514 23:17:49.520222 140128494741248 run_lib.py:152] step: 227750, training_loss: 2.61518e+01
I0514 23:17:55.706851 140128494741248 run_lib.py:152] step: 227800, training_loss: 3.54674e+01
I0514 23:17:55.766945 140128494741248 run_lib.py:165] step: 227800, eval_loss: 3.64484e+01
I0514 23:18:02.159250 140128494741248 run_lib.py:152] step: 227850, training_loss: 4.00990e+01
I0514 23:18:08.308486 140128494741248 run_lib.py:152] step: 227900, training_loss: 3.02815e+01
I0514 23:18:08.358957 140128494741248 run_lib.py:165] step: 227900, eval_loss: 4.21711e+01
I0514 23:18:14.574389 140128494741248 run_lib.py:152] step: 227950, training_loss: 4.03559e+01
I0514 23:18:20.798170 140128494741248 run_lib.py:152] step: 228000, training_loss: 3.59530e+01
I0514 23:18:20.850560 140128494741248 run_lib.py:165] step: 228000, eval_loss: 3.61041e+01
I0514 23:18:27.270399 140128494741248 run_lib.py:152] step: 228050, training_loss: 2.62496e+01
I0514 23:18:33.464440 140128494741248 run_lib.py:152] step: 228100, training_loss: 3.86173e+01
I0514 23:18:33.513384 140128494741248 run_lib.py:165] step: 228100, eval_loss: 3.42685e+01
I0514 23:18:39.759506 140128494741248 run_lib.py:152] step: 228150, training_loss: 3.11686e+01
I0514 23:18:46.187259 140128494741248 run_lib.py:152] step: 228200, training_loss: 3.62960e+01
I0514 23:18:46.237454 140128494741248 run_lib.py:165] step: 228200, eval_loss: 3.46104e+01
I0514 23:18:52.566611 140128494741248 run_lib.py:152] step: 228250, training_loss: 2.63486e+01
I0514 23:18:58.748589 140128494741248 run_lib.py:152] step: 228300, training_loss: 3.39762e+01
I0514 23:18:58.800623 140128494741248 run_lib.py:165] step: 228300, eval_loss: 4.08493e+01
I0514 23:19:05.043290 140128494741248 run_lib.py:152] step: 228350, training_loss: 3.64359e+01
I0514 23:19:11.457545 140128494741248 run_lib.py:152] step: 228400, training_loss: 4.27658e+01
I0514 23:19:11.509129 140128494741248 run_lib.py:165] step: 228400, eval_loss: 4.18255e+01
I0514 23:19:17.784258 140128494741248 run_lib.py:152] step: 228450, training_loss: 2.35540e+01
I0514 23:19:23.989557 140128494741248 run_lib.py:152] step: 228500, training_loss: 3.28859e+01
I0514 23:19:24.041423 140128494741248 run_lib.py:165] step: 228500, eval_loss: 3.84189e+01
I0514 23:19:30.502665 140128494741248 run_lib.py:152] step: 228550, training_loss: 3.76878e+01
I0514 23:19:36.780497 140128494741248 run_lib.py:152] step: 228600, training_loss: 2.27273e+01
I0514 23:19:36.837714 140128494741248 run_lib.py:165] step: 228600, eval_loss: 3.52602e+01
I0514 23:19:43.008758 140128494741248 run_lib.py:152] step: 228650, training_loss: 2.68391e+01
I0514 23:19:49.270967 140128494741248 run_lib.py:152] step: 228700, training_loss: 3.98725e+01
I0514 23:19:49.320968 140128494741248 run_lib.py:165] step: 228700, eval_loss: 2.67646e+01
I0514 23:19:55.752192 140128494741248 run_lib.py:152] step: 228750, training_loss: 2.22055e+01
I0514 23:20:01.997503 140128494741248 run_lib.py:152] step: 228800, training_loss: 1.79639e+01
I0514 23:20:02.048262 140128494741248 run_lib.py:165] step: 228800, eval_loss: 2.90144e+01
I0514 23:20:08.278909 140128494741248 run_lib.py:152] step: 228850, training_loss: 3.51519e+01
I0514 23:20:14.685030 140128494741248 run_lib.py:152] step: 228900, training_loss: 5.20529e+01
I0514 23:20:14.739056 140128494741248 run_lib.py:165] step: 228900, eval_loss: 3.57838e+01
I0514 23:20:20.968263 140128494741248 run_lib.py:152] step: 228950, training_loss: 2.78713e+01
I0514 23:20:27.155795 140128494741248 run_lib.py:152] step: 229000, training_loss: 3.22414e+01
I0514 23:20:27.205038 140128494741248 run_lib.py:165] step: 229000, eval_loss: 2.37676e+01
I0514 23:20:33.350110 140128494741248 run_lib.py:152] step: 229050, training_loss: 2.20374e+01
I0514 23:20:39.799561 140128494741248 run_lib.py:152] step: 229100, training_loss: 2.44612e+01
I0514 23:20:39.853746 140128494741248 run_lib.py:165] step: 229100, eval_loss: 4.77158e+01
I0514 23:20:46.048841 140128494741248 run_lib.py:152] step: 229150, training_loss: 2.65909e+01
I0514 23:20:52.266794 140128494741248 run_lib.py:152] step: 229200, training_loss: 2.76076e+01
I0514 23:20:52.319105 140128494741248 run_lib.py:165] step: 229200, eval_loss: 3.12227e+01
I0514 23:20:58.781319 140128494741248 run_lib.py:152] step: 229250, training_loss: 3.31094e+01
I0514 23:21:04.992156 140128494741248 run_lib.py:152] step: 229300, training_loss: 2.53522e+01
I0514 23:21:05.044609 140128494741248 run_lib.py:165] step: 229300, eval_loss: 3.39480e+01
I0514 23:21:11.237935 140128494741248 run_lib.py:152] step: 229350, training_loss: 1.86615e+01
I0514 23:21:17.443539 140128494741248 run_lib.py:152] step: 229400, training_loss: 1.58350e+01
I0514 23:21:17.496098 140128494741248 run_lib.py:165] step: 229400, eval_loss: 2.46465e+01
I0514 23:21:23.912281 140128494741248 run_lib.py:152] step: 229450, training_loss: 2.97763e+01
I0514 23:21:30.077408 140128494741248 run_lib.py:152] step: 229500, training_loss: 4.55537e+01
I0514 23:21:30.126463 140128494741248 run_lib.py:165] step: 229500, eval_loss: 3.58510e+01
I0514 23:21:36.307149 140128494741248 run_lib.py:152] step: 229550, training_loss: 4.66470e+01
I0514 23:21:42.741672 140128494741248 run_lib.py:152] step: 229600, training_loss: 2.30183e+01
I0514 23:21:42.791778 140128494741248 run_lib.py:165] step: 229600, eval_loss: 2.17845e+01
I0514 23:21:48.965835 140128494741248 run_lib.py:152] step: 229650, training_loss: 3.51372e+01
I0514 23:21:55.120831 140128494741248 run_lib.py:152] step: 229700, training_loss: 3.94874e+01
I0514 23:21:55.172067 140128494741248 run_lib.py:165] step: 229700, eval_loss: 3.86428e+01
I0514 23:22:01.393524 140128494741248 run_lib.py:152] step: 229750, training_loss: 2.48385e+01
I0514 23:22:07.876831 140128494741248 run_lib.py:152] step: 229800, training_loss: 4.35525e+01
I0514 23:22:07.924598 140128494741248 run_lib.py:165] step: 229800, eval_loss: 2.75834e+01
I0514 23:22:14.185287 140128494741248 run_lib.py:152] step: 229850, training_loss: 4.16907e+01
I0514 23:22:20.352676 140128494741248 run_lib.py:152] step: 229900, training_loss: 2.22648e+01
I0514 23:22:20.402533 140128494741248 run_lib.py:165] step: 229900, eval_loss: 5.36602e+01
I0514 23:22:27.000502 140128494741248 run_lib.py:152] step: 229950, training_loss: 4.84397e+01
I0514 23:22:33.160658 140128494741248 run_lib.py:152] step: 230000, training_loss: 2.71633e+01
I0514 23:22:33.369496 140128494741248 run_lib.py:165] step: 230000, eval_loss: 2.46898e+01
I0514 23:22:39.584576 140128494741248 run_lib.py:152] step: 230050, training_loss: 3.23603e+01
I0514 23:22:45.899656 140128494741248 run_lib.py:152] step: 230100, training_loss: 5.60190e+01
I0514 23:22:45.957507 140128494741248 run_lib.py:165] step: 230100, eval_loss: 2.67733e+01
I0514 23:22:52.366178 140128494741248 run_lib.py:152] step: 230150, training_loss: 4.68622e+01
I0514 23:22:58.596225 140128494741248 run_lib.py:152] step: 230200, training_loss: 2.84079e+01
I0514 23:22:58.649487 140128494741248 run_lib.py:165] step: 230200, eval_loss: 3.30845e+01
I0514 23:23:04.873589 140128494741248 run_lib.py:152] step: 230250, training_loss: 2.26369e+01
I0514 23:23:11.228750 140128494741248 run_lib.py:152] step: 230300, training_loss: 4.92243e+01
I0514 23:23:11.285737 140128494741248 run_lib.py:165] step: 230300, eval_loss: 3.50440e+01
I0514 23:23:17.475489 140128494741248 run_lib.py:152] step: 230350, training_loss: 2.78724e+01
I0514 23:23:23.646503 140128494741248 run_lib.py:152] step: 230400, training_loss: 3.98852e+01
I0514 23:23:23.704436 140128494741248 run_lib.py:165] step: 230400, eval_loss: 2.19842e+01
I0514 23:23:30.001287 140128494741248 run_lib.py:152] step: 230450, training_loss: 3.65777e+01
I0514 23:23:36.367370 140128494741248 run_lib.py:152] step: 230500, training_loss: 4.44243e+01
I0514 23:23:36.420711 140128494741248 run_lib.py:165] step: 230500, eval_loss: 3.46952e+01
I0514 23:23:42.588145 140128494741248 run_lib.py:152] step: 230550, training_loss: 2.75543e+01
I0514 23:23:48.772263 140128494741248 run_lib.py:152] step: 230600, training_loss: 2.69888e+01
I0514 23:23:48.818550 140128494741248 run_lib.py:165] step: 230600, eval_loss: 2.59398e+01
I0514 23:23:55.301380 140128494741248 run_lib.py:152] step: 230650, training_loss: 3.11245e+01
I0514 23:24:01.407625 140128494741248 run_lib.py:152] step: 230700, training_loss: 3.06970e+01
I0514 23:24:01.459411 140128494741248 run_lib.py:165] step: 230700, eval_loss: 2.80501e+01
I0514 23:24:07.716732 140128494741248 run_lib.py:152] step: 230750, training_loss: 3.38231e+01
I0514 23:24:13.870321 140128494741248 run_lib.py:152] step: 230800, training_loss: 2.46369e+01
I0514 23:24:13.927998 140128494741248 run_lib.py:165] step: 230800, eval_loss: 2.02679e+01
I0514 23:24:20.367882 140128494741248 run_lib.py:152] step: 230850, training_loss: 2.71194e+01
I0514 23:24:26.560452 140128494741248 run_lib.py:152] step: 230900, training_loss: 3.52923e+01
I0514 23:24:26.608451 140128494741248 run_lib.py:165] step: 230900, eval_loss: 2.91640e+01
I0514 23:24:32.782871 140128494741248 run_lib.py:152] step: 230950, training_loss: 3.20749e+01
I0514 23:24:39.184447 140128494741248 run_lib.py:152] step: 231000, training_loss: 1.69370e+01
I0514 23:24:39.236373 140128494741248 run_lib.py:165] step: 231000, eval_loss: 3.87200e+01
I0514 23:24:45.418478 140128494741248 run_lib.py:152] step: 231050, training_loss: 3.93019e+01
I0514 23:24:51.555612 140128494741248 run_lib.py:152] step: 231100, training_loss: 2.92900e+01
I0514 23:24:51.604212 140128494741248 run_lib.py:165] step: 231100, eval_loss: 2.48914e+01
I0514 23:24:58.083476 140128494741248 run_lib.py:152] step: 231150, training_loss: 4.30271e+01
I0514 23:25:04.286326 140128494741248 run_lib.py:152] step: 231200, training_loss: 3.50200e+01
I0514 23:25:04.337594 140128494741248 run_lib.py:165] step: 231200, eval_loss: 3.89727e+01
I0514 23:25:10.569851 140128494741248 run_lib.py:152] step: 231250, training_loss: 2.24050e+01
I0514 23:25:16.820778 140128494741248 run_lib.py:152] step: 231300, training_loss: 2.47134e+01
I0514 23:25:16.874494 140128494741248 run_lib.py:165] step: 231300, eval_loss: 2.29095e+01
I0514 23:25:23.416526 140128494741248 run_lib.py:152] step: 231350, training_loss: 3.85631e+01
I0514 23:25:29.606139 140128494741248 run_lib.py:152] step: 231400, training_loss: 3.24675e+01
I0514 23:25:29.653688 140128494741248 run_lib.py:165] step: 231400, eval_loss: 2.94996e+01
I0514 23:25:35.891951 140128494741248 run_lib.py:152] step: 231450, training_loss: 4.49017e+01
I0514 23:25:42.323504 140128494741248 run_lib.py:152] step: 231500, training_loss: 3.16825e+01
I0514 23:25:42.377879 140128494741248 run_lib.py:165] step: 231500, eval_loss: 2.41931e+01
I0514 23:25:48.596377 140128494741248 run_lib.py:152] step: 231550, training_loss: 2.52302e+01
I0514 23:25:54.849706 140128494741248 run_lib.py:152] step: 231600, training_loss: 2.16909e+01
I0514 23:25:54.900311 140128494741248 run_lib.py:165] step: 231600, eval_loss: 3.15243e+01
I0514 23:26:01.082440 140128494741248 run_lib.py:152] step: 231650, training_loss: 2.49198e+01
I0514 23:26:07.559317 140128494741248 run_lib.py:152] step: 231700, training_loss: 2.93080e+01
I0514 23:26:07.609416 140128494741248 run_lib.py:165] step: 231700, eval_loss: 2.62711e+01
I0514 23:26:13.882500 140128494741248 run_lib.py:152] step: 231750, training_loss: 4.03807e+01
I0514 23:26:20.096354 140128494741248 run_lib.py:152] step: 231800, training_loss: 2.24089e+01
I0514 23:26:20.147544 140128494741248 run_lib.py:165] step: 231800, eval_loss: 2.28211e+01
I0514 23:26:26.514888 140128494741248 run_lib.py:152] step: 231850, training_loss: 2.28817e+01
I0514 23:26:32.781604 140128494741248 run_lib.py:152] step: 231900, training_loss: 2.62823e+01
I0514 23:26:32.838739 140128494741248 run_lib.py:165] step: 231900, eval_loss: 4.13755e+01
I0514 23:26:38.972448 140128494741248 run_lib.py:152] step: 231950, training_loss: 2.47619e+01
I0514 23:26:45.204580 140128494741248 run_lib.py:152] step: 232000, training_loss: 2.93445e+01
I0514 23:26:45.256233 140128494741248 run_lib.py:165] step: 232000, eval_loss: 3.88299e+01
I0514 23:26:51.671231 140128494741248 run_lib.py:152] step: 232050, training_loss: 4.09116e+01
I0514 23:26:57.824592 140128494741248 run_lib.py:152] step: 232100, training_loss: 3.50329e+01
I0514 23:26:57.874130 140128494741248 run_lib.py:165] step: 232100, eval_loss: 1.99391e+01
I0514 23:27:04.108190 140128494741248 run_lib.py:152] step: 232150, training_loss: 4.30660e+01
I0514 23:27:10.611049 140128494741248 run_lib.py:152] step: 232200, training_loss: 1.74878e+01
I0514 23:27:10.661743 140128494741248 run_lib.py:165] step: 232200, eval_loss: 3.56197e+01
I0514 23:27:16.974480 140128494741248 run_lib.py:152] step: 232250, training_loss: 3.67858e+01
I0514 23:27:23.165383 140128494741248 run_lib.py:152] step: 232300, training_loss: 2.86016e+01
I0514 23:27:23.218834 140128494741248 run_lib.py:165] step: 232300, eval_loss: 3.36777e+01
I0514 23:27:29.453592 140128494741248 run_lib.py:152] step: 232350, training_loss: 1.86754e+01
I0514 23:27:35.869943 140128494741248 run_lib.py:152] step: 232400, training_loss: 4.79140e+01
I0514 23:27:35.923600 140128494741248 run_lib.py:165] step: 232400, eval_loss: 2.49621e+01
I0514 23:27:42.105140 140128494741248 run_lib.py:152] step: 232450, training_loss: 4.87209e+01
I0514 23:27:48.317910 140128494741248 run_lib.py:152] step: 232500, training_loss: 3.14795e+01
I0514 23:27:48.373489 140128494741248 run_lib.py:165] step: 232500, eval_loss: 2.71099e+01
I0514 23:27:54.752035 140128494741248 run_lib.py:152] step: 232550, training_loss: 3.15381e+01
I0514 23:28:00.867584 140128494741248 run_lib.py:152] step: 232600, training_loss: 2.41414e+01
I0514 23:28:00.919332 140128494741248 run_lib.py:165] step: 232600, eval_loss: 2.27366e+01
I0514 23:28:07.120036 140128494741248 run_lib.py:152] step: 232650, training_loss: 3.86994e+01
I0514 23:28:13.299145 140128494741248 run_lib.py:152] step: 232700, training_loss: 4.52306e+01
I0514 23:28:13.350428 140128494741248 run_lib.py:165] step: 232700, eval_loss: 3.01207e+01
I0514 23:28:19.800395 140128494741248 run_lib.py:152] step: 232750, training_loss: 2.64366e+01
I0514 23:28:25.900755 140128494741248 run_lib.py:152] step: 232800, training_loss: 2.02751e+01
I0514 23:28:25.951437 140128494741248 run_lib.py:165] step: 232800, eval_loss: 2.86327e+01
I0514 23:28:32.162026 140128494741248 run_lib.py:152] step: 232850, training_loss: 2.31113e+01
I0514 23:28:38.521927 140128494741248 run_lib.py:152] step: 232900, training_loss: 4.73769e+01
I0514 23:28:38.573853 140128494741248 run_lib.py:165] step: 232900, eval_loss: 2.07866e+01
I0514 23:28:44.693734 140128494741248 run_lib.py:152] step: 232950, training_loss: 3.64418e+01
I0514 23:28:50.994326 140128494741248 run_lib.py:152] step: 233000, training_loss: 1.86277e+01
I0514 23:28:51.049072 140128494741248 run_lib.py:165] step: 233000, eval_loss: 2.81837e+01
I0514 23:28:57.229899 140128494741248 run_lib.py:152] step: 233050, training_loss: 3.63965e+01
I0514 23:29:03.682361 140128494741248 run_lib.py:152] step: 233100, training_loss: 3.30434e+01
I0514 23:29:03.733386 140128494741248 run_lib.py:165] step: 233100, eval_loss: 4.22961e+01
I0514 23:29:09.892973 140128494741248 run_lib.py:152] step: 233150, training_loss: 4.45928e+01
I0514 23:29:16.042476 140128494741248 run_lib.py:152] step: 233200, training_loss: 3.11237e+01
I0514 23:29:16.096032 140128494741248 run_lib.py:165] step: 233200, eval_loss: 3.33597e+01
I0514 23:29:22.466936 140128494741248 run_lib.py:152] step: 233250, training_loss: 3.34494e+01
I0514 23:29:28.715436 140128494741248 run_lib.py:152] step: 233300, training_loss: 4.49258e+01
I0514 23:29:28.773146 140128494741248 run_lib.py:165] step: 233300, eval_loss: 1.57945e+01
I0514 23:29:35.051842 140128494741248 run_lib.py:152] step: 233350, training_loss: 3.38760e+01
I0514 23:29:41.178764 140128494741248 run_lib.py:152] step: 233400, training_loss: 3.90049e+01
I0514 23:29:41.236099 140128494741248 run_lib.py:165] step: 233400, eval_loss: 2.88348e+01
I0514 23:29:47.751146 140128494741248 run_lib.py:152] step: 233450, training_loss: 3.80724e+01
I0514 23:29:53.983395 140128494741248 run_lib.py:152] step: 233500, training_loss: 3.67773e+01
I0514 23:29:54.034707 140128494741248 run_lib.py:165] step: 233500, eval_loss: 3.27742e+01
I0514 23:30:00.148043 140128494741248 run_lib.py:152] step: 233550, training_loss: 4.08545e+01
I0514 23:30:06.467547 140128494741248 run_lib.py:152] step: 233600, training_loss: 4.34230e+01
I0514 23:30:06.743330 140128494741248 run_lib.py:165] step: 233600, eval_loss: 3.41274e+01
I0514 23:30:12.981372 140128494741248 run_lib.py:152] step: 233650, training_loss: 2.46182e+01
I0514 23:30:19.226803 140128494741248 run_lib.py:152] step: 233700, training_loss: 2.74425e+01
I0514 23:30:19.278265 140128494741248 run_lib.py:165] step: 233700, eval_loss: 3.40372e+01
I0514 23:30:25.389476 140128494741248 run_lib.py:152] step: 233750, training_loss: 2.81415e+01
I0514 23:30:31.745965 140128494741248 run_lib.py:152] step: 233800, training_loss: 2.34962e+01
I0514 23:30:31.794318 140128494741248 run_lib.py:165] step: 233800, eval_loss: 2.88919e+01
I0514 23:30:38.075842 140128494741248 run_lib.py:152] step: 233850, training_loss: 2.44778e+01
I0514 23:30:44.275565 140128494741248 run_lib.py:152] step: 233900, training_loss: 2.18166e+01
I0514 23:30:44.328045 140128494741248 run_lib.py:165] step: 233900, eval_loss: 3.43163e+01
I0514 23:30:50.788698 140128494741248 run_lib.py:152] step: 233950, training_loss: 3.03551e+01
I0514 23:30:57.005508 140128494741248 run_lib.py:152] step: 234000, training_loss: 3.50538e+01
I0514 23:30:57.059417 140128494741248 run_lib.py:165] step: 234000, eval_loss: 3.76267e+01
I0514 23:31:03.247094 140128494741248 run_lib.py:152] step: 234050, training_loss: 2.91267e+01
I0514 23:31:09.420583 140128494741248 run_lib.py:152] step: 234100, training_loss: 3.73411e+01
I0514 23:31:09.472213 140128494741248 run_lib.py:165] step: 234100, eval_loss: 3.58391e+01
I0514 23:31:15.974615 140128494741248 run_lib.py:152] step: 234150, training_loss: 2.86196e+01
I0514 23:31:22.162364 140128494741248 run_lib.py:152] step: 234200, training_loss: 3.45348e+01
I0514 23:31:22.213013 140128494741248 run_lib.py:165] step: 234200, eval_loss: 3.80390e+01
I0514 23:31:28.301648 140128494741248 run_lib.py:152] step: 234250, training_loss: 3.99033e+01
I0514 23:31:34.658118 140128494741248 run_lib.py:152] step: 234300, training_loss: 2.89161e+01
I0514 23:31:34.708460 140128494741248 run_lib.py:165] step: 234300, eval_loss: 2.53998e+01
I0514 23:31:40.853677 140128494741248 run_lib.py:152] step: 234350, training_loss: 2.20054e+01
I0514 23:31:47.091277 140128494741248 run_lib.py:152] step: 234400, training_loss: 3.55676e+01
I0514 23:31:47.147854 140128494741248 run_lib.py:165] step: 234400, eval_loss: 1.18408e+01
I0514 23:31:53.294155 140128494741248 run_lib.py:152] step: 234450, training_loss: 3.27719e+01
I0514 23:31:59.793730 140128494741248 run_lib.py:152] step: 234500, training_loss: 3.57778e+01
I0514 23:31:59.852048 140128494741248 run_lib.py:165] step: 234500, eval_loss: 3.95751e+01
I0514 23:32:05.983830 140128494741248 run_lib.py:152] step: 234550, training_loss: 4.75601e+01
I0514 23:32:12.087639 140128494741248 run_lib.py:152] step: 234600, training_loss: 3.38189e+01
I0514 23:32:12.133943 140128494741248 run_lib.py:165] step: 234600, eval_loss: 2.31927e+01
I0514 23:32:18.589979 140128494741248 run_lib.py:152] step: 234650, training_loss: 3.04927e+01
I0514 23:32:24.709650 140128494741248 run_lib.py:152] step: 234700, training_loss: 2.84908e+01
I0514 23:32:24.762125 140128494741248 run_lib.py:165] step: 234700, eval_loss: 3.62269e+01
I0514 23:32:30.917601 140128494741248 run_lib.py:152] step: 234750, training_loss: 3.17136e+01
I0514 23:32:37.163051 140128494741248 run_lib.py:152] step: 234800, training_loss: 2.56942e+01
I0514 23:32:37.220445 140128494741248 run_lib.py:165] step: 234800, eval_loss: 2.71414e+01
I0514 23:32:43.653720 140128494741248 run_lib.py:152] step: 234850, training_loss: 3.72792e+01
I0514 23:32:49.766905 140128494741248 run_lib.py:152] step: 234900, training_loss: 3.65431e+01
I0514 23:32:49.820137 140128494741248 run_lib.py:165] step: 234900, eval_loss: 4.74079e+01
I0514 23:32:56.005407 140128494741248 run_lib.py:152] step: 234950, training_loss: 3.45886e+01
I0514 23:33:02.338150 140128494741248 run_lib.py:152] step: 235000, training_loss: 3.01600e+01
I0514 23:33:02.389806 140128494741248 run_lib.py:165] step: 235000, eval_loss: 4.74042e+01
I0514 23:33:08.568104 140128494741248 run_lib.py:152] step: 235050, training_loss: 2.61349e+01
I0514 23:33:14.759650 140128494741248 run_lib.py:152] step: 235100, training_loss: 2.61277e+01
I0514 23:33:14.809649 140128494741248 run_lib.py:165] step: 235100, eval_loss: 3.81892e+01
I0514 23:33:21.078201 140128494741248 run_lib.py:152] step: 235150, training_loss: 1.65989e+01
I0514 23:33:27.409948 140128494741248 run_lib.py:152] step: 235200, training_loss: 3.39261e+01
I0514 23:33:27.466228 140128494741248 run_lib.py:165] step: 235200, eval_loss: 1.64743e+01
I0514 23:33:33.677552 140128494741248 run_lib.py:152] step: 235250, training_loss: 2.65656e+01
I0514 23:33:39.853720 140128494741248 run_lib.py:152] step: 235300, training_loss: 3.15809e+01
I0514 23:33:39.906266 140128494741248 run_lib.py:165] step: 235300, eval_loss: 3.42489e+01
I0514 23:33:46.252099 140128494741248 run_lib.py:152] step: 235350, training_loss: 4.78315e+01
I0514 23:33:52.403730 140128494741248 run_lib.py:152] step: 235400, training_loss: 2.20617e+01
I0514 23:33:52.459503 140128494741248 run_lib.py:165] step: 235400, eval_loss: 2.24043e+01
I0514 23:33:58.593315 140128494741248 run_lib.py:152] step: 235450, training_loss: 2.74239e+01
I0514 23:34:04.821561 140128494741248 run_lib.py:152] step: 235500, training_loss: 2.30071e+01
I0514 23:34:04.869952 140128494741248 run_lib.py:165] step: 235500, eval_loss: 3.25631e+01
I0514 23:34:11.369301 140128494741248 run_lib.py:152] step: 235550, training_loss: 3.40045e+01
I0514 23:34:17.522838 140128494741248 run_lib.py:152] step: 235600, training_loss: 2.82439e+01
I0514 23:34:17.580123 140128494741248 run_lib.py:165] step: 235600, eval_loss: 3.43817e+01
I0514 23:34:23.765533 140128494741248 run_lib.py:152] step: 235650, training_loss: 3.55832e+01
I0514 23:34:30.249569 140128494741248 run_lib.py:152] step: 235700, training_loss: 3.80849e+01
I0514 23:34:30.303118 140128494741248 run_lib.py:165] step: 235700, eval_loss: 2.44752e+01
I0514 23:34:36.506034 140128494741248 run_lib.py:152] step: 235750, training_loss: 3.05828e+01
I0514 23:34:42.761648 140128494741248 run_lib.py:152] step: 235800, training_loss: 4.15293e+01
I0514 23:34:42.816416 140128494741248 run_lib.py:165] step: 235800, eval_loss: 3.31595e+01
I0514 23:34:49.075442 140128494741248 run_lib.py:152] step: 235850, training_loss: 4.43568e+01
I0514 23:34:55.466231 140128494741248 run_lib.py:152] step: 235900, training_loss: 3.31214e+01
I0514 23:34:55.526650 140128494741248 run_lib.py:165] step: 235900, eval_loss: 2.44944e+01
I0514 23:35:01.766420 140128494741248 run_lib.py:152] step: 235950, training_loss: 2.49982e+01
I0514 23:35:08.073028 140128494741248 run_lib.py:152] step: 236000, training_loss: 3.36722e+01
I0514 23:35:08.123855 140128494741248 run_lib.py:165] step: 236000, eval_loss: 3.50902e+01
I0514 23:35:14.576123 140128494741248 run_lib.py:152] step: 236050, training_loss: 4.17603e+01
I0514 23:35:20.762815 140128494741248 run_lib.py:152] step: 236100, training_loss: 5.70930e+01
I0514 23:35:20.816296 140128494741248 run_lib.py:165] step: 236100, eval_loss: 2.79725e+01
I0514 23:35:26.989245 140128494741248 run_lib.py:152] step: 236150, training_loss: 2.54440e+01
I0514 23:35:33.240963 140128494741248 run_lib.py:152] step: 236200, training_loss: 4.80261e+01
I0514 23:35:33.297562 140128494741248 run_lib.py:165] step: 236200, eval_loss: 3.35673e+01
I0514 23:35:39.703684 140128494741248 run_lib.py:152] step: 236250, training_loss: 2.99839e+01
I0514 23:35:46.015339 140128494741248 run_lib.py:152] step: 236300, training_loss: 3.41755e+01
I0514 23:35:46.063937 140128494741248 run_lib.py:165] step: 236300, eval_loss: 3.79759e+01
I0514 23:35:52.181475 140128494741248 run_lib.py:152] step: 236350, training_loss: 3.23738e+01
I0514 23:35:58.679569 140128494741248 run_lib.py:152] step: 236400, training_loss: 1.21901e+01
I0514 23:35:58.727671 140128494741248 run_lib.py:165] step: 236400, eval_loss: 2.64803e+01
I0514 23:36:04.939407 140128494741248 run_lib.py:152] step: 236450, training_loss: 4.36234e+01
I0514 23:36:11.155422 140128494741248 run_lib.py:152] step: 236500, training_loss: 2.87973e+01
I0514 23:36:11.208456 140128494741248 run_lib.py:165] step: 236500, eval_loss: 2.65813e+01
I0514 23:36:17.334766 140128494741248 run_lib.py:152] step: 236550, training_loss: 3.02311e+01
I0514 23:36:23.764424 140128494741248 run_lib.py:152] step: 236600, training_loss: 2.42679e+01
I0514 23:36:23.814446 140128494741248 run_lib.py:165] step: 236600, eval_loss: 3.98795e+01
I0514 23:36:30.038276 140128494741248 run_lib.py:152] step: 236650, training_loss: 2.47805e+01
I0514 23:36:36.190040 140128494741248 run_lib.py:152] step: 236700, training_loss: 4.49996e+01
I0514 23:36:36.241069 140128494741248 run_lib.py:165] step: 236700, eval_loss: 1.87988e+01
I0514 23:36:42.606235 140128494741248 run_lib.py:152] step: 236750, training_loss: 2.45060e+01
I0514 23:36:48.785589 140128494741248 run_lib.py:152] step: 236800, training_loss: 2.61954e+01
I0514 23:36:48.836149 140128494741248 run_lib.py:165] step: 236800, eval_loss: 4.61966e+01
I0514 23:36:55.059311 140128494741248 run_lib.py:152] step: 236850, training_loss: 3.63428e+01
I0514 23:37:01.290911 140128494741248 run_lib.py:152] step: 236900, training_loss: 3.16087e+01
I0514 23:37:01.345686 140128494741248 run_lib.py:165] step: 236900, eval_loss: 4.22751e+01
I0514 23:37:07.769363 140128494741248 run_lib.py:152] step: 236950, training_loss: 4.40318e+01
I0514 23:37:13.889333 140128494741248 run_lib.py:152] step: 237000, training_loss: 2.41951e+01
I0514 23:37:13.944205 140128494741248 run_lib.py:165] step: 237000, eval_loss: 3.08090e+01
I0514 23:37:20.168127 140128494741248 run_lib.py:152] step: 237050, training_loss: 3.67671e+01
I0514 23:37:26.360484 140128494741248 run_lib.py:152] step: 237100, training_loss: 2.72730e+01
I0514 23:37:26.644382 140128494741248 run_lib.py:165] step: 237100, eval_loss: 2.16904e+01
I0514 23:37:32.818213 140128494741248 run_lib.py:152] step: 237150, training_loss: 4.68427e+01
I0514 23:37:39.051747 140128494741248 run_lib.py:152] step: 237200, training_loss: 2.78277e+01
I0514 23:37:39.102845 140128494741248 run_lib.py:165] step: 237200, eval_loss: 5.10010e+01
I0514 23:37:45.336449 140128494741248 run_lib.py:152] step: 237250, training_loss: 3.36666e+01
I0514 23:37:51.818690 140128494741248 run_lib.py:152] step: 237300, training_loss: 4.12607e+01
I0514 23:37:51.875267 140128494741248 run_lib.py:165] step: 237300, eval_loss: 2.80157e+01
I0514 23:37:58.115957 140128494741248 run_lib.py:152] step: 237350, training_loss: 3.05098e+01
I0514 23:38:04.332701 140128494741248 run_lib.py:152] step: 237400, training_loss: 2.30608e+01
I0514 23:38:04.380786 140128494741248 run_lib.py:165] step: 237400, eval_loss: 2.64825e+01
I0514 23:38:10.752115 140128494741248 run_lib.py:152] step: 237450, training_loss: 1.72941e+01
I0514 23:38:16.931991 140128494741248 run_lib.py:152] step: 237500, training_loss: 4.78018e+01
I0514 23:38:16.984476 140128494741248 run_lib.py:165] step: 237500, eval_loss: 1.41871e+01
I0514 23:38:23.103721 140128494741248 run_lib.py:152] step: 237550, training_loss: 3.18822e+01
I0514 23:38:29.291591 140128494741248 run_lib.py:152] step: 237600, training_loss: 3.14805e+01
I0514 23:38:29.346819 140128494741248 run_lib.py:165] step: 237600, eval_loss: 2.83221e+01
I0514 23:38:35.697152 140128494741248 run_lib.py:152] step: 237650, training_loss: 4.53597e+01
I0514 23:38:41.895520 140128494741248 run_lib.py:152] step: 237700, training_loss: 3.67695e+01
I0514 23:38:41.949334 140128494741248 run_lib.py:165] step: 237700, eval_loss: 1.63332e+01
I0514 23:38:48.235704 140128494741248 run_lib.py:152] step: 237750, training_loss: 3.46195e+01
I0514 23:38:54.720067 140128494741248 run_lib.py:152] step: 237800, training_loss: 1.88205e+01
I0514 23:38:54.779127 140128494741248 run_lib.py:165] step: 237800, eval_loss: 2.93998e+01
I0514 23:39:00.979935 140128494741248 run_lib.py:152] step: 237850, training_loss: 2.68342e+01
I0514 23:39:07.235417 140128494741248 run_lib.py:152] step: 237900, training_loss: 4.25187e+01
I0514 23:39:07.285957 140128494741248 run_lib.py:165] step: 237900, eval_loss: 3.49613e+01
I0514 23:39:13.501960 140128494741248 run_lib.py:152] step: 237950, training_loss: 2.46287e+01
I0514 23:39:20.007214 140128494741248 run_lib.py:152] step: 238000, training_loss: 3.54343e+01
I0514 23:39:20.058897 140128494741248 run_lib.py:165] step: 238000, eval_loss: 5.03179e+01
I0514 23:39:26.333319 140128494741248 run_lib.py:152] step: 238050, training_loss: 2.81923e+01
I0514 23:39:32.555354 140128494741248 run_lib.py:152] step: 238100, training_loss: 3.09559e+01
I0514 23:39:32.610208 140128494741248 run_lib.py:165] step: 238100, eval_loss: 1.85654e+01
I0514 23:39:39.028016 140128494741248 run_lib.py:152] step: 238150, training_loss: 2.43944e+01
I0514 23:39:45.201289 140128494741248 run_lib.py:152] step: 238200, training_loss: 2.05063e+01
I0514 23:39:45.253680 140128494741248 run_lib.py:165] step: 238200, eval_loss: 2.16456e+01
I0514 23:39:51.451104 140128494741248 run_lib.py:152] step: 238250, training_loss: 3.68144e+01
I0514 23:39:57.695994 140128494741248 run_lib.py:152] step: 238300, training_loss: 2.87799e+01
I0514 23:39:57.747213 140128494741248 run_lib.py:165] step: 238300, eval_loss: 3.80167e+01
I0514 23:40:04.101337 140128494741248 run_lib.py:152] step: 238350, training_loss: 2.79461e+01
I0514 23:40:10.245999 140128494741248 run_lib.py:152] step: 238400, training_loss: 4.34355e+01
I0514 23:40:10.301164 140128494741248 run_lib.py:165] step: 238400, eval_loss: 3.61342e+01
I0514 23:40:16.492374 140128494741248 run_lib.py:152] step: 238450, training_loss: 4.05505e+01
I0514 23:40:22.916696 140128494741248 run_lib.py:152] step: 238500, training_loss: 2.45972e+01
I0514 23:40:22.971526 140128494741248 run_lib.py:165] step: 238500, eval_loss: 1.94945e+01
I0514 23:40:29.123978 140128494741248 run_lib.py:152] step: 238550, training_loss: 4.30463e+01
I0514 23:40:35.299371 140128494741248 run_lib.py:152] step: 238600, training_loss: 3.85089e+01
I0514 23:40:35.352287 140128494741248 run_lib.py:165] step: 238600, eval_loss: 4.04462e+01
I0514 23:40:41.490264 140128494741248 run_lib.py:152] step: 238650, training_loss: 4.24365e+01
I0514 23:40:47.842544 140128494741248 run_lib.py:152] step: 238700, training_loss: 3.82651e+01
I0514 23:40:47.903226 140128494741248 run_lib.py:165] step: 238700, eval_loss: 2.96854e+01
I0514 23:40:53.971327 140128494741248 run_lib.py:152] step: 238750, training_loss: 2.23706e+01
I0514 23:40:59.968485 140128494741248 run_lib.py:152] step: 238800, training_loss: 3.23535e+01
I0514 23:41:00.022977 140128494741248 run_lib.py:165] step: 238800, eval_loss: 2.52493e+01
I0514 23:41:06.430702 140128494741248 run_lib.py:152] step: 238850, training_loss: 3.15855e+01
I0514 23:41:12.619885 140128494741248 run_lib.py:152] step: 238900, training_loss: 2.23373e+01
I0514 23:41:12.672108 140128494741248 run_lib.py:165] step: 238900, eval_loss: 2.43800e+01
I0514 23:41:18.873471 140128494741248 run_lib.py:152] step: 238950, training_loss: 1.93786e+01
I0514 23:41:25.134267 140128494741248 run_lib.py:152] step: 239000, training_loss: 3.70884e+01
I0514 23:41:25.185403 140128494741248 run_lib.py:165] step: 239000, eval_loss: 3.80120e+01
I0514 23:41:31.561800 140128494741248 run_lib.py:152] step: 239050, training_loss: 2.29976e+01
I0514 23:41:37.756649 140128494741248 run_lib.py:152] step: 239100, training_loss: 4.08041e+01
I0514 23:41:37.808144 140128494741248 run_lib.py:165] step: 239100, eval_loss: 2.62334e+01
I0514 23:41:44.069862 140128494741248 run_lib.py:152] step: 239150, training_loss: 2.90337e+01
I0514 23:41:50.443755 140128494741248 run_lib.py:152] step: 239200, training_loss: 2.74341e+01
I0514 23:41:50.495428 140128494741248 run_lib.py:165] step: 239200, eval_loss: 2.82006e+01
I0514 23:41:56.692508 140128494741248 run_lib.py:152] step: 239250, training_loss: 1.83352e+01
I0514 23:42:02.860726 140128494741248 run_lib.py:152] step: 239300, training_loss: 3.31523e+01
I0514 23:42:02.905804 140128494741248 run_lib.py:165] step: 239300, eval_loss: 1.80151e+01
I0514 23:42:09.127827 140128494741248 run_lib.py:152] step: 239350, training_loss: 3.45882e+01
I0514 23:42:15.479045 140128494741248 run_lib.py:152] step: 239400, training_loss: 3.01264e+01
I0514 23:42:15.529414 140128494741248 run_lib.py:165] step: 239400, eval_loss: 2.33753e+01
I0514 23:42:21.705144 140128494741248 run_lib.py:152] step: 239450, training_loss: 3.53578e+01
I0514 23:42:27.930648 140128494741248 run_lib.py:152] step: 239500, training_loss: 3.49588e+01
I0514 23:42:27.985340 140128494741248 run_lib.py:165] step: 239500, eval_loss: 4.82571e+01
I0514 23:42:34.404500 140128494741248 run_lib.py:152] step: 239550, training_loss: 3.11092e+01
I0514 23:42:40.649445 140128494741248 run_lib.py:152] step: 239600, training_loss: 4.11675e+01
I0514 23:42:40.702382 140128494741248 run_lib.py:165] step: 239600, eval_loss: 2.87504e+01
I0514 23:42:46.887721 140128494741248 run_lib.py:152] step: 239650, training_loss: 3.74082e+01
I0514 23:42:53.045175 140128494741248 run_lib.py:152] step: 239700, training_loss: 2.81525e+01
I0514 23:42:53.102004 140128494741248 run_lib.py:165] step: 239700, eval_loss: 4.23634e+01
I0514 23:42:59.547070 140128494741248 run_lib.py:152] step: 239750, training_loss: 2.40473e+01
I0514 23:43:05.791990 140128494741248 run_lib.py:152] step: 239800, training_loss: 3.33889e+01
I0514 23:43:05.843660 140128494741248 run_lib.py:165] step: 239800, eval_loss: 2.94974e+01
I0514 23:43:12.073853 140128494741248 run_lib.py:152] step: 239850, training_loss: 3.39542e+01
I0514 23:43:18.436040 140128494741248 run_lib.py:152] step: 239900, training_loss: 3.30156e+01
I0514 23:43:18.488505 140128494741248 run_lib.py:165] step: 239900, eval_loss: 4.61788e+01
I0514 23:43:24.718555 140128494741248 run_lib.py:152] step: 239950, training_loss: 2.79137e+01
I0514 23:43:30.857121 140128494741248 run_lib.py:152] step: 240000, training_loss: 2.70652e+01
I0514 23:43:31.057266 140128494741248 run_lib.py:165] step: 240000, eval_loss: 3.28125e+01
I0514 23:43:37.255366 140128494741248 run_lib.py:152] step: 240050, training_loss: 2.59916e+01
I0514 23:43:43.690235 140128494741248 run_lib.py:152] step: 240100, training_loss: 3.44852e+01
I0514 23:43:43.745428 140128494741248 run_lib.py:165] step: 240100, eval_loss: 2.21389e+01
I0514 23:43:49.859575 140128494741248 run_lib.py:152] step: 240150, training_loss: 2.28097e+01
I0514 23:43:56.032279 140128494741248 run_lib.py:152] step: 240200, training_loss: 2.78538e+01
I0514 23:43:56.085499 140128494741248 run_lib.py:165] step: 240200, eval_loss: 4.06932e+01
I0514 23:44:02.449256 140128494741248 run_lib.py:152] step: 240250, training_loss: 3.05106e+01
I0514 23:44:08.614133 140128494741248 run_lib.py:152] step: 240300, training_loss: 2.50287e+01
I0514 23:44:08.667380 140128494741248 run_lib.py:165] step: 240300, eval_loss: 2.95931e+01
I0514 23:44:14.829479 140128494741248 run_lib.py:152] step: 240350, training_loss: 2.77625e+01
I0514 23:44:21.046498 140128494741248 run_lib.py:152] step: 240400, training_loss: 2.72811e+01
I0514 23:44:21.096721 140128494741248 run_lib.py:165] step: 240400, eval_loss: 4.66449e+01
I0514 23:44:27.524756 140128494741248 run_lib.py:152] step: 240450, training_loss: 2.28982e+01
I0514 23:44:33.694257 140128494741248 run_lib.py:152] step: 240500, training_loss: 2.33339e+01
I0514 23:44:33.749085 140128494741248 run_lib.py:165] step: 240500, eval_loss: 3.08952e+01
I0514 23:44:39.933738 140128494741248 run_lib.py:152] step: 240550, training_loss: 1.82536e+01
I0514 23:44:46.096711 140128494741248 run_lib.py:152] step: 240600, training_loss: 3.04321e+01
I0514 23:44:46.375781 140128494741248 run_lib.py:165] step: 240600, eval_loss: 4.23575e+01
I0514 23:44:52.622619 140128494741248 run_lib.py:152] step: 240650, training_loss: 2.39459e+01
I0514 23:44:58.838799 140128494741248 run_lib.py:152] step: 240700, training_loss: 2.83404e+01
I0514 23:44:58.890124 140128494741248 run_lib.py:165] step: 240700, eval_loss: 5.07253e+01
I0514 23:45:05.026177 140128494741248 run_lib.py:152] step: 240750, training_loss: 2.45629e+01
I0514 23:45:11.562437 140128494741248 run_lib.py:152] step: 240800, training_loss: 3.79925e+01
I0514 23:45:11.615830 140128494741248 run_lib.py:165] step: 240800, eval_loss: 3.10265e+01
I0514 23:45:17.875707 140128494741248 run_lib.py:152] step: 240850, training_loss: 3.73574e+01
I0514 23:45:24.107702 140128494741248 run_lib.py:152] step: 240900, training_loss: 3.32365e+01
I0514 23:45:24.156904 140128494741248 run_lib.py:165] step: 240900, eval_loss: 2.44400e+01
I0514 23:45:30.570177 140128494741248 run_lib.py:152] step: 240950, training_loss: 2.13300e+01
I0514 23:45:36.804965 140128494741248 run_lib.py:152] step: 241000, training_loss: 3.99951e+01
I0514 23:45:36.861959 140128494741248 run_lib.py:165] step: 241000, eval_loss: 4.94000e+01
I0514 23:45:43.082669 140128494741248 run_lib.py:152] step: 241050, training_loss: 3.09243e+01
I0514 23:45:49.319988 140128494741248 run_lib.py:152] step: 241100, training_loss: 2.77019e+01
I0514 23:45:49.370461 140128494741248 run_lib.py:165] step: 241100, eval_loss: 1.84436e+01
I0514 23:45:55.745505 140128494741248 run_lib.py:152] step: 241150, training_loss: 2.33544e+01
I0514 23:46:01.981416 140128494741248 run_lib.py:152] step: 241200, training_loss: 2.50402e+01
I0514 23:46:02.032409 140128494741248 run_lib.py:165] step: 241200, eval_loss: 1.54590e+01
I0514 23:46:08.339206 140128494741248 run_lib.py:152] step: 241250, training_loss: 3.20759e+01
I0514 23:46:14.818604 140128494741248 run_lib.py:152] step: 241300, training_loss: 2.58803e+01
I0514 23:46:14.875708 140128494741248 run_lib.py:165] step: 241300, eval_loss: 5.13318e+01
I0514 23:46:21.123208 140128494741248 run_lib.py:152] step: 241350, training_loss: 3.22015e+01
I0514 23:46:27.405135 140128494741248 run_lib.py:152] step: 241400, training_loss: 3.30367e+01
I0514 23:46:27.459986 140128494741248 run_lib.py:165] step: 241400, eval_loss: 3.63131e+01
I0514 23:46:33.522359 140128494741248 run_lib.py:152] step: 241450, training_loss: 4.19768e+01
I0514 23:46:39.991058 140128494741248 run_lib.py:152] step: 241500, training_loss: 1.80539e+01
I0514 23:46:40.044126 140128494741248 run_lib.py:165] step: 241500, eval_loss: 3.77836e+01
I0514 23:46:46.319778 140128494741248 run_lib.py:152] step: 241550, training_loss: 4.07638e+01
I0514 23:46:52.544783 140128494741248 run_lib.py:152] step: 241600, training_loss: 1.94188e+01
I0514 23:46:52.595909 140128494741248 run_lib.py:165] step: 241600, eval_loss: 3.22021e+01
I0514 23:46:59.019308 140128494741248 run_lib.py:152] step: 241650, training_loss: 4.82348e+01
I0514 23:47:05.131356 140128494741248 run_lib.py:152] step: 241700, training_loss: 3.95433e+01
I0514 23:47:05.179070 140128494741248 run_lib.py:165] step: 241700, eval_loss: 2.28805e+01
I0514 23:47:11.499799 140128494741248 run_lib.py:152] step: 241750, training_loss: 2.87476e+01
I0514 23:47:17.782020 140128494741248 run_lib.py:152] step: 241800, training_loss: 2.89708e+01
I0514 23:47:17.835932 140128494741248 run_lib.py:165] step: 241800, eval_loss: 1.84417e+01
I0514 23:47:24.184356 140128494741248 run_lib.py:152] step: 241850, training_loss: 2.45630e+01
I0514 23:47:30.396968 140128494741248 run_lib.py:152] step: 241900, training_loss: 4.64044e+01
I0514 23:47:30.455596 140128494741248 run_lib.py:165] step: 241900, eval_loss: 3.21328e+01
I0514 23:47:36.566019 140128494741248 run_lib.py:152] step: 241950, training_loss: 4.61775e+01
I0514 23:47:43.027300 140128494741248 run_lib.py:152] step: 242000, training_loss: 3.21226e+01
I0514 23:47:43.076520 140128494741248 run_lib.py:165] step: 242000, eval_loss: 3.43926e+01
I0514 23:47:49.273760 140128494741248 run_lib.py:152] step: 242050, training_loss: 3.10630e+01
I0514 23:47:55.430497 140128494741248 run_lib.py:152] step: 242100, training_loss: 3.16494e+01
I0514 23:47:55.482707 140128494741248 run_lib.py:165] step: 242100, eval_loss: 3.68699e+01
I0514 23:48:01.669133 140128494741248 run_lib.py:152] step: 242150, training_loss: 4.41146e+01
I0514 23:48:08.128281 140128494741248 run_lib.py:152] step: 242200, training_loss: 3.76818e+01
I0514 23:48:08.184581 140128494741248 run_lib.py:165] step: 242200, eval_loss: 4.38742e+01
I0514 23:48:14.461823 140128494741248 run_lib.py:152] step: 242250, training_loss: 3.39073e+01
I0514 23:48:20.677106 140128494741248 run_lib.py:152] step: 242300, training_loss: 2.57875e+01
I0514 23:48:20.731207 140128494741248 run_lib.py:165] step: 242300, eval_loss: 2.03056e+01
I0514 23:48:27.204024 140128494741248 run_lib.py:152] step: 242350, training_loss: 3.97594e+01
I0514 23:48:33.387001 140128494741248 run_lib.py:152] step: 242400, training_loss: 3.17513e+01
I0514 23:48:33.441570 140128494741248 run_lib.py:165] step: 242400, eval_loss: 3.16568e+01
I0514 23:48:39.576792 140128494741248 run_lib.py:152] step: 242450, training_loss: 3.64365e+01
I0514 23:48:45.762175 140128494741248 run_lib.py:152] step: 242500, training_loss: 3.30486e+01
I0514 23:48:45.813198 140128494741248 run_lib.py:165] step: 242500, eval_loss: 2.92742e+01
I0514 23:48:52.214327 140128494741248 run_lib.py:152] step: 242550, training_loss: 3.41829e+01
I0514 23:48:58.363175 140128494741248 run_lib.py:152] step: 242600, training_loss: 4.27410e+01
I0514 23:48:58.417392 140128494741248 run_lib.py:165] step: 242600, eval_loss: 2.39131e+01
I0514 23:49:04.703592 140128494741248 run_lib.py:152] step: 242650, training_loss: 4.46731e+01
I0514 23:49:11.114190 140128494741248 run_lib.py:152] step: 242700, training_loss: 2.55943e+01
I0514 23:49:11.166238 140128494741248 run_lib.py:165] step: 242700, eval_loss: 2.03329e+01
I0514 23:49:17.221757 140128494741248 run_lib.py:152] step: 242750, training_loss: 2.00519e+01
I0514 23:49:23.475291 140128494741248 run_lib.py:152] step: 242800, training_loss: 3.01183e+01
I0514 23:49:23.529552 140128494741248 run_lib.py:165] step: 242800, eval_loss: 3.04549e+01
I0514 23:49:29.666737 140128494741248 run_lib.py:152] step: 242850, training_loss: 2.17544e+01
I0514 23:49:36.145576 140128494741248 run_lib.py:152] step: 242900, training_loss: 3.44770e+01
I0514 23:49:36.196559 140128494741248 run_lib.py:165] step: 242900, eval_loss: 2.75029e+01
I0514 23:49:42.306442 140128494741248 run_lib.py:152] step: 242950, training_loss: 2.91759e+01
I0514 23:49:48.443313 140128494741248 run_lib.py:152] step: 243000, training_loss: 3.07899e+01
I0514 23:49:48.493208 140128494741248 run_lib.py:165] step: 243000, eval_loss: 1.41475e+01
I0514 23:49:54.903306 140128494741248 run_lib.py:152] step: 243050, training_loss: 2.53456e+01
I0514 23:50:01.089838 140128494741248 run_lib.py:152] step: 243100, training_loss: 4.12112e+01
I0514 23:50:01.138157 140128494741248 run_lib.py:165] step: 243100, eval_loss: 3.15568e+01
I0514 23:50:07.330324 140128494741248 run_lib.py:152] step: 243150, training_loss: 3.54107e+01
I0514 23:50:13.439846 140128494741248 run_lib.py:152] step: 243200, training_loss: 3.58774e+01
I0514 23:50:13.491754 140128494741248 run_lib.py:165] step: 243200, eval_loss: 4.32958e+01
I0514 23:50:19.922698 140128494741248 run_lib.py:152] step: 243250, training_loss: 2.73165e+01
I0514 23:50:26.198877 140128494741248 run_lib.py:152] step: 243300, training_loss: 2.55783e+01
I0514 23:50:26.247893 140128494741248 run_lib.py:165] step: 243300, eval_loss: 2.82715e+01
I0514 23:50:32.340549 140128494741248 run_lib.py:152] step: 243350, training_loss: 2.70925e+01
I0514 23:50:38.787129 140128494741248 run_lib.py:152] step: 243400, training_loss: 3.08203e+01
I0514 23:50:38.842432 140128494741248 run_lib.py:165] step: 243400, eval_loss: 4.71197e+01
I0514 23:50:45.108583 140128494741248 run_lib.py:152] step: 243450, training_loss: 2.85144e+01
I0514 23:50:51.323044 140128494741248 run_lib.py:152] step: 243500, training_loss: 4.49728e+01
I0514 23:50:51.380297 140128494741248 run_lib.py:165] step: 243500, eval_loss: 3.80348e+01
I0514 23:50:57.554341 140128494741248 run_lib.py:152] step: 243550, training_loss: 3.25445e+01
I0514 23:51:04.029206 140128494741248 run_lib.py:152] step: 243600, training_loss: 3.70443e+01
I0514 23:51:04.079019 140128494741248 run_lib.py:165] step: 243600, eval_loss: 3.13505e+01
I0514 23:51:10.336760 140128494741248 run_lib.py:152] step: 243650, training_loss: 4.33689e+01
I0514 23:51:16.553944 140128494741248 run_lib.py:152] step: 243700, training_loss: 4.23127e+01
I0514 23:51:16.602015 140128494741248 run_lib.py:165] step: 243700, eval_loss: 3.29699e+01
I0514 23:51:23.135908 140128494741248 run_lib.py:152] step: 243750, training_loss: 2.16981e+01
I0514 23:51:29.345098 140128494741248 run_lib.py:152] step: 243800, training_loss: 2.90619e+01
I0514 23:51:29.396651 140128494741248 run_lib.py:165] step: 243800, eval_loss: 3.91217e+01
I0514 23:51:35.506942 140128494741248 run_lib.py:152] step: 243850, training_loss: 2.09148e+01
I0514 23:51:41.832916 140128494741248 run_lib.py:152] step: 243900, training_loss: 3.91538e+01
I0514 23:51:41.880633 140128494741248 run_lib.py:165] step: 243900, eval_loss: 2.25302e+01
I0514 23:51:48.313406 140128494741248 run_lib.py:152] step: 243950, training_loss: 4.01413e+01
I0514 23:51:54.472766 140128494741248 run_lib.py:152] step: 244000, training_loss: 3.87932e+01
I0514 23:51:54.522997 140128494741248 run_lib.py:165] step: 244000, eval_loss: 2.58546e+01
I0514 23:52:00.767892 140128494741248 run_lib.py:152] step: 244050, training_loss: 3.83008e+01
I0514 23:52:07.016683 140128494741248 run_lib.py:152] step: 244100, training_loss: 2.42104e+01
I0514 23:52:07.294633 140128494741248 run_lib.py:165] step: 244100, eval_loss: 2.81771e+01
I0514 23:52:13.474035 140128494741248 run_lib.py:152] step: 244150, training_loss: 2.15830e+01
I0514 23:52:19.734213 140128494741248 run_lib.py:152] step: 244200, training_loss: 2.27939e+01
I0514 23:52:19.789858 140128494741248 run_lib.py:165] step: 244200, eval_loss: 3.00145e+01
I0514 23:52:25.959622 140128494741248 run_lib.py:152] step: 244250, training_loss: 3.03269e+01
I0514 23:52:32.259388 140128494741248 run_lib.py:152] step: 244300, training_loss: 3.07589e+01
I0514 23:52:32.310013 140128494741248 run_lib.py:165] step: 244300, eval_loss: 3.10511e+01
I0514 23:52:38.529299 140128494741248 run_lib.py:152] step: 244350, training_loss: 3.11436e+01
I0514 23:52:44.679249 140128494741248 run_lib.py:152] step: 244400, training_loss: 3.77227e+01
I0514 23:52:44.733453 140128494741248 run_lib.py:165] step: 244400, eval_loss: 1.92436e+01
I0514 23:52:51.337394 140128494741248 run_lib.py:152] step: 244450, training_loss: 3.84309e+01
I0514 23:52:57.428235 140128494741248 run_lib.py:152] step: 244500, training_loss: 2.78449e+01
I0514 23:52:57.485753 140128494741248 run_lib.py:165] step: 244500, eval_loss: 4.97055e+01
I0514 23:53:03.647399 140128494741248 run_lib.py:152] step: 244550, training_loss: 3.27514e+01
I0514 23:53:09.805802 140128494741248 run_lib.py:152] step: 244600, training_loss: 2.10966e+01
I0514 23:53:09.864050 140128494741248 run_lib.py:165] step: 244600, eval_loss: 2.84294e+01
I0514 23:53:16.229084 140128494741248 run_lib.py:152] step: 244650, training_loss: 2.82419e+01
I0514 23:53:22.467653 140128494741248 run_lib.py:152] step: 244700, training_loss: 2.27499e+01
I0514 23:53:22.532085 140128494741248 run_lib.py:165] step: 244700, eval_loss: 2.68604e+01
I0514 23:53:28.739998 140128494741248 run_lib.py:152] step: 244750, training_loss: 3.74597e+01
I0514 23:53:35.169182 140128494741248 run_lib.py:152] step: 244800, training_loss: 3.65301e+01
I0514 23:53:35.220655 140128494741248 run_lib.py:165] step: 244800, eval_loss: 3.83042e+01
I0514 23:53:41.440702 140128494741248 run_lib.py:152] step: 244850, training_loss: 3.63368e+01
I0514 23:53:47.642496 140128494741248 run_lib.py:152] step: 244900, training_loss: 2.03996e+01
I0514 23:53:47.695787 140128494741248 run_lib.py:165] step: 244900, eval_loss: 2.57433e+01
I0514 23:53:53.905161 140128494741248 run_lib.py:152] step: 244950, training_loss: 2.63793e+01
I0514 23:54:00.337634 140128494741248 run_lib.py:152] step: 245000, training_loss: 5.05726e+01
I0514 23:54:00.384217 140128494741248 run_lib.py:165] step: 245000, eval_loss: 5.57102e+01
I0514 23:54:06.617711 140128494741248 run_lib.py:152] step: 245050, training_loss: 2.05015e+01
I0514 23:54:12.903311 140128494741248 run_lib.py:152] step: 245100, training_loss: 2.25180e+01
I0514 23:54:12.955456 140128494741248 run_lib.py:165] step: 245100, eval_loss: 4.50788e+01
I0514 23:54:19.340040 140128494741248 run_lib.py:152] step: 245150, training_loss: 3.88159e+01
I0514 23:54:25.556482 140128494741248 run_lib.py:152] step: 245200, training_loss: 3.43899e+01
I0514 23:54:25.606875 140128494741248 run_lib.py:165] step: 245200, eval_loss: 2.73281e+01
I0514 23:54:31.801486 140128494741248 run_lib.py:152] step: 245250, training_loss: 2.61468e+01
I0514 23:54:37.951302 140128494741248 run_lib.py:152] step: 245300, training_loss: 2.22652e+01
I0514 23:54:38.001981 140128494741248 run_lib.py:165] step: 245300, eval_loss: 3.27197e+01
I0514 23:54:44.500431 140128494741248 run_lib.py:152] step: 245350, training_loss: 3.38715e+01
I0514 23:54:50.653104 140128494741248 run_lib.py:152] step: 245400, training_loss: 1.88529e+01
I0514 23:54:50.706664 140128494741248 run_lib.py:165] step: 245400, eval_loss: 2.44684e+01
I0514 23:54:56.937407 140128494741248 run_lib.py:152] step: 245450, training_loss: 3.21916e+01
I0514 23:55:03.485561 140128494741248 run_lib.py:152] step: 245500, training_loss: 1.39104e+01
I0514 23:55:03.536596 140128494741248 run_lib.py:165] step: 245500, eval_loss: 2.66595e+01
I0514 23:55:09.685563 140128494741248 run_lib.py:152] step: 245550, training_loss: 2.45550e+01
I0514 23:55:15.879560 140128494741248 run_lib.py:152] step: 245600, training_loss: 2.58857e+01
I0514 23:55:15.934425 140128494741248 run_lib.py:165] step: 245600, eval_loss: 2.88933e+01
I0514 23:55:22.133318 140128494741248 run_lib.py:152] step: 245650, training_loss: 4.53264e+01
I0514 23:55:28.571649 140128494741248 run_lib.py:152] step: 245700, training_loss: 4.96384e+01
I0514 23:55:28.627468 140128494741248 run_lib.py:165] step: 245700, eval_loss: 2.52123e+01
I0514 23:55:34.771848 140128494741248 run_lib.py:152] step: 245750, training_loss: 3.55107e+01
I0514 23:55:40.982027 140128494741248 run_lib.py:152] step: 245800, training_loss: 4.15212e+01
I0514 23:55:41.031264 140128494741248 run_lib.py:165] step: 245800, eval_loss: 2.22071e+01
I0514 23:55:47.498785 140128494741248 run_lib.py:152] step: 245850, training_loss: 3.68517e+01
I0514 23:55:53.700340 140128494741248 run_lib.py:152] step: 245900, training_loss: 3.75412e+01
I0514 23:55:53.752228 140128494741248 run_lib.py:165] step: 245900, eval_loss: 2.22195e+01
I0514 23:56:00.055805 140128494741248 run_lib.py:152] step: 245950, training_loss: 4.88273e+01
I0514 23:56:06.409542 140128494741248 run_lib.py:152] step: 246000, training_loss: 1.78589e+01
I0514 23:56:06.463489 140128494741248 run_lib.py:165] step: 246000, eval_loss: 2.43516e+01
I0514 23:56:12.898789 140128494741248 run_lib.py:152] step: 246050, training_loss: 1.86553e+01
I0514 23:56:19.110369 140128494741248 run_lib.py:152] step: 246100, training_loss: 2.91460e+01
I0514 23:56:19.159886 140128494741248 run_lib.py:165] step: 246100, eval_loss: 2.40813e+01
I0514 23:56:25.439095 140128494741248 run_lib.py:152] step: 246150, training_loss: 3.19223e+01
I0514 23:56:31.882784 140128494741248 run_lib.py:152] step: 246200, training_loss: 3.46954e+01
I0514 23:56:31.938039 140128494741248 run_lib.py:165] step: 246200, eval_loss: 2.36764e+01
I0514 23:56:38.114720 140128494741248 run_lib.py:152] step: 246250, training_loss: 2.29661e+01
I0514 23:56:44.358215 140128494741248 run_lib.py:152] step: 246300, training_loss: 4.63619e+01
I0514 23:56:44.414088 140128494741248 run_lib.py:165] step: 246300, eval_loss: 4.08681e+01
I0514 23:56:50.564357 140128494741248 run_lib.py:152] step: 246350, training_loss: 3.56564e+01
I0514 23:56:56.995791 140128494741248 run_lib.py:152] step: 246400, training_loss: 2.46009e+01
I0514 23:56:57.047608 140128494741248 run_lib.py:165] step: 246400, eval_loss: 3.17937e+01
I0514 23:57:03.214014 140128494741248 run_lib.py:152] step: 246450, training_loss: 3.12008e+01
I0514 23:57:09.503766 140128494741248 run_lib.py:152] step: 246500, training_loss: 3.39294e+01
I0514 23:57:09.552881 140128494741248 run_lib.py:165] step: 246500, eval_loss: 3.57545e+01
I0514 23:57:15.989579 140128494741248 run_lib.py:152] step: 246550, training_loss: 2.59295e+01
I0514 23:57:22.260395 140128494741248 run_lib.py:152] step: 246600, training_loss: 3.83615e+01
I0514 23:57:22.313728 140128494741248 run_lib.py:165] step: 246600, eval_loss: 2.56969e+01
I0514 23:57:28.409766 140128494741248 run_lib.py:152] step: 246650, training_loss: 3.97387e+01
I0514 23:57:34.609273 140128494741248 run_lib.py:152] step: 246700, training_loss: 3.26393e+01
I0514 23:57:34.660664 140128494741248 run_lib.py:165] step: 246700, eval_loss: 3.00919e+01
I0514 23:57:41.045883 140128494741248 run_lib.py:152] step: 246750, training_loss: 2.62617e+01
I0514 23:57:47.192585 140128494741248 run_lib.py:152] step: 246800, training_loss: 2.97424e+01
I0514 23:57:47.242230 140128494741248 run_lib.py:165] step: 246800, eval_loss: 3.64240e+01
I0514 23:57:53.427941 140128494741248 run_lib.py:152] step: 246850, training_loss: 1.97907e+01
I0514 23:57:59.930183 140128494741248 run_lib.py:152] step: 246900, training_loss: 3.98162e+01
I0514 23:57:59.985534 140128494741248 run_lib.py:165] step: 246900, eval_loss: 3.50790e+01
I0514 23:58:06.188614 140128494741248 run_lib.py:152] step: 246950, training_loss: 3.57981e+01
I0514 23:58:12.363903 140128494741248 run_lib.py:152] step: 247000, training_loss: 2.17285e+01
I0514 23:58:12.411529 140128494741248 run_lib.py:165] step: 247000, eval_loss: 2.40549e+01
I0514 23:58:18.584206 140128494741248 run_lib.py:152] step: 247050, training_loss: 3.47735e+01
I0514 23:58:25.062452 140128494741248 run_lib.py:152] step: 247100, training_loss: 2.22164e+01
I0514 23:58:25.113878 140128494741248 run_lib.py:165] step: 247100, eval_loss: 2.79552e+01
I0514 23:58:31.218428 140128494741248 run_lib.py:152] step: 247150, training_loss: 2.47123e+01
I0514 23:58:37.372596 140128494741248 run_lib.py:152] step: 247200, training_loss: 4.95861e+01
I0514 23:58:37.427609 140128494741248 run_lib.py:165] step: 247200, eval_loss: 2.29216e+01
I0514 23:58:43.850667 140128494741248 run_lib.py:152] step: 247250, training_loss: 1.78349e+01
I0514 23:58:50.097772 140128494741248 run_lib.py:152] step: 247300, training_loss: 3.18225e+01
I0514 23:58:50.154076 140128494741248 run_lib.py:165] step: 247300, eval_loss: 2.85954e+01
I0514 23:58:56.237131 140128494741248 run_lib.py:152] step: 247350, training_loss: 2.97405e+01
I0514 23:59:02.468145 140128494741248 run_lib.py:152] step: 247400, training_loss: 1.62749e+01
I0514 23:59:02.521938 140128494741248 run_lib.py:165] step: 247400, eval_loss: 3.07785e+01
I0514 23:59:08.923219 140128494741248 run_lib.py:152] step: 247450, training_loss: 2.50372e+01
I0514 23:59:15.155390 140128494741248 run_lib.py:152] step: 247500, training_loss: 1.59546e+01
I0514 23:59:15.208425 140128494741248 run_lib.py:165] step: 247500, eval_loss: 2.35718e+01
I0514 23:59:21.385162 140128494741248 run_lib.py:152] step: 247550, training_loss: 5.10381e+01
I0514 23:59:27.584243 140128494741248 run_lib.py:152] step: 247600, training_loss: 3.67583e+01
I0514 23:59:27.856118 140128494741248 run_lib.py:165] step: 247600, eval_loss: 3.20404e+01
I0514 23:59:34.032413 140128494741248 run_lib.py:152] step: 247650, training_loss: 3.18098e+01
I0514 23:59:40.240319 140128494741248 run_lib.py:152] step: 247700, training_loss: 4.60317e+01
I0514 23:59:40.296871 140128494741248 run_lib.py:165] step: 247700, eval_loss: 4.01739e+01
I0514 23:59:46.543302 140128494741248 run_lib.py:152] step: 247750, training_loss: 3.61761e+01
I0514 23:59:52.918331 140128494741248 run_lib.py:152] step: 247800, training_loss: 4.19387e+01
I0514 23:59:52.970252 140128494741248 run_lib.py:165] step: 247800, eval_loss: 3.77244e+01
I0514 23:59:59.258740 140128494741248 run_lib.py:152] step: 247850, training_loss: 3.42758e+01
I0515 00:00:05.617871 140128494741248 run_lib.py:152] step: 247900, training_loss: 2.65466e+01
I0515 00:00:05.668165 140128494741248 run_lib.py:165] step: 247900, eval_loss: 3.37207e+01
I0515 00:00:12.286703 140128494741248 run_lib.py:152] step: 247950, training_loss: 3.76876e+01
I0515 00:00:19.008949 140128494741248 run_lib.py:152] step: 248000, training_loss: 2.20310e+01
I0515 00:00:19.059628 140128494741248 run_lib.py:165] step: 248000, eval_loss: 3.50207e+01
I0515 00:00:25.614677 140128494741248 run_lib.py:152] step: 248050, training_loss: 3.01981e+01
I0515 00:00:32.113151 140128494741248 run_lib.py:152] step: 248100, training_loss: 1.99976e+01
I0515 00:00:32.166858 140128494741248 run_lib.py:165] step: 248100, eval_loss: 2.59190e+01
I0515 00:00:38.803913 140128494741248 run_lib.py:152] step: 248150, training_loss: 3.15958e+01
I0515 00:00:45.162703 140128494741248 run_lib.py:152] step: 248200, training_loss: 3.26818e+01
I0515 00:00:45.219185 140128494741248 run_lib.py:165] step: 248200, eval_loss: 3.71673e+01
I0515 00:00:51.617020 140128494741248 run_lib.py:152] step: 248250, training_loss: 2.53254e+01
I0515 00:00:58.220203 140128494741248 run_lib.py:152] step: 248300, training_loss: 3.92765e+01
I0515 00:00:58.271940 140128494741248 run_lib.py:165] step: 248300, eval_loss: 2.08579e+01
I0515 00:01:04.551410 140128494741248 run_lib.py:152] step: 248350, training_loss: 3.87465e+01
I0515 00:01:10.816648 140128494741248 run_lib.py:152] step: 248400, training_loss: 3.23774e+01
I0515 00:01:10.872322 140128494741248 run_lib.py:165] step: 248400, eval_loss: 2.47558e+01
I0515 00:01:17.090135 140128494741248 run_lib.py:152] step: 248450, training_loss: 4.91918e+01
I0515 00:01:23.474733 140128494741248 run_lib.py:152] step: 248500, training_loss: 2.45715e+01
I0515 00:01:23.527127 140128494741248 run_lib.py:165] step: 248500, eval_loss: 2.20946e+01
I0515 00:01:29.761913 140128494741248 run_lib.py:152] step: 248550, training_loss: 3.33031e+01
I0515 00:01:35.967828 140128494741248 run_lib.py:152] step: 248600, training_loss: 2.96904e+01
I0515 00:01:36.020157 140128494741248 run_lib.py:165] step: 248600, eval_loss: 1.26839e+01
I0515 00:01:42.474335 140128494741248 run_lib.py:152] step: 248650, training_loss: 4.31917e+01
I0515 00:01:48.764903 140128494741248 run_lib.py:152] step: 248700, training_loss: 2.29672e+01
I0515 00:01:48.819435 140128494741248 run_lib.py:165] step: 248700, eval_loss: 2.84638e+01
I0515 00:01:55.098252 140128494741248 run_lib.py:152] step: 248750, training_loss: 2.13901e+01
I0515 00:02:01.335556 140128494741248 run_lib.py:152] step: 248800, training_loss: 3.35025e+01
I0515 00:02:01.386392 140128494741248 run_lib.py:165] step: 248800, eval_loss: 4.10005e+01
I0515 00:02:07.895849 140128494741248 run_lib.py:152] step: 248850, training_loss: 2.94916e+01
I0515 00:02:14.016098 140128494741248 run_lib.py:152] step: 248900, training_loss: 2.58775e+01
I0515 00:02:14.067485 140128494741248 run_lib.py:165] step: 248900, eval_loss: 4.10325e+01
I0515 00:02:20.289619 140128494741248 run_lib.py:152] step: 248950, training_loss: 2.85249e+01
I0515 00:02:26.766707 140128494741248 run_lib.py:152] step: 249000, training_loss: 3.57934e+01
I0515 00:02:26.817750 140128494741248 run_lib.py:165] step: 249000, eval_loss: 4.07152e+01
I0515 00:02:33.033869 140128494741248 run_lib.py:152] step: 249050, training_loss: 2.32258e+01
I0515 00:02:39.192561 140128494741248 run_lib.py:152] step: 249100, training_loss: 3.72364e+01
I0515 00:02:39.246806 140128494741248 run_lib.py:165] step: 249100, eval_loss: 2.36714e+01
I0515 00:02:45.484465 140128494741248 run_lib.py:152] step: 249150, training_loss: 2.75761e+01
I0515 00:02:52.012625 140128494741248 run_lib.py:152] step: 249200, training_loss: 2.11166e+01
I0515 00:02:52.065098 140128494741248 run_lib.py:165] step: 249200, eval_loss: 3.77574e+01
I0515 00:02:58.248435 140128494741248 run_lib.py:152] step: 249250, training_loss: 2.17712e+01
I0515 00:03:04.424468 140128494741248 run_lib.py:152] step: 249300, training_loss: 3.51915e+01
I0515 00:03:04.475874 140128494741248 run_lib.py:165] step: 249300, eval_loss: 2.48295e+01
I0515 00:03:10.917617 140128494741248 run_lib.py:152] step: 249350, training_loss: 3.31770e+01
I0515 00:03:17.039383 140128494741248 run_lib.py:152] step: 249400, training_loss: 4.16240e+01
I0515 00:03:17.090857 140128494741248 run_lib.py:165] step: 249400, eval_loss: 3.51896e+01
I0515 00:03:23.346739 140128494741248 run_lib.py:152] step: 249450, training_loss: 2.79173e+01
I0515 00:03:29.533961 140128494741248 run_lib.py:152] step: 249500, training_loss: 2.61481e+01
I0515 00:03:29.582197 140128494741248 run_lib.py:165] step: 249500, eval_loss: 4.39195e+01
I0515 00:03:36.065490 140128494741248 run_lib.py:152] step: 249550, training_loss: 2.45837e+01
I0515 00:03:42.215424 140128494741248 run_lib.py:152] step: 249600, training_loss: 2.57167e+01
I0515 00:03:42.265754 140128494741248 run_lib.py:165] step: 249600, eval_loss: 2.11275e+01
I0515 00:03:48.502805 140128494741248 run_lib.py:152] step: 249650, training_loss: 2.29561e+01
I0515 00:03:54.950930 140128494741248 run_lib.py:152] step: 249700, training_loss: 2.57604e+01
I0515 00:03:55.008507 140128494741248 run_lib.py:165] step: 249700, eval_loss: 4.59655e+01
I0515 00:04:01.190250 140128494741248 run_lib.py:152] step: 249750, training_loss: 4.11155e+01
I0515 00:04:07.430284 140128494741248 run_lib.py:152] step: 249800, training_loss: 2.15604e+01
I0515 00:04:07.487119 140128494741248 run_lib.py:165] step: 249800, eval_loss: 3.60072e+01
I0515 00:04:13.602667 140128494741248 run_lib.py:152] step: 249850, training_loss: 2.28914e+01
I0515 00:04:20.113928 140128494741248 run_lib.py:152] step: 249900, training_loss: 3.90149e+01
I0515 00:04:20.161080 140128494741248 run_lib.py:165] step: 249900, eval_loss: 3.07154e+01
I0515 00:04:26.316349 140128494741248 run_lib.py:152] step: 249950, training_loss: 3.19100e+01
I0515 00:04:32.422270 140128494741248 run_lib.py:152] step: 250000, training_loss: 4.07170e+01
I0515 00:04:32.629719 140128494741248 run_lib.py:165] step: 250000, eval_loss: 1.77088e+01
I0515 00:05:53.368714 140128494741248 run_lib.py:152] step: 250050, training_loss: 2.77416e+01
I0515 00:05:59.550472 140128494741248 run_lib.py:152] step: 250100, training_loss: 3.87663e+01
I0515 00:05:59.601547 140128494741248 run_lib.py:165] step: 250100, eval_loss: 4.06601e+01
I0515 00:06:05.975902 140128494741248 run_lib.py:152] step: 250150, training_loss: 3.28677e+01
I0515 00:06:12.501378 140128494741248 run_lib.py:152] step: 250200, training_loss: 3.54563e+01
I0515 00:06:12.551484 140128494741248 run_lib.py:165] step: 250200, eval_loss: 2.87307e+01
I0515 00:06:18.965425 140128494741248 run_lib.py:152] step: 250250, training_loss: 2.63674e+01
I0515 00:06:25.212615 140128494741248 run_lib.py:152] step: 250300, training_loss: 4.34141e+01
I0515 00:06:25.262991 140128494741248 run_lib.py:165] step: 250300, eval_loss: 2.44138e+01
I0515 00:06:31.540012 140128494741248 run_lib.py:152] step: 250350, training_loss: 3.52258e+01
I0515 00:06:38.123777 140128494741248 run_lib.py:152] step: 250400, training_loss: 2.43169e+01
I0515 00:06:38.175867 140128494741248 run_lib.py:165] step: 250400, eval_loss: 2.17418e+01
I0515 00:06:44.367827 140128494741248 run_lib.py:152] step: 250450, training_loss: 2.44902e+01
I0515 00:06:50.660418 140128494741248 run_lib.py:152] step: 250500, training_loss: 4.95477e+01
I0515 00:06:50.717942 140128494741248 run_lib.py:165] step: 250500, eval_loss: 3.36444e+01
I0515 00:06:57.248912 140128494741248 run_lib.py:152] step: 250550, training_loss: 2.35317e+01
I0515 00:07:03.681977 140128494741248 run_lib.py:152] step: 250600, training_loss: 3.59142e+01
I0515 00:07:03.735455 140128494741248 run_lib.py:165] step: 250600, eval_loss: 3.82949e+01
I0515 00:07:10.010892 140128494741248 run_lib.py:152] step: 250650, training_loss: 1.49022e+01
I0515 00:07:16.292545 140128494741248 run_lib.py:152] step: 250700, training_loss: 4.18562e+01
I0515 00:07:16.344118 140128494741248 run_lib.py:165] step: 250700, eval_loss: 2.15473e+01
I0515 00:07:22.937418 140128494741248 run_lib.py:152] step: 250750, training_loss: 3.38205e+01
I0515 00:07:29.158720 140128494741248 run_lib.py:152] step: 250800, training_loss: 2.78510e+01
I0515 00:07:29.214912 140128494741248 run_lib.py:165] step: 250800, eval_loss: 3.03357e+01
I0515 00:07:35.507698 140128494741248 run_lib.py:152] step: 250850, training_loss: 2.13612e+01
I0515 00:07:42.010929 140128494741248 run_lib.py:152] step: 250900, training_loss: 3.70747e+01
I0515 00:07:42.063762 140128494741248 run_lib.py:165] step: 250900, eval_loss: 1.58912e+01
I0515 00:07:48.409406 140128494741248 run_lib.py:152] step: 250950, training_loss: 1.75076e+01
I0515 00:07:54.758102 140128494741248 run_lib.py:152] step: 251000, training_loss: 2.75761e+01
I0515 00:07:54.813104 140128494741248 run_lib.py:165] step: 251000, eval_loss: 4.00108e+01
I0515 00:08:01.092267 140128494741248 run_lib.py:152] step: 251050, training_loss: 2.20180e+01
I0515 00:08:07.578811 140128494741248 run_lib.py:152] step: 251100, training_loss: 4.84732e+01
I0515 00:08:07.629808 140128494741248 run_lib.py:165] step: 251100, eval_loss: 2.50853e+01
I0515 00:08:13.889643 140128494741248 run_lib.py:152] step: 251150, training_loss: 2.18459e+01
I0515 00:08:20.108011 140128494741248 run_lib.py:152] step: 251200, training_loss: 1.79644e+01
I0515 00:08:20.159264 140128494741248 run_lib.py:165] step: 251200, eval_loss: 1.91738e+01
I0515 00:08:26.624539 140128494741248 run_lib.py:152] step: 251250, training_loss: 2.29410e+01
I0515 00:08:33.089445 140128494741248 run_lib.py:152] step: 251300, training_loss: 3.64522e+01
I0515 00:08:33.141148 140128494741248 run_lib.py:165] step: 251300, eval_loss: 3.22128e+01
I0515 00:08:39.509876 140128494741248 run_lib.py:152] step: 251350, training_loss: 2.50251e+01
I0515 00:08:45.830639 140128494741248 run_lib.py:152] step: 251400, training_loss: 3.06557e+01
I0515 00:08:45.882606 140128494741248 run_lib.py:165] step: 251400, eval_loss: 3.13433e+01
I0515 00:08:52.486319 140128494741248 run_lib.py:152] step: 251450, training_loss: 4.62405e+01
I0515 00:08:58.800619 140128494741248 run_lib.py:152] step: 251500, training_loss: 3.67337e+01
I0515 00:08:58.859148 140128494741248 run_lib.py:165] step: 251500, eval_loss: 3.15785e+01
I0515 00:09:05.168518 140128494741248 run_lib.py:152] step: 251550, training_loss: 3.18487e+01
I0515 00:09:11.674482 140128494741248 run_lib.py:152] step: 251600, training_loss: 2.95704e+01
I0515 00:09:11.727010 140128494741248 run_lib.py:165] step: 251600, eval_loss: 3.42521e+01
I0515 00:09:17.995149 140128494741248 run_lib.py:152] step: 251650, training_loss: 3.10191e+01
I0515 00:09:24.325592 140128494741248 run_lib.py:152] step: 251700, training_loss: 2.35394e+01
I0515 00:09:24.378452 140128494741248 run_lib.py:165] step: 251700, eval_loss: 2.73516e+01
I0515 00:09:30.724347 140128494741248 run_lib.py:152] step: 251750, training_loss: 2.58829e+01
I0515 00:09:37.151571 140128494741248 run_lib.py:152] step: 251800, training_loss: 3.83377e+01
I0515 00:09:37.206009 140128494741248 run_lib.py:165] step: 251800, eval_loss: 2.92494e+01
I0515 00:09:43.461572 140128494741248 run_lib.py:152] step: 251850, training_loss: 2.74852e+01
I0515 00:09:49.893629 140128494741248 run_lib.py:152] step: 251900, training_loss: 2.93644e+01
I0515 00:09:49.959452 140128494741248 run_lib.py:165] step: 251900, eval_loss: 3.40096e+01
I0515 00:09:56.395787 140128494741248 run_lib.py:152] step: 251950, training_loss: 2.37389e+01
I0515 00:10:02.633562 140128494741248 run_lib.py:152] step: 252000, training_loss: 2.55289e+01
I0515 00:10:02.687682 140128494741248 run_lib.py:165] step: 252000, eval_loss: 1.61941e+01
I0515 00:10:08.989486 140128494741248 run_lib.py:152] step: 252050, training_loss: 3.58698e+01
I0515 00:10:15.222939 140128494741248 run_lib.py:152] step: 252100, training_loss: 2.10532e+01
I0515 00:10:15.273886 140128494741248 run_lib.py:165] step: 252100, eval_loss: 3.46189e+01
I0515 00:10:21.756844 140128494741248 run_lib.py:152] step: 252150, training_loss: 4.06441e+01
I0515 00:10:27.939233 140128494741248 run_lib.py:152] step: 252200, training_loss: 3.29148e+01
I0515 00:10:27.993487 140128494741248 run_lib.py:165] step: 252200, eval_loss: 1.52245e+01
I0515 00:10:34.210895 140128494741248 run_lib.py:152] step: 252250, training_loss: 4.54136e+01
I0515 00:10:40.537302 140128494741248 run_lib.py:152] step: 252300, training_loss: 4.65169e+01
I0515 00:10:40.587501 140128494741248 run_lib.py:165] step: 252300, eval_loss: 3.13420e+01
I0515 00:10:46.833762 140128494741248 run_lib.py:152] step: 252350, training_loss: 3.54467e+01
I0515 00:10:53.034037 140128494741248 run_lib.py:152] step: 252400, training_loss: 3.49291e+01
I0515 00:10:53.080656 140128494741248 run_lib.py:165] step: 252400, eval_loss: 2.07082e+01
I0515 00:10:59.309405 140128494741248 run_lib.py:152] step: 252450, training_loss: 2.99386e+01
I0515 00:11:05.739573 140128494741248 run_lib.py:152] step: 252500, training_loss: 3.18845e+01
I0515 00:11:05.790963 140128494741248 run_lib.py:165] step: 252500, eval_loss: 3.31554e+01
I0515 00:11:11.924509 140128494741248 run_lib.py:152] step: 252550, training_loss: 3.87392e+01
I0515 00:11:18.164168 140128494741248 run_lib.py:152] step: 252600, training_loss: 1.96749e+01
I0515 00:11:18.216309 140128494741248 run_lib.py:165] step: 252600, eval_loss: 4.31668e+01
I0515 00:11:24.707906 140128494741248 run_lib.py:152] step: 252650, training_loss: 3.47653e+01
I0515 00:11:30.949035 140128494741248 run_lib.py:152] step: 252700, training_loss: 2.42943e+01
I0515 00:11:31.002624 140128494741248 run_lib.py:165] step: 252700, eval_loss: 2.68239e+01
I0515 00:11:37.238094 140128494741248 run_lib.py:152] step: 252750, training_loss: 3.61189e+01
I0515 00:11:43.430168 140128494741248 run_lib.py:152] step: 252800, training_loss: 3.83507e+01
I0515 00:11:43.482448 140128494741248 run_lib.py:165] step: 252800, eval_loss: 3.14132e+01
I0515 00:11:49.902571 140128494741248 run_lib.py:152] step: 252850, training_loss: 2.48173e+01
I0515 00:11:56.130884 140128494741248 run_lib.py:152] step: 252900, training_loss: 4.03832e+01
I0515 00:11:56.184944 140128494741248 run_lib.py:165] step: 252900, eval_loss: 1.84296e+01
I0515 00:12:02.448529 140128494741248 run_lib.py:152] step: 252950, training_loss: 2.17343e+01
I0515 00:12:08.809463 140128494741248 run_lib.py:152] step: 253000, training_loss: 3.30337e+01
I0515 00:12:08.859213 140128494741248 run_lib.py:165] step: 253000, eval_loss: 3.09750e+01
I0515 00:12:15.120437 140128494741248 run_lib.py:152] step: 253050, training_loss: 2.45339e+01
I0515 00:12:21.400580 140128494741248 run_lib.py:152] step: 253100, training_loss: 2.48148e+01
I0515 00:12:21.451898 140128494741248 run_lib.py:165] step: 253100, eval_loss: 2.59030e+01
I0515 00:12:27.654966 140128494741248 run_lib.py:152] step: 253150, training_loss: 3.26763e+01
I0515 00:12:34.083994 140128494741248 run_lib.py:152] step: 253200, training_loss: 2.71364e+01
I0515 00:12:34.134732 140128494741248 run_lib.py:165] step: 253200, eval_loss: 1.99981e+01
I0515 00:12:40.296855 140128494741248 run_lib.py:152] step: 253250, training_loss: 3.19551e+01
I0515 00:12:46.506437 140128494741248 run_lib.py:152] step: 253300, training_loss: 2.56799e+01
I0515 00:12:46.561807 140128494741248 run_lib.py:165] step: 253300, eval_loss: 3.90413e+01
I0515 00:12:52.832248 140128494741248 run_lib.py:152] step: 253350, training_loss: 1.78967e+01
I0515 00:12:58.974659 140128494741248 run_lib.py:152] step: 253400, training_loss: 3.63202e+01
I0515 00:12:59.028478 140128494741248 run_lib.py:165] step: 253400, eval_loss: 3.74415e+01
I0515 00:13:05.194295 140128494741248 run_lib.py:152] step: 253450, training_loss: 3.70824e+01
I0515 00:13:11.329142 140128494741248 run_lib.py:152] step: 253500, training_loss: 3.29576e+01
I0515 00:13:11.377485 140128494741248 run_lib.py:165] step: 253500, eval_loss: 3.93282e+01
I0515 00:13:17.805212 140128494741248 run_lib.py:152] step: 253550, training_loss: 2.48502e+01
I0515 00:13:23.911819 140128494741248 run_lib.py:152] step: 253600, training_loss: 2.54409e+01
I0515 00:13:23.966623 140128494741248 run_lib.py:165] step: 253600, eval_loss: 3.01732e+01
I0515 00:13:30.242045 140128494741248 run_lib.py:152] step: 253650, training_loss: 3.27988e+01
I0515 00:13:36.659736 140128494741248 run_lib.py:152] step: 253700, training_loss: 3.24735e+01
I0515 00:13:36.714523 140128494741248 run_lib.py:165] step: 253700, eval_loss: 4.67740e+01
I0515 00:13:42.937333 140128494741248 run_lib.py:152] step: 253750, training_loss: 1.57870e+01
I0515 00:13:49.044794 140128494741248 run_lib.py:152] step: 253800, training_loss: 2.79519e+01
I0515 00:13:49.092440 140128494741248 run_lib.py:165] step: 253800, eval_loss: 2.75417e+01
I0515 00:13:55.258768 140128494741248 run_lib.py:152] step: 253850, training_loss: 3.05747e+01
I0515 00:14:01.602360 140128494741248 run_lib.py:152] step: 253900, training_loss: 3.83990e+01
I0515 00:14:01.656529 140128494741248 run_lib.py:165] step: 253900, eval_loss: 4.60368e+01
I0515 00:14:07.831358 140128494741248 run_lib.py:152] step: 253950, training_loss: 2.61006e+01
I0515 00:14:14.051378 140128494741248 run_lib.py:152] step: 254000, training_loss: 4.51152e+01
I0515 00:14:14.104427 140128494741248 run_lib.py:165] step: 254000, eval_loss: 2.02013e+01
I0515 00:14:20.580350 140128494741248 run_lib.py:152] step: 254050, training_loss: 2.58501e+01
I0515 00:14:26.760549 140128494741248 run_lib.py:152] step: 254100, training_loss: 2.64598e+01
I0515 00:14:26.810512 140128494741248 run_lib.py:165] step: 254100, eval_loss: 2.00528e+01
I0515 00:14:32.972509 140128494741248 run_lib.py:152] step: 254150, training_loss: 3.29909e+01
I0515 00:14:39.275220 140128494741248 run_lib.py:152] step: 254200, training_loss: 4.15873e+01
I0515 00:14:39.333556 140128494741248 run_lib.py:165] step: 254200, eval_loss: 3.79211e+01
I0515 00:14:45.829806 140128494741248 run_lib.py:152] step: 254250, training_loss: 2.00373e+01
I0515 00:14:52.077688 140128494741248 run_lib.py:152] step: 254300, training_loss: 3.40519e+01
I0515 00:14:52.129891 140128494741248 run_lib.py:165] step: 254300, eval_loss: 3.03258e+01
I0515 00:14:58.271650 140128494741248 run_lib.py:152] step: 254350, training_loss: 3.42588e+01
I0515 00:15:04.752899 140128494741248 run_lib.py:152] step: 254400, training_loss: 3.18103e+01
I0515 00:15:04.803419 140128494741248 run_lib.py:165] step: 254400, eval_loss: 1.63746e+01
I0515 00:15:10.988854 140128494741248 run_lib.py:152] step: 254450, training_loss: 3.01046e+01
I0515 00:15:17.134240 140128494741248 run_lib.py:152] step: 254500, training_loss: 3.47920e+01
I0515 00:15:17.185933 140128494741248 run_lib.py:165] step: 254500, eval_loss: 2.02920e+01
I0515 00:15:23.409397 140128494741248 run_lib.py:152] step: 254550, training_loss: 3.16740e+01
I0515 00:15:29.813987 140128494741248 run_lib.py:152] step: 254600, training_loss: 3.58515e+01
I0515 00:15:29.865678 140128494741248 run_lib.py:165] step: 254600, eval_loss: 3.17652e+01
I0515 00:15:36.044970 140128494741248 run_lib.py:152] step: 254650, training_loss: 2.97789e+01
I0515 00:15:42.323744 140128494741248 run_lib.py:152] step: 254700, training_loss: 4.22460e+01
I0515 00:15:42.372859 140128494741248 run_lib.py:165] step: 254700, eval_loss: 2.50919e+01
I0515 00:15:48.805611 140128494741248 run_lib.py:152] step: 254750, training_loss: 3.04632e+01
I0515 00:15:55.087559 140128494741248 run_lib.py:152] step: 254800, training_loss: 2.77231e+01
I0515 00:15:55.140506 140128494741248 run_lib.py:165] step: 254800, eval_loss: 2.27638e+01
I0515 00:16:01.414896 140128494741248 run_lib.py:152] step: 254850, training_loss: 2.77351e+01
I0515 00:16:07.570310 140128494741248 run_lib.py:152] step: 254900, training_loss: 2.40007e+01
I0515 00:16:07.617835 140128494741248 run_lib.py:165] step: 254900, eval_loss: 3.29034e+01
I0515 00:16:14.032516 140128494741248 run_lib.py:152] step: 254950, training_loss: 3.03016e+01
I0515 00:16:20.223102 140128494741248 run_lib.py:152] step: 255000, training_loss: 3.99870e+01
I0515 00:16:20.271438 140128494741248 run_lib.py:165] step: 255000, eval_loss: 2.63914e+01
I0515 00:16:26.406427 140128494741248 run_lib.py:152] step: 255050, training_loss: 2.63872e+01
I0515 00:16:32.885151 140128494741248 run_lib.py:152] step: 255100, training_loss: 2.13940e+01
I0515 00:16:32.941858 140128494741248 run_lib.py:165] step: 255100, eval_loss: 3.26776e+01
I0515 00:16:39.117223 140128494741248 run_lib.py:152] step: 255150, training_loss: 2.28187e+01
I0515 00:16:45.286449 140128494741248 run_lib.py:152] step: 255200, training_loss: 2.87001e+01
I0515 00:16:45.341405 140128494741248 run_lib.py:165] step: 255200, eval_loss: 2.44398e+01
I0515 00:16:51.611477 140128494741248 run_lib.py:152] step: 255250, training_loss: 3.14104e+01
I0515 00:16:58.045641 140128494741248 run_lib.py:152] step: 255300, training_loss: 3.88339e+01
I0515 00:16:58.100086 140128494741248 run_lib.py:165] step: 255300, eval_loss: 2.29873e+01
I0515 00:17:04.295781 140128494741248 run_lib.py:152] step: 255350, training_loss: 4.86215e+01
I0515 00:17:10.438416 140128494741248 run_lib.py:152] step: 255400, training_loss: 2.76574e+01
I0515 00:17:10.486773 140128494741248 run_lib.py:165] step: 255400, eval_loss: 3.05901e+01
I0515 00:17:16.927439 140128494741248 run_lib.py:152] step: 255450, training_loss: 3.66891e+01
I0515 00:17:23.069950 140128494741248 run_lib.py:152] step: 255500, training_loss: 2.48890e+01
I0515 00:17:23.119493 140128494741248 run_lib.py:165] step: 255500, eval_loss: 3.03926e+01
I0515 00:17:29.335063 140128494741248 run_lib.py:152] step: 255550, training_loss: 3.03422e+01
I0515 00:17:35.564689 140128494741248 run_lib.py:152] step: 255600, training_loss: 1.87154e+01
I0515 00:17:35.624060 140128494741248 run_lib.py:165] step: 255600, eval_loss: 2.40143e+01
I0515 00:17:42.024505 140128494741248 run_lib.py:152] step: 255650, training_loss: 3.42402e+01
I0515 00:17:48.182768 140128494741248 run_lib.py:152] step: 255700, training_loss: 3.25375e+01
I0515 00:17:48.248174 140128494741248 run_lib.py:165] step: 255700, eval_loss: 1.75559e+01
I0515 00:17:54.475952 140128494741248 run_lib.py:152] step: 255750, training_loss: 3.50571e+01
I0515 00:18:00.860649 140128494741248 run_lib.py:152] step: 255800, training_loss: 2.69328e+01
I0515 00:18:00.909359 140128494741248 run_lib.py:165] step: 255800, eval_loss: 2.73853e+01
I0515 00:18:07.212395 140128494741248 run_lib.py:152] step: 255850, training_loss: 3.02048e+01
I0515 00:18:13.438120 140128494741248 run_lib.py:152] step: 255900, training_loss: 2.99105e+01
I0515 00:18:13.494450 140128494741248 run_lib.py:165] step: 255900, eval_loss: 2.68368e+01
I0515 00:18:19.619439 140128494741248 run_lib.py:152] step: 255950, training_loss: 4.09795e+01
I0515 00:18:26.091964 140128494741248 run_lib.py:152] step: 256000, training_loss: 2.70484e+01
I0515 00:18:26.145934 140128494741248 run_lib.py:165] step: 256000, eval_loss: 3.36724e+01
I0515 00:18:32.353395 140128494741248 run_lib.py:152] step: 256050, training_loss: 2.36808e+01
I0515 00:18:38.592916 140128494741248 run_lib.py:152] step: 256100, training_loss: 2.93301e+01
I0515 00:18:38.645961 140128494741248 run_lib.py:165] step: 256100, eval_loss: 3.75604e+01
I0515 00:18:45.080729 140128494741248 run_lib.py:152] step: 256150, training_loss: 3.60851e+01
I0515 00:18:51.286375 140128494741248 run_lib.py:152] step: 256200, training_loss: 2.82294e+01
I0515 00:18:51.337259 140128494741248 run_lib.py:165] step: 256200, eval_loss: 3.35528e+01
I0515 00:18:57.571753 140128494741248 run_lib.py:152] step: 256250, training_loss: 2.29216e+01
I0515 00:19:03.802322 140128494741248 run_lib.py:152] step: 256300, training_loss: 2.96521e+01
I0515 00:19:03.853121 140128494741248 run_lib.py:165] step: 256300, eval_loss: 2.69795e+01
I0515 00:19:10.369943 140128494741248 run_lib.py:152] step: 256350, training_loss: 1.65323e+01
I0515 00:19:16.527625 140128494741248 run_lib.py:152] step: 256400, training_loss: 3.54185e+01
I0515 00:19:16.583634 140128494741248 run_lib.py:165] step: 256400, eval_loss: 1.85921e+01
I0515 00:19:22.754032 140128494741248 run_lib.py:152] step: 256450, training_loss: 2.66717e+01
I0515 00:19:29.362962 140128494741248 run_lib.py:152] step: 256500, training_loss: 3.37011e+01
I0515 00:19:29.418720 140128494741248 run_lib.py:165] step: 256500, eval_loss: 2.29049e+01
I0515 00:19:35.563840 140128494741248 run_lib.py:152] step: 256550, training_loss: 3.79081e+01
I0515 00:19:41.791653 140128494741248 run_lib.py:152] step: 256600, training_loss: 2.65759e+01
I0515 00:19:41.840037 140128494741248 run_lib.py:165] step: 256600, eval_loss: 5.23917e+01
I0515 00:19:48.009368 140128494741248 run_lib.py:152] step: 256650, training_loss: 2.71362e+01
I0515 00:19:54.530519 140128494741248 run_lib.py:152] step: 256700, training_loss: 3.95874e+01
I0515 00:19:54.588697 140128494741248 run_lib.py:165] step: 256700, eval_loss: 3.55626e+01
I0515 00:20:00.823357 140128494741248 run_lib.py:152] step: 256750, training_loss: 4.25828e+01
I0515 00:20:07.114566 140128494741248 run_lib.py:152] step: 256800, training_loss: 5.13699e+01
I0515 00:20:07.166098 140128494741248 run_lib.py:165] step: 256800, eval_loss: 3.08182e+01
I0515 00:20:13.507153 140128494741248 run_lib.py:152] step: 256850, training_loss: 1.92322e+01
I0515 00:20:19.727582 140128494741248 run_lib.py:152] step: 256900, training_loss: 4.99596e+01
I0515 00:20:19.777530 140128494741248 run_lib.py:165] step: 256900, eval_loss: 2.52551e+01
I0515 00:20:25.959688 140128494741248 run_lib.py:152] step: 256950, training_loss: 3.45004e+01
I0515 00:20:32.229632 140128494741248 run_lib.py:152] step: 257000, training_loss: 3.51289e+01
I0515 00:20:32.284261 140128494741248 run_lib.py:165] step: 257000, eval_loss: 2.62263e+01
I0515 00:20:38.758540 140128494741248 run_lib.py:152] step: 257050, training_loss: 2.75090e+01
I0515 00:20:44.919115 140128494741248 run_lib.py:152] step: 257100, training_loss: 3.37409e+01
I0515 00:20:44.976891 140128494741248 run_lib.py:165] step: 257100, eval_loss: 4.22541e+01
I0515 00:20:51.254057 140128494741248 run_lib.py:152] step: 257150, training_loss: 2.72671e+01
I0515 00:20:57.777674 140128494741248 run_lib.py:152] step: 257200, training_loss: 2.81826e+01
I0515 00:20:57.835853 140128494741248 run_lib.py:165] step: 257200, eval_loss: 3.00171e+01
I0515 00:21:03.997814 140128494741248 run_lib.py:152] step: 257250, training_loss: 3.37654e+01
I0515 00:21:10.290453 140128494741248 run_lib.py:152] step: 257300, training_loss: 2.99464e+01
I0515 00:21:10.348638 140128494741248 run_lib.py:165] step: 257300, eval_loss: 2.52977e+01
I0515 00:21:16.495114 140128494741248 run_lib.py:152] step: 257350, training_loss: 2.34868e+01
I0515 00:21:23.008052 140128494741248 run_lib.py:152] step: 257400, training_loss: 2.81221e+01
I0515 00:21:23.058486 140128494741248 run_lib.py:165] step: 257400, eval_loss: 2.77718e+01
I0515 00:21:29.295576 140128494741248 run_lib.py:152] step: 257450, training_loss: 4.41839e+01
I0515 00:21:35.489803 140128494741248 run_lib.py:152] step: 257500, training_loss: 3.85089e+01
I0515 00:21:35.547280 140128494741248 run_lib.py:165] step: 257500, eval_loss: 3.17885e+01
I0515 00:21:41.984384 140128494741248 run_lib.py:152] step: 257550, training_loss: 2.68667e+01
I0515 00:21:48.235781 140128494741248 run_lib.py:152] step: 257600, training_loss: 4.00758e+01
I0515 00:21:48.287130 140128494741248 run_lib.py:165] step: 257600, eval_loss: 3.77820e+01
I0515 00:21:54.545502 140128494741248 run_lib.py:152] step: 257650, training_loss: 3.86061e+01
I0515 00:22:00.774686 140128494741248 run_lib.py:152] step: 257700, training_loss: 3.51832e+01
I0515 00:22:00.826579 140128494741248 run_lib.py:165] step: 257700, eval_loss: 3.08495e+01
I0515 00:22:07.345195 140128494741248 run_lib.py:152] step: 257750, training_loss: 1.79895e+01
I0515 00:22:13.562172 140128494741248 run_lib.py:152] step: 257800, training_loss: 4.33032e+01
I0515 00:22:13.612469 140128494741248 run_lib.py:165] step: 257800, eval_loss: 2.59749e+01
I0515 00:22:19.874604 140128494741248 run_lib.py:152] step: 257850, training_loss: 2.33700e+01
I0515 00:22:26.281592 140128494741248 run_lib.py:152] step: 257900, training_loss: 2.84975e+01
I0515 00:22:26.328665 140128494741248 run_lib.py:165] step: 257900, eval_loss: 2.86263e+01
I0515 00:22:32.594297 140128494741248 run_lib.py:152] step: 257950, training_loss: 3.79907e+01
I0515 00:22:38.804582 140128494741248 run_lib.py:152] step: 258000, training_loss: 3.22594e+01
I0515 00:22:38.856241 140128494741248 run_lib.py:165] step: 258000, eval_loss: 2.93004e+01
I0515 00:22:44.967317 140128494741248 run_lib.py:152] step: 258050, training_loss: 4.02832e+01
I0515 00:22:51.455075 140128494741248 run_lib.py:152] step: 258100, training_loss: 3.67498e+01
I0515 00:22:51.508400 140128494741248 run_lib.py:165] step: 258100, eval_loss: 3.59112e+01
I0515 00:22:57.589270 140128494741248 run_lib.py:152] step: 258150, training_loss: 2.45136e+01
I0515 00:23:03.770735 140128494741248 run_lib.py:152] step: 258200, training_loss: 2.93060e+01
I0515 00:23:03.824379 140128494741248 run_lib.py:165] step: 258200, eval_loss: 3.62010e+01
I0515 00:23:10.337063 140128494741248 run_lib.py:152] step: 258250, training_loss: 2.73778e+01
I0515 00:23:16.509730 140128494741248 run_lib.py:152] step: 258300, training_loss: 2.76748e+01
I0515 00:23:16.561603 140128494741248 run_lib.py:165] step: 258300, eval_loss: 4.21456e+01
I0515 00:23:22.801308 140128494741248 run_lib.py:152] step: 258350, training_loss: 2.50819e+01
I0515 00:23:28.964810 140128494741248 run_lib.py:152] step: 258400, training_loss: 3.30161e+01
I0515 00:23:29.010943 140128494741248 run_lib.py:165] step: 258400, eval_loss: 3.79628e+01
I0515 00:23:35.416090 140128494741248 run_lib.py:152] step: 258450, training_loss: 3.08083e+01
I0515 00:23:41.555040 140128494741248 run_lib.py:152] step: 258500, training_loss: 3.85700e+01
I0515 00:23:41.603058 140128494741248 run_lib.py:165] step: 258500, eval_loss: 2.96888e+01
I0515 00:23:47.805871 140128494741248 run_lib.py:152] step: 258550, training_loss: 4.18199e+01
I0515 00:23:54.225994 140128494741248 run_lib.py:152] step: 258600, training_loss: 4.59311e+01
I0515 00:23:54.277483 140128494741248 run_lib.py:165] step: 258600, eval_loss: 3.20493e+01
I0515 00:24:00.444100 140128494741248 run_lib.py:152] step: 258650, training_loss: 2.90210e+01
I0515 00:24:06.559701 140128494741248 run_lib.py:152] step: 258700, training_loss: 2.11602e+01
I0515 00:24:06.607809 140128494741248 run_lib.py:165] step: 258700, eval_loss: 1.89851e+01
I0515 00:24:12.823883 140128494741248 run_lib.py:152] step: 258750, training_loss: 3.45346e+01
I0515 00:24:19.240816 140128494741248 run_lib.py:152] step: 258800, training_loss: 4.07484e+01
I0515 00:24:19.294095 140128494741248 run_lib.py:165] step: 258800, eval_loss: 3.48630e+01
I0515 00:24:25.453745 140128494741248 run_lib.py:152] step: 258850, training_loss: 2.34944e+01
I0515 00:24:31.637836 140128494741248 run_lib.py:152] step: 258900, training_loss: 2.51859e+01
I0515 00:24:31.691406 140128494741248 run_lib.py:165] step: 258900, eval_loss: 1.83440e+01
I0515 00:24:38.134578 140128494741248 run_lib.py:152] step: 258950, training_loss: 2.56595e+01
I0515 00:24:44.375358 140128494741248 run_lib.py:152] step: 259000, training_loss: 2.35526e+01
I0515 00:24:44.426220 140128494741248 run_lib.py:165] step: 259000, eval_loss: 2.05342e+01
I0515 00:24:50.655502 140128494741248 run_lib.py:152] step: 259050, training_loss: 2.57646e+01
I0515 00:24:56.934272 140128494741248 run_lib.py:152] step: 259100, training_loss: 2.00530e+01
I0515 00:24:56.989944 140128494741248 run_lib.py:165] step: 259100, eval_loss: 2.63490e+01
I0515 00:25:03.514827 140128494741248 run_lib.py:152] step: 259150, training_loss: 3.54601e+01
I0515 00:25:09.723735 140128494741248 run_lib.py:152] step: 259200, training_loss: 2.23535e+01
I0515 00:25:09.778056 140128494741248 run_lib.py:165] step: 259200, eval_loss: 4.22391e+01
I0515 00:25:15.974790 140128494741248 run_lib.py:152] step: 259250, training_loss: 2.63989e+01
I0515 00:25:22.342602 140128494741248 run_lib.py:152] step: 259300, training_loss: 4.51936e+01
I0515 00:25:22.392048 140128494741248 run_lib.py:165] step: 259300, eval_loss: 3.68742e+01
I0515 00:25:28.550000 140128494741248 run_lib.py:152] step: 259350, training_loss: 3.22277e+01
I0515 00:25:34.695841 140128494741248 run_lib.py:152] step: 259400, training_loss: 3.83259e+01
I0515 00:25:34.746461 140128494741248 run_lib.py:165] step: 259400, eval_loss: 2.15460e+01
I0515 00:25:40.935577 140128494741248 run_lib.py:152] step: 259450, training_loss: 2.24863e+01
I0515 00:25:47.362919 140128494741248 run_lib.py:152] step: 259500, training_loss: 2.58870e+01
I0515 00:25:47.417432 140128494741248 run_lib.py:165] step: 259500, eval_loss: 3.04538e+01
I0515 00:25:53.614933 140128494741248 run_lib.py:152] step: 259550, training_loss: 3.78788e+01
I0515 00:25:59.794217 140128494741248 run_lib.py:152] step: 259600, training_loss: 2.26984e+01
I0515 00:25:59.848662 140128494741248 run_lib.py:165] step: 259600, eval_loss: 2.48217e+01
I0515 00:26:06.258707 140128494741248 run_lib.py:152] step: 259650, training_loss: 2.04691e+01
I0515 00:26:12.466293 140128494741248 run_lib.py:152] step: 259700, training_loss: 4.05353e+01
I0515 00:26:12.519178 140128494741248 run_lib.py:165] step: 259700, eval_loss: 2.12236e+01
I0515 00:26:18.749945 140128494741248 run_lib.py:152] step: 259750, training_loss: 2.44783e+01
I0515 00:26:24.985032 140128494741248 run_lib.py:152] step: 259800, training_loss: 2.49279e+01
I0515 00:26:25.031238 140128494741248 run_lib.py:165] step: 259800, eval_loss: 2.43167e+01
I0515 00:26:31.443635 140128494741248 run_lib.py:152] step: 259850, training_loss: 1.71219e+01
I0515 00:26:37.559027 140128494741248 run_lib.py:152] step: 259900, training_loss: 2.51950e+01
I0515 00:26:37.616465 140128494741248 run_lib.py:165] step: 259900, eval_loss: 3.34036e+01
I0515 00:26:43.824366 140128494741248 run_lib.py:152] step: 259950, training_loss: 3.48647e+01
I0515 00:26:50.255616 140128494741248 run_lib.py:152] step: 260000, training_loss: 2.72988e+01
I0515 00:26:50.450495 140128494741248 run_lib.py:165] step: 260000, eval_loss: 2.73531e+01
I0515 00:26:56.613301 140128494741248 run_lib.py:152] step: 260050, training_loss: 3.84041e+01
I0515 00:27:02.796343 140128494741248 run_lib.py:152] step: 260100, training_loss: 1.87730e+01
I0515 00:27:02.850878 140128494741248 run_lib.py:165] step: 260100, eval_loss: 2.85122e+01
I0515 00:27:09.114512 140128494741248 run_lib.py:152] step: 260150, training_loss: 4.60677e+01
I0515 00:27:15.564877 140128494741248 run_lib.py:152] step: 260200, training_loss: 3.20831e+01
I0515 00:27:15.618389 140128494741248 run_lib.py:165] step: 260200, eval_loss: 5.26287e+01
I0515 00:27:21.788221 140128494741248 run_lib.py:152] step: 260250, training_loss: 1.29264e+01
I0515 00:27:27.994898 140128494741248 run_lib.py:152] step: 260300, training_loss: 2.46932e+01
I0515 00:27:28.043308 140128494741248 run_lib.py:165] step: 260300, eval_loss: 2.24904e+01
I0515 00:27:34.385810 140128494741248 run_lib.py:152] step: 260350, training_loss: 5.20856e+01
I0515 00:27:40.546030 140128494741248 run_lib.py:152] step: 260400, training_loss: 3.35672e+01
I0515 00:27:40.604851 140128494741248 run_lib.py:165] step: 260400, eval_loss: 3.49126e+01
I0515 00:27:46.804339 140128494741248 run_lib.py:152] step: 260450, training_loss: 2.33690e+01
I0515 00:27:53.162523 140128494741248 run_lib.py:152] step: 260500, training_loss: 2.04115e+01
I0515 00:27:53.217663 140128494741248 run_lib.py:165] step: 260500, eval_loss: 1.70873e+01
I0515 00:27:59.626674 140128494741248 run_lib.py:152] step: 260550, training_loss: 2.74335e+01
I0515 00:28:05.851481 140128494741248 run_lib.py:152] step: 260600, training_loss: 3.24023e+01
I0515 00:28:05.903509 140128494741248 run_lib.py:165] step: 260600, eval_loss: 1.91914e+01
I0515 00:28:11.972762 140128494741248 run_lib.py:152] step: 260650, training_loss: 2.42849e+01
I0515 00:28:18.256470 140128494741248 run_lib.py:152] step: 260700, training_loss: 3.39453e+01
I0515 00:28:18.309185 140128494741248 run_lib.py:165] step: 260700, eval_loss: 2.98614e+01
I0515 00:28:24.445231 140128494741248 run_lib.py:152] step: 260750, training_loss: 2.62232e+01
I0515 00:28:30.755628 140128494741248 run_lib.py:152] step: 260800, training_loss: 1.83146e+01
I0515 00:28:30.811398 140128494741248 run_lib.py:165] step: 260800, eval_loss: 2.31286e+01
I0515 00:28:36.998954 140128494741248 run_lib.py:152] step: 260850, training_loss: 3.53471e+01
I0515 00:28:43.503082 140128494741248 run_lib.py:152] step: 260900, training_loss: 3.65011e+01
I0515 00:28:43.555555 140128494741248 run_lib.py:165] step: 260900, eval_loss: 3.55884e+01
I0515 00:28:49.749115 140128494741248 run_lib.py:152] step: 260950, training_loss: 2.55226e+01
I0515 00:28:55.916987 140128494741248 run_lib.py:152] step: 261000, training_loss: 1.96138e+01
I0515 00:28:55.968636 140128494741248 run_lib.py:165] step: 261000, eval_loss: 3.36710e+01
I0515 00:29:02.395031 140128494741248 run_lib.py:152] step: 261050, training_loss: 2.19900e+01
I0515 00:29:08.722898 140128494741248 run_lib.py:152] step: 261100, training_loss: 3.30480e+01
I0515 00:29:08.774267 140128494741248 run_lib.py:165] step: 261100, eval_loss: 3.66378e+01
I0515 00:29:14.895076 140128494741248 run_lib.py:152] step: 261150, training_loss: 3.16409e+01
I0515 00:29:21.123019 140128494741248 run_lib.py:152] step: 261200, training_loss: 3.49154e+01
I0515 00:29:21.173853 140128494741248 run_lib.py:165] step: 261200, eval_loss: 4.30531e+01
I0515 00:29:27.630410 140128494741248 run_lib.py:152] step: 261250, training_loss: 2.94079e+01
I0515 00:29:33.881713 140128494741248 run_lib.py:152] step: 261300, training_loss: 4.08056e+01
I0515 00:29:33.939717 140128494741248 run_lib.py:165] step: 261300, eval_loss: 2.74086e+01
I0515 00:29:40.244122 140128494741248 run_lib.py:152] step: 261350, training_loss: 3.60193e+01
I0515 00:29:46.640383 140128494741248 run_lib.py:152] step: 261400, training_loss: 2.52621e+01
I0515 00:29:46.691205 140128494741248 run_lib.py:165] step: 261400, eval_loss: 4.31824e+01
I0515 00:29:53.006892 140128494741248 run_lib.py:152] step: 261450, training_loss: 2.53881e+01
I0515 00:29:59.200344 140128494741248 run_lib.py:152] step: 261500, training_loss: 6.15900e+01
I0515 00:29:59.249312 140128494741248 run_lib.py:165] step: 261500, eval_loss: 2.66916e+01
I0515 00:30:05.516365 140128494741248 run_lib.py:152] step: 261550, training_loss: 2.15487e+01
I0515 00:30:11.941325 140128494741248 run_lib.py:152] step: 261600, training_loss: 3.85295e+01
I0515 00:30:11.996296 140128494741248 run_lib.py:165] step: 261600, eval_loss: 2.01055e+01
I0515 00:30:18.260857 140128494741248 run_lib.py:152] step: 261650, training_loss: 2.86458e+01
I0515 00:30:24.413148 140128494741248 run_lib.py:152] step: 261700, training_loss: 2.74731e+01
I0515 00:30:24.469199 140128494741248 run_lib.py:165] step: 261700, eval_loss: 2.83671e+01
I0515 00:30:30.946185 140128494741248 run_lib.py:152] step: 261750, training_loss: 3.28342e+01
I0515 00:30:37.193149 140128494741248 run_lib.py:152] step: 261800, training_loss: 2.90817e+01
I0515 00:30:37.253064 140128494741248 run_lib.py:165] step: 261800, eval_loss: 2.64023e+01
I0515 00:30:43.531311 140128494741248 run_lib.py:152] step: 261850, training_loss: 3.81458e+01
I0515 00:30:49.727734 140128494741248 run_lib.py:152] step: 261900, training_loss: 3.19907e+01
I0515 00:30:49.786066 140128494741248 run_lib.py:165] step: 261900, eval_loss: 4.51929e+01
I0515 00:30:56.170187 140128494741248 run_lib.py:152] step: 261950, training_loss: 3.16509e+01
I0515 00:31:02.322089 140128494741248 run_lib.py:152] step: 262000, training_loss: 3.46164e+01
I0515 00:31:02.377680 140128494741248 run_lib.py:165] step: 262000, eval_loss: 3.23927e+01
I0515 00:31:08.536893 140128494741248 run_lib.py:152] step: 262050, training_loss: 3.21839e+01
I0515 00:31:14.853578 140128494741248 run_lib.py:152] step: 262100, training_loss: 2.86575e+01
I0515 00:31:14.905856 140128494741248 run_lib.py:165] step: 262100, eval_loss: 3.08570e+01
I0515 00:31:21.093398 140128494741248 run_lib.py:152] step: 262150, training_loss: 3.00918e+01
I0515 00:31:27.232791 140128494741248 run_lib.py:152] step: 262200, training_loss: 3.97337e+01
I0515 00:31:27.280498 140128494741248 run_lib.py:165] step: 262200, eval_loss: 4.21881e+01
I0515 00:31:33.464711 140128494741248 run_lib.py:152] step: 262250, training_loss: 4.95435e+01
I0515 00:31:39.891227 140128494741248 run_lib.py:152] step: 262300, training_loss: 2.57713e+01
I0515 00:31:39.943718 140128494741248 run_lib.py:165] step: 262300, eval_loss: 4.79662e+01
I0515 00:31:46.214822 140128494741248 run_lib.py:152] step: 262350, training_loss: 3.91267e+01
I0515 00:31:52.474025 140128494741248 run_lib.py:152] step: 262400, training_loss: 2.52671e+01
I0515 00:31:52.522878 140128494741248 run_lib.py:165] step: 262400, eval_loss: 1.69940e+01
I0515 00:31:59.037603 140128494741248 run_lib.py:152] step: 262450, training_loss: 3.29249e+01
I0515 00:32:05.174274 140128494741248 run_lib.py:152] step: 262500, training_loss: 5.97397e+01
I0515 00:32:05.229279 140128494741248 run_lib.py:165] step: 262500, eval_loss: 3.27772e+01
I0515 00:32:11.461953 140128494741248 run_lib.py:152] step: 262550, training_loss: 3.16486e+01
I0515 00:32:17.655512 140128494741248 run_lib.py:152] step: 262600, training_loss: 2.14992e+01
I0515 00:32:17.705765 140128494741248 run_lib.py:165] step: 262600, eval_loss: 3.05318e+01
I0515 00:32:24.142934 140128494741248 run_lib.py:152] step: 262650, training_loss: 3.64827e+01
I0515 00:32:30.429852 140128494741248 run_lib.py:152] step: 262700, training_loss: 1.79417e+01
I0515 00:32:30.481752 140128494741248 run_lib.py:165] step: 262700, eval_loss: 3.48637e+01
I0515 00:32:36.693605 140128494741248 run_lib.py:152] step: 262750, training_loss: 3.18274e+01
I0515 00:32:43.169996 140128494741248 run_lib.py:152] step: 262800, training_loss: 3.29671e+01
I0515 00:32:43.221833 140128494741248 run_lib.py:165] step: 262800, eval_loss: 2.69890e+01
I0515 00:32:49.439854 140128494741248 run_lib.py:152] step: 262850, training_loss: 3.00356e+01
I0515 00:32:55.630192 140128494741248 run_lib.py:152] step: 262900, training_loss: 2.63338e+01
I0515 00:32:55.686992 140128494741248 run_lib.py:165] step: 262900, eval_loss: 2.99488e+01
I0515 00:33:01.913470 140128494741248 run_lib.py:152] step: 262950, training_loss: 3.49542e+01
I0515 00:33:08.288676 140128494741248 run_lib.py:152] step: 263000, training_loss: 3.96421e+01
I0515 00:33:08.334561 140128494741248 run_lib.py:165] step: 263000, eval_loss: 2.45287e+01
I0515 00:33:14.560428 140128494741248 run_lib.py:152] step: 263050, training_loss: 2.68832e+01
I0515 00:33:20.708580 140128494741248 run_lib.py:152] step: 263100, training_loss: 2.69438e+01
I0515 00:33:20.758671 140128494741248 run_lib.py:165] step: 263100, eval_loss: 3.22362e+01
I0515 00:33:27.217201 140128494741248 run_lib.py:152] step: 263150, training_loss: 4.69326e+01
I0515 00:33:33.441357 140128494741248 run_lib.py:152] step: 263200, training_loss: 2.16083e+01
I0515 00:33:33.493446 140128494741248 run_lib.py:165] step: 263200, eval_loss: 4.24700e+01
I0515 00:33:39.738069 140128494741248 run_lib.py:152] step: 263250, training_loss: 3.71951e+01
I0515 00:33:45.838270 140128494741248 run_lib.py:152] step: 263300, training_loss: 3.06267e+01
I0515 00:33:45.893547 140128494741248 run_lib.py:165] step: 263300, eval_loss: 2.51452e+01
I0515 00:33:52.375478 140128494741248 run_lib.py:152] step: 263350, training_loss: 3.73371e+01
I0515 00:33:58.612310 140128494741248 run_lib.py:152] step: 263400, training_loss: 4.71475e+01
I0515 00:33:58.663477 140128494741248 run_lib.py:165] step: 263400, eval_loss: 4.34907e+01
I0515 00:34:04.846830 140128494741248 run_lib.py:152] step: 263450, training_loss: 4.13303e+01
I0515 00:34:11.241744 140128494741248 run_lib.py:152] step: 263500, training_loss: 4.31919e+01
I0515 00:34:11.293597 140128494741248 run_lib.py:165] step: 263500, eval_loss: 5.60067e+01
I0515 00:34:17.450423 140128494741248 run_lib.py:152] step: 263550, training_loss: 4.64362e+01
I0515 00:34:23.732515 140128494741248 run_lib.py:152] step: 263600, training_loss: 3.63094e+01
I0515 00:34:23.781026 140128494741248 run_lib.py:165] step: 263600, eval_loss: 2.18353e+01
I0515 00:34:30.013221 140128494741248 run_lib.py:152] step: 263650, training_loss: 2.86387e+01
I0515 00:34:36.417727 140128494741248 run_lib.py:152] step: 263700, training_loss: 2.50578e+01
I0515 00:34:36.465581 140128494741248 run_lib.py:165] step: 263700, eval_loss: 3.23644e+01
I0515 00:34:42.764906 140128494741248 run_lib.py:152] step: 263750, training_loss: 4.34971e+01
I0515 00:34:48.958313 140128494741248 run_lib.py:152] step: 263800, training_loss: 3.56482e+01
I0515 00:34:49.012506 140128494741248 run_lib.py:165] step: 263800, eval_loss: 3.63727e+01
I0515 00:34:55.450189 140128494741248 run_lib.py:152] step: 263850, training_loss: 2.66622e+01
I0515 00:35:01.664214 140128494741248 run_lib.py:152] step: 263900, training_loss: 4.31171e+01
I0515 00:35:01.711446 140128494741248 run_lib.py:165] step: 263900, eval_loss: 2.36754e+01
I0515 00:35:07.998758 140128494741248 run_lib.py:152] step: 263950, training_loss: 2.81991e+01
I0515 00:35:14.118442 140128494741248 run_lib.py:152] step: 264000, training_loss: 2.48738e+01
I0515 00:35:14.171933 140128494741248 run_lib.py:165] step: 264000, eval_loss: 2.84744e+01
I0515 00:35:20.676227 140128494741248 run_lib.py:152] step: 264050, training_loss: 2.57305e+01
I0515 00:35:26.849307 140128494741248 run_lib.py:152] step: 264100, training_loss: 3.62660e+01
I0515 00:35:26.903494 140128494741248 run_lib.py:165] step: 264100, eval_loss: 3.55723e+01
I0515 00:35:33.140589 140128494741248 run_lib.py:152] step: 264150, training_loss: 3.82417e+01
I0515 00:35:39.596456 140128494741248 run_lib.py:152] step: 264200, training_loss: 2.28286e+01
I0515 00:35:39.647011 140128494741248 run_lib.py:165] step: 264200, eval_loss: 2.06092e+01
I0515 00:35:45.787398 140128494741248 run_lib.py:152] step: 264250, training_loss: 3.64905e+01
I0515 00:35:52.051374 140128494741248 run_lib.py:152] step: 264300, training_loss: 4.64928e+01
I0515 00:35:52.105885 140128494741248 run_lib.py:165] step: 264300, eval_loss: 3.98884e+01
I0515 00:35:58.355157 140128494741248 run_lib.py:152] step: 264350, training_loss: 3.04810e+01
I0515 00:36:04.948487 140128494741248 run_lib.py:152] step: 264400, training_loss: 1.56320e+01
I0515 00:36:05.000322 140128494741248 run_lib.py:165] step: 264400, eval_loss: 3.18303e+01
I0515 00:36:11.200961 140128494741248 run_lib.py:152] step: 264450, training_loss: 3.03742e+01
I0515 00:36:17.430548 140128494741248 run_lib.py:152] step: 264500, training_loss: 2.26170e+01
I0515 00:36:17.480648 140128494741248 run_lib.py:165] step: 264500, eval_loss: 2.77229e+01
I0515 00:36:23.956372 140128494741248 run_lib.py:152] step: 264550, training_loss: 3.28396e+01
I0515 00:36:30.261377 140128494741248 run_lib.py:152] step: 264600, training_loss: 4.26826e+01
I0515 00:36:30.309708 140128494741248 run_lib.py:165] step: 264600, eval_loss: 4.47401e+01
I0515 00:36:36.488890 140128494741248 run_lib.py:152] step: 264650, training_loss: 2.65297e+01
I0515 00:36:42.830912 140128494741248 run_lib.py:152] step: 264700, training_loss: 3.55865e+01
I0515 00:36:42.886388 140128494741248 run_lib.py:165] step: 264700, eval_loss: 3.25763e+01
I0515 00:36:49.402497 140128494741248 run_lib.py:152] step: 264750, training_loss: 2.47008e+01
I0515 00:36:55.662465 140128494741248 run_lib.py:152] step: 264800, training_loss: 3.59356e+01
I0515 00:36:55.714488 140128494741248 run_lib.py:165] step: 264800, eval_loss: 3.75607e+01
I0515 00:37:01.937292 140128494741248 run_lib.py:152] step: 264850, training_loss: 3.06840e+01
I0515 00:37:08.495996 140128494741248 run_lib.py:152] step: 264900, training_loss: 2.39841e+01
I0515 00:37:08.549227 140128494741248 run_lib.py:165] step: 264900, eval_loss: 2.46904e+01
I0515 00:37:14.700578 140128494741248 run_lib.py:152] step: 264950, training_loss: 2.32288e+01
I0515 00:37:20.899217 140128494741248 run_lib.py:152] step: 265000, training_loss: 2.00544e+01
I0515 00:37:20.950335 140128494741248 run_lib.py:165] step: 265000, eval_loss: 2.29618e+01
I0515 00:37:27.179936 140128494741248 run_lib.py:152] step: 265050, training_loss: 4.56040e+01
I0515 00:37:33.602039 140128494741248 run_lib.py:152] step: 265100, training_loss: 3.02237e+01
I0515 00:37:33.656062 140128494741248 run_lib.py:165] step: 265100, eval_loss: 3.68475e+01
I0515 00:37:39.887446 140128494741248 run_lib.py:152] step: 265150, training_loss: 3.80924e+01
I0515 00:37:46.058508 140128494741248 run_lib.py:152] step: 265200, training_loss: 4.14087e+01
I0515 00:37:46.111408 140128494741248 run_lib.py:165] step: 265200, eval_loss: 3.80610e+01
I0515 00:37:52.612466 140128494741248 run_lib.py:152] step: 265250, training_loss: 4.65457e+01
I0515 00:37:58.819839 140128494741248 run_lib.py:152] step: 265300, training_loss: 4.70795e+01
I0515 00:37:58.870699 140128494741248 run_lib.py:165] step: 265300, eval_loss: 2.82193e+01
I0515 00:38:05.202368 140128494741248 run_lib.py:152] step: 265350, training_loss: 2.53059e+01
I0515 00:38:11.425471 140128494741248 run_lib.py:152] step: 265400, training_loss: 3.57540e+01
I0515 00:38:11.481514 140128494741248 run_lib.py:165] step: 265400, eval_loss: 1.91645e+01
I0515 00:38:17.951615 140128494741248 run_lib.py:152] step: 265450, training_loss: 4.05084e+01
I0515 00:38:24.133440 140128494741248 run_lib.py:152] step: 265500, training_loss: 3.30503e+01
I0515 00:38:24.179396 140128494741248 run_lib.py:165] step: 265500, eval_loss: 3.19113e+01
I0515 00:38:30.402638 140128494741248 run_lib.py:152] step: 265550, training_loss: 3.29816e+01
I0515 00:38:36.810969 140128494741248 run_lib.py:152] step: 265600, training_loss: 3.49839e+01
I0515 00:38:36.861046 140128494741248 run_lib.py:165] step: 265600, eval_loss: 1.67019e+01
I0515 00:38:43.093057 140128494741248 run_lib.py:152] step: 265650, training_loss: 3.09296e+01
I0515 00:38:49.285104 140128494741248 run_lib.py:152] step: 265700, training_loss: 3.61216e+01
I0515 00:38:49.338544 140128494741248 run_lib.py:165] step: 265700, eval_loss: 3.10542e+01
I0515 00:38:55.589998 140128494741248 run_lib.py:152] step: 265750, training_loss: 2.43376e+01
I0515 00:39:02.093483 140128494741248 run_lib.py:152] step: 265800, training_loss: 2.12849e+01
I0515 00:39:02.154360 140128494741248 run_lib.py:165] step: 265800, eval_loss: 1.98266e+01
I0515 00:39:08.445691 140128494741248 run_lib.py:152] step: 265850, training_loss: 3.57372e+01
I0515 00:39:14.664354 140128494741248 run_lib.py:152] step: 265900, training_loss: 4.50400e+01
I0515 00:39:14.715172 140128494741248 run_lib.py:165] step: 265900, eval_loss: 2.73530e+01
I0515 00:39:21.183583 140128494741248 run_lib.py:152] step: 265950, training_loss: 4.71340e+01
I0515 00:39:27.376827 140128494741248 run_lib.py:152] step: 266000, training_loss: 3.47176e+01
I0515 00:39:27.435848 140128494741248 run_lib.py:165] step: 266000, eval_loss: 2.40020e+01
I0515 00:39:33.623667 140128494741248 run_lib.py:152] step: 266050, training_loss: 1.80918e+01
I0515 00:39:39.842904 140128494741248 run_lib.py:152] step: 266100, training_loss: 3.64576e+01
I0515 00:39:39.895456 140128494741248 run_lib.py:165] step: 266100, eval_loss: 3.34677e+01
I0515 00:39:46.331053 140128494741248 run_lib.py:152] step: 266150, training_loss: 2.73282e+01
I0515 00:39:52.597522 140128494741248 run_lib.py:152] step: 266200, training_loss: 1.93837e+01
I0515 00:39:52.644857 140128494741248 run_lib.py:165] step: 266200, eval_loss: 3.43451e+01
I0515 00:39:58.783050 140128494741248 run_lib.py:152] step: 266250, training_loss: 2.41922e+01
I0515 00:40:05.192780 140128494741248 run_lib.py:152] step: 266300, training_loss: 2.39738e+01
I0515 00:40:05.239339 140128494741248 run_lib.py:165] step: 266300, eval_loss: 1.94533e+01
I0515 00:40:11.467694 140128494741248 run_lib.py:152] step: 266350, training_loss: 2.81424e+01
I0515 00:40:17.745653 140128494741248 run_lib.py:152] step: 266400, training_loss: 2.87763e+01
I0515 00:40:17.792132 140128494741248 run_lib.py:165] step: 266400, eval_loss: 1.90871e+01
I0515 00:40:23.927478 140128494741248 run_lib.py:152] step: 266450, training_loss: 3.55048e+01
I0515 00:40:30.439624 140128494741248 run_lib.py:152] step: 266500, training_loss: 2.74101e+01
I0515 00:40:30.490915 140128494741248 run_lib.py:165] step: 266500, eval_loss: 2.90488e+01
I0515 00:40:36.698541 140128494741248 run_lib.py:152] step: 266550, training_loss: 3.97604e+01
I0515 00:40:42.793652 140128494741248 run_lib.py:152] step: 266600, training_loss: 3.67141e+01
I0515 00:40:42.846943 140128494741248 run_lib.py:165] step: 266600, eval_loss: 3.05252e+01
I0515 00:40:49.369413 140128494741248 run_lib.py:152] step: 266650, training_loss: 3.25396e+01
I0515 00:40:55.556515 140128494741248 run_lib.py:152] step: 266700, training_loss: 2.41492e+01
I0515 00:40:55.617425 140128494741248 run_lib.py:165] step: 266700, eval_loss: 3.10244e+01
I0515 00:41:01.851767 140128494741248 run_lib.py:152] step: 266750, training_loss: 2.56069e+01
I0515 00:41:07.983234 140128494741248 run_lib.py:152] step: 266800, training_loss: 3.18120e+01
I0515 00:41:08.030705 140128494741248 run_lib.py:165] step: 266800, eval_loss: 3.65932e+01
I0515 00:41:14.475133 140128494741248 run_lib.py:152] step: 266850, training_loss: 2.58929e+01
I0515 00:41:20.768902 140128494741248 run_lib.py:152] step: 266900, training_loss: 4.30265e+01
I0515 00:41:20.821221 140128494741248 run_lib.py:165] step: 266900, eval_loss: 3.31369e+01
I0515 00:41:27.027227 140128494741248 run_lib.py:152] step: 266950, training_loss: 2.96594e+01
I0515 00:41:33.687353 140128494741248 run_lib.py:152] step: 267000, training_loss: 4.21926e+01
I0515 00:41:33.738132 140128494741248 run_lib.py:165] step: 267000, eval_loss: 3.97886e+01
I0515 00:41:39.931594 140128494741248 run_lib.py:152] step: 267050, training_loss: 3.91839e+01
I0515 00:41:46.171824 140128494741248 run_lib.py:152] step: 267100, training_loss: 2.60876e+01
I0515 00:41:46.219680 140128494741248 run_lib.py:165] step: 267100, eval_loss: 3.20726e+01
I0515 00:41:52.507607 140128494741248 run_lib.py:152] step: 267150, training_loss: 2.13862e+01
I0515 00:41:59.076995 140128494741248 run_lib.py:152] step: 267200, training_loss: 2.77519e+01
I0515 00:41:59.135928 140128494741248 run_lib.py:165] step: 267200, eval_loss: 3.44842e+01
I0515 00:42:05.347158 140128494741248 run_lib.py:152] step: 267250, training_loss: 4.52429e+01
I0515 00:42:11.544763 140128494741248 run_lib.py:152] step: 267300, training_loss: 5.05814e+01
I0515 00:42:11.594247 140128494741248 run_lib.py:165] step: 267300, eval_loss: 2.58888e+01
I0515 00:42:18.099076 140128494741248 run_lib.py:152] step: 267350, training_loss: 3.03315e+01
I0515 00:42:24.317275 140128494741248 run_lib.py:152] step: 267400, training_loss: 3.40812e+01
I0515 00:42:24.370219 140128494741248 run_lib.py:165] step: 267400, eval_loss: 2.13919e+01
I0515 00:42:30.654128 140128494741248 run_lib.py:152] step: 267450, training_loss: 3.52950e+01
I0515 00:42:36.852584 140128494741248 run_lib.py:152] step: 267500, training_loss: 2.81641e+01
I0515 00:42:36.914297 140128494741248 run_lib.py:165] step: 267500, eval_loss: 3.18517e+01
I0515 00:42:43.437873 140128494741248 run_lib.py:152] step: 267550, training_loss: 3.31774e+01
I0515 00:42:49.746039 140128494741248 run_lib.py:152] step: 267600, training_loss: 3.13701e+01
I0515 00:42:49.798896 140128494741248 run_lib.py:165] step: 267600, eval_loss: 2.97450e+01
I0515 00:42:56.075943 140128494741248 run_lib.py:152] step: 267650, training_loss: 2.65785e+01
I0515 00:43:02.485250 140128494741248 run_lib.py:152] step: 267700, training_loss: 2.87659e+01
I0515 00:43:02.542218 140128494741248 run_lib.py:165] step: 267700, eval_loss: 1.73594e+01
I0515 00:43:08.682501 140128494741248 run_lib.py:152] step: 267750, training_loss: 2.80974e+01
I0515 00:43:14.886779 140128494741248 run_lib.py:152] step: 267800, training_loss: 2.06349e+01
I0515 00:43:14.941538 140128494741248 run_lib.py:165] step: 267800, eval_loss: 2.98635e+01
I0515 00:43:21.150357 140128494741248 run_lib.py:152] step: 267850, training_loss: 3.84733e+01
I0515 00:43:27.539870 140128494741248 run_lib.py:152] step: 267900, training_loss: 3.71061e+01
I0515 00:43:27.586867 140128494741248 run_lib.py:165] step: 267900, eval_loss: 1.67665e+01
I0515 00:43:33.826138 140128494741248 run_lib.py:152] step: 267950, training_loss: 2.87159e+01
I0515 00:43:39.984874 140128494741248 run_lib.py:152] step: 268000, training_loss: 3.59548e+01
I0515 00:43:40.036159 140128494741248 run_lib.py:165] step: 268000, eval_loss: 4.24677e+01
I0515 00:43:46.529033 140128494741248 run_lib.py:152] step: 268050, training_loss: 3.83430e+01
I0515 00:43:52.746336 140128494741248 run_lib.py:152] step: 268100, training_loss: 3.13982e+01
I0515 00:43:52.798092 140128494741248 run_lib.py:165] step: 268100, eval_loss: 3.84654e+01
I0515 00:43:58.959350 140128494741248 run_lib.py:152] step: 268150, training_loss: 3.13180e+01
I0515 00:44:05.149204 140128494741248 run_lib.py:152] step: 268200, training_loss: 3.53424e+01
I0515 00:44:05.196270 140128494741248 run_lib.py:165] step: 268200, eval_loss: 3.10761e+01
I0515 00:44:11.647246 140128494741248 run_lib.py:152] step: 268250, training_loss: 1.68594e+01
I0515 00:44:17.888686 140128494741248 run_lib.py:152] step: 268300, training_loss: 3.47378e+01
I0515 00:44:17.943529 140128494741248 run_lib.py:165] step: 268300, eval_loss: 3.61065e+01
I0515 00:44:24.118326 140128494741248 run_lib.py:152] step: 268350, training_loss: 1.89387e+01
I0515 00:44:30.649922 140128494741248 run_lib.py:152] step: 268400, training_loss: 3.18147e+01
I0515 00:44:30.702763 140128494741248 run_lib.py:165] step: 268400, eval_loss: 2.91347e+01
I0515 00:44:36.798418 140128494741248 run_lib.py:152] step: 268450, training_loss: 2.17514e+01
I0515 00:44:42.856964 140128494741248 run_lib.py:152] step: 268500, training_loss: 2.53478e+01
I0515 00:44:42.917183 140128494741248 run_lib.py:165] step: 268500, eval_loss: 2.32534e+01
I0515 00:44:49.117869 140128494741248 run_lib.py:152] step: 268550, training_loss: 4.03553e+01
I0515 00:44:55.587965 140128494741248 run_lib.py:152] step: 268600, training_loss: 3.39167e+01
I0515 00:44:55.638092 140128494741248 run_lib.py:165] step: 268600, eval_loss: 2.97430e+01
I0515 00:45:01.876274 140128494741248 run_lib.py:152] step: 268650, training_loss: 2.79012e+01
I0515 00:45:08.129063 140128494741248 run_lib.py:152] step: 268700, training_loss: 2.19268e+01
I0515 00:45:08.183528 140128494741248 run_lib.py:165] step: 268700, eval_loss: 2.14547e+01
I0515 00:45:14.762183 140128494741248 run_lib.py:152] step: 268750, training_loss: 4.19077e+01
I0515 00:45:21.011155 140128494741248 run_lib.py:152] step: 268800, training_loss: 3.94607e+01
I0515 00:45:21.064532 140128494741248 run_lib.py:165] step: 268800, eval_loss: 2.52378e+01
I0515 00:45:27.228724 140128494741248 run_lib.py:152] step: 268850, training_loss: 3.23698e+01
I0515 00:45:33.498489 140128494741248 run_lib.py:152] step: 268900, training_loss: 3.91203e+01
I0515 00:45:33.550939 140128494741248 run_lib.py:165] step: 268900, eval_loss: 2.59833e+01
I0515 00:45:40.109110 140128494741248 run_lib.py:152] step: 268950, training_loss: 3.38652e+01
I0515 00:45:46.299301 140128494741248 run_lib.py:152] step: 269000, training_loss: 4.54840e+01
I0515 00:45:46.348590 140128494741248 run_lib.py:165] step: 269000, eval_loss: 2.82300e+01
I0515 00:45:52.651305 140128494741248 run_lib.py:152] step: 269050, training_loss: 2.30095e+01
I0515 00:45:59.129975 140128494741248 run_lib.py:152] step: 269100, training_loss: 3.41284e+01
I0515 00:45:59.181172 140128494741248 run_lib.py:165] step: 269100, eval_loss: 1.28443e+01
I0515 00:46:05.323950 140128494741248 run_lib.py:152] step: 269150, training_loss: 2.98579e+01
I0515 00:46:11.636470 140128494741248 run_lib.py:152] step: 269200, training_loss: 1.92042e+01
I0515 00:46:11.686992 140128494741248 run_lib.py:165] step: 269200, eval_loss: 3.22095e+01
I0515 00:46:17.875908 140128494741248 run_lib.py:152] step: 269250, training_loss: 3.17777e+01
I0515 00:46:24.303445 140128494741248 run_lib.py:152] step: 269300, training_loss: 4.07416e+01
I0515 00:46:24.355717 140128494741248 run_lib.py:165] step: 269300, eval_loss: 3.33136e+01
I0515 00:46:30.554244 140128494741248 run_lib.py:152] step: 269350, training_loss: 3.73216e+01
I0515 00:46:36.754491 140128494741248 run_lib.py:152] step: 269400, training_loss: 2.43009e+01
I0515 00:46:36.804114 140128494741248 run_lib.py:165] step: 269400, eval_loss: 3.23251e+01
I0515 00:46:43.296699 140128494741248 run_lib.py:152] step: 269450, training_loss: 2.82886e+01
I0515 00:46:49.498903 140128494741248 run_lib.py:152] step: 269500, training_loss: 4.09684e+01
I0515 00:46:49.556302 140128494741248 run_lib.py:165] step: 269500, eval_loss: 3.72882e+01
I0515 00:46:55.718418 140128494741248 run_lib.py:152] step: 269550, training_loss: 3.62949e+01
I0515 00:47:01.977816 140128494741248 run_lib.py:152] step: 269600, training_loss: 1.74366e+01
I0515 00:47:02.028332 140128494741248 run_lib.py:165] step: 269600, eval_loss: 2.00071e+01
I0515 00:47:08.464370 140128494741248 run_lib.py:152] step: 269650, training_loss: 3.07120e+01
I0515 00:47:14.786709 140128494741248 run_lib.py:152] step: 269700, training_loss: 3.66941e+01
I0515 00:47:14.843338 140128494741248 run_lib.py:165] step: 269700, eval_loss: 3.02417e+01
I0515 00:47:21.110781 140128494741248 run_lib.py:152] step: 269750, training_loss: 2.73803e+01
I0515 00:47:27.543925 140128494741248 run_lib.py:152] step: 269800, training_loss: 3.01964e+01
I0515 00:47:27.592638 140128494741248 run_lib.py:165] step: 269800, eval_loss: 3.08290e+01
I0515 00:47:33.770162 140128494741248 run_lib.py:152] step: 269850, training_loss: 3.29568e+01
I0515 00:47:40.062818 140128494741248 run_lib.py:152] step: 269900, training_loss: 3.70190e+01
I0515 00:47:40.111145 140128494741248 run_lib.py:165] step: 269900, eval_loss: 3.49245e+01
I0515 00:47:46.331001 140128494741248 run_lib.py:152] step: 269950, training_loss: 4.01559e+01
I0515 00:47:52.800538 140128494741248 run_lib.py:152] step: 270000, training_loss: 3.75628e+01
I0515 00:47:53.007540 140128494741248 run_lib.py:165] step: 270000, eval_loss: 3.36885e+01
I0515 00:47:59.283193 140128494741248 run_lib.py:152] step: 270050, training_loss: 3.24032e+01
I0515 00:48:05.491292 140128494741248 run_lib.py:152] step: 270100, training_loss: 3.22397e+01
I0515 00:48:05.543047 140128494741248 run_lib.py:165] step: 270100, eval_loss: 2.31690e+01
I0515 00:48:12.020712 140128494741248 run_lib.py:152] step: 270150, training_loss: 3.95020e+01
I0515 00:48:18.174982 140128494741248 run_lib.py:152] step: 270200, training_loss: 2.39956e+01
I0515 00:48:18.226424 140128494741248 run_lib.py:165] step: 270200, eval_loss: 4.48036e+01
I0515 00:48:24.526473 140128494741248 run_lib.py:152] step: 270250, training_loss: 3.44682e+01
I0515 00:48:30.705565 140128494741248 run_lib.py:152] step: 270300, training_loss: 3.19291e+01
I0515 00:48:30.766770 140128494741248 run_lib.py:165] step: 270300, eval_loss: 1.88815e+01
I0515 00:48:37.262432 140128494741248 run_lib.py:152] step: 270350, training_loss: 3.15275e+01
I0515 00:48:43.463403 140128494741248 run_lib.py:152] step: 270400, training_loss: 4.01908e+01
I0515 00:48:43.520684 140128494741248 run_lib.py:165] step: 270400, eval_loss: 2.67232e+01
I0515 00:48:49.759238 140128494741248 run_lib.py:152] step: 270450, training_loss: 3.95726e+01
I0515 00:48:56.072667 140128494741248 run_lib.py:152] step: 270500, training_loss: 3.69133e+01
I0515 00:48:56.125650 140128494741248 run_lib.py:165] step: 270500, eval_loss: 2.99419e+01
I0515 00:49:02.323095 140128494741248 run_lib.py:152] step: 270550, training_loss: 4.39824e+01
I0515 00:49:08.510459 140128494741248 run_lib.py:152] step: 270600, training_loss: 3.16975e+01
I0515 00:49:08.560714 140128494741248 run_lib.py:165] step: 270600, eval_loss: 2.64403e+01
I0515 00:49:14.847342 140128494741248 run_lib.py:152] step: 270650, training_loss: 3.24087e+01
I0515 00:49:21.326477 140128494741248 run_lib.py:152] step: 270700, training_loss: 2.96571e+01
I0515 00:49:21.379564 140128494741248 run_lib.py:165] step: 270700, eval_loss: 1.54720e+01
I0515 00:49:27.543762 140128494741248 run_lib.py:152] step: 270750, training_loss: 3.19113e+01
I0515 00:49:33.821097 140128494741248 run_lib.py:152] step: 270800, training_loss: 4.54572e+01
I0515 00:49:33.880434 140128494741248 run_lib.py:165] step: 270800, eval_loss: 1.83912e+01
I0515 00:49:40.310716 140128494741248 run_lib.py:152] step: 270850, training_loss: 3.49633e+01
I0515 00:49:46.444505 140128494741248 run_lib.py:152] step: 270900, training_loss: 2.47659e+01
I0515 00:49:46.496166 140128494741248 run_lib.py:165] step: 270900, eval_loss: 4.31479e+01
I0515 00:49:52.715951 140128494741248 run_lib.py:152] step: 270950, training_loss: 3.94004e+01
I0515 00:49:58.993767 140128494741248 run_lib.py:152] step: 271000, training_loss: 2.77559e+01
I0515 00:49:59.043532 140128494741248 run_lib.py:165] step: 271000, eval_loss: 2.88291e+01
I0515 00:50:05.388472 140128494741248 run_lib.py:152] step: 271050, training_loss: 1.71765e+01
I0515 00:50:11.659279 140128494741248 run_lib.py:152] step: 271100, training_loss: 3.76960e+01
I0515 00:50:11.709808 140128494741248 run_lib.py:165] step: 271100, eval_loss: 2.95868e+01
I0515 00:50:17.850266 140128494741248 run_lib.py:152] step: 271150, training_loss: 3.60302e+01
I0515 00:50:24.277860 140128494741248 run_lib.py:152] step: 271200, training_loss: 2.83643e+01
I0515 00:50:24.335067 140128494741248 run_lib.py:165] step: 271200, eval_loss: 1.84217e+01
I0515 00:50:30.452506 140128494741248 run_lib.py:152] step: 271250, training_loss: 4.99932e+01
I0515 00:50:36.789991 140128494741248 run_lib.py:152] step: 271300, training_loss: 1.98615e+01
I0515 00:50:36.847512 140128494741248 run_lib.py:165] step: 271300, eval_loss: 3.26128e+01
I0515 00:50:43.029462 140128494741248 run_lib.py:152] step: 271350, training_loss: 2.02826e+01
I0515 00:50:49.485194 140128494741248 run_lib.py:152] step: 271400, training_loss: 3.42494e+01
I0515 00:50:49.536362 140128494741248 run_lib.py:165] step: 271400, eval_loss: 4.24550e+01
I0515 00:50:55.717209 140128494741248 run_lib.py:152] step: 271450, training_loss: 3.41126e+01
I0515 00:51:01.892822 140128494741248 run_lib.py:152] step: 271500, training_loss: 3.47486e+01
I0515 00:51:01.949512 140128494741248 run_lib.py:165] step: 271500, eval_loss: 3.72193e+01
I0515 00:51:08.479447 140128494741248 run_lib.py:152] step: 271550, training_loss: 2.98628e+01
I0515 00:51:14.706616 140128494741248 run_lib.py:152] step: 271600, training_loss: 3.16728e+01
I0515 00:51:14.756596 140128494741248 run_lib.py:165] step: 271600, eval_loss: 4.45310e+01
I0515 00:51:21.004622 140128494741248 run_lib.py:152] step: 271650, training_loss: 2.89270e+01
I0515 00:51:27.165336 140128494741248 run_lib.py:152] step: 271700, training_loss: 3.52746e+01
I0515 00:51:27.213285 140128494741248 run_lib.py:165] step: 271700, eval_loss: 2.64795e+01
I0515 00:51:33.708781 140128494741248 run_lib.py:152] step: 271750, training_loss: 2.62473e+01
I0515 00:51:39.836153 140128494741248 run_lib.py:152] step: 271800, training_loss: 2.23385e+01
I0515 00:51:39.891103 140128494741248 run_lib.py:165] step: 271800, eval_loss: 3.17857e+01
I0515 00:51:46.054941 140128494741248 run_lib.py:152] step: 271850, training_loss: 2.09482e+01
I0515 00:51:52.532368 140128494741248 run_lib.py:152] step: 271900, training_loss: 3.50816e+01
I0515 00:51:52.590090 140128494741248 run_lib.py:165] step: 271900, eval_loss: 3.94946e+01
I0515 00:51:58.731097 140128494741248 run_lib.py:152] step: 271950, training_loss: 3.39657e+01
I0515 00:52:04.908944 140128494741248 run_lib.py:152] step: 272000, training_loss: 4.31336e+01
I0515 00:52:04.964530 140128494741248 run_lib.py:165] step: 272000, eval_loss: 4.82040e+01
I0515 00:52:11.257244 140128494741248 run_lib.py:152] step: 272050, training_loss: 1.53485e+01
I0515 00:52:17.619057 140128494741248 run_lib.py:152] step: 272100, training_loss: 3.67369e+01
I0515 00:52:17.668596 140128494741248 run_lib.py:165] step: 272100, eval_loss: 4.64217e+01
I0515 00:52:23.926338 140128494741248 run_lib.py:152] step: 272150, training_loss: 3.16603e+01
I0515 00:52:30.150629 140128494741248 run_lib.py:152] step: 272200, training_loss: 2.36691e+01
I0515 00:52:30.200181 140128494741248 run_lib.py:165] step: 272200, eval_loss: 1.87203e+01
I0515 00:52:36.645723 140128494741248 run_lib.py:152] step: 272250, training_loss: 3.11755e+01
I0515 00:52:42.864320 140128494741248 run_lib.py:152] step: 272300, training_loss: 3.17851e+01
I0515 00:52:42.920575 140128494741248 run_lib.py:165] step: 272300, eval_loss: 3.72536e+01
I0515 00:52:49.178761 140128494741248 run_lib.py:152] step: 272350, training_loss: 4.77780e+01
I0515 00:52:55.419966 140128494741248 run_lib.py:152] step: 272400, training_loss: 5.88987e+01
I0515 00:52:55.473983 140128494741248 run_lib.py:165] step: 272400, eval_loss: 4.20342e+01
I0515 00:53:01.850388 140128494741248 run_lib.py:152] step: 272450, training_loss: 3.10193e+01
I0515 00:53:08.064643 140128494741248 run_lib.py:152] step: 272500, training_loss: 4.18588e+01
I0515 00:53:08.113409 140128494741248 run_lib.py:165] step: 272500, eval_loss: 4.00946e+01
I0515 00:53:14.320118 140128494741248 run_lib.py:152] step: 272550, training_loss: 3.57143e+01
I0515 00:53:20.700792 140128494741248 run_lib.py:152] step: 272600, training_loss: 3.00336e+01
I0515 00:53:20.749532 140128494741248 run_lib.py:165] step: 272600, eval_loss: 2.58392e+01
I0515 00:53:26.964256 140128494741248 run_lib.py:152] step: 272650, training_loss: 5.49912e+01
I0515 00:53:33.101377 140128494741248 run_lib.py:152] step: 272700, training_loss: 3.57499e+01
I0515 00:53:33.150595 140128494741248 run_lib.py:165] step: 272700, eval_loss: 2.21267e+01
I0515 00:53:39.404993 140128494741248 run_lib.py:152] step: 272750, training_loss: 2.48188e+01
I0515 00:53:45.751507 140128494741248 run_lib.py:152] step: 272800, training_loss: 2.42440e+01
I0515 00:53:45.799757 140128494741248 run_lib.py:165] step: 272800, eval_loss: 3.11174e+01
I0515 00:53:52.030076 140128494741248 run_lib.py:152] step: 272850, training_loss: 2.39637e+01
I0515 00:53:58.249830 140128494741248 run_lib.py:152] step: 272900, training_loss: 3.39182e+01
I0515 00:53:58.301624 140128494741248 run_lib.py:165] step: 272900, eval_loss: 3.48046e+01
I0515 00:54:04.784881 140128494741248 run_lib.py:152] step: 272950, training_loss: 3.63117e+01
I0515 00:54:10.929178 140128494741248 run_lib.py:152] step: 273000, training_loss: 3.93138e+01
I0515 00:54:10.981086 140128494741248 run_lib.py:165] step: 273000, eval_loss: 2.19023e+01
I0515 00:54:17.158196 140128494741248 run_lib.py:152] step: 273050, training_loss: 2.21269e+01
I0515 00:54:23.441105 140128494741248 run_lib.py:152] step: 273100, training_loss: 3.29858e+01
I0515 00:54:23.490532 140128494741248 run_lib.py:165] step: 273100, eval_loss: 2.75589e+01
I0515 00:54:29.978420 140128494741248 run_lib.py:152] step: 273150, training_loss: 1.74929e+01
I0515 00:54:36.205793 140128494741248 run_lib.py:152] step: 273200, training_loss: 2.30733e+01
I0515 00:54:36.262487 140128494741248 run_lib.py:165] step: 273200, eval_loss: 1.95334e+01
I0515 00:54:42.410978 140128494741248 run_lib.py:152] step: 273250, training_loss: 2.38731e+01
I0515 00:54:48.874085 140128494741248 run_lib.py:152] step: 273300, training_loss: 2.03898e+01
I0515 00:54:48.933291 140128494741248 run_lib.py:165] step: 273300, eval_loss: 3.63520e+01
I0515 00:54:55.058158 140128494741248 run_lib.py:152] step: 273350, training_loss: 4.43962e+01
I0515 00:55:01.384624 140128494741248 run_lib.py:152] step: 273400, training_loss: 2.07316e+01
I0515 00:55:01.438944 140128494741248 run_lib.py:165] step: 273400, eval_loss: 3.85378e+01
I0515 00:55:07.794460 140128494741248 run_lib.py:152] step: 273450, training_loss: 3.39631e+01
I0515 00:55:14.300308 140128494741248 run_lib.py:152] step: 273500, training_loss: 3.03833e+01
I0515 00:55:14.354400 140128494741248 run_lib.py:165] step: 273500, eval_loss: 3.02544e+01
I0515 00:55:20.566018 140128494741248 run_lib.py:152] step: 273550, training_loss: 3.47144e+01
I0515 00:55:26.755215 140128494741248 run_lib.py:152] step: 273600, training_loss: 3.59930e+01
I0515 00:55:26.805854 140128494741248 run_lib.py:165] step: 273600, eval_loss: 3.69561e+01
I0515 00:55:33.207244 140128494741248 run_lib.py:152] step: 273650, training_loss: 4.43557e+01
I0515 00:55:39.491950 140128494741248 run_lib.py:152] step: 273700, training_loss: 3.46473e+01
I0515 00:55:39.542280 140128494741248 run_lib.py:165] step: 273700, eval_loss: 2.21579e+01
I0515 00:55:45.653591 140128494741248 run_lib.py:152] step: 273750, training_loss: 2.84726e+01
I0515 00:55:51.957141 140128494741248 run_lib.py:152] step: 273800, training_loss: 3.45739e+01
I0515 00:55:52.008174 140128494741248 run_lib.py:165] step: 273800, eval_loss: 3.12364e+01
I0515 00:55:58.494281 140128494741248 run_lib.py:152] step: 273850, training_loss: 3.27773e+01
I0515 00:56:04.726008 140128494741248 run_lib.py:152] step: 273900, training_loss: 3.02885e+01
I0515 00:56:04.774849 140128494741248 run_lib.py:165] step: 273900, eval_loss: 1.76835e+01
I0515 00:56:10.964204 140128494741248 run_lib.py:152] step: 273950, training_loss: 1.63819e+01
I0515 00:56:17.393891 140128494741248 run_lib.py:152] step: 274000, training_loss: 3.67130e+01
I0515 00:56:17.448404 140128494741248 run_lib.py:165] step: 274000, eval_loss: 1.86351e+01
I0515 00:56:23.576509 140128494741248 run_lib.py:152] step: 274050, training_loss: 2.93065e+01
I0515 00:56:29.783998 140128494741248 run_lib.py:152] step: 274100, training_loss: 2.76264e+01
I0515 00:56:29.838919 140128494741248 run_lib.py:165] step: 274100, eval_loss: 4.42095e+01
I0515 00:56:35.960575 140128494741248 run_lib.py:152] step: 274150, training_loss: 3.95341e+01
I0515 00:56:42.300898 140128494741248 run_lib.py:152] step: 274200, training_loss: 3.47946e+01
I0515 00:56:42.360898 140128494741248 run_lib.py:165] step: 274200, eval_loss: 3.54936e+01
I0515 00:56:48.541280 140128494741248 run_lib.py:152] step: 274250, training_loss: 4.93695e+01
I0515 00:56:54.722748 140128494741248 run_lib.py:152] step: 274300, training_loss: 2.85157e+01
I0515 00:56:54.775347 140128494741248 run_lib.py:165] step: 274300, eval_loss: 3.47317e+01
I0515 00:57:01.249210 140128494741248 run_lib.py:152] step: 274350, training_loss: 2.72929e+01
I0515 00:57:07.490044 140128494741248 run_lib.py:152] step: 274400, training_loss: 4.18293e+01
I0515 00:57:07.542346 140128494741248 run_lib.py:165] step: 274400, eval_loss: 3.75126e+01
I0515 00:57:13.705418 140128494741248 run_lib.py:152] step: 274450, training_loss: 3.38606e+01
I0515 00:57:19.887017 140128494741248 run_lib.py:152] step: 274500, training_loss: 2.27102e+01
I0515 00:57:19.941068 140128494741248 run_lib.py:165] step: 274500, eval_loss: 2.40314e+01
I0515 00:57:26.345378 140128494741248 run_lib.py:152] step: 274550, training_loss: 4.56991e+01
I0515 00:57:32.580703 140128494741248 run_lib.py:152] step: 274600, training_loss: 3.07722e+01
I0515 00:57:32.634808 140128494741248 run_lib.py:165] step: 274600, eval_loss: 5.17707e+01
I0515 00:57:38.733337 140128494741248 run_lib.py:152] step: 274650, training_loss: 3.11371e+01
I0515 00:57:45.283822 140128494741248 run_lib.py:152] step: 274700, training_loss: 3.66291e+01
I0515 00:57:45.332351 140128494741248 run_lib.py:165] step: 274700, eval_loss: 3.22804e+01
I0515 00:57:51.558416 140128494741248 run_lib.py:152] step: 274750, training_loss: 2.44082e+01
I0515 00:57:57.779792 140128494741248 run_lib.py:152] step: 274800, training_loss: 2.91302e+01
I0515 00:57:57.830216 140128494741248 run_lib.py:165] step: 274800, eval_loss: 4.91460e+01
I0515 00:58:04.166133 140128494741248 run_lib.py:152] step: 274850, training_loss: 2.36483e+01
I0515 00:58:10.613124 140128494741248 run_lib.py:152] step: 274900, training_loss: 3.75137e+01
I0515 00:58:10.660011 140128494741248 run_lib.py:165] step: 274900, eval_loss: 3.17637e+01
I0515 00:58:16.826136 140128494741248 run_lib.py:152] step: 274950, training_loss: 2.93072e+01
I0515 00:58:22.995419 140128494741248 run_lib.py:152] step: 275000, training_loss: 2.64322e+01
I0515 00:58:23.044378 140128494741248 run_lib.py:165] step: 275000, eval_loss: 2.59178e+01
I0515 00:58:29.440673 140128494741248 run_lib.py:152] step: 275050, training_loss: 3.10625e+01
I0515 00:58:35.624000 140128494741248 run_lib.py:152] step: 275100, training_loss: 4.02525e+01
I0515 00:58:35.685759 140128494741248 run_lib.py:165] step: 275100, eval_loss: 3.24551e+01
I0515 00:58:41.866479 140128494741248 run_lib.py:152] step: 275150, training_loss: 2.22743e+01
I0515 00:58:48.905045 140128494741248 run_lib.py:152] step: 275200, training_loss: 1.51935e+01
I0515 00:58:48.958094 140128494741248 run_lib.py:165] step: 275200, eval_loss: 4.19473e+01
I0515 00:58:55.429850 140128494741248 run_lib.py:152] step: 275250, training_loss: 3.61087e+01
I0515 00:59:02.010262 140128494741248 run_lib.py:152] step: 275300, training_loss: 3.51879e+01
I0515 00:59:02.066560 140128494741248 run_lib.py:165] step: 275300, eval_loss: 3.92327e+01
I0515 00:59:08.309331 140128494741248 run_lib.py:152] step: 275350, training_loss: 2.14321e+01
I0515 00:59:14.826502 140128494741248 run_lib.py:152] step: 275400, training_loss: 4.44075e+01
I0515 00:59:14.880206 140128494741248 run_lib.py:165] step: 275400, eval_loss: 3.51753e+01
I0515 00:59:21.032483 140128494741248 run_lib.py:152] step: 275450, training_loss: 2.93414e+01
I0515 00:59:27.127056 140128494741248 run_lib.py:152] step: 275500, training_loss: 2.46042e+01
I0515 00:59:27.178501 140128494741248 run_lib.py:165] step: 275500, eval_loss: 1.03810e+01
I0515 00:59:33.403702 140128494741248 run_lib.py:152] step: 275550, training_loss: 3.18381e+01
I0515 00:59:39.840754 140128494741248 run_lib.py:152] step: 275600, training_loss: 4.03035e+01
I0515 00:59:39.893819 140128494741248 run_lib.py:165] step: 275600, eval_loss: 3.65852e+01
I0515 00:59:46.194308 140128494741248 run_lib.py:152] step: 275650, training_loss: 3.74804e+01
I0515 00:59:52.335096 140128494741248 run_lib.py:152] step: 275700, training_loss: 2.87972e+01
I0515 00:59:52.388496 140128494741248 run_lib.py:165] step: 275700, eval_loss: 3.47686e+01
I0515 00:59:58.783492 140128494741248 run_lib.py:152] step: 275750, training_loss: 3.45131e+01
I0515 01:00:05.077639 140128494741248 run_lib.py:152] step: 275800, training_loss: 3.40345e+01
I0515 01:00:05.127072 140128494741248 run_lib.py:165] step: 275800, eval_loss: 2.33516e+01
I0515 01:00:11.262230 140128494741248 run_lib.py:152] step: 275850, training_loss: 2.89353e+01
I0515 01:00:17.556181 140128494741248 run_lib.py:152] step: 275900, training_loss: 3.41570e+01
I0515 01:00:17.608398 140128494741248 run_lib.py:165] step: 275900, eval_loss: 2.08556e+01
I0515 01:00:23.990740 140128494741248 run_lib.py:152] step: 275950, training_loss: 3.52021e+01
I0515 01:00:30.238297 140128494741248 run_lib.py:152] step: 276000, training_loss: 3.01471e+01
I0515 01:00:30.300959 140128494741248 run_lib.py:165] step: 276000, eval_loss: 2.92135e+01
I0515 01:00:36.465556 140128494741248 run_lib.py:152] step: 276050, training_loss: 3.39184e+01
I0515 01:00:42.854043 140128494741248 run_lib.py:152] step: 276100, training_loss: 2.06762e+01
I0515 01:00:42.906199 140128494741248 run_lib.py:165] step: 276100, eval_loss: 3.60453e+01
I0515 01:00:49.051858 140128494741248 run_lib.py:152] step: 276150, training_loss: 3.10453e+01
I0515 01:00:55.302770 140128494741248 run_lib.py:152] step: 276200, training_loss: 2.81134e+01
I0515 01:00:55.355304 140128494741248 run_lib.py:165] step: 276200, eval_loss: 2.97559e+01
I0515 01:01:01.511092 140128494741248 run_lib.py:152] step: 276250, training_loss: 4.61625e+01
I0515 01:01:07.983922 140128494741248 run_lib.py:152] step: 276300, training_loss: 3.47063e+01
I0515 01:01:08.034706 140128494741248 run_lib.py:165] step: 276300, eval_loss: 4.64591e+01
I0515 01:01:14.307251 140128494741248 run_lib.py:152] step: 276350, training_loss: 4.21123e+01
I0515 01:01:20.580097 140128494741248 run_lib.py:152] step: 276400, training_loss: 2.89678e+01
I0515 01:01:20.631361 140128494741248 run_lib.py:165] step: 276400, eval_loss: 3.30533e+01
I0515 01:01:27.063106 140128494741248 run_lib.py:152] step: 276450, training_loss: 4.57684e+01
I0515 01:01:33.395704 140128494741248 run_lib.py:152] step: 276500, training_loss: 2.08655e+01
I0515 01:01:33.445749 140128494741248 run_lib.py:165] step: 276500, eval_loss: 1.45841e+01
I0515 01:01:39.688255 140128494741248 run_lib.py:152] step: 276550, training_loss: 2.30575e+01
I0515 01:01:45.893329 140128494741248 run_lib.py:152] step: 276600, training_loss: 3.31086e+01
I0515 01:01:45.943170 140128494741248 run_lib.py:165] step: 276600, eval_loss: 4.00584e+01
I0515 01:01:52.259073 140128494741248 run_lib.py:152] step: 276650, training_loss: 3.28236e+01
I0515 01:01:58.373106 140128494741248 run_lib.py:152] step: 276700, training_loss: 2.07741e+01
I0515 01:01:58.428750 140128494741248 run_lib.py:165] step: 276700, eval_loss: 4.25037e+01
I0515 01:02:04.565139 140128494741248 run_lib.py:152] step: 276750, training_loss: 2.57089e+01
I0515 01:02:11.063495 140128494741248 run_lib.py:152] step: 276800, training_loss: 4.07158e+01
I0515 01:02:11.121894 140128494741248 run_lib.py:165] step: 276800, eval_loss: 1.65935e+01
I0515 01:02:17.350698 140128494741248 run_lib.py:152] step: 276850, training_loss: 3.26674e+01
I0515 01:02:23.522528 140128494741248 run_lib.py:152] step: 276900, training_loss: 1.32554e+01
I0515 01:02:23.580197 140128494741248 run_lib.py:165] step: 276900, eval_loss: 3.27290e+01
I0515 01:02:29.758388 140128494741248 run_lib.py:152] step: 276950, training_loss: 3.42962e+01
I0515 01:02:36.246609 140128494741248 run_lib.py:152] step: 277000, training_loss: 2.75040e+01
I0515 01:02:36.300310 140128494741248 run_lib.py:165] step: 277000, eval_loss: 3.25184e+01
I0515 01:02:42.487243 140128494741248 run_lib.py:152] step: 277050, training_loss: 3.71214e+01
I0515 01:02:48.668193 140128494741248 run_lib.py:152] step: 277100, training_loss: 2.71722e+01
I0515 01:02:48.719949 140128494741248 run_lib.py:165] step: 277100, eval_loss: 3.18402e+01
I0515 01:02:55.204782 140128494741248 run_lib.py:152] step: 277150, training_loss: 4.27339e+01
I0515 01:03:01.441023 140128494741248 run_lib.py:152] step: 277200, training_loss: 4.09842e+01
I0515 01:03:01.491529 140128494741248 run_lib.py:165] step: 277200, eval_loss: 4.31056e+01
I0515 01:03:07.760071 140128494741248 run_lib.py:152] step: 277250, training_loss: 4.09567e+01
I0515 01:03:13.955577 140128494741248 run_lib.py:152] step: 277300, training_loss: 2.51318e+01
I0515 01:03:14.007750 140128494741248 run_lib.py:165] step: 277300, eval_loss: 3.58688e+01
I0515 01:03:20.531025 140128494741248 run_lib.py:152] step: 277350, training_loss: 3.16091e+01
I0515 01:03:26.740923 140128494741248 run_lib.py:152] step: 277400, training_loss: 2.92080e+01
I0515 01:03:26.790631 140128494741248 run_lib.py:165] step: 277400, eval_loss: 3.53975e+01
I0515 01:03:32.964488 140128494741248 run_lib.py:152] step: 277450, training_loss: 2.99585e+01
I0515 01:03:39.555489 140128494741248 run_lib.py:152] step: 277500, training_loss: 1.93353e+01
I0515 01:03:39.606678 140128494741248 run_lib.py:165] step: 277500, eval_loss: 4.19008e+01
I0515 01:03:45.869880 140128494741248 run_lib.py:152] step: 277550, training_loss: 3.27992e+01
I0515 01:03:52.133043 140128494741248 run_lib.py:152] step: 277600, training_loss: 3.76295e+01
I0515 01:03:52.190415 140128494741248 run_lib.py:165] step: 277600, eval_loss: 4.40488e+01
I0515 01:03:58.447911 140128494741248 run_lib.py:152] step: 277650, training_loss: 3.33496e+01
I0515 01:04:04.929805 140128494741248 run_lib.py:152] step: 277700, training_loss: 2.47081e+01
I0515 01:04:04.981925 140128494741248 run_lib.py:165] step: 277700, eval_loss: 3.31492e+01
I0515 01:04:11.174598 140128494741248 run_lib.py:152] step: 277750, training_loss: 5.42975e+01
I0515 01:04:17.500451 140128494741248 run_lib.py:152] step: 277800, training_loss: 2.17713e+01
I0515 01:04:17.556367 140128494741248 run_lib.py:165] step: 277800, eval_loss: 3.43176e+01
I0515 01:04:24.039166 140128494741248 run_lib.py:152] step: 277850, training_loss: 2.78007e+01
I0515 01:04:30.285564 140128494741248 run_lib.py:152] step: 277900, training_loss: 3.97227e+01
I0515 01:04:30.334368 140128494741248 run_lib.py:165] step: 277900, eval_loss: 3.42278e+01
I0515 01:04:36.452093 140128494741248 run_lib.py:152] step: 277950, training_loss: 3.25618e+01
I0515 01:04:42.760238 140128494741248 run_lib.py:152] step: 278000, training_loss: 2.67795e+01
I0515 01:04:42.810816 140128494741248 run_lib.py:165] step: 278000, eval_loss: 2.77572e+01
I0515 01:04:49.193340 140128494741248 run_lib.py:152] step: 278050, training_loss: 4.58531e+01
I0515 01:04:55.382356 140128494741248 run_lib.py:152] step: 278100, training_loss: 2.46614e+01
I0515 01:04:55.443998 140128494741248 run_lib.py:165] step: 278100, eval_loss: 2.33933e+01
I0515 01:05:01.672590 140128494741248 run_lib.py:152] step: 278150, training_loss: 3.18719e+01
I0515 01:05:08.026116 140128494741248 run_lib.py:152] step: 278200, training_loss: 4.40890e+01
I0515 01:05:08.077507 140128494741248 run_lib.py:165] step: 278200, eval_loss: 3.40113e+01
I0515 01:05:14.330521 140128494741248 run_lib.py:152] step: 278250, training_loss: 3.67644e+01
I0515 01:05:20.599466 140128494741248 run_lib.py:152] step: 278300, training_loss: 3.48838e+01
I0515 01:05:20.651235 140128494741248 run_lib.py:165] step: 278300, eval_loss: 2.63208e+01
I0515 01:05:26.809217 140128494741248 run_lib.py:152] step: 278350, training_loss: 2.18483e+01
I0515 01:05:33.202443 140128494741248 run_lib.py:152] step: 278400, training_loss: 3.16726e+01
I0515 01:05:33.252794 140128494741248 run_lib.py:165] step: 278400, eval_loss: 2.40442e+01
I0515 01:05:39.285127 140128494741248 run_lib.py:152] step: 278450, training_loss: 5.06988e+01
I0515 01:05:45.367916 140128494741248 run_lib.py:152] step: 278500, training_loss: 4.12021e+01
I0515 01:05:45.423038 140128494741248 run_lib.py:165] step: 278500, eval_loss: 2.77454e+01
I0515 01:05:51.955855 140128494741248 run_lib.py:152] step: 278550, training_loss: 3.39461e+01
I0515 01:05:58.254697 140128494741248 run_lib.py:152] step: 278600, training_loss: 2.96368e+01
I0515 01:05:58.309942 140128494741248 run_lib.py:165] step: 278600, eval_loss: 2.17135e+01
I0515 01:06:04.511371 140128494741248 run_lib.py:152] step: 278650, training_loss: 2.57098e+01
I0515 01:06:10.740379 140128494741248 run_lib.py:152] step: 278700, training_loss: 3.62327e+01
I0515 01:06:10.792297 140128494741248 run_lib.py:165] step: 278700, eval_loss: 3.12190e+01
I0515 01:06:17.319482 140128494741248 run_lib.py:152] step: 278750, training_loss: 3.03972e+01
I0515 01:06:23.560690 140128494741248 run_lib.py:152] step: 278800, training_loss: 4.55851e+01
I0515 01:06:23.610423 140128494741248 run_lib.py:165] step: 278800, eval_loss: 3.29804e+01
I0515 01:06:29.871997 140128494741248 run_lib.py:152] step: 278850, training_loss: 3.60985e+01
I0515 01:06:36.273508 140128494741248 run_lib.py:152] step: 278900, training_loss: 3.47986e+01
I0515 01:06:36.326236 140128494741248 run_lib.py:165] step: 278900, eval_loss: 3.67302e+01
I0515 01:06:42.516623 140128494741248 run_lib.py:152] step: 278950, training_loss: 2.97966e+01
I0515 01:06:48.630813 140128494741248 run_lib.py:152] step: 279000, training_loss: 2.67854e+01
I0515 01:06:48.683101 140128494741248 run_lib.py:165] step: 279000, eval_loss: 3.14554e+01
I0515 01:06:54.945714 140128494741248 run_lib.py:152] step: 279050, training_loss: 4.34582e+01
I0515 01:07:01.285242 140128494741248 run_lib.py:152] step: 279100, training_loss: 2.20712e+01
I0515 01:07:01.336150 140128494741248 run_lib.py:165] step: 279100, eval_loss: 2.12515e+01
I0515 01:07:07.565518 140128494741248 run_lib.py:152] step: 279150, training_loss: 1.82651e+01
I0515 01:07:13.793253 140128494741248 run_lib.py:152] step: 279200, training_loss: 4.37562e+01
I0515 01:07:13.850746 140128494741248 run_lib.py:165] step: 279200, eval_loss: 2.79644e+01
I0515 01:07:20.239049 140128494741248 run_lib.py:152] step: 279250, training_loss: 3.78487e+01
I0515 01:07:26.463113 140128494741248 run_lib.py:152] step: 279300, training_loss: 3.26144e+01
I0515 01:07:26.514284 140128494741248 run_lib.py:165] step: 279300, eval_loss: 3.93856e+01
I0515 01:07:32.652360 140128494741248 run_lib.py:152] step: 279350, training_loss: 2.49837e+01
I0515 01:07:38.859631 140128494741248 run_lib.py:152] step: 279400, training_loss: 2.03362e+01
I0515 01:07:38.912670 140128494741248 run_lib.py:165] step: 279400, eval_loss: 2.27893e+01
I0515 01:07:45.427620 140128494741248 run_lib.py:152] step: 279450, training_loss: 3.32010e+01
I0515 01:07:51.576030 140128494741248 run_lib.py:152] step: 279500, training_loss: 4.12909e+01
I0515 01:07:51.626559 140128494741248 run_lib.py:165] step: 279500, eval_loss: 2.37183e+01
I0515 01:07:57.826148 140128494741248 run_lib.py:152] step: 279550, training_loss: 1.00224e+01
I0515 01:08:04.124315 140128494741248 run_lib.py:152] step: 279600, training_loss: 3.32036e+01
I0515 01:08:04.175334 140128494741248 run_lib.py:165] step: 279600, eval_loss: 1.73596e+01
I0515 01:08:10.292121 140128494741248 run_lib.py:152] step: 279650, training_loss: 4.54148e+01
I0515 01:08:16.484784 140128494741248 run_lib.py:152] step: 279700, training_loss: 2.71627e+01
I0515 01:08:16.542874 140128494741248 run_lib.py:165] step: 279700, eval_loss: 2.63836e+01
I0515 01:08:22.762034 140128494741248 run_lib.py:152] step: 279750, training_loss: 3.02263e+01
I0515 01:08:29.150582 140128494741248 run_lib.py:152] step: 279800, training_loss: 2.43012e+01
I0515 01:08:29.207313 140128494741248 run_lib.py:165] step: 279800, eval_loss: 2.47389e+01
I0515 01:08:35.437954 140128494741248 run_lib.py:152] step: 279850, training_loss: 3.84129e+01
I0515 01:08:41.604041 140128494741248 run_lib.py:152] step: 279900, training_loss: 2.68644e+01
I0515 01:08:41.653992 140128494741248 run_lib.py:165] step: 279900, eval_loss: 2.94703e+01
I0515 01:08:48.114505 140128494741248 run_lib.py:152] step: 279950, training_loss: 3.32863e+01
I0515 01:08:54.318880 140128494741248 run_lib.py:152] step: 280000, training_loss: 3.06411e+01
I0515 01:08:54.526498 140128494741248 run_lib.py:165] step: 280000, eval_loss: 3.96850e+01
I0515 01:09:00.737735 140128494741248 run_lib.py:152] step: 280050, training_loss: 3.30868e+01
I0515 01:09:06.912627 140128494741248 run_lib.py:152] step: 280100, training_loss: 3.46918e+01
I0515 01:09:06.963956 140128494741248 run_lib.py:165] step: 280100, eval_loss: 2.13027e+01
I0515 01:09:13.449094 140128494741248 run_lib.py:152] step: 280150, training_loss: 4.88113e+01
I0515 01:09:19.600452 140128494741248 run_lib.py:152] step: 280200, training_loss: 4.23268e+01
I0515 01:09:19.649794 140128494741248 run_lib.py:165] step: 280200, eval_loss: 4.54341e+01
I0515 01:09:25.902873 140128494741248 run_lib.py:152] step: 280250, training_loss: 3.75673e+01
I0515 01:09:32.290675 140128494741248 run_lib.py:152] step: 280300, training_loss: 3.03277e+01
I0515 01:09:32.343132 140128494741248 run_lib.py:165] step: 280300, eval_loss: 2.63120e+01
I0515 01:09:38.532754 140128494741248 run_lib.py:152] step: 280350, training_loss: 2.24721e+01
I0515 01:09:44.614327 140128494741248 run_lib.py:152] step: 280400, training_loss: 4.02089e+01
I0515 01:09:44.664133 140128494741248 run_lib.py:165] step: 280400, eval_loss: 1.89136e+01
I0515 01:09:50.909302 140128494741248 run_lib.py:152] step: 280450, training_loss: 2.59455e+01
I0515 01:09:57.261286 140128494741248 run_lib.py:152] step: 280500, training_loss: 1.85341e+01
I0515 01:09:57.320277 140128494741248 run_lib.py:165] step: 280500, eval_loss: 3.56961e+01
I0515 01:10:03.553607 140128494741248 run_lib.py:152] step: 280550, training_loss: 3.18754e+01
I0515 01:10:09.822172 140128494741248 run_lib.py:152] step: 280600, training_loss: 2.00881e+01
I0515 01:10:09.876379 140128494741248 run_lib.py:165] step: 280600, eval_loss: 2.77238e+01
I0515 01:10:16.354262 140128494741248 run_lib.py:152] step: 280650, training_loss: 2.09077e+01
I0515 01:10:22.619102 140128494741248 run_lib.py:152] step: 280700, training_loss: 3.56790e+01
I0515 01:10:22.672485 140128494741248 run_lib.py:165] step: 280700, eval_loss: 3.05667e+01
I0515 01:10:28.825924 140128494741248 run_lib.py:152] step: 280750, training_loss: 2.18119e+01
I0515 01:10:35.047199 140128494741248 run_lib.py:152] step: 280800, training_loss: 3.27731e+01
I0515 01:10:35.102342 140128494741248 run_lib.py:165] step: 280800, eval_loss: 3.31050e+01
I0515 01:10:41.588250 140128494741248 run_lib.py:152] step: 280850, training_loss: 3.69521e+01
I0515 01:10:47.825697 140128494741248 run_lib.py:152] step: 280900, training_loss: 4.15821e+01
I0515 01:10:47.877367 140128494741248 run_lib.py:165] step: 280900, eval_loss: 3.49897e+01
I0515 01:10:54.062084 140128494741248 run_lib.py:152] step: 280950, training_loss: 3.55363e+01
I0515 01:11:00.470541 140128494741248 run_lib.py:152] step: 281000, training_loss: 3.69427e+01
I0515 01:11:00.523146 140128494741248 run_lib.py:165] step: 281000, eval_loss: 3.79869e+01
I0515 01:11:06.726424 140128494741248 run_lib.py:152] step: 281050, training_loss: 4.63881e+01
I0515 01:11:13.047742 140128494741248 run_lib.py:152] step: 281100, training_loss: 3.71883e+01
I0515 01:11:13.099231 140128494741248 run_lib.py:165] step: 281100, eval_loss: 2.68258e+01
I0515 01:11:19.493829 140128494741248 run_lib.py:152] step: 281150, training_loss: 2.71408e+01
I0515 01:11:25.674458 140128494741248 run_lib.py:152] step: 281200, training_loss: 5.45144e+01
I0515 01:11:25.723277 140128494741248 run_lib.py:165] step: 281200, eval_loss: 4.22271e+01
I0515 01:11:31.888946 140128494741248 run_lib.py:152] step: 281250, training_loss: 5.11924e+01
I0515 01:11:38.065519 140128494741248 run_lib.py:152] step: 281300, training_loss: 4.92713e+01
I0515 01:11:38.118850 140128494741248 run_lib.py:165] step: 281300, eval_loss: 2.28022e+01
I0515 01:11:44.490074 140128494741248 run_lib.py:152] step: 281350, training_loss: 2.47280e+01
I0515 01:11:50.766502 140128494741248 run_lib.py:152] step: 281400, training_loss: 2.46410e+01
I0515 01:11:50.818442 140128494741248 run_lib.py:165] step: 281400, eval_loss: 3.43190e+01
I0515 01:11:56.990462 140128494741248 run_lib.py:152] step: 281450, training_loss: 3.93992e+01
I0515 01:12:03.436402 140128494741248 run_lib.py:152] step: 281500, training_loss: 2.63410e+01
I0515 01:12:03.487719 140128494741248 run_lib.py:165] step: 281500, eval_loss: 2.98853e+01
I0515 01:12:09.659121 140128494741248 run_lib.py:152] step: 281550, training_loss: 2.10365e+01
I0515 01:12:15.857683 140128494741248 run_lib.py:152] step: 281600, training_loss: 3.00400e+01
I0515 01:12:15.908856 140128494741248 run_lib.py:165] step: 281600, eval_loss: 4.41292e+01
I0515 01:12:22.071027 140128494741248 run_lib.py:152] step: 281650, training_loss: 4.65535e+01
I0515 01:12:28.542960 140128494741248 run_lib.py:152] step: 281700, training_loss: 3.24624e+01
I0515 01:12:28.599908 140128494741248 run_lib.py:165] step: 281700, eval_loss: 2.26148e+01
I0515 01:12:34.733220 140128494741248 run_lib.py:152] step: 281750, training_loss: 2.22033e+01
I0515 01:12:40.968760 140128494741248 run_lib.py:152] step: 281800, training_loss: 3.02725e+01
I0515 01:12:41.022710 140128494741248 run_lib.py:165] step: 281800, eval_loss: 3.34124e+01
I0515 01:12:47.488761 140128494741248 run_lib.py:152] step: 281850, training_loss: 3.94027e+01
I0515 01:12:53.680123 140128494741248 run_lib.py:152] step: 281900, training_loss: 2.84101e+01
I0515 01:12:53.735549 140128494741248 run_lib.py:165] step: 281900, eval_loss: 4.23497e+01
I0515 01:12:59.966115 140128494741248 run_lib.py:152] step: 281950, training_loss: 3.42071e+01
I0515 01:13:06.112804 140128494741248 run_lib.py:152] step: 282000, training_loss: 2.38680e+01
I0515 01:13:06.163953 140128494741248 run_lib.py:165] step: 282000, eval_loss: 3.85444e+01
I0515 01:13:12.627478 140128494741248 run_lib.py:152] step: 282050, training_loss: 4.23962e+01
I0515 01:13:18.785060 140128494741248 run_lib.py:152] step: 282100, training_loss: 2.53773e+01
I0515 01:13:18.838349 140128494741248 run_lib.py:165] step: 282100, eval_loss: 2.15770e+01
I0515 01:13:25.069208 140128494741248 run_lib.py:152] step: 282150, training_loss: 4.92627e+01
I0515 01:13:31.429010 140128494741248 run_lib.py:152] step: 282200, training_loss: 2.24068e+01
I0515 01:13:31.479337 140128494741248 run_lib.py:165] step: 282200, eval_loss: 3.81418e+01
I0515 01:13:37.726875 140128494741248 run_lib.py:152] step: 282250, training_loss: 2.77383e+01
I0515 01:13:43.914649 140128494741248 run_lib.py:152] step: 282300, training_loss: 3.26563e+01
I0515 01:13:43.970015 140128494741248 run_lib.py:165] step: 282300, eval_loss: 4.22677e+01
I0515 01:13:50.169096 140128494741248 run_lib.py:152] step: 282350, training_loss: 2.81892e+01
I0515 01:13:56.572667 140128494741248 run_lib.py:152] step: 282400, training_loss: 3.46933e+01
I0515 01:13:56.623241 140128494741248 run_lib.py:165] step: 282400, eval_loss: 2.54653e+01
I0515 01:14:02.830830 140128494741248 run_lib.py:152] step: 282450, training_loss: 2.56129e+01
I0515 01:14:08.980632 140128494741248 run_lib.py:152] step: 282500, training_loss: 3.54382e+01
I0515 01:14:09.033326 140128494741248 run_lib.py:165] step: 282500, eval_loss: 3.21502e+01
I0515 01:14:15.481597 140128494741248 run_lib.py:152] step: 282550, training_loss: 3.40773e+01
I0515 01:14:21.619939 140128494741248 run_lib.py:152] step: 282600, training_loss: 2.32337e+01
I0515 01:14:21.667369 140128494741248 run_lib.py:165] step: 282600, eval_loss: 5.73216e+01
I0515 01:14:27.906586 140128494741248 run_lib.py:152] step: 282650, training_loss: 2.13587e+01
I0515 01:14:33.986895 140128494741248 run_lib.py:152] step: 282700, training_loss: 1.72067e+01
I0515 01:14:34.043635 140128494741248 run_lib.py:165] step: 282700, eval_loss: 4.25795e+01
I0515 01:14:40.474726 140128494741248 run_lib.py:152] step: 282750, training_loss: 4.26279e+01
I0515 01:14:46.757981 140128494741248 run_lib.py:152] step: 282800, training_loss: 2.52489e+01
I0515 01:14:46.809648 140128494741248 run_lib.py:165] step: 282800, eval_loss: 3.67439e+01
I0515 01:14:52.938647 140128494741248 run_lib.py:152] step: 282850, training_loss: 4.37594e+01
I0515 01:14:59.381085 140128494741248 run_lib.py:152] step: 282900, training_loss: 4.93347e+01
I0515 01:14:59.435238 140128494741248 run_lib.py:165] step: 282900, eval_loss: 3.53639e+01
I0515 01:15:05.626184 140128494741248 run_lib.py:152] step: 282950, training_loss: 2.77643e+01
I0515 01:15:11.906951 140128494741248 run_lib.py:152] step: 283000, training_loss: 2.26956e+01
I0515 01:15:11.961424 140128494741248 run_lib.py:165] step: 283000, eval_loss: 2.26789e+01
I0515 01:15:18.234462 140128494741248 run_lib.py:152] step: 283050, training_loss: 4.31315e+01
I0515 01:15:24.613589 140128494741248 run_lib.py:152] step: 283100, training_loss: 3.05085e+01
I0515 01:15:24.661611 140128494741248 run_lib.py:165] step: 283100, eval_loss: 2.77507e+01
I0515 01:15:30.922863 140128494741248 run_lib.py:152] step: 283150, training_loss: 3.71558e+01
I0515 01:15:37.106347 140128494741248 run_lib.py:152] step: 283200, training_loss: 4.17312e+01
I0515 01:15:37.155692 140128494741248 run_lib.py:165] step: 283200, eval_loss: 3.28906e+01
I0515 01:15:43.639993 140128494741248 run_lib.py:152] step: 283250, training_loss: 3.35226e+01
I0515 01:15:49.846129 140128494741248 run_lib.py:152] step: 283300, training_loss: 2.79939e+01
I0515 01:15:49.903423 140128494741248 run_lib.py:165] step: 283300, eval_loss: 3.91134e+01
I0515 01:15:56.128568 140128494741248 run_lib.py:152] step: 283350, training_loss: 3.85107e+01
I0515 01:16:02.291291 140128494741248 run_lib.py:152] step: 283400, training_loss: 3.81785e+01
I0515 01:16:02.350996 140128494741248 run_lib.py:165] step: 283400, eval_loss: 2.32748e+01
I0515 01:16:08.788722 140128494741248 run_lib.py:152] step: 283450, training_loss: 2.94507e+01
I0515 01:16:14.901900 140128494741248 run_lib.py:152] step: 283500, training_loss: 2.72159e+01
I0515 01:16:14.954751 140128494741248 run_lib.py:165] step: 283500, eval_loss: 2.14177e+01
I0515 01:16:21.101397 140128494741248 run_lib.py:152] step: 283550, training_loss: 3.43865e+01
I0515 01:16:27.263379 140128494741248 run_lib.py:152] step: 283600, training_loss: 5.23195e+01
I0515 01:16:27.546503 140128494741248 run_lib.py:165] step: 283600, eval_loss: 3.61238e+01
I0515 01:16:33.750484 140128494741248 run_lib.py:152] step: 283650, training_loss: 2.70919e+01
I0515 01:16:39.938218 140128494741248 run_lib.py:152] step: 283700, training_loss: 2.28491e+01
I0515 01:16:39.993260 140128494741248 run_lib.py:165] step: 283700, eval_loss: 3.08730e+01
I0515 01:16:46.163865 140128494741248 run_lib.py:152] step: 283750, training_loss: 4.60883e+01
I0515 01:16:52.577215 140128494741248 run_lib.py:152] step: 283800, training_loss: 3.45117e+01
I0515 01:16:52.635791 140128494741248 run_lib.py:165] step: 283800, eval_loss: 3.82827e+01
I0515 01:16:58.797002 140128494741248 run_lib.py:152] step: 283850, training_loss: 2.66119e+01
I0515 01:17:05.020874 140128494741248 run_lib.py:152] step: 283900, training_loss: 2.47895e+01
I0515 01:17:05.072125 140128494741248 run_lib.py:165] step: 283900, eval_loss: 1.79403e+01
I0515 01:17:11.594808 140128494741248 run_lib.py:152] step: 283950, training_loss: 3.80062e+01
I0515 01:17:17.750203 140128494741248 run_lib.py:152] step: 284000, training_loss: 3.29360e+01
I0515 01:17:17.801773 140128494741248 run_lib.py:165] step: 284000, eval_loss: 3.33592e+01
I0515 01:17:23.966162 140128494741248 run_lib.py:152] step: 284050, training_loss: 1.88853e+01
I0515 01:17:30.077523 140128494741248 run_lib.py:152] step: 284100, training_loss: 3.42264e+01
I0515 01:17:30.128690 140128494741248 run_lib.py:165] step: 284100, eval_loss: 3.52750e+01
I0515 01:17:36.509869 140128494741248 run_lib.py:152] step: 284150, training_loss: 3.01830e+01
I0515 01:17:42.691262 140128494741248 run_lib.py:152] step: 284200, training_loss: 3.80152e+01
I0515 01:17:42.741756 140128494741248 run_lib.py:165] step: 284200, eval_loss: 3.34077e+01
I0515 01:17:48.835501 140128494741248 run_lib.py:152] step: 284250, training_loss: 2.36676e+01
I0515 01:17:55.247802 140128494741248 run_lib.py:152] step: 284300, training_loss: 4.66694e+01
I0515 01:17:55.302015 140128494741248 run_lib.py:165] step: 284300, eval_loss: 2.18210e+01
I0515 01:18:01.456185 140128494741248 run_lib.py:152] step: 284350, training_loss: 3.14118e+01
I0515 01:18:07.847519 140128494741248 run_lib.py:152] step: 284400, training_loss: 1.93487e+01
I0515 01:18:07.903522 140128494741248 run_lib.py:165] step: 284400, eval_loss: 1.88018e+01
I0515 01:18:14.052214 140128494741248 run_lib.py:152] step: 284450, training_loss: 3.67102e+01
I0515 01:18:20.513759 140128494741248 run_lib.py:152] step: 284500, training_loss: 4.38160e+01
I0515 01:18:20.566015 140128494741248 run_lib.py:165] step: 284500, eval_loss: 2.49935e+01
I0515 01:18:26.793525 140128494741248 run_lib.py:152] step: 284550, training_loss: 2.73855e+01
I0515 01:18:32.975270 140128494741248 run_lib.py:152] step: 284600, training_loss: 2.26282e+01
I0515 01:18:33.026833 140128494741248 run_lib.py:165] step: 284600, eval_loss: 2.64403e+01
I0515 01:18:39.448903 140128494741248 run_lib.py:152] step: 284650, training_loss: 2.37671e+01
I0515 01:18:45.715347 140128494741248 run_lib.py:152] step: 284700, training_loss: 4.11722e+01
I0515 01:18:45.766100 140128494741248 run_lib.py:165] step: 284700, eval_loss: 2.46651e+01
I0515 01:18:51.970240 140128494741248 run_lib.py:152] step: 284750, training_loss: 3.17093e+01
I0515 01:18:58.099008 140128494741248 run_lib.py:152] step: 284800, training_loss: 3.78357e+01
I0515 01:18:58.154011 140128494741248 run_lib.py:165] step: 284800, eval_loss: 5.49762e+01
I0515 01:19:04.578722 140128494741248 run_lib.py:152] step: 284850, training_loss: 4.00098e+01
I0515 01:19:10.727559 140128494741248 run_lib.py:152] step: 284900, training_loss: 1.91746e+01
I0515 01:19:10.785479 140128494741248 run_lib.py:165] step: 284900, eval_loss: 4.73188e+01
I0515 01:19:17.018079 140128494741248 run_lib.py:152] step: 284950, training_loss: 3.36667e+01
I0515 01:19:23.460943 140128494741248 run_lib.py:152] step: 285000, training_loss: 3.03794e+01
I0515 01:19:23.514899 140128494741248 run_lib.py:165] step: 285000, eval_loss: 2.92032e+01
I0515 01:19:29.733918 140128494741248 run_lib.py:152] step: 285050, training_loss: 3.09659e+01
I0515 01:19:35.992419 140128494741248 run_lib.py:152] step: 285100, training_loss: 3.03939e+01
I0515 01:19:36.047096 140128494741248 run_lib.py:165] step: 285100, eval_loss: 4.00776e+01
I0515 01:19:42.265825 140128494741248 run_lib.py:152] step: 285150, training_loss: 2.03003e+01
I0515 01:19:48.643770 140128494741248 run_lib.py:152] step: 285200, training_loss: 3.96655e+01
I0515 01:19:48.694367 140128494741248 run_lib.py:165] step: 285200, eval_loss: 4.46133e+01
I0515 01:19:54.919939 140128494741248 run_lib.py:152] step: 285250, training_loss: 3.85028e+01
I0515 01:20:01.034286 140128494741248 run_lib.py:152] step: 285300, training_loss: 4.26054e+01
I0515 01:20:01.082818 140128494741248 run_lib.py:165] step: 285300, eval_loss: 2.62748e+01
I0515 01:20:07.502151 140128494741248 run_lib.py:152] step: 285350, training_loss: 2.60015e+01
I0515 01:20:13.637171 140128494741248 run_lib.py:152] step: 285400, training_loss: 2.43382e+01
I0515 01:20:13.691749 140128494741248 run_lib.py:165] step: 285400, eval_loss: 3.62142e+01
I0515 01:20:19.967729 140128494741248 run_lib.py:152] step: 285450, training_loss: 2.90056e+01
I0515 01:20:26.085925 140128494741248 run_lib.py:152] step: 285500, training_loss: 3.67904e+01
I0515 01:20:26.135817 140128494741248 run_lib.py:165] step: 285500, eval_loss: 3.63159e+01
I0515 01:20:32.629361 140128494741248 run_lib.py:152] step: 285550, training_loss: 5.28383e+01
I0515 01:20:38.813461 140128494741248 run_lib.py:152] step: 285600, training_loss: 3.39473e+01
I0515 01:20:38.865456 140128494741248 run_lib.py:165] step: 285600, eval_loss: 3.98077e+01
I0515 01:20:45.099873 140128494741248 run_lib.py:152] step: 285650, training_loss: 2.31778e+01
I0515 01:20:51.609086 140128494741248 run_lib.py:152] step: 285700, training_loss: 4.16351e+01
I0515 01:20:51.661366 140128494741248 run_lib.py:165] step: 285700, eval_loss: 1.86164e+01
I0515 01:20:57.842087 140128494741248 run_lib.py:152] step: 285750, training_loss: 3.63827e+01
I0515 01:21:03.994359 140128494741248 run_lib.py:152] step: 285800, training_loss: 2.67701e+01
I0515 01:21:04.046916 140128494741248 run_lib.py:165] step: 285800, eval_loss: 2.80051e+01
I0515 01:21:10.337440 140128494741248 run_lib.py:152] step: 285850, training_loss: 3.91163e+01
I0515 01:21:16.798157 140128494741248 run_lib.py:152] step: 285900, training_loss: 2.63337e+01
I0515 01:21:16.848819 140128494741248 run_lib.py:165] step: 285900, eval_loss: 2.66338e+01
I0515 01:21:22.966505 140128494741248 run_lib.py:152] step: 285950, training_loss: 4.10569e+01
I0515 01:21:29.204625 140128494741248 run_lib.py:152] step: 286000, training_loss: 2.88421e+01
I0515 01:21:29.256899 140128494741248 run_lib.py:165] step: 286000, eval_loss: 3.85006e+01
I0515 01:21:35.686950 140128494741248 run_lib.py:152] step: 286050, training_loss: 3.26838e+01
I0515 01:21:41.898594 140128494741248 run_lib.py:152] step: 286100, training_loss: 3.35378e+01
I0515 01:21:41.949685 140128494741248 run_lib.py:165] step: 286100, eval_loss: 5.55824e+01
I0515 01:21:48.131600 140128494741248 run_lib.py:152] step: 286150, training_loss: 2.86716e+01
I0515 01:21:54.244600 140128494741248 run_lib.py:152] step: 286200, training_loss: 4.89077e+01
I0515 01:21:54.294843 140128494741248 run_lib.py:165] step: 286200, eval_loss: 2.50663e+01
I0515 01:22:00.698632 140128494741248 run_lib.py:152] step: 286250, training_loss: 2.72114e+01
I0515 01:22:06.873809 140128494741248 run_lib.py:152] step: 286300, training_loss: 2.64591e+01
I0515 01:22:06.922405 140128494741248 run_lib.py:165] step: 286300, eval_loss: 2.53134e+01
I0515 01:22:13.125553 140128494741248 run_lib.py:152] step: 286350, training_loss: 3.60170e+01
I0515 01:22:19.435233 140128494741248 run_lib.py:152] step: 286400, training_loss: 3.01295e+01
I0515 01:22:19.488758 140128494741248 run_lib.py:165] step: 286400, eval_loss: 2.69077e+01
I0515 01:22:25.762790 140128494741248 run_lib.py:152] step: 286450, training_loss: 3.09754e+01
I0515 01:22:31.923225 140128494741248 run_lib.py:152] step: 286500, training_loss: 2.97623e+01
I0515 01:22:31.976198 140128494741248 run_lib.py:165] step: 286500, eval_loss: 3.05806e+01
I0515 01:22:38.213574 140128494741248 run_lib.py:152] step: 286550, training_loss: 1.69523e+01
I0515 01:22:44.709565 140128494741248 run_lib.py:152] step: 286600, training_loss: 3.59789e+01
I0515 01:22:44.756810 140128494741248 run_lib.py:165] step: 286600, eval_loss: 2.40210e+01
I0515 01:22:50.944029 140128494741248 run_lib.py:152] step: 286650, training_loss: 3.37504e+01
I0515 01:22:57.161699 140128494741248 run_lib.py:152] step: 286700, training_loss: 3.40741e+01
I0515 01:22:57.217846 140128494741248 run_lib.py:165] step: 286700, eval_loss: 5.14118e+01
I0515 01:23:03.736202 140128494741248 run_lib.py:152] step: 286750, training_loss: 2.55157e+01
I0515 01:23:09.867007 140128494741248 run_lib.py:152] step: 286800, training_loss: 3.87413e+01
I0515 01:23:09.919859 140128494741248 run_lib.py:165] step: 286800, eval_loss: 2.97194e+01
I0515 01:23:16.192397 140128494741248 run_lib.py:152] step: 286850, training_loss: 4.41923e+01
I0515 01:23:22.362442 140128494741248 run_lib.py:152] step: 286900, training_loss: 2.15929e+01
I0515 01:23:22.410160 140128494741248 run_lib.py:165] step: 286900, eval_loss: 2.72297e+01
I0515 01:23:28.881915 140128494741248 run_lib.py:152] step: 286950, training_loss: 2.67635e+01
I0515 01:23:35.017166 140128494741248 run_lib.py:152] step: 287000, training_loss: 2.72852e+01
I0515 01:23:35.068311 140128494741248 run_lib.py:165] step: 287000, eval_loss: 2.59927e+01
I0515 01:23:41.297503 140128494741248 run_lib.py:152] step: 287050, training_loss: 3.07937e+01
I0515 01:23:47.569940 140128494741248 run_lib.py:152] step: 287100, training_loss: 3.14178e+01
I0515 01:23:47.848343 140128494741248 run_lib.py:165] step: 287100, eval_loss: 3.07935e+01
I0515 01:23:53.953008 140128494741248 run_lib.py:152] step: 287150, training_loss: 3.46360e+01
I0515 01:24:00.072284 140128494741248 run_lib.py:152] step: 287200, training_loss: 4.27261e+01
I0515 01:24:00.123144 140128494741248 run_lib.py:165] step: 287200, eval_loss: 3.11088e+01
I0515 01:24:06.331334 140128494741248 run_lib.py:152] step: 287250, training_loss: 3.75874e+01
I0515 01:24:12.829102 140128494741248 run_lib.py:152] step: 287300, training_loss: 3.03477e+01
I0515 01:24:12.891327 140128494741248 run_lib.py:165] step: 287300, eval_loss: 4.86238e+01
I0515 01:24:19.146513 140128494741248 run_lib.py:152] step: 287350, training_loss: 4.18753e+01
I0515 01:24:25.410953 140128494741248 run_lib.py:152] step: 287400, training_loss: 2.06624e+01
I0515 01:24:25.465610 140128494741248 run_lib.py:165] step: 287400, eval_loss: 3.60391e+01
I0515 01:24:31.882286 140128494741248 run_lib.py:152] step: 287450, training_loss: 3.54763e+01
I0515 01:24:38.003751 140128494741248 run_lib.py:152] step: 287500, training_loss: 4.54648e+01
I0515 01:24:38.057213 140128494741248 run_lib.py:165] step: 287500, eval_loss: 3.13210e+01
I0515 01:24:44.265760 140128494741248 run_lib.py:152] step: 287550, training_loss: 2.82801e+01
I0515 01:24:50.401801 140128494741248 run_lib.py:152] step: 287600, training_loss: 1.61177e+01
I0515 01:24:50.451132 140128494741248 run_lib.py:165] step: 287600, eval_loss: 3.11232e+01
I0515 01:24:56.920181 140128494741248 run_lib.py:152] step: 287650, training_loss: 2.89541e+01
I0515 01:25:03.108781 140128494741248 run_lib.py:152] step: 287700, training_loss: 3.35848e+01
I0515 01:25:03.159420 140128494741248 run_lib.py:165] step: 287700, eval_loss: 1.35017e+01
I0515 01:25:09.422919 140128494741248 run_lib.py:152] step: 287750, training_loss: 3.30834e+01
I0515 01:25:15.953567 140128494741248 run_lib.py:152] step: 287800, training_loss: 3.54624e+01
I0515 01:25:16.003336 140128494741248 run_lib.py:165] step: 287800, eval_loss: 4.39025e+01
I0515 01:25:22.333110 140128494741248 run_lib.py:152] step: 287850, training_loss: 2.61998e+01
I0515 01:25:28.504388 140128494741248 run_lib.py:152] step: 287900, training_loss: 3.72260e+01
I0515 01:25:28.563206 140128494741248 run_lib.py:165] step: 287900, eval_loss: 3.83200e+01
I0515 01:25:34.747004 140128494741248 run_lib.py:152] step: 287950, training_loss: 3.69612e+01
I0515 01:25:41.243993 140128494741248 run_lib.py:152] step: 288000, training_loss: 3.86395e+01
I0515 01:25:41.296511 140128494741248 run_lib.py:165] step: 288000, eval_loss: 9.34089e+00
I0515 01:25:47.567175 140128494741248 run_lib.py:152] step: 288050, training_loss: 4.64899e+01
I0515 01:25:53.653353 140128494741248 run_lib.py:152] step: 288100, training_loss: 3.32634e+01
I0515 01:25:53.703887 140128494741248 run_lib.py:165] step: 288100, eval_loss: 2.59132e+01
I0515 01:26:00.166536 140128494741248 run_lib.py:152] step: 288150, training_loss: 1.80433e+01
I0515 01:26:06.378204 140128494741248 run_lib.py:152] step: 288200, training_loss: 4.03956e+01
I0515 01:26:06.428322 140128494741248 run_lib.py:165] step: 288200, eval_loss: 1.47688e+01
I0515 01:26:12.626561 140128494741248 run_lib.py:152] step: 288250, training_loss: 2.30982e+01
I0515 01:26:18.724659 140128494741248 run_lib.py:152] step: 288300, training_loss: 3.56737e+01
I0515 01:26:18.779482 140128494741248 run_lib.py:165] step: 288300, eval_loss: 2.96424e+01
I0515 01:26:25.252856 140128494741248 run_lib.py:152] step: 288350, training_loss: 2.82699e+01
I0515 01:26:31.531411 140128494741248 run_lib.py:152] step: 288400, training_loss: 3.44099e+01
I0515 01:26:31.584029 140128494741248 run_lib.py:165] step: 288400, eval_loss: 3.92262e+01
I0515 01:26:37.705077 140128494741248 run_lib.py:152] step: 288450, training_loss: 4.74438e+01
I0515 01:26:44.197942 140128494741248 run_lib.py:152] step: 288500, training_loss: 3.03267e+01
I0515 01:26:44.253868 140128494741248 run_lib.py:165] step: 288500, eval_loss: 2.40209e+01
I0515 01:26:50.505057 140128494741248 run_lib.py:152] step: 288550, training_loss: 4.02273e+01
I0515 01:26:56.709036 140128494741248 run_lib.py:152] step: 288600, training_loss: 2.44589e+01
I0515 01:26:56.762969 140128494741248 run_lib.py:165] step: 288600, eval_loss: 3.95183e+01
I0515 01:27:02.932555 140128494741248 run_lib.py:152] step: 288650, training_loss: 2.94146e+01
I0515 01:27:09.414385 140128494741248 run_lib.py:152] step: 288700, training_loss: 3.23033e+01
I0515 01:27:09.470640 140128494741248 run_lib.py:165] step: 288700, eval_loss: 2.71423e+01
I0515 01:27:15.679955 140128494741248 run_lib.py:152] step: 288750, training_loss: 2.87936e+01
I0515 01:27:21.933932 140128494741248 run_lib.py:152] step: 288800, training_loss: 2.91555e+01
I0515 01:27:21.982769 140128494741248 run_lib.py:165] step: 288800, eval_loss: 3.26482e+01
I0515 01:27:28.455311 140128494741248 run_lib.py:152] step: 288850, training_loss: 4.50805e+01
I0515 01:27:34.610654 140128494741248 run_lib.py:152] step: 288900, training_loss: 2.98344e+01
I0515 01:27:34.665716 140128494741248 run_lib.py:165] step: 288900, eval_loss: 4.69443e+01
I0515 01:27:40.876221 140128494741248 run_lib.py:152] step: 288950, training_loss: 4.50803e+01
I0515 01:27:47.054308 140128494741248 run_lib.py:152] step: 289000, training_loss: 2.51575e+01
I0515 01:27:47.110375 140128494741248 run_lib.py:165] step: 289000, eval_loss: 3.91812e+01
I0515 01:27:53.467156 140128494741248 run_lib.py:152] step: 289050, training_loss: 3.01655e+01
I0515 01:27:59.753912 140128494741248 run_lib.py:152] step: 289100, training_loss: 3.14927e+01
I0515 01:27:59.805956 140128494741248 run_lib.py:165] step: 289100, eval_loss: 3.08605e+01
I0515 01:28:06.051178 140128494741248 run_lib.py:152] step: 289150, training_loss: 3.41763e+01
I0515 01:28:12.551210 140128494741248 run_lib.py:152] step: 289200, training_loss: 1.92171e+01
I0515 01:28:12.601894 140128494741248 run_lib.py:165] step: 289200, eval_loss: 1.87523e+01
I0515 01:28:18.714622 140128494741248 run_lib.py:152] step: 289250, training_loss: 4.19421e+01
I0515 01:28:24.925551 140128494741248 run_lib.py:152] step: 289300, training_loss: 3.45235e+01
I0515 01:28:24.973928 140128494741248 run_lib.py:165] step: 289300, eval_loss: 2.86963e+01
I0515 01:28:31.142099 140128494741248 run_lib.py:152] step: 289350, training_loss: 1.97116e+01
I0515 01:28:37.566452 140128494741248 run_lib.py:152] step: 289400, training_loss: 2.11032e+01
I0515 01:28:37.620720 140128494741248 run_lib.py:165] step: 289400, eval_loss: 3.08061e+01
I0515 01:28:43.762326 140128494741248 run_lib.py:152] step: 289450, training_loss: 3.42033e+01
I0515 01:28:49.946507 140128494741248 run_lib.py:152] step: 289500, training_loss: 2.84798e+01
I0515 01:28:50.005706 140128494741248 run_lib.py:165] step: 289500, eval_loss: 2.70543e+01
I0515 01:28:56.328145 140128494741248 run_lib.py:152] step: 289550, training_loss: 2.89594e+01
I0515 01:29:02.507851 140128494741248 run_lib.py:152] step: 289600, training_loss: 3.17609e+01
I0515 01:29:02.556020 140128494741248 run_lib.py:165] step: 289600, eval_loss: 3.34415e+01
I0515 01:29:08.744621 140128494741248 run_lib.py:152] step: 289650, training_loss: 3.45931e+01
I0515 01:29:14.915935 140128494741248 run_lib.py:152] step: 289700, training_loss: 2.98329e+01
I0515 01:29:14.966983 140128494741248 run_lib.py:165] step: 289700, eval_loss: 2.49525e+01
I0515 01:29:21.471782 140128494741248 run_lib.py:152] step: 289750, training_loss: 3.60303e+01
I0515 01:29:27.653079 140128494741248 run_lib.py:152] step: 289800, training_loss: 4.31301e+01
I0515 01:29:27.705368 140128494741248 run_lib.py:165] step: 289800, eval_loss: 2.94200e+01
I0515 01:29:33.880651 140128494741248 run_lib.py:152] step: 289850, training_loss: 2.66800e+01
I0515 01:29:40.422806 140128494741248 run_lib.py:152] step: 289900, training_loss: 2.53604e+01
I0515 01:29:40.474661 140128494741248 run_lib.py:165] step: 289900, eval_loss: 2.60982e+01
I0515 01:29:46.752783 140128494741248 run_lib.py:152] step: 289950, training_loss: 2.69192e+01
I0515 01:29:52.912405 140128494741248 run_lib.py:152] step: 290000, training_loss: 3.42913e+01
I0515 01:29:53.130730 140128494741248 run_lib.py:165] step: 290000, eval_loss: 2.50938e+01
I0515 01:29:59.255937 140128494741248 run_lib.py:152] step: 290050, training_loss: 2.31757e+01
I0515 01:30:05.766231 140128494741248 run_lib.py:152] step: 290100, training_loss: 3.78174e+01
I0515 01:30:05.822240 140128494741248 run_lib.py:165] step: 290100, eval_loss: 2.85221e+01
I0515 01:30:11.980265 140128494741248 run_lib.py:152] step: 290150, training_loss: 4.75500e+01
I0515 01:30:18.179894 140128494741248 run_lib.py:152] step: 290200, training_loss: 2.02260e+01
I0515 01:30:18.230638 140128494741248 run_lib.py:165] step: 290200, eval_loss: 2.98436e+01
I0515 01:30:24.621146 140128494741248 run_lib.py:152] step: 290250, training_loss: 3.82417e+01
I0515 01:30:30.890901 140128494741248 run_lib.py:152] step: 290300, training_loss: 3.95074e+01
I0515 01:30:30.945739 140128494741248 run_lib.py:165] step: 290300, eval_loss: 3.10247e+01
I0515 01:30:37.096896 140128494741248 run_lib.py:152] step: 290350, training_loss: 4.97163e+01
I0515 01:30:43.271945 140128494741248 run_lib.py:152] step: 290400, training_loss: 4.17877e+01
I0515 01:30:43.323072 140128494741248 run_lib.py:165] step: 290400, eval_loss: 2.68595e+01
I0515 01:30:49.773707 140128494741248 run_lib.py:152] step: 290450, training_loss: 3.68093e+01
I0515 01:30:56.028393 140128494741248 run_lib.py:152] step: 290500, training_loss: 3.44295e+01
I0515 01:30:56.080291 140128494741248 run_lib.py:165] step: 290500, eval_loss: 2.79949e+01
I0515 01:31:02.155891 140128494741248 run_lib.py:152] step: 290550, training_loss: 5.25811e+01
I0515 01:31:08.404402 140128494741248 run_lib.py:152] step: 290600, training_loss: 3.06586e+01
I0515 01:31:08.690016 140128494741248 run_lib.py:165] step: 290600, eval_loss: 2.79101e+01
I0515 01:31:14.876479 140128494741248 run_lib.py:152] step: 290650, training_loss: 1.61622e+01
I0515 01:31:20.937624 140128494741248 run_lib.py:152] step: 290700, training_loss: 3.39929e+01
I0515 01:31:20.986842 140128494741248 run_lib.py:165] step: 290700, eval_loss: 2.03629e+01
I0515 01:31:27.205526 140128494741248 run_lib.py:152] step: 290750, training_loss: 3.50747e+01
I0515 01:31:33.521229 140128494741248 run_lib.py:152] step: 290800, training_loss: 3.69606e+01
I0515 01:31:33.572386 140128494741248 run_lib.py:165] step: 290800, eval_loss: 3.10476e+01
I0515 01:31:39.781708 140128494741248 run_lib.py:152] step: 290850, training_loss: 3.95899e+01
I0515 01:31:45.907131 140128494741248 run_lib.py:152] step: 290900, training_loss: 3.31927e+01
I0515 01:31:45.964138 140128494741248 run_lib.py:165] step: 290900, eval_loss: 4.33531e+01
I0515 01:31:52.404222 140128494741248 run_lib.py:152] step: 290950, training_loss: 3.83275e+01
I0515 01:31:58.597915 140128494741248 run_lib.py:152] step: 291000, training_loss: 2.62031e+01
I0515 01:31:58.650593 140128494741248 run_lib.py:165] step: 291000, eval_loss: 3.99117e+01
I0515 01:32:04.898576 140128494741248 run_lib.py:152] step: 291050, training_loss: 3.74513e+01
I0515 01:32:11.079254 140128494741248 run_lib.py:152] step: 291100, training_loss: 2.94666e+01
I0515 01:32:11.127837 140128494741248 run_lib.py:165] step: 291100, eval_loss: 3.15264e+01
I0515 01:32:17.521268 140128494741248 run_lib.py:152] step: 291150, training_loss: 2.45346e+01
I0515 01:32:23.756732 140128494741248 run_lib.py:152] step: 291200, training_loss: 3.40164e+01
I0515 01:32:23.806052 140128494741248 run_lib.py:165] step: 291200, eval_loss: 3.03970e+01
I0515 01:32:29.965386 140128494741248 run_lib.py:152] step: 291250, training_loss: 3.56412e+01
I0515 01:32:36.378770 140128494741248 run_lib.py:152] step: 291300, training_loss: 2.13174e+01
I0515 01:32:36.432385 140128494741248 run_lib.py:165] step: 291300, eval_loss: 3.17184e+01
I0515 01:32:42.532691 140128494741248 run_lib.py:152] step: 291350, training_loss: 3.02472e+01
I0515 01:32:48.808508 140128494741248 run_lib.py:152] step: 291400, training_loss: 2.22218e+01
I0515 01:32:48.861901 140128494741248 run_lib.py:165] step: 291400, eval_loss: 3.37209e+01
I0515 01:32:55.018774 140128494741248 run_lib.py:152] step: 291450, training_loss: 3.31416e+01
I0515 01:33:01.401742 140128494741248 run_lib.py:152] step: 291500, training_loss: 2.25023e+01
I0515 01:33:01.462265 140128494741248 run_lib.py:165] step: 291500, eval_loss: 3.12917e+01
I0515 01:33:07.688899 140128494741248 run_lib.py:152] step: 291550, training_loss: 4.48726e+01
I0515 01:33:13.988451 140128494741248 run_lib.py:152] step: 291600, training_loss: 2.61394e+01
I0515 01:33:14.045140 140128494741248 run_lib.py:165] step: 291600, eval_loss: 3.10386e+01
I0515 01:33:20.402285 140128494741248 run_lib.py:152] step: 291650, training_loss: 3.97885e+01
I0515 01:33:26.552552 140128494741248 run_lib.py:152] step: 291700, training_loss: 3.67448e+01
I0515 01:33:26.605340 140128494741248 run_lib.py:165] step: 291700, eval_loss: 2.70675e+01
I0515 01:33:32.812347 140128494741248 run_lib.py:152] step: 291750, training_loss: 3.61841e+01
I0515 01:33:39.134201 140128494741248 run_lib.py:152] step: 291800, training_loss: 3.32969e+01
I0515 01:33:39.187123 140128494741248 run_lib.py:165] step: 291800, eval_loss: 2.97049e+01
I0515 01:33:45.662195 140128494741248 run_lib.py:152] step: 291850, training_loss: 3.58892e+01
I0515 01:33:51.914437 140128494741248 run_lib.py:152] step: 291900, training_loss: 3.35093e+01
I0515 01:33:51.967674 140128494741248 run_lib.py:165] step: 291900, eval_loss: 3.54259e+01
I0515 01:33:58.186513 140128494741248 run_lib.py:152] step: 291950, training_loss: 3.91701e+01
I0515 01:34:04.550415 140128494741248 run_lib.py:152] step: 292000, training_loss: 2.99489e+01
I0515 01:34:04.597742 140128494741248 run_lib.py:165] step: 292000, eval_loss: 2.82947e+01
I0515 01:34:10.728860 140128494741248 run_lib.py:152] step: 292050, training_loss: 2.92679e+01
I0515 01:34:16.918237 140128494741248 run_lib.py:152] step: 292100, training_loss: 3.70569e+01
I0515 01:34:16.971601 140128494741248 run_lib.py:165] step: 292100, eval_loss: 4.62538e+01
I0515 01:34:23.132005 140128494741248 run_lib.py:152] step: 292150, training_loss: 2.04169e+01
I0515 01:34:29.588804 140128494741248 run_lib.py:152] step: 292200, training_loss: 2.10881e+01
I0515 01:34:29.642487 140128494741248 run_lib.py:165] step: 292200, eval_loss: 2.26087e+01
I0515 01:34:35.744277 140128494741248 run_lib.py:152] step: 292250, training_loss: 3.47728e+01
I0515 01:34:41.936680 140128494741248 run_lib.py:152] step: 292300, training_loss: 4.15183e+01
I0515 01:34:41.986221 140128494741248 run_lib.py:165] step: 292300, eval_loss: 2.01244e+01
I0515 01:34:48.423445 140128494741248 run_lib.py:152] step: 292350, training_loss: 3.40907e+01
I0515 01:34:54.511130 140128494741248 run_lib.py:152] step: 292400, training_loss: 3.70006e+01
I0515 01:34:54.565522 140128494741248 run_lib.py:165] step: 292400, eval_loss: 3.87715e+01
I0515 01:35:00.834031 140128494741248 run_lib.py:152] step: 292450, training_loss: 4.00356e+01
I0515 01:35:07.042011 140128494741248 run_lib.py:152] step: 292500, training_loss: 3.10428e+01
I0515 01:35:07.089855 140128494741248 run_lib.py:165] step: 292500, eval_loss: 2.43500e+01
I0515 01:35:13.486217 140128494741248 run_lib.py:152] step: 292550, training_loss: 2.07005e+01
I0515 01:35:19.718675 140128494741248 run_lib.py:152] step: 292600, training_loss: 3.67726e+01
I0515 01:35:19.768406 140128494741248 run_lib.py:165] step: 292600, eval_loss: 3.60535e+01
I0515 01:35:26.091959 140128494741248 run_lib.py:152] step: 292650, training_loss: 3.46942e+01
I0515 01:35:32.616575 140128494741248 run_lib.py:152] step: 292700, training_loss: 3.59949e+01
I0515 01:35:32.672571 140128494741248 run_lib.py:165] step: 292700, eval_loss: 2.44277e+01
I0515 01:35:38.897780 140128494741248 run_lib.py:152] step: 292750, training_loss: 2.92471e+01
I0515 01:35:45.186522 140128494741248 run_lib.py:152] step: 292800, training_loss: 4.41822e+01
I0515 01:35:45.237725 140128494741248 run_lib.py:165] step: 292800, eval_loss: 1.82899e+01
I0515 01:35:51.404040 140128494741248 run_lib.py:152] step: 292850, training_loss: 2.39444e+01
I0515 01:35:57.863013 140128494741248 run_lib.py:152] step: 292900, training_loss: 2.97928e+01
I0515 01:35:57.916632 140128494741248 run_lib.py:165] step: 292900, eval_loss: 2.54666e+01
I0515 01:36:04.168010 140128494741248 run_lib.py:152] step: 292950, training_loss: 3.86895e+01
I0515 01:36:10.422107 140128494741248 run_lib.py:152] step: 293000, training_loss: 2.94700e+01
I0515 01:36:10.478142 140128494741248 run_lib.py:165] step: 293000, eval_loss: 4.19328e+01
I0515 01:36:16.943423 140128494741248 run_lib.py:152] step: 293050, training_loss: 3.97189e+01
I0515 01:36:23.191033 140128494741248 run_lib.py:152] step: 293100, training_loss: 2.93260e+01
I0515 01:36:23.241920 140128494741248 run_lib.py:165] step: 293100, eval_loss: 3.32397e+01
I0515 01:36:29.458026 140128494741248 run_lib.py:152] step: 293150, training_loss: 2.74762e+01
I0515 01:36:35.589237 140128494741248 run_lib.py:152] step: 293200, training_loss: 3.70732e+01
I0515 01:36:35.639524 140128494741248 run_lib.py:165] step: 293200, eval_loss: 3.14379e+01
I0515 01:36:42.031443 140128494741248 run_lib.py:152] step: 293250, training_loss: 4.72895e+01
I0515 01:36:48.281755 140128494741248 run_lib.py:152] step: 293300, training_loss: 3.75809e+01
I0515 01:36:48.345299 140128494741248 run_lib.py:165] step: 293300, eval_loss: 2.51477e+01
I0515 01:36:54.509513 140128494741248 run_lib.py:152] step: 293350, training_loss: 3.46924e+01
I0515 01:37:01.005416 140128494741248 run_lib.py:152] step: 293400, training_loss: 3.77454e+01
I0515 01:37:01.053662 140128494741248 run_lib.py:165] step: 293400, eval_loss: 2.88025e+01
I0515 01:37:07.235104 140128494741248 run_lib.py:152] step: 293450, training_loss: 3.11052e+01
I0515 01:37:13.440747 140128494741248 run_lib.py:152] step: 293500, training_loss: 3.58632e+01
I0515 01:37:13.491331 140128494741248 run_lib.py:165] step: 293500, eval_loss: 3.69724e+01
I0515 01:37:19.680440 140128494741248 run_lib.py:152] step: 293550, training_loss: 4.10842e+01
I0515 01:37:26.067824 140128494741248 run_lib.py:152] step: 293600, training_loss: 2.12035e+01
I0515 01:37:26.116679 140128494741248 run_lib.py:165] step: 293600, eval_loss: 5.87590e+01
I0515 01:37:32.366368 140128494741248 run_lib.py:152] step: 293650, training_loss: 3.22558e+01
I0515 01:37:38.524811 140128494741248 run_lib.py:152] step: 293700, training_loss: 2.29771e+01
I0515 01:37:38.577416 140128494741248 run_lib.py:165] step: 293700, eval_loss: 2.15352e+01
I0515 01:37:45.090886 140128494741248 run_lib.py:152] step: 293750, training_loss: 2.53225e+01
I0515 01:37:51.333007 140128494741248 run_lib.py:152] step: 293800, training_loss: 4.41779e+01
I0515 01:37:51.390948 140128494741248 run_lib.py:165] step: 293800, eval_loss: 4.04930e+01
I0515 01:37:57.672881 140128494741248 run_lib.py:152] step: 293850, training_loss: 1.30463e+01
I0515 01:38:03.835787 140128494741248 run_lib.py:152] step: 293900, training_loss: 3.71062e+01
I0515 01:38:03.887586 140128494741248 run_lib.py:165] step: 293900, eval_loss: 2.49905e+01
I0515 01:38:10.387767 140128494741248 run_lib.py:152] step: 293950, training_loss: 3.66203e+01
I0515 01:38:16.586415 140128494741248 run_lib.py:152] step: 294000, training_loss: 3.78502e+01
I0515 01:38:16.638845 140128494741248 run_lib.py:165] step: 294000, eval_loss: 4.57243e+01
I0515 01:38:22.851959 140128494741248 run_lib.py:152] step: 294050, training_loss: 2.92972e+01
I0515 01:38:29.080303 140128494741248 run_lib.py:152] step: 294100, training_loss: 3.53633e+01
I0515 01:38:29.365194 140128494741248 run_lib.py:165] step: 294100, eval_loss: 4.30885e+01
I0515 01:38:35.501443 140128494741248 run_lib.py:152] step: 294150, training_loss: 4.99753e+01
I0515 01:38:41.794019 140128494741248 run_lib.py:152] step: 294200, training_loss: 3.19130e+01
I0515 01:38:41.846114 140128494741248 run_lib.py:165] step: 294200, eval_loss: 2.15362e+01
I0515 01:38:48.040322 140128494741248 run_lib.py:152] step: 294250, training_loss: 4.30862e+01
I0515 01:38:54.456228 140128494741248 run_lib.py:152] step: 294300, training_loss: 4.17593e+01
I0515 01:38:54.506641 140128494741248 run_lib.py:165] step: 294300, eval_loss: 2.02062e+01
I0515 01:39:00.678674 140128494741248 run_lib.py:152] step: 294350, training_loss: 3.43437e+01
I0515 01:39:06.790122 140128494741248 run_lib.py:152] step: 294400, training_loss: 3.85096e+01
I0515 01:39:06.837999 140128494741248 run_lib.py:165] step: 294400, eval_loss: 2.82005e+01
I0515 01:39:13.267653 140128494741248 run_lib.py:152] step: 294450, training_loss: 2.53966e+01
I0515 01:39:19.453163 140128494741248 run_lib.py:152] step: 294500, training_loss: 3.15064e+01
I0515 01:39:19.504338 140128494741248 run_lib.py:165] step: 294500, eval_loss: 3.52758e+01
I0515 01:39:25.697180 140128494741248 run_lib.py:152] step: 294550, training_loss: 3.56630e+01
I0515 01:39:31.901133 140128494741248 run_lib.py:152] step: 294600, training_loss: 2.72606e+01
I0515 01:39:31.958043 140128494741248 run_lib.py:165] step: 294600, eval_loss: 1.90935e+01
I0515 01:39:38.342521 140128494741248 run_lib.py:152] step: 294650, training_loss: 3.19747e+01
I0515 01:39:44.639189 140128494741248 run_lib.py:152] step: 294700, training_loss: 3.44395e+01
I0515 01:39:44.689182 140128494741248 run_lib.py:165] step: 294700, eval_loss: 3.21992e+01
I0515 01:39:50.849230 140128494741248 run_lib.py:152] step: 294750, training_loss: 2.85896e+01
I0515 01:39:57.325919 140128494741248 run_lib.py:152] step: 294800, training_loss: 3.41168e+01
I0515 01:39:57.375938 140128494741248 run_lib.py:165] step: 294800, eval_loss: 2.79242e+01
I0515 01:40:03.574066 140128494741248 run_lib.py:152] step: 294850, training_loss: 4.45444e+01
I0515 01:40:09.767857 140128494741248 run_lib.py:152] step: 294900, training_loss: 2.72200e+01
I0515 01:40:09.823785 140128494741248 run_lib.py:165] step: 294900, eval_loss: 2.06493e+01
I0515 01:40:16.017548 140128494741248 run_lib.py:152] step: 294950, training_loss: 3.82754e+01
I0515 01:40:22.446524 140128494741248 run_lib.py:152] step: 295000, training_loss: 2.79823e+01
I0515 01:40:22.501283 140128494741248 run_lib.py:165] step: 295000, eval_loss: 3.41101e+01
I0515 01:40:28.616844 140128494741248 run_lib.py:152] step: 295050, training_loss: 2.32117e+01
I0515 01:40:34.762773 140128494741248 run_lib.py:152] step: 295100, training_loss: 3.25572e+01
I0515 01:40:34.812249 140128494741248 run_lib.py:165] step: 295100, eval_loss: 2.86650e+01
I0515 01:40:41.219994 140128494741248 run_lib.py:152] step: 295150, training_loss: 3.02407e+01
I0515 01:40:47.431897 140128494741248 run_lib.py:152] step: 295200, training_loss: 3.53589e+01
I0515 01:40:47.486553 140128494741248 run_lib.py:165] step: 295200, eval_loss: 3.14448e+01
I0515 01:40:53.729636 140128494741248 run_lib.py:152] step: 295250, training_loss: 2.32895e+01
I0515 01:40:59.947995 140128494741248 run_lib.py:152] step: 295300, training_loss: 2.64648e+01
I0515 01:40:59.998980 140128494741248 run_lib.py:165] step: 295300, eval_loss: 2.26219e+01
I0515 01:41:06.339232 140128494741248 run_lib.py:152] step: 295350, training_loss: 4.33769e+01
I0515 01:41:12.545974 140128494741248 run_lib.py:152] step: 295400, training_loss: 2.65286e+01
I0515 01:41:12.599846 140128494741248 run_lib.py:165] step: 295400, eval_loss: 3.15311e+01
I0515 01:41:18.849142 140128494741248 run_lib.py:152] step: 295450, training_loss: 2.54203e+01
I0515 01:41:25.290818 140128494741248 run_lib.py:152] step: 295500, training_loss: 4.16404e+01
I0515 01:41:25.342402 140128494741248 run_lib.py:165] step: 295500, eval_loss: 3.50686e+01
I0515 01:41:31.531600 140128494741248 run_lib.py:152] step: 295550, training_loss: 2.73354e+01
I0515 01:41:37.722004 140128494741248 run_lib.py:152] step: 295600, training_loss: 3.63114e+01
I0515 01:41:37.773837 140128494741248 run_lib.py:165] step: 295600, eval_loss: 2.21787e+01
I0515 01:41:44.049171 140128494741248 run_lib.py:152] step: 295650, training_loss: 4.21732e+01
I0515 01:41:50.362288 140128494741248 run_lib.py:152] step: 295700, training_loss: 2.91182e+01
I0515 01:41:50.418282 140128494741248 run_lib.py:165] step: 295700, eval_loss: 2.51388e+01
I0515 01:41:56.702932 140128494741248 run_lib.py:152] step: 295750, training_loss: 3.02384e+01
I0515 01:42:02.858450 140128494741248 run_lib.py:152] step: 295800, training_loss: 4.36993e+01
I0515 01:42:02.910393 140128494741248 run_lib.py:165] step: 295800, eval_loss: 3.73569e+01
I0515 01:42:09.361187 140128494741248 run_lib.py:152] step: 295850, training_loss: 4.96282e+01
I0515 01:42:15.479017 140128494741248 run_lib.py:152] step: 295900, training_loss: 3.24439e+01
I0515 01:42:15.528723 140128494741248 run_lib.py:165] step: 295900, eval_loss: 4.83779e+01
I0515 01:42:21.697981 140128494741248 run_lib.py:152] step: 295950, training_loss: 4.26095e+01
I0515 01:42:27.929531 140128494741248 run_lib.py:152] step: 296000, training_loss: 3.67496e+01
I0515 01:42:27.986354 140128494741248 run_lib.py:165] step: 296000, eval_loss: 2.90667e+01
I0515 01:42:34.434959 140128494741248 run_lib.py:152] step: 296050, training_loss: 2.66842e+01
I0515 01:42:40.603534 140128494741248 run_lib.py:152] step: 296100, training_loss: 1.99599e+01
I0515 01:42:40.650182 140128494741248 run_lib.py:165] step: 296100, eval_loss: 2.29209e+01
I0515 01:42:46.831570 140128494741248 run_lib.py:152] step: 296150, training_loss: 5.22305e+01
I0515 01:42:53.145824 140128494741248 run_lib.py:152] step: 296200, training_loss: 3.28753e+01
I0515 01:42:53.197120 140128494741248 run_lib.py:165] step: 296200, eval_loss: 4.02539e+01
I0515 01:42:59.410913 140128494741248 run_lib.py:152] step: 296250, training_loss: 1.91971e+01
I0515 01:43:05.581365 140128494741248 run_lib.py:152] step: 296300, training_loss: 2.88901e+01
I0515 01:43:05.635489 140128494741248 run_lib.py:165] step: 296300, eval_loss: 4.24271e+01
I0515 01:43:11.812643 140128494741248 run_lib.py:152] step: 296350, training_loss: 3.99332e+01
I0515 01:43:18.244434 140128494741248 run_lib.py:152] step: 296400, training_loss: 4.96479e+01
I0515 01:43:18.297971 140128494741248 run_lib.py:165] step: 296400, eval_loss: 2.27278e+01
I0515 01:43:24.509451 140128494741248 run_lib.py:152] step: 296450, training_loss: 3.26325e+01
I0515 01:43:30.685925 140128494741248 run_lib.py:152] step: 296500, training_loss: 2.77548e+01
I0515 01:43:30.738760 140128494741248 run_lib.py:165] step: 296500, eval_loss: 2.81459e+01
I0515 01:43:37.129253 140128494741248 run_lib.py:152] step: 296550, training_loss: 3.16908e+01
I0515 01:43:43.338142 140128494741248 run_lib.py:152] step: 296600, training_loss: 2.46743e+01
I0515 01:43:43.394259 140128494741248 run_lib.py:165] step: 296600, eval_loss: 3.81285e+01
I0515 01:43:49.642472 140128494741248 run_lib.py:152] step: 296650, training_loss: 3.17221e+01
I0515 01:43:55.861854 140128494741248 run_lib.py:152] step: 296700, training_loss: 3.91791e+01
I0515 01:43:55.910259 140128494741248 run_lib.py:165] step: 296700, eval_loss: 1.47454e+01
I0515 01:44:02.288436 140128494741248 run_lib.py:152] step: 296750, training_loss: 2.74269e+01
I0515 01:44:08.543641 140128494741248 run_lib.py:152] step: 296800, training_loss: 2.96078e+01
I0515 01:44:08.594192 140128494741248 run_lib.py:165] step: 296800, eval_loss: 3.57417e+01
I0515 01:44:14.696835 140128494741248 run_lib.py:152] step: 296850, training_loss: 2.77783e+01
I0515 01:44:21.243200 140128494741248 run_lib.py:152] step: 296900, training_loss: 2.40926e+01
I0515 01:44:21.294166 140128494741248 run_lib.py:165] step: 296900, eval_loss: 2.06170e+01
I0515 01:44:27.522489 140128494741248 run_lib.py:152] step: 296950, training_loss: 3.48716e+01
I0515 01:44:33.734140 140128494741248 run_lib.py:152] step: 297000, training_loss: 4.13504e+01
I0515 01:44:33.782591 140128494741248 run_lib.py:165] step: 297000, eval_loss: 2.56670e+01
I0515 01:44:39.907658 140128494741248 run_lib.py:152] step: 297050, training_loss: 2.35147e+01
I0515 01:44:46.269292 140128494741248 run_lib.py:152] step: 297100, training_loss: 2.34287e+01
I0515 01:44:46.321955 140128494741248 run_lib.py:165] step: 297100, eval_loss: 3.82301e+01
I0515 01:44:52.602914 140128494741248 run_lib.py:152] step: 297150, training_loss: 3.32292e+01
I0515 01:44:58.818562 140128494741248 run_lib.py:152] step: 297200, training_loss: 2.94838e+01
I0515 01:44:58.869835 140128494741248 run_lib.py:165] step: 297200, eval_loss: 4.26034e+01
I0515 01:45:05.354937 140128494741248 run_lib.py:152] step: 297250, training_loss: 3.53456e+01
I0515 01:45:11.531635 140128494741248 run_lib.py:152] step: 297300, training_loss: 4.69205e+01
I0515 01:45:11.581339 140128494741248 run_lib.py:165] step: 297300, eval_loss: 2.58347e+01
I0515 01:45:17.697858 140128494741248 run_lib.py:152] step: 297350, training_loss: 3.04548e+01
I0515 01:45:23.898844 140128494741248 run_lib.py:152] step: 297400, training_loss: 2.00116e+01
I0515 01:45:23.955236 140128494741248 run_lib.py:165] step: 297400, eval_loss: 4.23007e+01
I0515 01:45:30.334469 140128494741248 run_lib.py:152] step: 297450, training_loss: 1.86959e+01
I0515 01:45:36.584808 140128494741248 run_lib.py:152] step: 297500, training_loss: 3.05492e+01
I0515 01:45:36.636636 140128494741248 run_lib.py:165] step: 297500, eval_loss: 1.96379e+01
I0515 01:45:42.984139 140128494741248 run_lib.py:152] step: 297550, training_loss: 2.77468e+01
I0515 01:45:49.278578 140128494741248 run_lib.py:152] step: 297600, training_loss: 2.59629e+01
I0515 01:45:49.550621 140128494741248 run_lib.py:165] step: 297600, eval_loss: 2.29723e+01
I0515 01:45:55.761877 140128494741248 run_lib.py:152] step: 297650, training_loss: 3.67296e+01
I0515 01:46:02.004369 140128494741248 run_lib.py:152] step: 297700, training_loss: 3.02967e+01
I0515 01:46:02.054265 140128494741248 run_lib.py:165] step: 297700, eval_loss: 3.10851e+01
I0515 01:46:08.217060 140128494741248 run_lib.py:152] step: 297750, training_loss: 3.89685e+01
I0515 01:46:14.682822 140128494741248 run_lib.py:152] step: 297800, training_loss: 5.52364e+01
I0515 01:46:14.735832 140128494741248 run_lib.py:165] step: 297800, eval_loss: 1.38995e+01
I0515 01:46:20.830847 140128494741248 run_lib.py:152] step: 297850, training_loss: 3.14955e+01
I0515 01:46:27.075371 140128494741248 run_lib.py:152] step: 297900, training_loss: 2.68395e+01
I0515 01:46:27.133587 140128494741248 run_lib.py:165] step: 297900, eval_loss: 4.38136e+01
I0515 01:46:33.589211 140128494741248 run_lib.py:152] step: 297950, training_loss: 2.61269e+01
I0515 01:46:39.932611 140128494741248 run_lib.py:152] step: 298000, training_loss: 2.96460e+01
I0515 01:46:39.982294 140128494741248 run_lib.py:165] step: 298000, eval_loss: 1.55461e+01
I0515 01:46:46.176681 140128494741248 run_lib.py:152] step: 298050, training_loss: 3.92884e+01
I0515 01:46:52.356710 140128494741248 run_lib.py:152] step: 298100, training_loss: 3.22646e+01
I0515 01:46:52.404643 140128494741248 run_lib.py:165] step: 298100, eval_loss: 3.46637e+01
I0515 01:46:58.880567 140128494741248 run_lib.py:152] step: 298150, training_loss: 3.31758e+01
I0515 01:47:05.014838 140128494741248 run_lib.py:152] step: 298200, training_loss: 2.68035e+01
I0515 01:47:05.070683 140128494741248 run_lib.py:165] step: 298200, eval_loss: 2.74529e+01
I0515 01:47:11.295585 140128494741248 run_lib.py:152] step: 298250, training_loss: 4.40658e+01
I0515 01:47:17.795082 140128494741248 run_lib.py:152] step: 298300, training_loss: 1.79550e+01
I0515 01:47:17.846210 140128494741248 run_lib.py:165] step: 298300, eval_loss: 4.64073e+01
I0515 01:47:24.020938 140128494741248 run_lib.py:152] step: 298350, training_loss: 4.70028e+01
I0515 01:47:30.182087 140128494741248 run_lib.py:152] step: 298400, training_loss: 3.51428e+01
I0515 01:47:30.239557 140128494741248 run_lib.py:165] step: 298400, eval_loss: 3.20235e+01
I0515 01:47:36.365922 140128494741248 run_lib.py:152] step: 298450, training_loss: 3.53809e+01
I0515 01:47:42.867024 140128494741248 run_lib.py:152] step: 298500, training_loss: 4.71736e+01
I0515 01:47:42.916315 140128494741248 run_lib.py:165] step: 298500, eval_loss: 3.43126e+01
I0515 01:47:49.095579 140128494741248 run_lib.py:152] step: 298550, training_loss: 4.24916e+01
I0515 01:47:55.316841 140128494741248 run_lib.py:152] step: 298600, training_loss: 2.75277e+01
I0515 01:47:55.368770 140128494741248 run_lib.py:165] step: 298600, eval_loss: 3.22626e+01
I0515 01:48:01.841170 140128494741248 run_lib.py:152] step: 298650, training_loss: 3.65361e+01
I0515 01:48:08.000421 140128494741248 run_lib.py:152] step: 298700, training_loss: 3.50785e+01
I0515 01:48:08.052399 140128494741248 run_lib.py:165] step: 298700, eval_loss: 3.51232e+01
I0515 01:48:14.269880 140128494741248 run_lib.py:152] step: 298750, training_loss: 3.75558e+01
I0515 01:48:20.506086 140128494741248 run_lib.py:152] step: 298800, training_loss: 3.83620e+01
I0515 01:48:20.561397 140128494741248 run_lib.py:165] step: 298800, eval_loss: 2.49550e+01
I0515 01:48:26.950044 140128494741248 run_lib.py:152] step: 298850, training_loss: 2.85250e+01
I0515 01:48:33.127887 140128494741248 run_lib.py:152] step: 298900, training_loss: 2.64182e+01
I0515 01:48:33.179910 140128494741248 run_lib.py:165] step: 298900, eval_loss: 2.57561e+01
I0515 01:48:39.382493 140128494741248 run_lib.py:152] step: 298950, training_loss: 2.48307e+01
I0515 01:48:45.896946 140128494741248 run_lib.py:152] step: 299000, training_loss: 4.38878e+01
I0515 01:48:45.953989 140128494741248 run_lib.py:165] step: 299000, eval_loss: 1.87052e+01
I0515 01:48:52.167209 140128494741248 run_lib.py:152] step: 299050, training_loss: 3.62602e+01
I0515 01:48:58.391812 140128494741248 run_lib.py:152] step: 299100, training_loss: 2.77526e+01
I0515 01:48:58.443990 140128494741248 run_lib.py:165] step: 299100, eval_loss: 3.22663e+01
I0515 01:49:04.694272 140128494741248 run_lib.py:152] step: 299150, training_loss: 2.81559e+01
I0515 01:49:11.177685 140128494741248 run_lib.py:152] step: 299200, training_loss: 4.14437e+01
I0515 01:49:11.229618 140128494741248 run_lib.py:165] step: 299200, eval_loss: 1.21084e+01
I0515 01:49:17.362742 140128494741248 run_lib.py:152] step: 299250, training_loss: 2.92693e+01
I0515 01:49:23.520775 140128494741248 run_lib.py:152] step: 299300, training_loss: 1.61321e+01
I0515 01:49:23.573976 140128494741248 run_lib.py:165] step: 299300, eval_loss: 3.15068e+01
I0515 01:49:30.022159 140128494741248 run_lib.py:152] step: 299350, training_loss: 1.86063e+01
I0515 01:49:36.238395 140128494741248 run_lib.py:152] step: 299400, training_loss: 4.47754e+01
I0515 01:49:36.289791 140128494741248 run_lib.py:165] step: 299400, eval_loss: 3.03832e+01
I0515 01:49:42.546756 140128494741248 run_lib.py:152] step: 299450, training_loss: 2.91512e+01
I0515 01:49:48.744110 140128494741248 run_lib.py:152] step: 299500, training_loss: 3.29238e+01
I0515 01:49:48.796565 140128494741248 run_lib.py:165] step: 299500, eval_loss: 3.92224e+01
I0515 01:49:55.187278 140128494741248 run_lib.py:152] step: 299550, training_loss: 2.62036e+01
I0515 01:50:01.416231 140128494741248 run_lib.py:152] step: 299600, training_loss: 3.04166e+01
I0515 01:50:01.467480 140128494741248 run_lib.py:165] step: 299600, eval_loss: 1.87666e+01
I0515 01:50:07.721807 140128494741248 run_lib.py:152] step: 299650, training_loss: 3.21876e+01
I0515 01:50:14.137630 140128494741248 run_lib.py:152] step: 299700, training_loss: 3.03364e+01
I0515 01:50:14.191866 140128494741248 run_lib.py:165] step: 299700, eval_loss: 4.38379e+01
I0515 01:50:20.427387 140128494741248 run_lib.py:152] step: 299750, training_loss: 4.19788e+01
I0515 01:50:26.636780 140128494741248 run_lib.py:152] step: 299800, training_loss: 3.42325e+01
I0515 01:50:26.689498 140128494741248 run_lib.py:165] step: 299800, eval_loss: 3.34530e+01
I0515 01:50:32.938974 140128494741248 run_lib.py:152] step: 299850, training_loss: 1.61829e+01
I0515 01:50:39.445755 140128494741248 run_lib.py:152] step: 299900, training_loss: 3.63097e+01
I0515 01:50:39.494122 140128494741248 run_lib.py:165] step: 299900, eval_loss: 2.89254e+01
I0515 01:50:45.644493 140128494741248 run_lib.py:152] step: 299950, training_loss: 2.75659e+01
I0515 01:50:51.886552 140128494741248 run_lib.py:152] step: 300000, training_loss: 3.20761e+01
I0515 01:50:52.090551 140128494741248 run_lib.py:165] step: 300000, eval_loss: 2.51844e+01
I0515 01:52:12.575695 140128494741248 run_lib.py:152] step: 300050, training_loss: 2.09544e+01
I0515 01:52:18.765305 140128494741248 run_lib.py:152] step: 300100, training_loss: 3.95198e+01
I0515 01:52:18.814468 140128494741248 run_lib.py:165] step: 300100, eval_loss: 2.29707e+01
I0515 01:52:25.134616 140128494741248 run_lib.py:152] step: 300150, training_loss: 3.59292e+01
I0515 01:52:31.507098 140128494741248 run_lib.py:152] step: 300200, training_loss: 3.25928e+01
I0515 01:52:31.558915 140128494741248 run_lib.py:165] step: 300200, eval_loss: 4.20333e+01
I0515 01:52:37.852604 140128494741248 run_lib.py:152] step: 300250, training_loss: 3.16266e+01
I0515 01:52:44.140521 140128494741248 run_lib.py:152] step: 300300, training_loss: 2.75015e+01
I0515 01:52:44.194205 140128494741248 run_lib.py:165] step: 300300, eval_loss: 3.13568e+01
I0515 01:52:50.298448 140128494741248 run_lib.py:152] step: 300350, training_loss: 1.73412e+01
I0515 01:52:56.714168 140128494741248 run_lib.py:152] step: 300400, training_loss: 3.67170e+01
I0515 01:52:56.765413 140128494741248 run_lib.py:165] step: 300400, eval_loss: 3.19007e+01
I0515 01:53:03.021557 140128494741248 run_lib.py:152] step: 300450, training_loss: 3.51289e+01
I0515 01:53:09.269355 140128494741248 run_lib.py:152] step: 300500, training_loss: 3.86503e+01
I0515 01:53:09.319958 140128494741248 run_lib.py:165] step: 300500, eval_loss: 3.41494e+01
I0515 01:53:15.753908 140128494741248 run_lib.py:152] step: 300550, training_loss: 2.44601e+01
I0515 01:53:22.010508 140128494741248 run_lib.py:152] step: 300600, training_loss: 2.52193e+01
I0515 01:53:22.060175 140128494741248 run_lib.py:165] step: 300600, eval_loss: 2.69171e+01
I0515 01:53:28.359133 140128494741248 run_lib.py:152] step: 300650, training_loss: 2.54561e+01
I0515 01:53:34.466704 140128494741248 run_lib.py:152] step: 300700, training_loss: 3.03518e+01
I0515 01:53:34.519715 140128494741248 run_lib.py:165] step: 300700, eval_loss: 2.02860e+01
I0515 01:53:40.992454 140128494741248 run_lib.py:152] step: 300750, training_loss: 3.05933e+01
I0515 01:53:47.267120 140128494741248 run_lib.py:152] step: 300800, training_loss: 2.84624e+01
I0515 01:53:47.326852 140128494741248 run_lib.py:165] step: 300800, eval_loss: 5.01851e+01
I0515 01:53:53.620882 140128494741248 run_lib.py:152] step: 300850, training_loss: 2.07597e+01
I0515 01:53:59.972644 140128494741248 run_lib.py:152] step: 300900, training_loss: 2.88034e+01
I0515 01:54:00.028447 140128494741248 run_lib.py:165] step: 300900, eval_loss: 4.53790e+01
I0515 01:54:06.343958 140128494741248 run_lib.py:152] step: 300950, training_loss: 3.44256e+01
I0515 01:54:12.658054 140128494741248 run_lib.py:152] step: 301000, training_loss: 4.28244e+01
I0515 01:54:12.710532 140128494741248 run_lib.py:165] step: 301000, eval_loss: 2.72586e+01
I0515 01:54:18.987082 140128494741248 run_lib.py:152] step: 301050, training_loss: 3.72372e+01
I0515 01:54:25.477170 140128494741248 run_lib.py:152] step: 301100, training_loss: 2.91706e+01
I0515 01:54:25.533221 140128494741248 run_lib.py:165] step: 301100, eval_loss: 3.28654e+01
I0515 01:54:31.734611 140128494741248 run_lib.py:152] step: 301150, training_loss: 2.36924e+01
I0515 01:54:37.940899 140128494741248 run_lib.py:152] step: 301200, training_loss: 2.36153e+01
I0515 01:54:37.995928 140128494741248 run_lib.py:165] step: 301200, eval_loss: 4.02336e+01
I0515 01:54:44.410443 140128494741248 run_lib.py:152] step: 301250, training_loss: 2.71476e+01
I0515 01:54:50.717036 140128494741248 run_lib.py:152] step: 301300, training_loss: 4.06611e+01
I0515 01:54:50.771507 140128494741248 run_lib.py:165] step: 301300, eval_loss: 2.10465e+01
I0515 01:54:56.996767 140128494741248 run_lib.py:152] step: 301350, training_loss: 3.13670e+01
I0515 01:55:03.220982 140128494741248 run_lib.py:152] step: 301400, training_loss: 3.35653e+01
I0515 01:55:03.272705 140128494741248 run_lib.py:165] step: 301400, eval_loss: 3.38481e+01
I0515 01:55:09.666259 140128494741248 run_lib.py:152] step: 301450, training_loss: 3.05541e+01
I0515 01:55:15.891546 140128494741248 run_lib.py:152] step: 301500, training_loss: 3.33138e+01
I0515 01:55:15.946130 140128494741248 run_lib.py:165] step: 301500, eval_loss: 3.72676e+01
I0515 01:55:22.123494 140128494741248 run_lib.py:152] step: 301550, training_loss: 3.39844e+01
I0515 01:55:28.508042 140128494741248 run_lib.py:152] step: 301600, training_loss: 3.38052e+01
I0515 01:55:28.563528 140128494741248 run_lib.py:165] step: 301600, eval_loss: 3.14787e+01
I0515 01:55:34.656118 140128494741248 run_lib.py:152] step: 301650, training_loss: 3.49127e+01
I0515 01:55:40.793244 140128494741248 run_lib.py:152] step: 301700, training_loss: 3.65041e+01
I0515 01:55:40.843816 140128494741248 run_lib.py:165] step: 301700, eval_loss: 2.82615e+01
I0515 01:55:47.058394 140128494741248 run_lib.py:152] step: 301750, training_loss: 3.12532e+01
I0515 01:55:53.528125 140128494741248 run_lib.py:152] step: 301800, training_loss: 2.44742e+01
I0515 01:55:53.583779 140128494741248 run_lib.py:165] step: 301800, eval_loss: 4.07854e+01
I0515 01:55:59.779186 140128494741248 run_lib.py:152] step: 301850, training_loss: 4.03997e+01
I0515 01:56:06.066045 140128494741248 run_lib.py:152] step: 301900, training_loss: 2.42664e+01
I0515 01:56:06.123369 140128494741248 run_lib.py:165] step: 301900, eval_loss: 1.63454e+01
I0515 01:56:12.620365 140128494741248 run_lib.py:152] step: 301950, training_loss: 4.79995e+01
I0515 01:56:18.834479 140128494741248 run_lib.py:152] step: 302000, training_loss: 2.96389e+01
I0515 01:56:18.886023 140128494741248 run_lib.py:165] step: 302000, eval_loss: 1.90961e+01
I0515 01:56:25.176318 140128494741248 run_lib.py:152] step: 302050, training_loss: 1.76225e+01
I0515 01:56:31.490047 140128494741248 run_lib.py:152] step: 302100, training_loss: 1.56139e+01
I0515 01:56:31.543610 140128494741248 run_lib.py:165] step: 302100, eval_loss: 2.94622e+01
I0515 01:56:38.001420 140128494741248 run_lib.py:152] step: 302150, training_loss: 2.10132e+01
I0515 01:56:44.187182 140128494741248 run_lib.py:152] step: 302200, training_loss: 2.92196e+01
I0515 01:56:44.245339 140128494741248 run_lib.py:165] step: 302200, eval_loss: 4.44307e+01
I0515 01:56:50.432955 140128494741248 run_lib.py:152] step: 302250, training_loss: 1.90012e+01
I0515 01:56:56.929989 140128494741248 run_lib.py:152] step: 302300, training_loss: 2.83018e+01
I0515 01:56:56.983885 140128494741248 run_lib.py:165] step: 302300, eval_loss: 3.97597e+01
I0515 01:57:03.192312 140128494741248 run_lib.py:152] step: 302350, training_loss: 2.50288e+01
I0515 01:57:09.378876 140128494741248 run_lib.py:152] step: 302400, training_loss: 3.39165e+01
I0515 01:57:09.430321 140128494741248 run_lib.py:165] step: 302400, eval_loss: 2.97246e+01
I0515 01:57:15.646251 140128494741248 run_lib.py:152] step: 302450, training_loss: 3.14445e+01
I0515 01:57:22.088761 140128494741248 run_lib.py:152] step: 302500, training_loss: 4.19804e+01
I0515 01:57:22.138103 140128494741248 run_lib.py:165] step: 302500, eval_loss: 3.37689e+01
I0515 01:57:28.249157 140128494741248 run_lib.py:152] step: 302550, training_loss: 2.14990e+01
I0515 01:57:34.458699 140128494741248 run_lib.py:152] step: 302600, training_loss: 3.27890e+01
I0515 01:57:34.511511 140128494741248 run_lib.py:165] step: 302600, eval_loss: 2.89593e+01
I0515 01:57:40.941095 140128494741248 run_lib.py:152] step: 302650, training_loss: 3.40216e+01
I0515 01:57:47.276846 140128494741248 run_lib.py:152] step: 302700, training_loss: 3.05422e+01
I0515 01:57:47.329881 140128494741248 run_lib.py:165] step: 302700, eval_loss: 1.90537e+01
I0515 01:57:53.482814 140128494741248 run_lib.py:152] step: 302750, training_loss: 4.42930e+01
I0515 01:57:59.570911 140128494741248 run_lib.py:152] step: 302800, training_loss: 2.69850e+01
I0515 01:57:59.627942 140128494741248 run_lib.py:165] step: 302800, eval_loss: 1.79238e+01
I0515 01:58:06.168090 140128494741248 run_lib.py:152] step: 302850, training_loss: 2.14497e+01
I0515 01:58:12.335266 140128494741248 run_lib.py:152] step: 302900, training_loss: 4.53646e+01
I0515 01:58:12.386620 140128494741248 run_lib.py:165] step: 302900, eval_loss: 3.27364e+01
I0515 01:58:18.558979 140128494741248 run_lib.py:152] step: 302950, training_loss: 2.39777e+01
I0515 01:58:25.070464 140128494741248 run_lib.py:152] step: 303000, training_loss: 2.45318e+01
I0515 01:58:25.123409 140128494741248 run_lib.py:165] step: 303000, eval_loss: 4.75681e+01
I0515 01:58:31.302094 140128494741248 run_lib.py:152] step: 303050, training_loss: 4.09909e+01
I0515 01:58:37.539997 140128494741248 run_lib.py:152] step: 303100, training_loss: 3.13831e+01
I0515 01:58:37.593280 140128494741248 run_lib.py:165] step: 303100, eval_loss: 4.40103e+01
I0515 01:58:43.867810 140128494741248 run_lib.py:152] step: 303150, training_loss: 4.38535e+01
I0515 01:58:50.322225 140128494741248 run_lib.py:152] step: 303200, training_loss: 3.40250e+01
I0515 01:58:50.376053 140128494741248 run_lib.py:165] step: 303200, eval_loss: 2.99796e+01
I0515 01:58:56.546327 140128494741248 run_lib.py:152] step: 303250, training_loss: 4.53166e+01
I0515 01:59:02.797523 140128494741248 run_lib.py:152] step: 303300, training_loss: 4.39643e+01
I0515 01:59:02.856223 140128494741248 run_lib.py:165] step: 303300, eval_loss: 2.77641e+01
I0515 01:59:09.476285 140128494741248 run_lib.py:152] step: 303350, training_loss: 3.73542e+01
I0515 01:59:15.758623 140128494741248 run_lib.py:152] step: 303400, training_loss: 3.49604e+01
I0515 01:59:15.815816 140128494741248 run_lib.py:165] step: 303400, eval_loss: 2.95676e+01
I0515 01:59:21.937858 140128494741248 run_lib.py:152] step: 303450, training_loss: 1.50422e+01
I0515 01:59:28.204085 140128494741248 run_lib.py:152] step: 303500, training_loss: 3.04815e+01
I0515 01:59:28.260650 140128494741248 run_lib.py:165] step: 303500, eval_loss: 3.44059e+01
I0515 01:59:34.619415 140128494741248 run_lib.py:152] step: 303550, training_loss: 2.55257e+01
I0515 01:59:40.873871 140128494741248 run_lib.py:152] step: 303600, training_loss: 2.71518e+01
I0515 01:59:40.926884 140128494741248 run_lib.py:165] step: 303600, eval_loss: 2.28257e+01
I0515 01:59:47.152115 140128494741248 run_lib.py:152] step: 303650, training_loss: 2.91752e+01
I0515 01:59:53.635273 140128494741248 run_lib.py:152] step: 303700, training_loss: 3.32356e+01
I0515 01:59:53.684438 140128494741248 run_lib.py:165] step: 303700, eval_loss: 3.06112e+01
I0515 01:59:59.970808 140128494741248 run_lib.py:152] step: 303750, training_loss: 4.03337e+01
I0515 02:00:06.229830 140128494741248 run_lib.py:152] step: 303800, training_loss: 3.48302e+01
I0515 02:00:06.278745 140128494741248 run_lib.py:165] step: 303800, eval_loss: 2.77027e+01
I0515 02:00:12.512837 140128494741248 run_lib.py:152] step: 303850, training_loss: 2.14349e+01
I0515 02:00:18.932169 140128494741248 run_lib.py:152] step: 303900, training_loss: 2.19324e+01
I0515 02:00:18.982613 140128494741248 run_lib.py:165] step: 303900, eval_loss: 3.60673e+01
I0515 02:00:25.269018 140128494741248 run_lib.py:152] step: 303950, training_loss: 3.12045e+01
I0515 02:00:31.459494 140128494741248 run_lib.py:152] step: 304000, training_loss: 2.49747e+01
I0515 02:00:31.508563 140128494741248 run_lib.py:165] step: 304000, eval_loss: 4.28357e+01
I0515 02:00:37.976097 140128494741248 run_lib.py:152] step: 304050, training_loss: 1.42058e+01
I0515 02:00:44.227882 140128494741248 run_lib.py:152] step: 304100, training_loss: 2.51313e+01
I0515 02:00:44.276124 140128494741248 run_lib.py:165] step: 304100, eval_loss: 3.27381e+01
I0515 02:00:50.548509 140128494741248 run_lib.py:152] step: 304150, training_loss: 3.49610e+01
I0515 02:00:56.682775 140128494741248 run_lib.py:152] step: 304200, training_loss: 3.31036e+01
I0515 02:00:56.727913 140128494741248 run_lib.py:165] step: 304200, eval_loss: 3.43145e+01
I0515 02:01:03.170027 140128494741248 run_lib.py:152] step: 304250, training_loss: 1.50943e+01
I0515 02:01:09.510923 140128494741248 run_lib.py:152] step: 304300, training_loss: 2.91519e+01
I0515 02:01:09.561198 140128494741248 run_lib.py:165] step: 304300, eval_loss: 3.07103e+01
I0515 02:01:15.692795 140128494741248 run_lib.py:152] step: 304350, training_loss: 3.07443e+01
I0515 02:01:22.057410 140128494741248 run_lib.py:152] step: 304400, training_loss: 2.76680e+01
I0515 02:01:22.108709 140128494741248 run_lib.py:165] step: 304400, eval_loss: 2.26299e+01
I0515 02:01:28.374201 140128494741248 run_lib.py:152] step: 304450, training_loss: 2.35097e+01
I0515 02:01:34.552098 140128494741248 run_lib.py:152] step: 304500, training_loss: 3.14081e+01
I0515 02:01:34.611695 140128494741248 run_lib.py:165] step: 304500, eval_loss: 2.62757e+01
I0515 02:01:40.845074 140128494741248 run_lib.py:152] step: 304550, training_loss: 2.04705e+01
I0515 02:01:47.225784 140128494741248 run_lib.py:152] step: 304600, training_loss: 2.44736e+01
I0515 02:01:47.274490 140128494741248 run_lib.py:165] step: 304600, eval_loss: 2.85024e+01
I0515 02:01:53.488302 140128494741248 run_lib.py:152] step: 304650, training_loss: 5.57151e+01
I0515 02:01:59.686942 140128494741248 run_lib.py:152] step: 304700, training_loss: 3.78545e+01
I0515 02:01:59.738460 140128494741248 run_lib.py:165] step: 304700, eval_loss: 2.88028e+01
I0515 02:02:06.143570 140128494741248 run_lib.py:152] step: 304750, training_loss: 2.11979e+01
I0515 02:02:12.382195 140128494741248 run_lib.py:152] step: 304800, training_loss: 3.61471e+01
I0515 02:02:12.444776 140128494741248 run_lib.py:165] step: 304800, eval_loss: 2.87136e+01
I0515 02:02:18.618770 140128494741248 run_lib.py:152] step: 304850, training_loss: 2.77529e+01
I0515 02:02:24.927686 140128494741248 run_lib.py:152] step: 304900, training_loss: 3.32618e+01
I0515 02:02:24.979897 140128494741248 run_lib.py:165] step: 304900, eval_loss: 3.38688e+01
I0515 02:02:31.475902 140128494741248 run_lib.py:152] step: 304950, training_loss: 2.20276e+01
I0515 02:02:37.711477 140128494741248 run_lib.py:152] step: 305000, training_loss: 3.61868e+01
I0515 02:02:37.760557 140128494741248 run_lib.py:165] step: 305000, eval_loss: 3.00332e+01
I0515 02:02:43.968210 140128494741248 run_lib.py:152] step: 305050, training_loss: 2.47695e+01
I0515 02:02:50.404932 140128494741248 run_lib.py:152] step: 305100, training_loss: 3.23996e+01
I0515 02:02:50.463840 140128494741248 run_lib.py:165] step: 305100, eval_loss: 4.26808e+01
I0515 02:02:56.686492 140128494741248 run_lib.py:152] step: 305150, training_loss: 2.80535e+01
I0515 02:03:02.873701 140128494741248 run_lib.py:152] step: 305200, training_loss: 3.73253e+01
I0515 02:03:02.927285 140128494741248 run_lib.py:165] step: 305200, eval_loss: 3.42621e+01
I0515 02:03:09.061904 140128494741248 run_lib.py:152] step: 305250, training_loss: 2.26351e+01
I0515 02:03:15.525952 140128494741248 run_lib.py:152] step: 305300, training_loss: 3.35372e+01
I0515 02:03:15.575263 140128494741248 run_lib.py:165] step: 305300, eval_loss: 3.67363e+01
I0515 02:03:21.849445 140128494741248 run_lib.py:152] step: 305350, training_loss: 2.89163e+01
I0515 02:03:27.999098 140128494741248 run_lib.py:152] step: 305400, training_loss: 2.58360e+01
I0515 02:03:28.048182 140128494741248 run_lib.py:165] step: 305400, eval_loss: 1.58020e+01
I0515 02:03:34.478228 140128494741248 run_lib.py:152] step: 305450, training_loss: 1.93058e+01
I0515 02:03:40.602082 140128494741248 run_lib.py:152] step: 305500, training_loss: 3.27573e+01
I0515 02:03:40.651038 140128494741248 run_lib.py:165] step: 305500, eval_loss: 4.56427e+01
I0515 02:03:46.798637 140128494741248 run_lib.py:152] step: 305550, training_loss: 3.98533e+01
I0515 02:03:53.013812 140128494741248 run_lib.py:152] step: 305600, training_loss: 3.62624e+01
I0515 02:03:53.069805 140128494741248 run_lib.py:165] step: 305600, eval_loss: 2.05149e+01
I0515 02:03:59.451786 140128494741248 run_lib.py:152] step: 305650, training_loss: 4.13843e+01
I0515 02:04:05.624066 140128494741248 run_lib.py:152] step: 305700, training_loss: 3.79027e+01
I0515 02:04:05.672573 140128494741248 run_lib.py:165] step: 305700, eval_loss: 2.44420e+01
I0515 02:04:11.869256 140128494741248 run_lib.py:152] step: 305750, training_loss: 3.15185e+01
I0515 02:04:18.202216 140128494741248 run_lib.py:152] step: 305800, training_loss: 3.09071e+01
I0515 02:04:18.255399 140128494741248 run_lib.py:165] step: 305800, eval_loss: 3.84640e+01
I0515 02:04:24.476263 140128494741248 run_lib.py:152] step: 305850, training_loss: 3.65207e+01
I0515 02:04:30.675629 140128494741248 run_lib.py:152] step: 305900, training_loss: 2.37191e+01
I0515 02:04:30.733278 140128494741248 run_lib.py:165] step: 305900, eval_loss: 2.70813e+01
I0515 02:04:37.007402 140128494741248 run_lib.py:152] step: 305950, training_loss: 2.39517e+01
I0515 02:04:43.493701 140128494741248 run_lib.py:152] step: 306000, training_loss: 3.98472e+01
I0515 02:04:43.546483 140128494741248 run_lib.py:165] step: 306000, eval_loss: 4.41781e+01
I0515 02:04:49.688434 140128494741248 run_lib.py:152] step: 306050, training_loss: 3.16433e+01
I0515 02:04:55.851000 140128494741248 run_lib.py:152] step: 306100, training_loss: 3.64302e+01
I0515 02:04:55.901734 140128494741248 run_lib.py:165] step: 306100, eval_loss: 3.66904e+01
I0515 02:05:02.395567 140128494741248 run_lib.py:152] step: 306150, training_loss: 3.21567e+01
I0515 02:05:08.670576 140128494741248 run_lib.py:152] step: 306200, training_loss: 3.77399e+01
I0515 02:05:08.723147 140128494741248 run_lib.py:165] step: 306200, eval_loss: 2.98010e+01
I0515 02:05:14.958796 140128494741248 run_lib.py:152] step: 306250, training_loss: 4.33418e+01
I0515 02:05:21.084948 140128494741248 run_lib.py:152] step: 306300, training_loss: 1.52996e+01
I0515 02:05:21.132279 140128494741248 run_lib.py:165] step: 306300, eval_loss: 3.32254e+01
I0515 02:05:27.647532 140128494741248 run_lib.py:152] step: 306350, training_loss: 2.86579e+01
I0515 02:05:33.799224 140128494741248 run_lib.py:152] step: 306400, training_loss: 2.36034e+01
I0515 02:05:33.850440 140128494741248 run_lib.py:165] step: 306400, eval_loss: 2.47711e+01
I0515 02:05:40.093308 140128494741248 run_lib.py:152] step: 306450, training_loss: 2.32458e+01
I0515 02:05:46.579503 140128494741248 run_lib.py:152] step: 306500, training_loss: 3.89309e+01
I0515 02:05:46.636683 140128494741248 run_lib.py:165] step: 306500, eval_loss: 2.61639e+01
I0515 02:05:52.796339 140128494741248 run_lib.py:152] step: 306550, training_loss: 2.23847e+01
I0515 02:05:58.949026 140128494741248 run_lib.py:152] step: 306600, training_loss: 3.04056e+01
I0515 02:05:58.999613 140128494741248 run_lib.py:165] step: 306600, eval_loss: 2.79535e+01
I0515 02:06:05.122652 140128494741248 run_lib.py:152] step: 306650, training_loss: 3.88216e+01
I0515 02:06:11.551862 140128494741248 run_lib.py:152] step: 306700, training_loss: 2.59192e+01
I0515 02:06:11.609570 140128494741248 run_lib.py:165] step: 306700, eval_loss: 3.33937e+01
I0515 02:06:17.761259 140128494741248 run_lib.py:152] step: 306750, training_loss: 2.84397e+01
I0515 02:06:23.976185 140128494741248 run_lib.py:152] step: 306800, training_loss: 3.73586e+01
I0515 02:06:24.030866 140128494741248 run_lib.py:165] step: 306800, eval_loss: 2.59585e+01
I0515 02:06:30.406256 140128494741248 run_lib.py:152] step: 306850, training_loss: 3.82086e+01
I0515 02:06:36.584544 140128494741248 run_lib.py:152] step: 306900, training_loss: 3.22156e+01
I0515 02:06:36.638197 140128494741248 run_lib.py:165] step: 306900, eval_loss: 2.91796e+01
I0515 02:06:42.770868 140128494741248 run_lib.py:152] step: 306950, training_loss: 2.59806e+01
I0515 02:06:49.000267 140128494741248 run_lib.py:152] step: 307000, training_loss: 2.25421e+01
I0515 02:06:49.054772 140128494741248 run_lib.py:165] step: 307000, eval_loss: 1.13778e+01
I0515 02:06:55.468946 140128494741248 run_lib.py:152] step: 307050, training_loss: 3.66652e+01
I0515 02:07:01.598500 140128494741248 run_lib.py:152] step: 307100, training_loss: 2.78228e+01
I0515 02:07:01.646406 140128494741248 run_lib.py:165] step: 307100, eval_loss: 2.99313e+01
I0515 02:07:07.919240 140128494741248 run_lib.py:152] step: 307150, training_loss: 3.53685e+01
I0515 02:07:14.241769 140128494741248 run_lib.py:152] step: 307200, training_loss: 2.72685e+01
I0515 02:07:14.293939 140128494741248 run_lib.py:165] step: 307200, eval_loss: 3.88863e+01
I0515 02:07:20.354341 140128494741248 run_lib.py:152] step: 307250, training_loss: 3.96013e+01
I0515 02:07:26.524310 140128494741248 run_lib.py:152] step: 307300, training_loss: 2.76694e+01
I0515 02:07:26.576217 140128494741248 run_lib.py:165] step: 307300, eval_loss: 1.43370e+01
I0515 02:07:32.728864 140128494741248 run_lib.py:152] step: 307350, training_loss: 1.80524e+01
I0515 02:07:39.068701 140128494741248 run_lib.py:152] step: 307400, training_loss: 2.18100e+01
I0515 02:07:39.118816 140128494741248 run_lib.py:165] step: 307400, eval_loss: 3.18730e+01
I0515 02:07:45.351404 140128494741248 run_lib.py:152] step: 307450, training_loss: 3.88981e+01
I0515 02:07:51.533974 140128494741248 run_lib.py:152] step: 307500, training_loss: 3.48522e+01
I0515 02:07:51.590963 140128494741248 run_lib.py:165] step: 307500, eval_loss: 3.18464e+01
I0515 02:07:57.981162 140128494741248 run_lib.py:152] step: 307550, training_loss: 3.43542e+01
I0515 02:08:04.092698 140128494741248 run_lib.py:152] step: 307600, training_loss: 4.03173e+01
I0515 02:08:04.142198 140128494741248 run_lib.py:165] step: 307600, eval_loss: 2.21876e+01
I0515 02:08:10.322289 140128494741248 run_lib.py:152] step: 307650, training_loss: 3.58062e+01
I0515 02:08:16.498244 140128494741248 run_lib.py:152] step: 307700, training_loss: 3.74266e+01
I0515 02:08:16.549586 140128494741248 run_lib.py:165] step: 307700, eval_loss: 4.89751e+01
I0515 02:08:23.042069 140128494741248 run_lib.py:152] step: 307750, training_loss: 2.24974e+01
I0515 02:08:29.135821 140128494741248 run_lib.py:152] step: 307800, training_loss: 3.59468e+01
I0515 02:08:29.183566 140128494741248 run_lib.py:165] step: 307800, eval_loss: 2.58242e+01
I0515 02:08:35.218608 140128494741248 run_lib.py:152] step: 307850, training_loss: 3.59315e+01
I0515 02:08:41.577825 140128494741248 run_lib.py:152] step: 307900, training_loss: 2.00427e+01
I0515 02:08:41.628119 140128494741248 run_lib.py:165] step: 307900, eval_loss: 3.56508e+01
I0515 02:08:47.894464 140128494741248 run_lib.py:152] step: 307950, training_loss: 2.91854e+01
I0515 02:08:54.231392 140128494741248 run_lib.py:152] step: 308000, training_loss: 2.37546e+01
I0515 02:08:54.282688 140128494741248 run_lib.py:165] step: 308000, eval_loss: 4.78307e+01
I0515 02:09:00.517643 140128494741248 run_lib.py:152] step: 308050, training_loss: 3.72747e+01
I0515 02:09:07.053941 140128494741248 run_lib.py:152] step: 308100, training_loss: 4.89365e+01
I0515 02:09:07.105073 140128494741248 run_lib.py:165] step: 308100, eval_loss: 4.58153e+01
I0515 02:09:13.288543 140128494741248 run_lib.py:152] step: 308150, training_loss: 3.14785e+01
I0515 02:09:19.430298 140128494741248 run_lib.py:152] step: 308200, training_loss: 3.17492e+01
I0515 02:09:19.482515 140128494741248 run_lib.py:165] step: 308200, eval_loss: 2.98147e+01
I0515 02:09:26.067501 140128494741248 run_lib.py:152] step: 308250, training_loss: 5.45218e+01
I0515 02:09:32.166277 140128494741248 run_lib.py:152] step: 308300, training_loss: 3.94073e+01
I0515 02:09:32.218818 140128494741248 run_lib.py:165] step: 308300, eval_loss: 3.01782e+01
I0515 02:09:38.482661 140128494741248 run_lib.py:152] step: 308350, training_loss: 4.52767e+01
I0515 02:09:44.618181 140128494741248 run_lib.py:152] step: 308400, training_loss: 3.60255e+01
I0515 02:09:44.665435 140128494741248 run_lib.py:165] step: 308400, eval_loss: 3.79114e+01
I0515 02:09:51.072154 140128494741248 run_lib.py:152] step: 308450, training_loss: 2.42199e+01
I0515 02:09:57.203586 140128494741248 run_lib.py:152] step: 308500, training_loss: 2.32464e+01
I0515 02:09:57.257548 140128494741248 run_lib.py:165] step: 308500, eval_loss: 1.90381e+01
I0515 02:10:03.542968 140128494741248 run_lib.py:152] step: 308550, training_loss: 2.88478e+01
I0515 02:10:10.003256 140128494741248 run_lib.py:152] step: 308600, training_loss: 3.11555e+01
I0515 02:10:10.055480 140128494741248 run_lib.py:165] step: 308600, eval_loss: 4.73353e+01
I0515 02:10:16.153156 140128494741248 run_lib.py:152] step: 308650, training_loss: 2.63768e+01
I0515 02:10:22.403268 140128494741248 run_lib.py:152] step: 308700, training_loss: 3.52672e+01
I0515 02:10:22.459704 140128494741248 run_lib.py:165] step: 308700, eval_loss: 2.02785e+01
I0515 02:10:28.648025 140128494741248 run_lib.py:152] step: 308750, training_loss: 1.92673e+01
I0515 02:10:35.078787 140128494741248 run_lib.py:152] step: 308800, training_loss: 4.08723e+01
I0515 02:10:35.132575 140128494741248 run_lib.py:165] step: 308800, eval_loss: 2.52373e+01
I0515 02:10:41.363882 140128494741248 run_lib.py:152] step: 308850, training_loss: 2.47023e+01
I0515 02:10:47.635327 140128494741248 run_lib.py:152] step: 308900, training_loss: 2.87243e+01
I0515 02:10:47.689599 140128494741248 run_lib.py:165] step: 308900, eval_loss: 3.70988e+01
I0515 02:10:54.086856 140128494741248 run_lib.py:152] step: 308950, training_loss: 3.21240e+01
I0515 02:11:00.292041 140128494741248 run_lib.py:152] step: 309000, training_loss: 3.79189e+01
I0515 02:11:00.339939 140128494741248 run_lib.py:165] step: 309000, eval_loss: 3.09004e+01
I0515 02:11:06.611647 140128494741248 run_lib.py:152] step: 309050, training_loss: 3.52054e+01
I0515 02:11:12.836078 140128494741248 run_lib.py:152] step: 309100, training_loss: 3.46002e+01
I0515 02:11:12.886989 140128494741248 run_lib.py:165] step: 309100, eval_loss: 3.22597e+01
I0515 02:11:19.276107 140128494741248 run_lib.py:152] step: 309150, training_loss: 3.57127e+01
I0515 02:11:25.423028 140128494741248 run_lib.py:152] step: 309200, training_loss: 2.44828e+01
I0515 02:11:25.478549 140128494741248 run_lib.py:165] step: 309200, eval_loss: 3.76629e+01
I0515 02:11:31.682076 140128494741248 run_lib.py:152] step: 309250, training_loss: 3.57681e+01
I0515 02:11:38.159918 140128494741248 run_lib.py:152] step: 309300, training_loss: 3.70009e+01
I0515 02:11:38.210942 140128494741248 run_lib.py:165] step: 309300, eval_loss: 2.36238e+01
I0515 02:11:44.318409 140128494741248 run_lib.py:152] step: 309350, training_loss: 3.95526e+01
I0515 02:11:50.611622 140128494741248 run_lib.py:152] step: 309400, training_loss: 5.04253e+01
I0515 02:11:50.678935 140128494741248 run_lib.py:165] step: 309400, eval_loss: 2.42530e+01
I0515 02:11:56.806878 140128494741248 run_lib.py:152] step: 309450, training_loss: 2.88433e+01
I0515 02:12:03.322138 140128494741248 run_lib.py:152] step: 309500, training_loss: 4.11289e+01
I0515 02:12:03.380447 140128494741248 run_lib.py:165] step: 309500, eval_loss: 2.97182e+01
I0515 02:12:09.516551 140128494741248 run_lib.py:152] step: 309550, training_loss: 2.63189e+01
I0515 02:12:15.709404 140128494741248 run_lib.py:152] step: 309600, training_loss: 4.58340e+01
I0515 02:12:15.757621 140128494741248 run_lib.py:165] step: 309600, eval_loss: 3.31503e+01
I0515 02:12:22.177366 140128494741248 run_lib.py:152] step: 309650, training_loss: 2.83482e+01
I0515 02:12:28.273688 140128494741248 run_lib.py:152] step: 309700, training_loss: 3.72532e+01
I0515 02:12:28.326366 140128494741248 run_lib.py:165] step: 309700, eval_loss: 2.87685e+01
I0515 02:12:34.561646 140128494741248 run_lib.py:152] step: 309750, training_loss: 3.05026e+01
I0515 02:12:40.811043 140128494741248 run_lib.py:152] step: 309800, training_loss: 2.82348e+01
I0515 02:12:40.861164 140128494741248 run_lib.py:165] step: 309800, eval_loss: 3.18397e+01
I0515 02:12:47.299056 140128494741248 run_lib.py:152] step: 309850, training_loss: 2.18213e+01
I0515 02:12:53.517245 140128494741248 run_lib.py:152] step: 309900, training_loss: 4.06495e+01
I0515 02:12:53.582237 140128494741248 run_lib.py:165] step: 309900, eval_loss: 3.94819e+01
I0515 02:12:59.718764 140128494741248 run_lib.py:152] step: 309950, training_loss: 2.60397e+01
I0515 02:13:06.172404 140128494741248 run_lib.py:152] step: 310000, training_loss: 4.21251e+01
I0515 02:13:06.384320 140128494741248 run_lib.py:165] step: 310000, eval_loss: 3.17163e+01
I0515 02:13:12.651616 140128494741248 run_lib.py:152] step: 310050, training_loss: 2.01654e+01
I0515 02:13:18.804900 140128494741248 run_lib.py:152] step: 310100, training_loss: 4.05831e+01
I0515 02:13:18.858013 140128494741248 run_lib.py:165] step: 310100, eval_loss: 2.39728e+01
I0515 02:13:25.158706 140128494741248 run_lib.py:152] step: 310150, training_loss: 4.41155e+01
I0515 02:13:31.590635 140128494741248 run_lib.py:152] step: 310200, training_loss: 2.81665e+01
I0515 02:13:31.643569 140128494741248 run_lib.py:165] step: 310200, eval_loss: 2.70668e+01
I0515 02:13:37.753594 140128494741248 run_lib.py:152] step: 310250, training_loss: 3.04043e+01
I0515 02:13:44.048039 140128494741248 run_lib.py:152] step: 310300, training_loss: 4.20217e+01
I0515 02:13:44.097119 140128494741248 run_lib.py:165] step: 310300, eval_loss: 2.39045e+01
I0515 02:13:50.454282 140128494741248 run_lib.py:152] step: 310350, training_loss: 3.70656e+01
I0515 02:13:56.670700 140128494741248 run_lib.py:152] step: 310400, training_loss: 3.14860e+01
I0515 02:13:56.721746 140128494741248 run_lib.py:165] step: 310400, eval_loss: 2.55341e+01
I0515 02:14:02.959447 140128494741248 run_lib.py:152] step: 310450, training_loss: 3.43277e+01
I0515 02:14:09.133471 140128494741248 run_lib.py:152] step: 310500, training_loss: 3.73066e+01
I0515 02:14:09.186296 140128494741248 run_lib.py:165] step: 310500, eval_loss: 1.86048e+01
I0515 02:14:15.593571 140128494741248 run_lib.py:152] step: 310550, training_loss: 2.80020e+01
I0515 02:14:21.818927 140128494741248 run_lib.py:152] step: 310600, training_loss: 2.95804e+01
I0515 02:14:21.870053 140128494741248 run_lib.py:165] step: 310600, eval_loss: 3.01393e+01
I0515 02:14:28.115720 140128494741248 run_lib.py:152] step: 310650, training_loss: 2.08572e+01
I0515 02:14:34.439287 140128494741248 run_lib.py:152] step: 310700, training_loss: 3.35122e+01
I0515 02:14:34.488285 140128494741248 run_lib.py:165] step: 310700, eval_loss: 4.15695e+01
I0515 02:14:40.704162 140128494741248 run_lib.py:152] step: 310750, training_loss: 3.13567e+01
I0515 02:14:46.929631 140128494741248 run_lib.py:152] step: 310800, training_loss: 3.09884e+01
I0515 02:14:46.985505 140128494741248 run_lib.py:165] step: 310800, eval_loss: 4.61672e+01
I0515 02:14:53.077203 140128494741248 run_lib.py:152] step: 310850, training_loss: 2.95283e+01
I0515 02:14:59.476644 140128494741248 run_lib.py:152] step: 310900, training_loss: 3.11291e+01
I0515 02:14:59.523071 140128494741248 run_lib.py:165] step: 310900, eval_loss: 3.68293e+01
I0515 02:15:05.680612 140128494741248 run_lib.py:152] step: 310950, training_loss: 4.85936e+01
I0515 02:15:11.947511 140128494741248 run_lib.py:152] step: 311000, training_loss: 2.26786e+01
I0515 02:15:11.996712 140128494741248 run_lib.py:165] step: 311000, eval_loss: 5.28680e+01
I0515 02:15:18.357517 140128494741248 run_lib.py:152] step: 311050, training_loss: 1.81953e+01
I0515 02:15:24.541655 140128494741248 run_lib.py:152] step: 311100, training_loss: 2.31745e+01
I0515 02:15:24.595841 140128494741248 run_lib.py:165] step: 311100, eval_loss: 2.11321e+01
I0515 02:15:30.744169 140128494741248 run_lib.py:152] step: 311150, training_loss: 2.35459e+01
I0515 02:15:36.938972 140128494741248 run_lib.py:152] step: 311200, training_loss: 2.64584e+01
I0515 02:15:36.992982 140128494741248 run_lib.py:165] step: 311200, eval_loss: 2.93438e+01
I0515 02:15:43.429058 140128494741248 run_lib.py:152] step: 311250, training_loss: 4.03296e+01
I0515 02:15:49.790521 140128494741248 run_lib.py:152] step: 311300, training_loss: 3.14083e+01
I0515 02:15:49.839491 140128494741248 run_lib.py:165] step: 311300, eval_loss: 2.68564e+01
I0515 02:15:55.999160 140128494741248 run_lib.py:152] step: 311350, training_loss: 2.28085e+01
I0515 02:16:02.495247 140128494741248 run_lib.py:152] step: 311400, training_loss: 4.35898e+01
I0515 02:16:02.549518 140128494741248 run_lib.py:165] step: 311400, eval_loss: 3.20728e+01
I0515 02:16:08.724770 140128494741248 run_lib.py:152] step: 311450, training_loss: 4.10787e+01
I0515 02:16:14.791963 140128494741248 run_lib.py:152] step: 311500, training_loss: 3.00634e+01
I0515 02:16:14.846512 140128494741248 run_lib.py:165] step: 311500, eval_loss: 3.46163e+01
I0515 02:16:21.021558 140128494741248 run_lib.py:152] step: 311550, training_loss: 3.43478e+01
I0515 02:16:27.442025 140128494741248 run_lib.py:152] step: 311600, training_loss: 3.57837e+01
I0515 02:16:27.497831 140128494741248 run_lib.py:165] step: 311600, eval_loss: 2.14539e+01
I0515 02:16:33.680805 140128494741248 run_lib.py:152] step: 311650, training_loss: 3.59313e+01
I0515 02:16:39.823900 140128494741248 run_lib.py:152] step: 311700, training_loss: 3.64075e+01
I0515 02:16:39.874179 140128494741248 run_lib.py:165] step: 311700, eval_loss: 3.83497e+01
I0515 02:16:46.218764 140128494741248 run_lib.py:152] step: 311750, training_loss: 4.40581e+01
I0515 02:16:52.421814 140128494741248 run_lib.py:152] step: 311800, training_loss: 3.94991e+01
I0515 02:16:52.473662 140128494741248 run_lib.py:165] step: 311800, eval_loss: 3.25697e+01
I0515 02:16:58.734022 140128494741248 run_lib.py:152] step: 311850, training_loss: 3.45753e+01
I0515 02:17:05.045131 140128494741248 run_lib.py:152] step: 311900, training_loss: 2.43070e+01
I0515 02:17:05.102749 140128494741248 run_lib.py:165] step: 311900, eval_loss: 3.40730e+01
I0515 02:17:11.502432 140128494741248 run_lib.py:152] step: 311950, training_loss: 3.76291e+01
I0515 02:17:17.691049 140128494741248 run_lib.py:152] step: 312000, training_loss: 2.86568e+01
I0515 02:17:17.744422 140128494741248 run_lib.py:165] step: 312000, eval_loss: 2.34674e+01
I0515 02:17:23.904711 140128494741248 run_lib.py:152] step: 312050, training_loss: 2.59046e+01
I0515 02:17:30.364628 140128494741248 run_lib.py:152] step: 312100, training_loss: 3.56967e+01
I0515 02:17:30.419768 140128494741248 run_lib.py:165] step: 312100, eval_loss: 4.71413e+01
I0515 02:17:36.580309 140128494741248 run_lib.py:152] step: 312150, training_loss: 1.44642e+01
I0515 02:17:42.709056 140128494741248 run_lib.py:152] step: 312200, training_loss: 2.63370e+01
I0515 02:17:42.762840 140128494741248 run_lib.py:165] step: 312200, eval_loss: 2.35559e+01
I0515 02:17:49.001767 140128494741248 run_lib.py:152] step: 312250, training_loss: 3.59157e+01
I0515 02:17:55.458974 140128494741248 run_lib.py:152] step: 312300, training_loss: 1.86809e+01
I0515 02:17:55.510717 140128494741248 run_lib.py:165] step: 312300, eval_loss: 3.34438e+01
I0515 02:18:01.729389 140128494741248 run_lib.py:152] step: 312350, training_loss: 3.67419e+01
I0515 02:18:07.898509 140128494741248 run_lib.py:152] step: 312400, training_loss: 2.90580e+01
I0515 02:18:07.951495 140128494741248 run_lib.py:165] step: 312400, eval_loss: 4.67266e+01
I0515 02:18:14.441996 140128494741248 run_lib.py:152] step: 312450, training_loss: 2.94854e+01
I0515 02:18:20.720090 140128494741248 run_lib.py:152] step: 312500, training_loss: 4.60914e+01
I0515 02:18:20.773498 140128494741248 run_lib.py:165] step: 312500, eval_loss: 2.67775e+01
I0515 02:18:27.004851 140128494741248 run_lib.py:152] step: 312550, training_loss: 3.08639e+01
I0515 02:18:33.211120 140128494741248 run_lib.py:152] step: 312600, training_loss: 2.99900e+01
I0515 02:18:33.263064 140128494741248 run_lib.py:165] step: 312600, eval_loss: 3.54935e+01
I0515 02:18:39.729761 140128494741248 run_lib.py:152] step: 312650, training_loss: 3.76176e+01
I0515 02:18:45.955573 140128494741248 run_lib.py:152] step: 312700, training_loss: 2.93152e+01
I0515 02:18:46.013380 140128494741248 run_lib.py:165] step: 312700, eval_loss: 1.75905e+01
I0515 02:18:52.210899 140128494741248 run_lib.py:152] step: 312750, training_loss: 3.17435e+01
I0515 02:18:58.609800 140128494741248 run_lib.py:152] step: 312800, training_loss: 3.63903e+01
I0515 02:18:58.663309 140128494741248 run_lib.py:165] step: 312800, eval_loss: 2.95696e+01
I0515 02:19:05.000046 140128494741248 run_lib.py:152] step: 312850, training_loss: 2.77252e+01
I0515 02:19:11.109155 140128494741248 run_lib.py:152] step: 312900, training_loss: 2.28198e+01
I0515 02:19:11.162895 140128494741248 run_lib.py:165] step: 312900, eval_loss: 3.53609e+01
I0515 02:19:17.396848 140128494741248 run_lib.py:152] step: 312950, training_loss: 3.42464e+01
I0515 02:19:23.822793 140128494741248 run_lib.py:152] step: 313000, training_loss: 2.72520e+01
I0515 02:19:23.875239 140128494741248 run_lib.py:165] step: 313000, eval_loss: 3.64255e+01
I0515 02:19:30.072724 140128494741248 run_lib.py:152] step: 313050, training_loss: 4.19520e+01
I0515 02:19:36.254765 140128494741248 run_lib.py:152] step: 313100, training_loss: 2.55159e+01
I0515 02:19:36.309883 140128494741248 run_lib.py:165] step: 313100, eval_loss: 2.39673e+01
I0515 02:19:42.732576 140128494741248 run_lib.py:152] step: 313150, training_loss: 3.08601e+01
I0515 02:19:49.002297 140128494741248 run_lib.py:152] step: 313200, training_loss: 4.11135e+01
I0515 02:19:49.051865 140128494741248 run_lib.py:165] step: 313200, eval_loss: 2.28173e+01
I0515 02:19:55.274113 140128494741248 run_lib.py:152] step: 313250, training_loss: 5.28780e+01
I0515 02:20:01.457299 140128494741248 run_lib.py:152] step: 313300, training_loss: 1.98875e+01
I0515 02:20:01.507411 140128494741248 run_lib.py:165] step: 313300, eval_loss: 2.81661e+01
I0515 02:20:07.948390 140128494741248 run_lib.py:152] step: 313350, training_loss: 3.22563e+01
I0515 02:20:14.208972 140128494741248 run_lib.py:152] step: 313400, training_loss: 3.03203e+01
I0515 02:20:14.262112 140128494741248 run_lib.py:165] step: 313400, eval_loss: 4.67332e+01
I0515 02:20:20.448072 140128494741248 run_lib.py:152] step: 313450, training_loss: 4.58711e+01
I0515 02:20:26.836960 140128494741248 run_lib.py:152] step: 313500, training_loss: 2.47206e+01
I0515 02:20:26.890100 140128494741248 run_lib.py:165] step: 313500, eval_loss: 2.98138e+01
I0515 02:20:33.050191 140128494741248 run_lib.py:152] step: 313550, training_loss: 2.36904e+01
I0515 02:20:39.322745 140128494741248 run_lib.py:152] step: 313600, training_loss: 2.39147e+01
I0515 02:20:39.374178 140128494741248 run_lib.py:165] step: 313600, eval_loss: 3.25743e+01
I0515 02:20:45.637742 140128494741248 run_lib.py:152] step: 313650, training_loss: 4.18811e+01
I0515 02:20:52.071740 140128494741248 run_lib.py:152] step: 313700, training_loss: 3.86388e+01
I0515 02:20:52.126229 140128494741248 run_lib.py:165] step: 313700, eval_loss: 3.05266e+01
I0515 02:20:58.321944 140128494741248 run_lib.py:152] step: 313750, training_loss: 2.92981e+01
I0515 02:21:04.570461 140128494741248 run_lib.py:152] step: 313800, training_loss: 2.25743e+01
I0515 02:21:04.627092 140128494741248 run_lib.py:165] step: 313800, eval_loss: 3.15592e+01
I0515 02:21:11.090038 140128494741248 run_lib.py:152] step: 313850, training_loss: 3.26795e+01
I0515 02:21:17.343712 140128494741248 run_lib.py:152] step: 313900, training_loss: 2.85671e+01
I0515 02:21:17.392376 140128494741248 run_lib.py:165] step: 313900, eval_loss: 2.97961e+01
I0515 02:21:23.685706 140128494741248 run_lib.py:152] step: 313950, training_loss: 2.75434e+01
I0515 02:21:29.840778 140128494741248 run_lib.py:152] step: 314000, training_loss: 3.79056e+01
I0515 02:21:29.898191 140128494741248 run_lib.py:165] step: 314000, eval_loss: 3.09514e+01
I0515 02:21:36.328525 140128494741248 run_lib.py:152] step: 314050, training_loss: 3.55574e+01
I0515 02:21:42.547611 140128494741248 run_lib.py:152] step: 314100, training_loss: 2.72036e+01
I0515 02:21:42.598405 140128494741248 run_lib.py:165] step: 314100, eval_loss: 2.03956e+01
I0515 02:21:48.845107 140128494741248 run_lib.py:152] step: 314150, training_loss: 2.68025e+01
I0515 02:21:55.384585 140128494741248 run_lib.py:152] step: 314200, training_loss: 2.27187e+01
I0515 02:21:55.430774 140128494741248 run_lib.py:165] step: 314200, eval_loss: 3.29375e+01
I0515 02:22:01.675311 140128494741248 run_lib.py:152] step: 314250, training_loss: 3.97760e+01
I0515 02:22:07.841959 140128494741248 run_lib.py:152] step: 314300, training_loss: 2.86646e+01
I0515 02:22:07.898609 140128494741248 run_lib.py:165] step: 314300, eval_loss: 1.91831e+01
I0515 02:22:14.010838 140128494741248 run_lib.py:152] step: 314350, training_loss: 2.29468e+01
I0515 02:22:20.458274 140128494741248 run_lib.py:152] step: 314400, training_loss: 1.96582e+01
I0515 02:22:20.513946 140128494741248 run_lib.py:165] step: 314400, eval_loss: 3.47280e+01
I0515 02:22:26.646612 140128494741248 run_lib.py:152] step: 314450, training_loss: 2.20492e+01
I0515 02:22:32.937326 140128494741248 run_lib.py:152] step: 314500, training_loss: 2.36603e+01
I0515 02:22:32.986217 140128494741248 run_lib.py:165] step: 314500, eval_loss: 2.33607e+01
I0515 02:22:39.401669 140128494741248 run_lib.py:152] step: 314550, training_loss: 3.64611e+01
I0515 02:22:45.600926 140128494741248 run_lib.py:152] step: 314600, training_loss: 3.15520e+01
I0515 02:22:45.653987 140128494741248 run_lib.py:165] step: 314600, eval_loss: 3.46843e+01
I0515 02:22:51.946120 140128494741248 run_lib.py:152] step: 314650, training_loss: 3.47687e+01
I0515 02:22:58.111649 140128494741248 run_lib.py:152] step: 314700, training_loss: 2.20685e+01
I0515 02:22:58.166145 140128494741248 run_lib.py:165] step: 314700, eval_loss: 3.46261e+01
I0515 02:23:04.546010 140128494741248 run_lib.py:152] step: 314750, training_loss: 3.46824e+01
I0515 02:23:10.782253 140128494741248 run_lib.py:152] step: 314800, training_loss: 2.39318e+01
I0515 02:23:10.835501 140128494741248 run_lib.py:165] step: 314800, eval_loss: 2.60288e+01
I0515 02:23:17.111956 140128494741248 run_lib.py:152] step: 314850, training_loss: 3.83807e+01
I0515 02:23:23.534824 140128494741248 run_lib.py:152] step: 314900, training_loss: 1.82621e+01
I0515 02:23:23.596530 140128494741248 run_lib.py:165] step: 314900, eval_loss: 3.11923e+01
I0515 02:23:29.929533 140128494741248 run_lib.py:152] step: 314950, training_loss: 2.58175e+01
I0515 02:23:36.182994 140128494741248 run_lib.py:152] step: 315000, training_loss: 2.65364e+01
I0515 02:23:36.235881 140128494741248 run_lib.py:165] step: 315000, eval_loss: 2.40598e+01
I0515 02:23:42.426254 140128494741248 run_lib.py:152] step: 315050, training_loss: 4.82879e+01
I0515 02:23:48.950760 140128494741248 run_lib.py:152] step: 315100, training_loss: 1.89671e+01
I0515 02:23:49.005566 140128494741248 run_lib.py:165] step: 315100, eval_loss: 3.22199e+01
I0515 02:23:55.197986 140128494741248 run_lib.py:152] step: 315150, training_loss: 3.00375e+01
I0515 02:24:01.439279 140128494741248 run_lib.py:152] step: 315200, training_loss: 3.21284e+01
I0515 02:24:01.495587 140128494741248 run_lib.py:165] step: 315200, eval_loss: 3.54508e+01
I0515 02:24:08.083982 140128494741248 run_lib.py:152] step: 315250, training_loss: 2.66152e+01
I0515 02:24:14.364151 140128494741248 run_lib.py:152] step: 315300, training_loss: 4.24841e+01
I0515 02:24:14.415368 140128494741248 run_lib.py:165] step: 315300, eval_loss: 2.95771e+01
I0515 02:24:20.695321 140128494741248 run_lib.py:152] step: 315350, training_loss: 2.82544e+01
I0515 02:24:26.869889 140128494741248 run_lib.py:152] step: 315400, training_loss: 3.60401e+01
I0515 02:24:26.933616 140128494741248 run_lib.py:165] step: 315400, eval_loss: 4.32536e+01
I0515 02:24:33.292397 140128494741248 run_lib.py:152] step: 315450, training_loss: 4.15276e+01
I0515 02:24:39.550936 140128494741248 run_lib.py:152] step: 315500, training_loss: 2.09520e+01
I0515 02:24:39.603879 140128494741248 run_lib.py:165] step: 315500, eval_loss: 2.23161e+01
I0515 02:24:45.845399 140128494741248 run_lib.py:152] step: 315550, training_loss: 3.42212e+01
I0515 02:24:52.270460 140128494741248 run_lib.py:152] step: 315600, training_loss: 2.80887e+01
I0515 02:24:52.319786 140128494741248 run_lib.py:165] step: 315600, eval_loss: 2.36062e+01
I0515 02:24:58.564141 140128494741248 run_lib.py:152] step: 315650, training_loss: 4.78524e+01
I0515 02:25:04.762877 140128494741248 run_lib.py:152] step: 315700, training_loss: 2.64423e+01
I0515 02:25:04.814049 140128494741248 run_lib.py:165] step: 315700, eval_loss: 4.69911e+01
I0515 02:25:11.047185 140128494741248 run_lib.py:152] step: 315750, training_loss: 2.80497e+01
I0515 02:25:17.530593 140128494741248 run_lib.py:152] step: 315800, training_loss: 2.36322e+01
I0515 02:25:17.585637 140128494741248 run_lib.py:165] step: 315800, eval_loss: 3.74070e+01
I0515 02:25:23.901585 140128494741248 run_lib.py:152] step: 315850, training_loss: 4.39818e+01
I0515 02:25:30.083220 140128494741248 run_lib.py:152] step: 315900, training_loss: 3.13378e+01
I0515 02:25:30.135625 140128494741248 run_lib.py:165] step: 315900, eval_loss: 3.27939e+01
I0515 02:25:36.595751 140128494741248 run_lib.py:152] step: 315950, training_loss: 2.22417e+01
I0515 02:25:42.841501 140128494741248 run_lib.py:152] step: 316000, training_loss: 2.06342e+01
I0515 02:25:42.900348 140128494741248 run_lib.py:165] step: 316000, eval_loss: 2.21423e+01
I0515 02:25:49.141318 140128494741248 run_lib.py:152] step: 316050, training_loss: 3.45991e+01
I0515 02:25:55.433827 140128494741248 run_lib.py:152] step: 316100, training_loss: 3.47009e+01
I0515 02:25:55.488440 140128494741248 run_lib.py:165] step: 316100, eval_loss: 3.84145e+01
I0515 02:26:01.917580 140128494741248 run_lib.py:152] step: 316150, training_loss: 2.39251e+01
I0515 02:26:08.176912 140128494741248 run_lib.py:152] step: 316200, training_loss: 4.21989e+01
I0515 02:26:08.227128 140128494741248 run_lib.py:165] step: 316200, eval_loss: 3.03820e+01
I0515 02:26:14.404441 140128494741248 run_lib.py:152] step: 316250, training_loss: 4.33944e+01
I0515 02:26:20.874821 140128494741248 run_lib.py:152] step: 316300, training_loss: 3.70534e+01
I0515 02:26:20.925337 140128494741248 run_lib.py:165] step: 316300, eval_loss: 2.59202e+01
I0515 02:26:27.147178 140128494741248 run_lib.py:152] step: 316350, training_loss: 3.14370e+01
I0515 02:26:33.354935 140128494741248 run_lib.py:152] step: 316400, training_loss: 3.29486e+01
I0515 02:26:33.406728 140128494741248 run_lib.py:165] step: 316400, eval_loss: 1.78192e+01
I0515 02:26:39.593373 140128494741248 run_lib.py:152] step: 316450, training_loss: 2.75342e+01
I0515 02:26:46.041302 140128494741248 run_lib.py:152] step: 316500, training_loss: 3.21923e+01
I0515 02:26:46.099792 140128494741248 run_lib.py:165] step: 316500, eval_loss: 3.88850e+01
I0515 02:26:52.339777 140128494741248 run_lib.py:152] step: 316550, training_loss: 3.35157e+01
I0515 02:26:58.496584 140128494741248 run_lib.py:152] step: 316600, training_loss: 2.83715e+01
I0515 02:26:58.549247 140128494741248 run_lib.py:165] step: 316600, eval_loss: 2.45164e+01
I0515 02:27:04.963926 140128494741248 run_lib.py:152] step: 316650, training_loss: 2.13962e+01
I0515 02:27:11.103519 140128494741248 run_lib.py:152] step: 316700, training_loss: 2.05953e+01
I0515 02:27:11.149789 140128494741248 run_lib.py:165] step: 316700, eval_loss: 3.37785e+01
I0515 02:27:17.354111 140128494741248 run_lib.py:152] step: 316750, training_loss: 3.49503e+01
I0515 02:27:23.493703 140128494741248 run_lib.py:152] step: 316800, training_loss: 2.79605e+01
I0515 02:27:23.543406 140128494741248 run_lib.py:165] step: 316800, eval_loss: 2.49297e+01
I0515 02:27:29.970257 140128494741248 run_lib.py:152] step: 316850, training_loss: 2.51042e+01
I0515 02:27:36.223303 140128494741248 run_lib.py:152] step: 316900, training_loss: 2.18453e+01
I0515 02:27:36.272748 140128494741248 run_lib.py:165] step: 316900, eval_loss: 3.49341e+01
I0515 02:27:42.478474 140128494741248 run_lib.py:152] step: 316950, training_loss: 2.49784e+01
I0515 02:27:48.886393 140128494741248 run_lib.py:152] step: 317000, training_loss: 2.80129e+01
I0515 02:27:48.944115 140128494741248 run_lib.py:165] step: 317000, eval_loss: 3.96922e+01
I0515 02:27:55.157588 140128494741248 run_lib.py:152] step: 317050, training_loss: 3.11831e+01
I0515 02:28:01.254385 140128494741248 run_lib.py:152] step: 317100, training_loss: 4.00456e+01
I0515 02:28:01.306653 140128494741248 run_lib.py:165] step: 317100, eval_loss: 4.95540e+01
I0515 02:28:07.561819 140128494741248 run_lib.py:152] step: 317150, training_loss: 2.74682e+01
I0515 02:28:13.847505 140128494741248 run_lib.py:152] step: 317200, training_loss: 2.58325e+01
I0515 02:28:13.897938 140128494741248 run_lib.py:165] step: 317200, eval_loss: 3.88252e+01
I0515 02:28:20.145796 140128494741248 run_lib.py:152] step: 317250, training_loss: 4.87621e+01
I0515 02:28:26.339818 140128494741248 run_lib.py:152] step: 317300, training_loss: 3.99953e+01
I0515 02:28:26.390345 140128494741248 run_lib.py:165] step: 317300, eval_loss: 4.03351e+01
I0515 02:28:32.839653 140128494741248 run_lib.py:152] step: 317350, training_loss: 4.55014e+01
I0515 02:28:38.982238 140128494741248 run_lib.py:152] step: 317400, training_loss: 3.55249e+01
I0515 02:28:39.028358 140128494741248 run_lib.py:165] step: 317400, eval_loss: 1.86337e+01
I0515 02:28:45.254212 140128494741248 run_lib.py:152] step: 317450, training_loss: 3.40981e+01
I0515 02:28:51.386697 140128494741248 run_lib.py:152] step: 317500, training_loss: 3.25317e+01
I0515 02:28:51.439223 140128494741248 run_lib.py:165] step: 317500, eval_loss: 3.62675e+01
I0515 02:28:57.913879 140128494741248 run_lib.py:152] step: 317550, training_loss: 2.19677e+01
I0515 02:29:04.147174 140128494741248 run_lib.py:152] step: 317600, training_loss: 3.20386e+01
I0515 02:29:04.200123 140128494741248 run_lib.py:165] step: 317600, eval_loss: 1.92087e+01
I0515 02:29:10.404312 140128494741248 run_lib.py:152] step: 317650, training_loss: 3.39511e+01
I0515 02:29:16.789761 140128494741248 run_lib.py:152] step: 317700, training_loss: 2.27453e+01
I0515 02:29:16.836971 140128494741248 run_lib.py:165] step: 317700, eval_loss: 5.94348e+01
I0515 02:29:23.074070 140128494741248 run_lib.py:152] step: 317750, training_loss: 2.10809e+01
I0515 02:29:29.286171 140128494741248 run_lib.py:152] step: 317800, training_loss: 2.72758e+01
I0515 02:29:29.343272 140128494741248 run_lib.py:165] step: 317800, eval_loss: 3.27985e+01
I0515 02:29:35.561742 140128494741248 run_lib.py:152] step: 317850, training_loss: 2.37824e+01
I0515 02:29:41.994021 140128494741248 run_lib.py:152] step: 317900, training_loss: 4.99774e+01
I0515 02:29:42.044882 140128494741248 run_lib.py:165] step: 317900, eval_loss: 2.05406e+01
I0515 02:29:48.162691 140128494741248 run_lib.py:152] step: 317950, training_loss: 3.23920e+01
I0515 02:29:54.413608 140128494741248 run_lib.py:152] step: 318000, training_loss: 2.63991e+01
I0515 02:29:54.465762 140128494741248 run_lib.py:165] step: 318000, eval_loss: 3.67267e+01
I0515 02:30:00.827320 140128494741248 run_lib.py:152] step: 318050, training_loss: 3.43000e+01
I0515 02:30:07.072665 140128494741248 run_lib.py:152] step: 318100, training_loss: 3.55207e+01
I0515 02:30:07.128063 140128494741248 run_lib.py:165] step: 318100, eval_loss: 2.30506e+01
I0515 02:30:13.280394 140128494741248 run_lib.py:152] step: 318150, training_loss: 3.61251e+01
I0515 02:30:19.530103 140128494741248 run_lib.py:152] step: 318200, training_loss: 3.74091e+01
I0515 02:30:19.585387 140128494741248 run_lib.py:165] step: 318200, eval_loss: 2.77793e+01
I0515 02:30:25.975100 140128494741248 run_lib.py:152] step: 318250, training_loss: 3.85680e+01
I0515 02:30:32.223273 140128494741248 run_lib.py:152] step: 318300, training_loss: 3.72290e+01
I0515 02:30:32.275140 140128494741248 run_lib.py:165] step: 318300, eval_loss: 3.58674e+01
I0515 02:30:38.466750 140128494741248 run_lib.py:152] step: 318350, training_loss: 3.13799e+01
I0515 02:30:44.966192 140128494741248 run_lib.py:152] step: 318400, training_loss: 2.89939e+01
I0515 02:30:45.023768 140128494741248 run_lib.py:165] step: 318400, eval_loss: 1.52671e+01
I0515 02:30:51.107438 140128494741248 run_lib.py:152] step: 318450, training_loss: 2.80381e+01
I0515 02:30:57.345672 140128494741248 run_lib.py:152] step: 318500, training_loss: 3.17001e+01
I0515 02:30:57.396928 140128494741248 run_lib.py:165] step: 318500, eval_loss: 3.94955e+01
I0515 02:31:03.546336 140128494741248 run_lib.py:152] step: 318550, training_loss: 4.32018e+01
I0515 02:31:09.994809 140128494741248 run_lib.py:152] step: 318600, training_loss: 2.24537e+01
I0515 02:31:10.043999 140128494741248 run_lib.py:165] step: 318600, eval_loss: 1.88207e+01
I0515 02:31:16.174586 140128494741248 run_lib.py:152] step: 318650, training_loss: 2.28517e+01
I0515 02:31:22.391033 140128494741248 run_lib.py:152] step: 318700, training_loss: 4.27651e+01
I0515 02:31:22.445716 140128494741248 run_lib.py:165] step: 318700, eval_loss: 2.43790e+01
I0515 02:31:28.849922 140128494741248 run_lib.py:152] step: 318750, training_loss: 2.78748e+01
I0515 02:31:35.100557 140128494741248 run_lib.py:152] step: 318800, training_loss: 3.45077e+01
I0515 02:31:35.152112 140128494741248 run_lib.py:165] step: 318800, eval_loss: 2.48447e+01
I0515 02:31:41.454949 140128494741248 run_lib.py:152] step: 318850, training_loss: 2.97184e+01
I0515 02:31:47.646363 140128494741248 run_lib.py:152] step: 318900, training_loss: 2.30260e+01
I0515 02:31:47.700441 140128494741248 run_lib.py:165] step: 318900, eval_loss: 3.50719e+01
I0515 02:31:54.194209 140128494741248 run_lib.py:152] step: 318950, training_loss: 3.72432e+01
I0515 02:32:00.437790 140128494741248 run_lib.py:152] step: 319000, training_loss: 2.87797e+01
I0515 02:32:00.495511 140128494741248 run_lib.py:165] step: 319000, eval_loss: 2.35068e+01
I0515 02:32:06.785485 140128494741248 run_lib.py:152] step: 319050, training_loss: 1.84525e+01
I0515 02:32:13.166856 140128494741248 run_lib.py:152] step: 319100, training_loss: 2.39082e+01
I0515 02:32:13.219809 140128494741248 run_lib.py:165] step: 319100, eval_loss: 2.72648e+01
I0515 02:32:19.446096 140128494741248 run_lib.py:152] step: 319150, training_loss: 3.81956e+01
I0515 02:32:25.724953 140128494741248 run_lib.py:152] step: 319200, training_loss: 3.48443e+01
I0515 02:32:25.775224 140128494741248 run_lib.py:165] step: 319200, eval_loss: 5.24212e+01
I0515 02:32:31.948282 140128494741248 run_lib.py:152] step: 319250, training_loss: 3.39451e+01
I0515 02:32:38.435207 140128494741248 run_lib.py:152] step: 319300, training_loss: 4.38233e+01
I0515 02:32:38.491936 140128494741248 run_lib.py:165] step: 319300, eval_loss: 3.91007e+01
I0515 02:32:44.686542 140128494741248 run_lib.py:152] step: 319350, training_loss: 3.98330e+01
I0515 02:32:50.932254 140128494741248 run_lib.py:152] step: 319400, training_loss: 1.73376e+01
I0515 02:32:50.980381 140128494741248 run_lib.py:165] step: 319400, eval_loss: 3.06731e+01
I0515 02:32:57.499168 140128494741248 run_lib.py:152] step: 319450, training_loss: 3.55687e+01
I0515 02:33:03.568078 140128494741248 run_lib.py:152] step: 319500, training_loss: 4.41157e+01
I0515 02:33:03.616675 140128494741248 run_lib.py:165] step: 319500, eval_loss: 2.28211e+01
I0515 02:33:09.841994 140128494741248 run_lib.py:152] step: 319550, training_loss: 4.21569e+01
I0515 02:33:15.868385 140128494741248 run_lib.py:152] step: 319600, training_loss: 2.59046e+01
I0515 02:33:15.918926 140128494741248 run_lib.py:165] step: 319600, eval_loss: 3.20646e+01
I0515 02:33:22.276251 140128494741248 run_lib.py:152] step: 319650, training_loss: 2.95194e+01
I0515 02:33:28.507539 140128494741248 run_lib.py:152] step: 319700, training_loss: 3.22801e+01
I0515 02:33:28.562103 140128494741248 run_lib.py:165] step: 319700, eval_loss: 3.30810e+01
I0515 02:33:34.773111 140128494741248 run_lib.py:152] step: 319750, training_loss: 3.14555e+01
I0515 02:33:41.355543 140128494741248 run_lib.py:152] step: 319800, training_loss: 2.16027e+01
I0515 02:33:41.405694 140128494741248 run_lib.py:165] step: 319800, eval_loss: 3.57751e+01
I0515 02:33:47.641382 140128494741248 run_lib.py:152] step: 319850, training_loss: 4.65107e+01
I0515 02:33:53.820720 140128494741248 run_lib.py:152] step: 319900, training_loss: 2.00688e+01
I0515 02:33:53.871610 140128494741248 run_lib.py:165] step: 319900, eval_loss: 2.74206e+01
I0515 02:34:00.134171 140128494741248 run_lib.py:152] step: 319950, training_loss: 4.69962e+01
I0515 02:34:06.485929 140128494741248 run_lib.py:152] step: 320000, training_loss: 2.67161e+01
I0515 02:34:06.691269 140128494741248 run_lib.py:165] step: 320000, eval_loss: 1.85949e+01
I0515 02:34:12.902044 140128494741248 run_lib.py:152] step: 320050, training_loss: 3.30530e+01
I0515 02:34:19.167916 140128494741248 run_lib.py:152] step: 320100, training_loss: 4.06904e+01
I0515 02:34:19.219636 140128494741248 run_lib.py:165] step: 320100, eval_loss: 2.19759e+01
I0515 02:34:25.748081 140128494741248 run_lib.py:152] step: 320150, training_loss: 3.46536e+01
I0515 02:34:31.979396 140128494741248 run_lib.py:152] step: 320200, training_loss: 4.97536e+01
I0515 02:34:32.032296 140128494741248 run_lib.py:165] step: 320200, eval_loss: 3.98087e+01
I0515 02:34:38.277384 140128494741248 run_lib.py:152] step: 320250, training_loss: 2.29688e+01
I0515 02:34:44.433713 140128494741248 run_lib.py:152] step: 320300, training_loss: 5.08895e+01
I0515 02:34:44.487971 140128494741248 run_lib.py:165] step: 320300, eval_loss: 2.72275e+01
I0515 02:34:50.944677 140128494741248 run_lib.py:152] step: 320350, training_loss: 3.30878e+01
I0515 02:34:57.200383 140128494741248 run_lib.py:152] step: 320400, training_loss: 3.65624e+01
I0515 02:34:57.249509 140128494741248 run_lib.py:165] step: 320400, eval_loss: 2.43326e+01
I0515 02:35:03.485685 140128494741248 run_lib.py:152] step: 320450, training_loss: 4.74249e+01
I0515 02:35:09.974552 140128494741248 run_lib.py:152] step: 320500, training_loss: 3.40012e+01
I0515 02:35:10.027526 140128494741248 run_lib.py:165] step: 320500, eval_loss: 3.49363e+01
I0515 02:35:16.305788 140128494741248 run_lib.py:152] step: 320550, training_loss: 3.45907e+01
I0515 02:35:22.486222 140128494741248 run_lib.py:152] step: 320600, training_loss: 2.33825e+01
I0515 02:35:22.536508 140128494741248 run_lib.py:165] step: 320600, eval_loss: 4.33939e+01
I0515 02:35:28.670440 140128494741248 run_lib.py:152] step: 320650, training_loss: 3.80976e+01
I0515 02:35:35.199141 140128494741248 run_lib.py:152] step: 320700, training_loss: 3.47654e+01
I0515 02:35:35.250852 140128494741248 run_lib.py:165] step: 320700, eval_loss: 2.19598e+01
I0515 02:35:41.484192 140128494741248 run_lib.py:152] step: 320750, training_loss: 3.16459e+01
I0515 02:35:47.651817 140128494741248 run_lib.py:152] step: 320800, training_loss: 1.34368e+01
I0515 02:35:47.703088 140128494741248 run_lib.py:165] step: 320800, eval_loss: 2.61841e+01
I0515 02:35:54.144140 140128494741248 run_lib.py:152] step: 320850, training_loss: 3.01049e+01
I0515 02:36:00.425573 140128494741248 run_lib.py:152] step: 320900, training_loss: 2.59790e+01
I0515 02:36:00.474287 140128494741248 run_lib.py:165] step: 320900, eval_loss: 3.14288e+01
I0515 02:36:06.651833 140128494741248 run_lib.py:152] step: 320950, training_loss: 2.14218e+01
I0515 02:36:12.821567 140128494741248 run_lib.py:152] step: 321000, training_loss: 3.04093e+01
I0515 02:36:12.878508 140128494741248 run_lib.py:165] step: 321000, eval_loss: 2.67697e+01
I0515 02:36:19.221394 140128494741248 run_lib.py:152] step: 321050, training_loss: 2.62813e+01
I0515 02:36:25.487295 140128494741248 run_lib.py:152] step: 321100, training_loss: 1.79113e+01
I0515 02:36:25.540235 140128494741248 run_lib.py:165] step: 321100, eval_loss: 2.29862e+01
I0515 02:36:31.744439 140128494741248 run_lib.py:152] step: 321150, training_loss: 3.16363e+01
I0515 02:36:38.222642 140128494741248 run_lib.py:152] step: 321200, training_loss: 3.97137e+01
I0515 02:36:38.271810 140128494741248 run_lib.py:165] step: 321200, eval_loss: 3.11933e+01
I0515 02:36:44.393224 140128494741248 run_lib.py:152] step: 321250, training_loss: 2.97432e+01
I0515 02:36:50.531611 140128494741248 run_lib.py:152] step: 321300, training_loss: 2.24145e+01
I0515 02:36:50.583216 140128494741248 run_lib.py:165] step: 321300, eval_loss: 2.42447e+01
I0515 02:36:56.828433 140128494741248 run_lib.py:152] step: 321350, training_loss: 3.40062e+01
I0515 02:37:03.356394 140128494741248 run_lib.py:152] step: 321400, training_loss: 2.35299e+01
I0515 02:37:03.413803 140128494741248 run_lib.py:165] step: 321400, eval_loss: 4.36597e+01
I0515 02:37:09.570688 140128494741248 run_lib.py:152] step: 321450, training_loss: 2.67478e+01
I0515 02:37:15.661104 140128494741248 run_lib.py:152] step: 321500, training_loss: 2.41288e+01
I0515 02:37:15.714345 140128494741248 run_lib.py:165] step: 321500, eval_loss: 5.72037e+01
I0515 02:37:22.078331 140128494741248 run_lib.py:152] step: 321550, training_loss: 3.04480e+01
I0515 02:37:28.298989 140128494741248 run_lib.py:152] step: 321600, training_loss: 3.60023e+01
I0515 02:37:28.355062 140128494741248 run_lib.py:165] step: 321600, eval_loss: 2.27318e+01
I0515 02:37:34.626313 140128494741248 run_lib.py:152] step: 321650, training_loss: 4.42888e+01
I0515 02:37:40.854386 140128494741248 run_lib.py:152] step: 321700, training_loss: 3.04624e+01
I0515 02:37:40.902845 140128494741248 run_lib.py:165] step: 321700, eval_loss: 2.61692e+01
I0515 02:37:47.388162 140128494741248 run_lib.py:152] step: 321750, training_loss: 4.40001e+01
I0515 02:37:53.490922 140128494741248 run_lib.py:152] step: 321800, training_loss: 2.84905e+01
I0515 02:37:53.543821 140128494741248 run_lib.py:165] step: 321800, eval_loss: 2.32547e+01
I0515 02:37:59.827103 140128494741248 run_lib.py:152] step: 321850, training_loss: 2.45550e+01
I0515 02:38:06.307420 140128494741248 run_lib.py:152] step: 321900, training_loss: 2.21713e+01
I0515 02:38:06.365599 140128494741248 run_lib.py:165] step: 321900, eval_loss: 2.59885e+01
I0515 02:38:12.549607 140128494741248 run_lib.py:152] step: 321950, training_loss: 3.40024e+01
I0515 02:38:18.752554 140128494741248 run_lib.py:152] step: 322000, training_loss: 2.48436e+01
I0515 02:38:18.803671 140128494741248 run_lib.py:165] step: 322000, eval_loss: 1.63064e+01
I0515 02:38:25.060729 140128494741248 run_lib.py:152] step: 322050, training_loss: 2.61624e+01
I0515 02:38:31.569570 140128494741248 run_lib.py:152] step: 322100, training_loss: 3.21908e+01
I0515 02:38:31.618885 140128494741248 run_lib.py:165] step: 322100, eval_loss: 4.02389e+01
I0515 02:38:37.853080 140128494741248 run_lib.py:152] step: 322150, training_loss: 2.65326e+01
I0515 02:38:44.057490 140128494741248 run_lib.py:152] step: 322200, training_loss: 3.73787e+01
I0515 02:38:44.107472 140128494741248 run_lib.py:165] step: 322200, eval_loss: 2.32942e+01
I0515 02:38:50.613228 140128494741248 run_lib.py:152] step: 322250, training_loss: 3.82444e+01
I0515 02:38:56.740825 140128494741248 run_lib.py:152] step: 322300, training_loss: 3.42594e+01
I0515 02:38:56.790263 140128494741248 run_lib.py:165] step: 322300, eval_loss: 2.50461e+01
I0515 02:39:02.906449 140128494741248 run_lib.py:152] step: 322350, training_loss: 3.90529e+01
I0515 02:39:09.088621 140128494741248 run_lib.py:152] step: 322400, training_loss: 2.07889e+01
I0515 02:39:09.139460 140128494741248 run_lib.py:165] step: 322400, eval_loss: 2.84745e+01
I0515 02:39:15.534551 140128494741248 run_lib.py:152] step: 322450, training_loss: 2.09114e+01
I0515 02:39:21.833910 140128494741248 run_lib.py:152] step: 322500, training_loss: 3.46023e+01
I0515 02:39:21.887733 140128494741248 run_lib.py:165] step: 322500, eval_loss: 2.15667e+01
I0515 02:39:28.041373 140128494741248 run_lib.py:152] step: 322550, training_loss: 4.28264e+01
I0515 02:39:34.393842 140128494741248 run_lib.py:152] step: 322600, training_loss: 3.95168e+01
I0515 02:39:34.443912 140128494741248 run_lib.py:165] step: 322600, eval_loss: 2.41350e+01
I0515 02:39:40.657164 140128494741248 run_lib.py:152] step: 322650, training_loss: 4.21803e+01
I0515 02:39:46.763915 140128494741248 run_lib.py:152] step: 322700, training_loss: 2.57256e+01
I0515 02:39:46.819326 140128494741248 run_lib.py:165] step: 322700, eval_loss: 2.45757e+01
I0515 02:39:53.088145 140128494741248 run_lib.py:152] step: 322750, training_loss: 3.03749e+01
I0515 02:39:59.439206 140128494741248 run_lib.py:152] step: 322800, training_loss: 3.10396e+01
I0515 02:39:59.491438 140128494741248 run_lib.py:165] step: 322800, eval_loss: 2.88338e+01
I0515 02:40:05.803251 140128494741248 run_lib.py:152] step: 322850, training_loss: 2.99250e+01
I0515 02:40:12.036381 140128494741248 run_lib.py:152] step: 322900, training_loss: 1.64075e+01
I0515 02:40:12.086621 140128494741248 run_lib.py:165] step: 322900, eval_loss: 3.82246e+01
I0515 02:40:18.483654 140128494741248 run_lib.py:152] step: 322950, training_loss: 3.86482e+01
I0515 02:40:24.709076 140128494741248 run_lib.py:152] step: 323000, training_loss: 2.29516e+01
I0515 02:40:24.765392 140128494741248 run_lib.py:165] step: 323000, eval_loss: 3.39044e+01
I0515 02:40:30.965312 140128494741248 run_lib.py:152] step: 323050, training_loss: 3.88012e+01
I0515 02:40:37.231977 140128494741248 run_lib.py:152] step: 323100, training_loss: 3.04364e+01
I0515 02:40:37.280358 140128494741248 run_lib.py:165] step: 323100, eval_loss: 3.47465e+01
I0515 02:40:43.790978 140128494741248 run_lib.py:152] step: 323150, training_loss: 4.51794e+01
I0515 02:40:49.883016 140128494741248 run_lib.py:152] step: 323200, training_loss: 4.18062e+01
I0515 02:40:49.934570 140128494741248 run_lib.py:165] step: 323200, eval_loss: 2.98059e+01
I0515 02:40:56.141100 140128494741248 run_lib.py:152] step: 323250, training_loss: 3.00122e+01
I0515 02:41:02.523612 140128494741248 run_lib.py:152] step: 323300, training_loss: 2.07161e+01
I0515 02:41:02.570852 140128494741248 run_lib.py:165] step: 323300, eval_loss: 3.66213e+01
I0515 02:41:08.743167 140128494741248 run_lib.py:152] step: 323350, training_loss: 3.70747e+01
I0515 02:41:14.867898 140128494741248 run_lib.py:152] step: 323400, training_loss: 3.72214e+01
I0515 02:41:14.915728 140128494741248 run_lib.py:165] step: 323400, eval_loss: 2.48779e+01
I0515 02:41:21.138702 140128494741248 run_lib.py:152] step: 323450, training_loss: 5.09924e+01
I0515 02:41:27.489032 140128494741248 run_lib.py:152] step: 323500, training_loss: 4.98402e+01
I0515 02:41:27.543429 140128494741248 run_lib.py:165] step: 323500, eval_loss: 2.01236e+01
I0515 02:41:33.784409 140128494741248 run_lib.py:152] step: 323550, training_loss: 3.54092e+01
I0515 02:41:39.928441 140128494741248 run_lib.py:152] step: 323600, training_loss: 2.11768e+01
I0515 02:41:39.978334 140128494741248 run_lib.py:165] step: 323600, eval_loss: 2.34469e+01
I0515 02:41:46.475599 140128494741248 run_lib.py:152] step: 323650, training_loss: 3.81902e+01
I0515 02:41:52.605517 140128494741248 run_lib.py:152] step: 323700, training_loss: 3.74232e+01
I0515 02:41:52.656946 140128494741248 run_lib.py:165] step: 323700, eval_loss: 2.80012e+01
I0515 02:41:58.856279 140128494741248 run_lib.py:152] step: 323750, training_loss: 3.33706e+01
I0515 02:42:05.021443 140128494741248 run_lib.py:152] step: 323800, training_loss: 3.62875e+01
I0515 02:42:05.067655 140128494741248 run_lib.py:165] step: 323800, eval_loss: 2.55139e+01
I0515 02:42:11.587523 140128494741248 run_lib.py:152] step: 323850, training_loss: 2.68148e+01
I0515 02:42:17.804056 140128494741248 run_lib.py:152] step: 323900, training_loss: 2.10880e+01
I0515 02:42:17.853210 140128494741248 run_lib.py:165] step: 323900, eval_loss: 2.48870e+01
I0515 02:42:24.049291 140128494741248 run_lib.py:152] step: 323950, training_loss: 2.54091e+01
I0515 02:42:30.379175 140128494741248 run_lib.py:152] step: 324000, training_loss: 2.20400e+01
I0515 02:42:30.431081 140128494741248 run_lib.py:165] step: 324000, eval_loss: 3.01535e+01
I0515 02:42:36.633536 140128494741248 run_lib.py:152] step: 324050, training_loss: 4.41432e+01
I0515 02:42:42.838630 140128494741248 run_lib.py:152] step: 324100, training_loss: 2.97571e+01
I0515 02:42:42.898209 140128494741248 run_lib.py:165] step: 324100, eval_loss: 3.44016e+01
I0515 02:42:49.056333 140128494741248 run_lib.py:152] step: 324150, training_loss: 3.69480e+01
I0515 02:42:55.457239 140128494741248 run_lib.py:152] step: 324200, training_loss: 3.52045e+01
I0515 02:42:55.512254 140128494741248 run_lib.py:165] step: 324200, eval_loss: 2.84406e+01
I0515 02:43:01.688857 140128494741248 run_lib.py:152] step: 324250, training_loss: 3.32263e+01
I0515 02:43:07.938891 140128494741248 run_lib.py:152] step: 324300, training_loss: 3.29492e+01
I0515 02:43:07.993307 140128494741248 run_lib.py:165] step: 324300, eval_loss: 1.66228e+01
I0515 02:43:14.423347 140128494741248 run_lib.py:152] step: 324350, training_loss: 3.31211e+01
I0515 02:43:20.622445 140128494741248 run_lib.py:152] step: 324400, training_loss: 3.34474e+01
I0515 02:43:20.670438 140128494741248 run_lib.py:165] step: 324400, eval_loss: 2.75736e+01
I0515 02:43:26.979600 140128494741248 run_lib.py:152] step: 324450, training_loss: 4.32247e+01
I0515 02:43:33.197731 140128494741248 run_lib.py:152] step: 324500, training_loss: 2.12075e+01
I0515 02:43:33.249978 140128494741248 run_lib.py:165] step: 324500, eval_loss: 3.31119e+01
I0515 02:43:39.676580 140128494741248 run_lib.py:152] step: 324550, training_loss: 2.81694e+01
I0515 02:43:45.874101 140128494741248 run_lib.py:152] step: 324600, training_loss: 5.40924e+01
I0515 02:43:45.931056 140128494741248 run_lib.py:165] step: 324600, eval_loss: 2.91689e+01
I0515 02:43:52.073041 140128494741248 run_lib.py:152] step: 324650, training_loss: 3.51396e+01
I0515 02:43:58.537962 140128494741248 run_lib.py:152] step: 324700, training_loss: 2.60569e+01
I0515 02:43:58.589569 140128494741248 run_lib.py:165] step: 324700, eval_loss: 1.94821e+01
I0515 02:44:04.737788 140128494741248 run_lib.py:152] step: 324750, training_loss: 3.30827e+01
I0515 02:44:10.958233 140128494741248 run_lib.py:152] step: 324800, training_loss: 2.62448e+01
I0515 02:44:11.018045 140128494741248 run_lib.py:165] step: 324800, eval_loss: 2.11584e+01
I0515 02:44:17.317138 140128494741248 run_lib.py:152] step: 324850, training_loss: 5.27237e+01
I0515 02:44:23.844258 140128494741248 run_lib.py:152] step: 324900, training_loss: 3.25533e+01
I0515 02:44:23.899432 140128494741248 run_lib.py:165] step: 324900, eval_loss: 2.03123e+01
I0515 02:44:30.193241 140128494741248 run_lib.py:152] step: 324950, training_loss: 3.02404e+01
I0515 02:44:36.422719 140128494741248 run_lib.py:152] step: 325000, training_loss: 3.50524e+01
I0515 02:44:36.474890 140128494741248 run_lib.py:165] step: 325000, eval_loss: 2.67220e+01
I0515 02:44:42.928675 140128494741248 run_lib.py:152] step: 325050, training_loss: 3.52866e+01
I0515 02:44:49.129871 140128494741248 run_lib.py:152] step: 325100, training_loss: 2.66052e+01
I0515 02:44:49.183482 140128494741248 run_lib.py:165] step: 325100, eval_loss: 2.12102e+01
I0515 02:44:55.368648 140128494741248 run_lib.py:152] step: 325150, training_loss: 3.90967e+01
I0515 02:45:01.561362 140128494741248 run_lib.py:152] step: 325200, training_loss: 3.07571e+01
I0515 02:45:01.614517 140128494741248 run_lib.py:165] step: 325200, eval_loss: 3.58743e+01
I0515 02:45:07.995081 140128494741248 run_lib.py:152] step: 325250, training_loss: 4.22400e+01
I0515 02:45:14.308469 140128494741248 run_lib.py:152] step: 325300, training_loss: 4.32288e+01
I0515 02:45:14.357938 140128494741248 run_lib.py:165] step: 325300, eval_loss: 1.47575e+01
I0515 02:45:20.481121 140128494741248 run_lib.py:152] step: 325350, training_loss: 3.14567e+01
I0515 02:45:26.828576 140128494741248 run_lib.py:152] step: 325400, training_loss: 4.71973e+01
I0515 02:45:26.878561 140128494741248 run_lib.py:165] step: 325400, eval_loss: 2.87728e+01
I0515 02:45:33.165695 140128494741248 run_lib.py:152] step: 325450, training_loss: 3.77054e+01
I0515 02:45:39.364706 140128494741248 run_lib.py:152] step: 325500, training_loss: 1.55120e+01
I0515 02:45:39.419202 140128494741248 run_lib.py:165] step: 325500, eval_loss: 3.71960e+01
I0515 02:45:45.641803 140128494741248 run_lib.py:152] step: 325550, training_loss: 3.05980e+01
I0515 02:45:52.183048 140128494741248 run_lib.py:152] step: 325600, training_loss: 2.64148e+01
I0515 02:45:52.236308 140128494741248 run_lib.py:165] step: 325600, eval_loss: 3.67387e+01
I0515 02:45:58.373805 140128494741248 run_lib.py:152] step: 325650, training_loss: 2.73893e+01
I0515 02:46:04.649252 140128494741248 run_lib.py:152] step: 325700, training_loss: 3.90955e+01
I0515 02:46:04.701269 140128494741248 run_lib.py:165] step: 325700, eval_loss: 2.57425e+01
I0515 02:46:11.124729 140128494741248 run_lib.py:152] step: 325750, training_loss: 3.67199e+01
I0515 02:46:17.399677 140128494741248 run_lib.py:152] step: 325800, training_loss: 2.89688e+01
I0515 02:46:17.450401 140128494741248 run_lib.py:165] step: 325800, eval_loss: 2.93579e+01
I0515 02:46:23.595157 140128494741248 run_lib.py:152] step: 325850, training_loss: 3.14848e+01
I0515 02:46:29.849856 140128494741248 run_lib.py:152] step: 325900, training_loss: 2.47642e+01
I0515 02:46:29.903447 140128494741248 run_lib.py:165] step: 325900, eval_loss: 2.82936e+01
I0515 02:46:36.452395 140128494741248 run_lib.py:152] step: 325950, training_loss: 3.64140e+01
I0515 02:46:42.620202 140128494741248 run_lib.py:152] step: 326000, training_loss: 2.64440e+01
I0515 02:46:42.670097 140128494741248 run_lib.py:165] step: 326000, eval_loss: 3.58826e+01
I0515 02:46:48.875483 140128494741248 run_lib.py:152] step: 326050, training_loss: 4.52145e+01
I0515 02:46:55.242002 140128494741248 run_lib.py:152] step: 326100, training_loss: 2.10108e+01
I0515 02:46:55.293483 140128494741248 run_lib.py:165] step: 326100, eval_loss: 3.39964e+01
I0515 02:47:01.553599 140128494741248 run_lib.py:152] step: 326150, training_loss: 4.14799e+01
I0515 02:47:07.633559 140128494741248 run_lib.py:152] step: 326200, training_loss: 2.91101e+01
I0515 02:47:07.686012 140128494741248 run_lib.py:165] step: 326200, eval_loss: 2.84064e+01
I0515 02:47:13.933120 140128494741248 run_lib.py:152] step: 326250, training_loss: 3.10051e+01
I0515 02:47:20.327821 140128494741248 run_lib.py:152] step: 326300, training_loss: 2.54868e+01
I0515 02:47:20.376889 140128494741248 run_lib.py:165] step: 326300, eval_loss: 5.19404e+01
I0515 02:47:26.636526 140128494741248 run_lib.py:152] step: 326350, training_loss: 3.42145e+01
I0515 02:47:32.822646 140128494741248 run_lib.py:152] step: 326400, training_loss: 3.03502e+01
I0515 02:47:32.879401 140128494741248 run_lib.py:165] step: 326400, eval_loss: 2.16973e+01
I0515 02:47:39.262124 140128494741248 run_lib.py:152] step: 326450, training_loss: 4.10387e+01
I0515 02:47:45.403254 140128494741248 run_lib.py:152] step: 326500, training_loss: 3.44550e+01
I0515 02:47:45.457051 140128494741248 run_lib.py:165] step: 326500, eval_loss: 2.21081e+01
I0515 02:47:51.673933 140128494741248 run_lib.py:152] step: 326550, training_loss: 2.26487e+01
I0515 02:47:57.813864 140128494741248 run_lib.py:152] step: 326600, training_loss: 3.07951e+01
I0515 02:47:57.863191 140128494741248 run_lib.py:165] step: 326600, eval_loss: 4.28689e+01
I0515 02:48:04.356680 140128494741248 run_lib.py:152] step: 326650, training_loss: 2.98148e+01
I0515 02:48:10.641156 140128494741248 run_lib.py:152] step: 326700, training_loss: 3.83684e+01
I0515 02:48:10.692898 140128494741248 run_lib.py:165] step: 326700, eval_loss: 3.62841e+01
I0515 02:48:16.919259 140128494741248 run_lib.py:152] step: 326750, training_loss: 2.05133e+01
I0515 02:48:23.422269 140128494741248 run_lib.py:152] step: 326800, training_loss: 2.25161e+01
I0515 02:48:23.473539 140128494741248 run_lib.py:165] step: 326800, eval_loss: 3.30176e+01
I0515 02:48:29.617601 140128494741248 run_lib.py:152] step: 326850, training_loss: 1.76190e+01
I0515 02:48:35.823590 140128494741248 run_lib.py:152] step: 326900, training_loss: 2.74638e+01
I0515 02:48:35.875167 140128494741248 run_lib.py:165] step: 326900, eval_loss: 2.48532e+01
I0515 02:48:42.108067 140128494741248 run_lib.py:152] step: 326950, training_loss: 3.75211e+01
I0515 02:48:48.597147 140128494741248 run_lib.py:152] step: 327000, training_loss: 4.81908e+01
I0515 02:48:48.651959 140128494741248 run_lib.py:165] step: 327000, eval_loss: 2.14108e+01
I0515 02:48:54.778624 140128494741248 run_lib.py:152] step: 327050, training_loss: 3.78222e+01
I0515 02:49:00.935171 140128494741248 run_lib.py:152] step: 327100, training_loss: 2.15241e+01
I0515 02:49:00.989506 140128494741248 run_lib.py:165] step: 327100, eval_loss: 2.10504e+01
I0515 02:49:07.439341 140128494741248 run_lib.py:152] step: 327150, training_loss: 2.58302e+01
I0515 02:49:13.662942 140128494741248 run_lib.py:152] step: 327200, training_loss: 3.28153e+01
I0515 02:49:13.713667 140128494741248 run_lib.py:165] step: 327200, eval_loss: 2.43834e+01
I0515 02:49:19.837094 140128494741248 run_lib.py:152] step: 327250, training_loss: 4.19417e+01
I0515 02:49:26.098978 140128494741248 run_lib.py:152] step: 327300, training_loss: 2.19754e+01
I0515 02:49:26.153666 140128494741248 run_lib.py:165] step: 327300, eval_loss: 4.37946e+01
I0515 02:49:32.676893 140128494741248 run_lib.py:152] step: 327350, training_loss: 2.40756e+01
I0515 02:49:38.782208 140128494741248 run_lib.py:152] step: 327400, training_loss: 2.88113e+01
I0515 02:49:38.830891 140128494741248 run_lib.py:165] step: 327400, eval_loss: 2.79176e+01
I0515 02:49:44.991641 140128494741248 run_lib.py:152] step: 327450, training_loss: 2.17862e+01
I0515 02:49:51.441456 140128494741248 run_lib.py:152] step: 327500, training_loss: 1.95086e+01
I0515 02:49:51.492915 140128494741248 run_lib.py:165] step: 327500, eval_loss: 2.65905e+01
I0515 02:49:57.730472 140128494741248 run_lib.py:152] step: 327550, training_loss: 4.58424e+01
I0515 02:50:03.985408 140128494741248 run_lib.py:152] step: 327600, training_loss: 2.52567e+01
I0515 02:50:04.043444 140128494741248 run_lib.py:165] step: 327600, eval_loss: 4.83529e+01
I0515 02:50:10.270473 140128494741248 run_lib.py:152] step: 327650, training_loss: 4.48217e+01
I0515 02:50:16.728251 140128494741248 run_lib.py:152] step: 327700, training_loss: 3.80286e+01
I0515 02:50:16.779536 140128494741248 run_lib.py:165] step: 327700, eval_loss: 3.99546e+01
I0515 02:50:22.979183 140128494741248 run_lib.py:152] step: 327750, training_loss: 4.43319e+01
I0515 02:50:29.099841 140128494741248 run_lib.py:152] step: 327800, training_loss: 4.53299e+01
I0515 02:50:29.148386 140128494741248 run_lib.py:165] step: 327800, eval_loss: 2.16509e+01
I0515 02:50:35.678272 140128494741248 run_lib.py:152] step: 327850, training_loss: 2.63744e+01
I0515 02:50:41.890165 140128494741248 run_lib.py:152] step: 327900, training_loss: 3.96827e+01
I0515 02:50:41.950786 140128494741248 run_lib.py:165] step: 327900, eval_loss: 3.14924e+01
I0515 02:50:48.192360 140128494741248 run_lib.py:152] step: 327950, training_loss: 3.99573e+01
I0515 02:50:54.400115 140128494741248 run_lib.py:152] step: 328000, training_loss: 3.22426e+01
I0515 02:50:54.451111 140128494741248 run_lib.py:165] step: 328000, eval_loss: 4.19229e+01
I0515 02:51:00.943656 140128494741248 run_lib.py:152] step: 328050, training_loss: 2.73979e+01
I0515 02:51:07.260575 140128494741248 run_lib.py:152] step: 328100, training_loss: 2.93501e+01
I0515 02:51:07.312643 140128494741248 run_lib.py:165] step: 328100, eval_loss: 3.05546e+01
I0515 02:51:13.512763 140128494741248 run_lib.py:152] step: 328150, training_loss: 1.80677e+01
I0515 02:51:19.992213 140128494741248 run_lib.py:152] step: 328200, training_loss: 3.10224e+01
I0515 02:51:20.043511 140128494741248 run_lib.py:165] step: 328200, eval_loss: 2.77363e+01
I0515 02:51:26.232015 140128494741248 run_lib.py:152] step: 328250, training_loss: 3.35157e+01
I0515 02:51:32.397751 140128494741248 run_lib.py:152] step: 328300, training_loss: 3.24091e+01
I0515 02:51:32.446631 140128494741248 run_lib.py:165] step: 328300, eval_loss: 2.67287e+01
I0515 02:51:38.644940 140128494741248 run_lib.py:152] step: 328350, training_loss: 2.98630e+01
I0515 02:51:45.069210 140128494741248 run_lib.py:152] step: 328400, training_loss: 1.96599e+01
I0515 02:51:45.121958 140128494741248 run_lib.py:165] step: 328400, eval_loss: 2.47142e+01
I0515 02:51:51.374992 140128494741248 run_lib.py:152] step: 328450, training_loss: 2.06792e+01
I0515 02:51:57.586217 140128494741248 run_lib.py:152] step: 328500, training_loss: 2.32482e+01
I0515 02:51:57.633898 140128494741248 run_lib.py:165] step: 328500, eval_loss: 3.43880e+01
I0515 02:52:04.116340 140128494741248 run_lib.py:152] step: 328550, training_loss: 3.64602e+01
I0515 02:52:10.323772 140128494741248 run_lib.py:152] step: 328600, training_loss: 2.37644e+01
I0515 02:52:10.378196 140128494741248 run_lib.py:165] step: 328600, eval_loss: 3.50449e+01
I0515 02:52:16.651185 140128494741248 run_lib.py:152] step: 328650, training_loss: 3.75208e+01
I0515 02:52:22.758867 140128494741248 run_lib.py:152] step: 328700, training_loss: 2.98779e+01
I0515 02:52:22.811279 140128494741248 run_lib.py:165] step: 328700, eval_loss: 2.66887e+01
I0515 02:52:29.239376 140128494741248 run_lib.py:152] step: 328750, training_loss: 3.37292e+01
I0515 02:52:35.399910 140128494741248 run_lib.py:152] step: 328800, training_loss: 2.42703e+01
I0515 02:52:35.450962 140128494741248 run_lib.py:165] step: 328800, eval_loss: 3.37144e+01
I0515 02:52:41.712530 140128494741248 run_lib.py:152] step: 328850, training_loss: 3.58314e+01
I0515 02:52:48.045363 140128494741248 run_lib.py:152] step: 328900, training_loss: 2.22724e+01
I0515 02:52:48.093569 140128494741248 run_lib.py:165] step: 328900, eval_loss: 2.35409e+01
I0515 02:52:54.339300 140128494741248 run_lib.py:152] step: 328950, training_loss: 2.36832e+01
I0515 02:53:00.582258 140128494741248 run_lib.py:152] step: 329000, training_loss: 3.77986e+01
I0515 02:53:00.633857 140128494741248 run_lib.py:165] step: 329000, eval_loss: 4.39384e+01
I0515 02:53:06.827514 140128494741248 run_lib.py:152] step: 329050, training_loss: 2.11797e+01
I0515 02:53:13.194752 140128494741248 run_lib.py:152] step: 329100, training_loss: 3.60035e+01
I0515 02:53:13.245722 140128494741248 run_lib.py:165] step: 329100, eval_loss: 3.15990e+01
I0515 02:53:19.335266 140128494741248 run_lib.py:152] step: 329150, training_loss: 2.37339e+01
I0515 02:53:25.516017 140128494741248 run_lib.py:152] step: 329200, training_loss: 1.90328e+01
I0515 02:53:25.572952 140128494741248 run_lib.py:165] step: 329200, eval_loss: 3.76183e+01
I0515 02:53:32.054580 140128494741248 run_lib.py:152] step: 329250, training_loss: 4.28877e+01
I0515 02:53:38.362240 140128494741248 run_lib.py:152] step: 329300, training_loss: 2.91559e+01
I0515 02:53:38.419663 140128494741248 run_lib.py:165] step: 329300, eval_loss: 2.81590e+01
I0515 02:53:44.575194 140128494741248 run_lib.py:152] step: 329350, training_loss: 3.15602e+01
I0515 02:53:50.831560 140128494741248 run_lib.py:152] step: 329400, training_loss: 2.68897e+01
I0515 02:53:50.883119 140128494741248 run_lib.py:165] step: 329400, eval_loss: 2.16654e+01
I0515 02:53:57.302069 140128494741248 run_lib.py:152] step: 329450, training_loss: 2.46219e+01
I0515 02:54:03.559844 140128494741248 run_lib.py:152] step: 329500, training_loss: 2.95136e+01
I0515 02:54:03.613124 140128494741248 run_lib.py:165] step: 329500, eval_loss: 2.56112e+01
I0515 02:54:09.980920 140128494741248 run_lib.py:152] step: 329550, training_loss: 2.19054e+01
I0515 02:54:16.489078 140128494741248 run_lib.py:152] step: 329600, training_loss: 3.29922e+01
I0515 02:54:16.540057 140128494741248 run_lib.py:165] step: 329600, eval_loss: 1.95854e+01
I0515 02:54:22.710971 140128494741248 run_lib.py:152] step: 329650, training_loss: 4.20775e+01
I0515 02:54:28.991089 140128494741248 run_lib.py:152] step: 329700, training_loss: 3.41607e+01
I0515 02:54:29.042291 140128494741248 run_lib.py:165] step: 329700, eval_loss: 4.71149e+01
I0515 02:54:35.236562 140128494741248 run_lib.py:152] step: 329750, training_loss: 3.46762e+01
I0515 02:54:41.588523 140128494741248 run_lib.py:152] step: 329800, training_loss: 2.13788e+01
I0515 02:54:41.637357 140128494741248 run_lib.py:165] step: 329800, eval_loss: 3.21038e+01
I0515 02:54:47.765459 140128494741248 run_lib.py:152] step: 329850, training_loss: 3.03594e+01
I0515 02:54:53.980497 140128494741248 run_lib.py:152] step: 329900, training_loss: 3.47647e+01
I0515 02:54:54.027717 140128494741248 run_lib.py:165] step: 329900, eval_loss: 4.56993e+01
I0515 02:55:00.522329 140128494741248 run_lib.py:152] step: 329950, training_loss: 2.94780e+01
I0515 02:55:06.668306 140128494741248 run_lib.py:152] step: 330000, training_loss: 3.25968e+01
I0515 02:55:06.896031 140128494741248 run_lib.py:165] step: 330000, eval_loss: 2.34210e+01
I0515 02:55:13.140125 140128494741248 run_lib.py:152] step: 330050, training_loss: 4.17068e+01
I0515 02:55:19.270348 140128494741248 run_lib.py:152] step: 330100, training_loss: 3.04831e+01
I0515 02:55:19.319169 140128494741248 run_lib.py:165] step: 330100, eval_loss: 3.63696e+01
I0515 02:55:25.822628 140128494741248 run_lib.py:152] step: 330150, training_loss: 4.28833e+01
I0515 02:55:32.097522 140128494741248 run_lib.py:152] step: 330200, training_loss: 2.59160e+01
I0515 02:55:32.149287 140128494741248 run_lib.py:165] step: 330200, eval_loss: 4.01486e+01
I0515 02:55:38.399863 140128494741248 run_lib.py:152] step: 330250, training_loss: 2.61591e+01
I0515 02:55:44.851290 140128494741248 run_lib.py:152] step: 330300, training_loss: 2.16678e+01
I0515 02:55:44.911416 140128494741248 run_lib.py:165] step: 330300, eval_loss: 2.88163e+01
I0515 02:55:51.094262 140128494741248 run_lib.py:152] step: 330350, training_loss: 3.25671e+01
I0515 02:55:57.204716 140128494741248 run_lib.py:152] step: 330400, training_loss: 2.59832e+01
I0515 02:55:57.253178 140128494741248 run_lib.py:165] step: 330400, eval_loss: 4.73758e+01
I0515 02:56:03.496785 140128494741248 run_lib.py:152] step: 330450, training_loss: 2.33133e+01
I0515 02:56:09.897464 140128494741248 run_lib.py:152] step: 330500, training_loss: 2.06474e+01
I0515 02:56:09.953685 140128494741248 run_lib.py:165] step: 330500, eval_loss: 2.03936e+01
I0515 02:56:16.198494 140128494741248 run_lib.py:152] step: 330550, training_loss: 2.56017e+01
I0515 02:56:22.363978 140128494741248 run_lib.py:152] step: 330600, training_loss: 2.39361e+01
I0515 02:56:22.416359 140128494741248 run_lib.py:165] step: 330600, eval_loss: 3.61081e+01
I0515 02:56:28.803487 140128494741248 run_lib.py:152] step: 330650, training_loss: 3.84391e+01
I0515 02:56:34.964298 140128494741248 run_lib.py:152] step: 330700, training_loss: 3.85489e+01
I0515 02:56:35.013938 140128494741248 run_lib.py:165] step: 330700, eval_loss: 2.75223e+01
I0515 02:56:41.165115 140128494741248 run_lib.py:152] step: 330750, training_loss: 3.72933e+01
I0515 02:56:47.375708 140128494741248 run_lib.py:152] step: 330800, training_loss: 2.22516e+01
I0515 02:56:47.426555 140128494741248 run_lib.py:165] step: 330800, eval_loss: 2.08185e+01
I0515 02:56:53.912862 140128494741248 run_lib.py:152] step: 330850, training_loss: 3.47263e+01
I0515 02:57:00.190489 140128494741248 run_lib.py:152] step: 330900, training_loss: 2.16897e+01
I0515 02:57:00.248115 140128494741248 run_lib.py:165] step: 330900, eval_loss: 5.19635e+01
I0515 02:57:06.430711 140128494741248 run_lib.py:152] step: 330950, training_loss: 3.47262e+01
I0515 02:57:12.956672 140128494741248 run_lib.py:152] step: 331000, training_loss: 3.57954e+01
I0515 02:57:13.010478 140128494741248 run_lib.py:165] step: 331000, eval_loss: 2.92085e+01
I0515 02:57:19.155197 140128494741248 run_lib.py:152] step: 331050, training_loss: 2.35460e+01
I0515 02:57:25.444008 140128494741248 run_lib.py:152] step: 331100, training_loss: 2.63778e+01
I0515 02:57:25.496701 140128494741248 run_lib.py:165] step: 331100, eval_loss: 2.46346e+01
I0515 02:57:31.905891 140128494741248 run_lib.py:152] step: 331150, training_loss: 2.72850e+01
I0515 02:57:38.157436 140128494741248 run_lib.py:152] step: 331200, training_loss: 4.02938e+01
I0515 02:57:38.204860 140128494741248 run_lib.py:165] step: 331200, eval_loss: 1.72960e+01
I0515 02:57:44.384024 140128494741248 run_lib.py:152] step: 331250, training_loss: 2.78508e+01
I0515 02:57:50.642711 140128494741248 run_lib.py:152] step: 331300, training_loss: 3.78678e+01
I0515 02:57:50.694249 140128494741248 run_lib.py:165] step: 331300, eval_loss: 2.59926e+01
I0515 02:57:57.055403 140128494741248 run_lib.py:152] step: 331350, training_loss: 3.30439e+01
I0515 02:58:03.227301 140128494741248 run_lib.py:152] step: 331400, training_loss: 3.40447e+01
I0515 02:58:03.278978 140128494741248 run_lib.py:165] step: 331400, eval_loss: 2.99610e+01
I0515 02:58:09.391671 140128494741248 run_lib.py:152] step: 331450, training_loss: 2.79658e+01
I0515 02:58:15.899849 140128494741248 run_lib.py:152] step: 331500, training_loss: 3.25936e+01
I0515 02:58:15.950335 140128494741248 run_lib.py:165] step: 331500, eval_loss: 5.06325e+01
I0515 02:58:22.280493 140128494741248 run_lib.py:152] step: 331550, training_loss: 4.38533e+01
I0515 02:58:28.425951 140128494741248 run_lib.py:152] step: 331600, training_loss: 2.93486e+01
I0515 02:58:28.476312 140128494741248 run_lib.py:165] step: 331600, eval_loss: 2.74395e+01
I0515 02:58:34.702409 140128494741248 run_lib.py:152] step: 331650, training_loss: 2.66486e+01
I0515 02:58:41.054930 140128494741248 run_lib.py:152] step: 331700, training_loss: 2.85312e+01
I0515 02:58:41.108545 140128494741248 run_lib.py:165] step: 331700, eval_loss: 2.81358e+01
I0515 02:58:47.346837 140128494741248 run_lib.py:152] step: 331750, training_loss: 4.06505e+01
I0515 02:58:53.532350 140128494741248 run_lib.py:152] step: 331800, training_loss: 5.59175e+01
I0515 02:58:53.580147 140128494741248 run_lib.py:165] step: 331800, eval_loss: 2.81114e+01
I0515 02:58:59.977191 140128494741248 run_lib.py:152] step: 331850, training_loss: 2.90786e+01
I0515 02:59:06.176004 140128494741248 run_lib.py:152] step: 331900, training_loss: 1.67964e+01
I0515 02:59:06.230626 140128494741248 run_lib.py:165] step: 331900, eval_loss: 3.41806e+01
I0515 02:59:12.419421 140128494741248 run_lib.py:152] step: 331950, training_loss: 2.41238e+01
I0515 02:59:18.669061 140128494741248 run_lib.py:152] step: 332000, training_loss: 3.81809e+01
I0515 02:59:18.726956 140128494741248 run_lib.py:165] step: 332000, eval_loss: 4.07315e+01
I0515 02:59:25.044645 140128494741248 run_lib.py:152] step: 332050, training_loss: 2.42404e+01
I0515 02:59:31.242762 140128494741248 run_lib.py:152] step: 332100, training_loss: 2.79655e+01
I0515 02:59:31.295477 140128494741248 run_lib.py:165] step: 332100, eval_loss: 4.31642e+01
I0515 02:59:37.427856 140128494741248 run_lib.py:152] step: 332150, training_loss: 3.54059e+01
I0515 02:59:43.868866 140128494741248 run_lib.py:152] step: 332200, training_loss: 1.90788e+01
I0515 02:59:43.920724 140128494741248 run_lib.py:165] step: 332200, eval_loss: 2.96303e+01
I0515 02:59:50.074828 140128494741248 run_lib.py:152] step: 332250, training_loss: 3.19410e+01
I0515 02:59:56.330267 140128494741248 run_lib.py:152] step: 332300, training_loss: 3.86228e+01
I0515 02:59:56.382890 140128494741248 run_lib.py:165] step: 332300, eval_loss: 2.67104e+01
I0515 03:00:02.514441 140128494741248 run_lib.py:152] step: 332350, training_loss: 3.01230e+01
I0515 03:00:09.014875 140128494741248 run_lib.py:152] step: 332400, training_loss: 3.08212e+01
I0515 03:00:09.070659 140128494741248 run_lib.py:165] step: 332400, eval_loss: 3.86042e+01
I0515 03:00:15.178537 140128494741248 run_lib.py:152] step: 332450, training_loss: 3.22075e+01
I0515 03:00:21.418253 140128494741248 run_lib.py:152] step: 332500, training_loss: 3.65377e+01
I0515 03:00:21.472303 140128494741248 run_lib.py:165] step: 332500, eval_loss: 2.88208e+01
I0515 03:00:27.887899 140128494741248 run_lib.py:152] step: 332550, training_loss: 3.71781e+01
I0515 03:00:34.087461 140128494741248 run_lib.py:152] step: 332600, training_loss: 3.06640e+01
I0515 03:00:34.137509 140128494741248 run_lib.py:165] step: 332600, eval_loss: 3.26922e+01
I0515 03:00:40.280700 140128494741248 run_lib.py:152] step: 332650, training_loss: 2.09180e+01
I0515 03:00:46.360899 140128494741248 run_lib.py:152] step: 332700, training_loss: 4.55637e+01
I0515 03:00:46.413798 140128494741248 run_lib.py:165] step: 332700, eval_loss: 3.28965e+01
I0515 03:00:52.918443 140128494741248 run_lib.py:152] step: 332750, training_loss: 2.84435e+01
I0515 03:00:59.181344 140128494741248 run_lib.py:152] step: 332800, training_loss: 3.17259e+01
I0515 03:00:59.240376 140128494741248 run_lib.py:165] step: 332800, eval_loss: 3.03059e+01
I0515 03:01:05.351540 140128494741248 run_lib.py:152] step: 332850, training_loss: 2.87449e+01
I0515 03:01:11.842906 140128494741248 run_lib.py:152] step: 332900, training_loss: 5.45454e+01
I0515 03:01:11.898275 140128494741248 run_lib.py:165] step: 332900, eval_loss: 1.65053e+01
I0515 03:01:18.095950 140128494741248 run_lib.py:152] step: 332950, training_loss: 3.54612e+01
I0515 03:01:24.316380 140128494741248 run_lib.py:152] step: 333000, training_loss: 3.55293e+01
I0515 03:01:24.374046 140128494741248 run_lib.py:165] step: 333000, eval_loss: 2.77288e+01
I0515 03:01:30.505272 140128494741248 run_lib.py:152] step: 333050, training_loss: 3.20391e+01
I0515 03:01:36.959772 140128494741248 run_lib.py:152] step: 333100, training_loss: 1.94112e+01
I0515 03:01:37.012640 140128494741248 run_lib.py:165] step: 333100, eval_loss: 2.69756e+01
I0515 03:01:43.135002 140128494741248 run_lib.py:152] step: 333150, training_loss: 4.40169e+01
I0515 03:01:49.343251 140128494741248 run_lib.py:152] step: 333200, training_loss: 2.63658e+01
I0515 03:01:49.395209 140128494741248 run_lib.py:165] step: 333200, eval_loss: 2.28540e+01
I0515 03:01:55.782793 140128494741248 run_lib.py:152] step: 333250, training_loss: 1.92549e+01
I0515 03:02:01.949730 140128494741248 run_lib.py:152] step: 333300, training_loss: 1.64810e+01
I0515 03:02:01.998669 140128494741248 run_lib.py:165] step: 333300, eval_loss: 2.25350e+01
I0515 03:02:08.179235 140128494741248 run_lib.py:152] step: 333350, training_loss: 3.62185e+01
I0515 03:02:14.439499 140128494741248 run_lib.py:152] step: 333400, training_loss: 3.67048e+01
I0515 03:02:14.486524 140128494741248 run_lib.py:165] step: 333400, eval_loss: 3.10470e+01
I0515 03:02:20.943385 140128494741248 run_lib.py:152] step: 333450, training_loss: 1.86995e+01
I0515 03:02:27.025810 140128494741248 run_lib.py:152] step: 333500, training_loss: 3.37059e+01
I0515 03:02:27.080233 140128494741248 run_lib.py:165] step: 333500, eval_loss: 4.09689e+01
I0515 03:02:33.399168 140128494741248 run_lib.py:152] step: 333550, training_loss: 2.99510e+01
I0515 03:02:39.672125 140128494741248 run_lib.py:152] step: 333600, training_loss: 2.87026e+01
I0515 03:02:39.957546 140128494741248 run_lib.py:165] step: 333600, eval_loss: 2.41171e+01
I0515 03:02:46.173329 140128494741248 run_lib.py:152] step: 333650, training_loss: 3.59159e+01
I0515 03:02:52.431102 140128494741248 run_lib.py:152] step: 333700, training_loss: 2.78574e+01
I0515 03:02:52.482740 140128494741248 run_lib.py:165] step: 333700, eval_loss: 3.75416e+01
I0515 03:02:58.736726 140128494741248 run_lib.py:152] step: 333750, training_loss: 2.16791e+01
I0515 03:03:05.168021 140128494741248 run_lib.py:152] step: 333800, training_loss: 3.50294e+01
I0515 03:03:05.221558 140128494741248 run_lib.py:165] step: 333800, eval_loss: 4.38340e+01
I0515 03:03:11.429322 140128494741248 run_lib.py:152] step: 333850, training_loss: 3.34046e+01
I0515 03:03:17.703217 140128494741248 run_lib.py:152] step: 333900, training_loss: 2.95902e+01
I0515 03:03:17.754383 140128494741248 run_lib.py:165] step: 333900, eval_loss: 2.68659e+01
I0515 03:03:24.287745 140128494741248 run_lib.py:152] step: 333950, training_loss: 3.49928e+01
I0515 03:03:30.522461 140128494741248 run_lib.py:152] step: 334000, training_loss: 3.06091e+01
I0515 03:03:30.571779 140128494741248 run_lib.py:165] step: 334000, eval_loss: 2.68024e+01
I0515 03:03:36.745377 140128494741248 run_lib.py:152] step: 334050, training_loss: 2.87138e+01
I0515 03:03:42.982697 140128494741248 run_lib.py:152] step: 334100, training_loss: 3.35469e+01
I0515 03:03:43.042340 140128494741248 run_lib.py:165] step: 334100, eval_loss: 3.34936e+01
I0515 03:03:49.418514 140128494741248 run_lib.py:152] step: 334150, training_loss: 2.84384e+01
I0515 03:03:55.703016 140128494741248 run_lib.py:152] step: 334200, training_loss: 4.26912e+01
I0515 03:03:55.753832 140128494741248 run_lib.py:165] step: 334200, eval_loss: 3.70659e+01
I0515 03:04:01.941039 140128494741248 run_lib.py:152] step: 334250, training_loss: 2.44336e+01
I0515 03:04:08.282918 140128494741248 run_lib.py:152] step: 334300, training_loss: 2.81283e+01
I0515 03:04:08.334822 140128494741248 run_lib.py:165] step: 334300, eval_loss: 4.62940e+01
I0515 03:04:14.533550 140128494741248 run_lib.py:152] step: 334350, training_loss: 3.10303e+01
I0515 03:04:20.703020 140128494741248 run_lib.py:152] step: 334400, training_loss: 1.73856e+01
I0515 03:04:20.751622 140128494741248 run_lib.py:165] step: 334400, eval_loss: 3.58088e+01
I0515 03:04:26.952617 140128494741248 run_lib.py:152] step: 334450, training_loss: 2.70548e+01
I0515 03:04:33.446117 140128494741248 run_lib.py:152] step: 334500, training_loss: 4.69881e+01
I0515 03:04:33.496414 140128494741248 run_lib.py:165] step: 334500, eval_loss: 2.90724e+01
I0515 03:04:39.697824 140128494741248 run_lib.py:152] step: 334550, training_loss: 3.16795e+01
I0515 03:04:45.918504 140128494741248 run_lib.py:152] step: 334600, training_loss: 2.91014e+01
I0515 03:04:45.974998 140128494741248 run_lib.py:165] step: 334600, eval_loss: 2.73889e+01
I0515 03:04:52.430518 140128494741248 run_lib.py:152] step: 334650, training_loss: 1.54231e+01
I0515 03:04:58.594119 140128494741248 run_lib.py:152] step: 334700, training_loss: 2.80440e+01
I0515 03:04:58.642781 140128494741248 run_lib.py:165] step: 334700, eval_loss: 3.76742e+01
I0515 03:05:04.846487 140128494741248 run_lib.py:152] step: 334750, training_loss: 4.17488e+01
I0515 03:05:11.045277 140128494741248 run_lib.py:152] step: 334800, training_loss: 3.25201e+01
I0515 03:05:11.100250 140128494741248 run_lib.py:165] step: 334800, eval_loss: 3.95110e+01
I0515 03:05:17.587311 140128494741248 run_lib.py:152] step: 334850, training_loss: 2.44817e+01
I0515 03:05:23.719947 140128494741248 run_lib.py:152] step: 334900, training_loss: 3.03297e+01
I0515 03:05:23.770368 140128494741248 run_lib.py:165] step: 334900, eval_loss: 2.68179e+01
I0515 03:05:30.009907 140128494741248 run_lib.py:152] step: 334950, training_loss: 2.58129e+01
I0515 03:05:36.522691 140128494741248 run_lib.py:152] step: 335000, training_loss: 4.68675e+01
I0515 03:05:36.577760 140128494741248 run_lib.py:165] step: 335000, eval_loss: 3.37779e+01
I0515 03:05:42.748040 140128494741248 run_lib.py:152] step: 335050, training_loss: 3.95588e+01
I0515 03:05:49.014162 140128494741248 run_lib.py:152] step: 335100, training_loss: 2.73933e+01
I0515 03:05:49.065176 140128494741248 run_lib.py:165] step: 335100, eval_loss: 2.32490e+01
I0515 03:05:55.326072 140128494741248 run_lib.py:152] step: 335150, training_loss: 3.61391e+01
I0515 03:06:01.800391 140128494741248 run_lib.py:152] step: 335200, training_loss: 2.83941e+01
I0515 03:06:01.856243 140128494741248 run_lib.py:165] step: 335200, eval_loss: 3.64282e+01
I0515 03:06:08.060281 140128494741248 run_lib.py:152] step: 335250, training_loss: 4.22299e+01
I0515 03:06:14.354628 140128494741248 run_lib.py:152] step: 335300, training_loss: 3.19348e+01
I0515 03:06:14.410902 140128494741248 run_lib.py:165] step: 335300, eval_loss: 2.25901e+01
I0515 03:06:20.854395 140128494741248 run_lib.py:152] step: 335350, training_loss: 3.87790e+01
I0515 03:06:27.133077 140128494741248 run_lib.py:152] step: 335400, training_loss: 3.31747e+01
I0515 03:06:27.187144 140128494741248 run_lib.py:165] step: 335400, eval_loss: 3.44571e+01
I0515 03:06:33.355482 140128494741248 run_lib.py:152] step: 335450, training_loss: 4.75673e+01
I0515 03:06:39.594757 140128494741248 run_lib.py:152] step: 335500, training_loss: 2.96340e+01
I0515 03:06:39.656305 140128494741248 run_lib.py:165] step: 335500, eval_loss: 3.65389e+01
I0515 03:06:46.172848 140128494741248 run_lib.py:152] step: 335550, training_loss: 2.66812e+01
I0515 03:06:52.387978 140128494741248 run_lib.py:152] step: 335600, training_loss: 1.82828e+01
I0515 03:06:52.445331 140128494741248 run_lib.py:165] step: 335600, eval_loss: 3.10097e+01
I0515 03:06:58.637459 140128494741248 run_lib.py:152] step: 335650, training_loss: 4.24212e+01
I0515 03:07:05.143199 140128494741248 run_lib.py:152] step: 335700, training_loss: 5.35511e+01
I0515 03:07:05.204375 140128494741248 run_lib.py:165] step: 335700, eval_loss: 3.94910e+01
I0515 03:07:11.369265 140128494741248 run_lib.py:152] step: 335750, training_loss: 2.80268e+01
I0515 03:07:17.557292 140128494741248 run_lib.py:152] step: 335800, training_loss: 2.64361e+01
I0515 03:07:17.604605 140128494741248 run_lib.py:165] step: 335800, eval_loss: 3.68842e+01
I0515 03:07:23.891484 140128494741248 run_lib.py:152] step: 335850, training_loss: 3.20881e+01
I0515 03:07:30.259972 140128494741248 run_lib.py:152] step: 335900, training_loss: 4.30322e+01
I0515 03:07:30.310199 140128494741248 run_lib.py:165] step: 335900, eval_loss: 3.48375e+01
I0515 03:07:36.457947 140128494741248 run_lib.py:152] step: 335950, training_loss: 2.16904e+01
I0515 03:07:42.810676 140128494741248 run_lib.py:152] step: 336000, training_loss: 3.28626e+01
I0515 03:07:42.861914 140128494741248 run_lib.py:165] step: 336000, eval_loss: 3.11831e+01
I0515 03:07:49.326146 140128494741248 run_lib.py:152] step: 336050, training_loss: 3.52233e+01
I0515 03:07:55.495218 140128494741248 run_lib.py:152] step: 336100, training_loss: 2.86106e+01
I0515 03:07:55.545207 140128494741248 run_lib.py:165] step: 336100, eval_loss: 2.11696e+01
I0515 03:08:01.711763 140128494741248 run_lib.py:152] step: 336150, training_loss: 2.33510e+01
I0515 03:08:08.002001 140128494741248 run_lib.py:152] step: 336200, training_loss: 3.78902e+01
I0515 03:08:08.057759 140128494741248 run_lib.py:165] step: 336200, eval_loss: 3.59528e+01
I0515 03:08:14.444721 140128494741248 run_lib.py:152] step: 336250, training_loss: 4.38289e+01
I0515 03:08:20.696947 140128494741248 run_lib.py:152] step: 336300, training_loss: 3.68148e+01
I0515 03:08:20.749416 140128494741248 run_lib.py:165] step: 336300, eval_loss: 2.36089e+01
I0515 03:08:26.976956 140128494741248 run_lib.py:152] step: 336350, training_loss: 3.68337e+01
I0515 03:08:33.409389 140128494741248 run_lib.py:152] step: 336400, training_loss: 3.37810e+01
I0515 03:08:33.462139 140128494741248 run_lib.py:165] step: 336400, eval_loss: 1.98332e+01
I0515 03:08:39.692487 140128494741248 run_lib.py:152] step: 336450, training_loss: 2.74140e+01
I0515 03:08:45.904391 140128494741248 run_lib.py:152] step: 336500, training_loss: 3.47816e+01
I0515 03:08:45.958180 140128494741248 run_lib.py:165] step: 336500, eval_loss: 3.64369e+01
I0515 03:08:52.256668 140128494741248 run_lib.py:152] step: 336550, training_loss: 3.45327e+01
I0515 03:08:58.789661 140128494741248 run_lib.py:152] step: 336600, training_loss: 2.32735e+01
I0515 03:08:58.842855 140128494741248 run_lib.py:165] step: 336600, eval_loss: 1.90230e+01
I0515 03:09:04.986075 140128494741248 run_lib.py:152] step: 336650, training_loss: 3.51097e+01
I0515 03:09:11.220452 140128494741248 run_lib.py:152] step: 336700, training_loss: 2.13125e+01
I0515 03:09:11.272496 140128494741248 run_lib.py:165] step: 336700, eval_loss: 2.47462e+01
I0515 03:09:17.844894 140128494741248 run_lib.py:152] step: 336750, training_loss: 3.45352e+01
I0515 03:09:23.987051 140128494741248 run_lib.py:152] step: 336800, training_loss: 2.96767e+01
I0515 03:09:24.038815 140128494741248 run_lib.py:165] step: 336800, eval_loss: 3.18476e+01
I0515 03:09:30.213374 140128494741248 run_lib.py:152] step: 336850, training_loss: 2.65635e+01
I0515 03:09:36.598073 140128494741248 run_lib.py:152] step: 336900, training_loss: 2.74300e+01
I0515 03:09:36.649076 140128494741248 run_lib.py:165] step: 336900, eval_loss: 2.93316e+01
I0515 03:09:43.178595 140128494741248 run_lib.py:152] step: 336950, training_loss: 4.08444e+01
I0515 03:09:49.493715 140128494741248 run_lib.py:152] step: 337000, training_loss: 3.22229e+01
I0515 03:09:49.547178 140128494741248 run_lib.py:165] step: 337000, eval_loss: 2.64175e+01
I0515 03:09:55.833905 140128494741248 run_lib.py:152] step: 337050, training_loss: 3.51210e+01
I0515 03:10:02.140100 140128494741248 run_lib.py:152] step: 337100, training_loss: 3.42799e+01
I0515 03:10:02.433723 140128494741248 run_lib.py:165] step: 337100, eval_loss: 3.21542e+01
I0515 03:10:08.666129 140128494741248 run_lib.py:152] step: 337150, training_loss: 3.16013e+01
I0515 03:10:14.939970 140128494741248 run_lib.py:152] step: 337200, training_loss: 2.84062e+01
I0515 03:10:14.989199 140128494741248 run_lib.py:165] step: 337200, eval_loss: 3.42084e+01
I0515 03:10:21.123553 140128494741248 run_lib.py:152] step: 337250, training_loss: 2.01652e+01
I0515 03:10:27.599044 140128494741248 run_lib.py:152] step: 337300, training_loss: 3.25554e+01
I0515 03:10:27.649619 140128494741248 run_lib.py:165] step: 337300, eval_loss: 3.11027e+01
I0515 03:10:33.833862 140128494741248 run_lib.py:152] step: 337350, training_loss: 4.21780e+01
I0515 03:10:40.095370 140128494741248 run_lib.py:152] step: 337400, training_loss: 2.77085e+01
I0515 03:10:40.146514 140128494741248 run_lib.py:165] step: 337400, eval_loss: 3.34462e+01
I0515 03:10:46.610626 140128494741248 run_lib.py:152] step: 337450, training_loss: 2.50865e+01
I0515 03:10:52.789702 140128494741248 run_lib.py:152] step: 337500, training_loss: 3.30869e+01
I0515 03:10:52.842413 140128494741248 run_lib.py:165] step: 337500, eval_loss: 3.51733e+01
I0515 03:10:59.008536 140128494741248 run_lib.py:152] step: 337550, training_loss: 3.03436e+01
I0515 03:11:05.210473 140128494741248 run_lib.py:152] step: 337600, training_loss: 3.43457e+01
I0515 03:11:05.263967 140128494741248 run_lib.py:165] step: 337600, eval_loss: 2.65333e+01
I0515 03:11:11.785098 140128494741248 run_lib.py:152] step: 337650, training_loss: 2.91379e+01
I0515 03:11:17.998245 140128494741248 run_lib.py:152] step: 337700, training_loss: 2.77910e+01
I0515 03:11:18.047356 140128494741248 run_lib.py:165] step: 337700, eval_loss: 3.36916e+01
I0515 03:11:24.205786 140128494741248 run_lib.py:152] step: 337750, training_loss: 2.35357e+01
I0515 03:11:30.693623 140128494741248 run_lib.py:152] step: 337800, training_loss: 2.46853e+01
I0515 03:11:30.742912 140128494741248 run_lib.py:165] step: 337800, eval_loss: 3.36060e+01
I0515 03:11:36.994653 140128494741248 run_lib.py:152] step: 337850, training_loss: 4.03374e+01
I0515 03:11:43.187019 140128494741248 run_lib.py:152] step: 337900, training_loss: 3.22059e+01
I0515 03:11:43.236996 140128494741248 run_lib.py:165] step: 337900, eval_loss: 3.68101e+01
I0515 03:11:49.457873 140128494741248 run_lib.py:152] step: 337950, training_loss: 2.74303e+01
I0515 03:11:55.893847 140128494741248 run_lib.py:152] step: 338000, training_loss: 3.06675e+01
I0515 03:11:55.944251 140128494741248 run_lib.py:165] step: 338000, eval_loss: 2.95851e+01
I0515 03:12:02.118477 140128494741248 run_lib.py:152] step: 338050, training_loss: 2.33695e+01
I0515 03:12:08.349508 140128494741248 run_lib.py:152] step: 338100, training_loss: 3.47447e+01
I0515 03:12:08.401410 140128494741248 run_lib.py:165] step: 338100, eval_loss: 3.86676e+01
I0515 03:12:14.868133 140128494741248 run_lib.py:152] step: 338150, training_loss: 1.79129e+01
I0515 03:12:21.074827 140128494741248 run_lib.py:152] step: 338200, training_loss: 3.74471e+01
I0515 03:12:21.128918 140128494741248 run_lib.py:165] step: 338200, eval_loss: 2.92060e+01
I0515 03:12:27.383474 140128494741248 run_lib.py:152] step: 338250, training_loss: 4.13707e+01
I0515 03:12:33.578974 140128494741248 run_lib.py:152] step: 338300, training_loss: 2.45385e+01
I0515 03:12:33.630268 140128494741248 run_lib.py:165] step: 338300, eval_loss: 2.19748e+01
I0515 03:12:40.112057 140128494741248 run_lib.py:152] step: 338350, training_loss: 2.48596e+01
I0515 03:12:46.252727 140128494741248 run_lib.py:152] step: 338400, training_loss: 2.62900e+01
I0515 03:12:46.307108 140128494741248 run_lib.py:165] step: 338400, eval_loss: 2.15873e+01
I0515 03:12:52.557191 140128494741248 run_lib.py:152] step: 338450, training_loss: 3.11420e+01
I0515 03:12:59.041475 140128494741248 run_lib.py:152] step: 338500, training_loss: 3.20129e+01
I0515 03:12:59.091064 140128494741248 run_lib.py:165] step: 338500, eval_loss: 2.43931e+01
I0515 03:13:05.194623 140128494741248 run_lib.py:152] step: 338550, training_loss: 2.47717e+01
I0515 03:13:11.360997 140128494741248 run_lib.py:152] step: 338600, training_loss: 2.19478e+01
I0515 03:13:11.418868 140128494741248 run_lib.py:165] step: 338600, eval_loss: 2.88910e+01
I0515 03:13:17.578694 140128494741248 run_lib.py:152] step: 338650, training_loss: 3.14306e+01
I0515 03:13:24.083817 140128494741248 run_lib.py:152] step: 338700, training_loss: 2.66693e+01
I0515 03:13:24.137525 140128494741248 run_lib.py:165] step: 338700, eval_loss: 3.00338e+01
I0515 03:13:30.283102 140128494741248 run_lib.py:152] step: 338750, training_loss: 3.19843e+01
I0515 03:13:36.419553 140128494741248 run_lib.py:152] step: 338800, training_loss: 3.96983e+01
I0515 03:13:36.470769 140128494741248 run_lib.py:165] step: 338800, eval_loss: 3.29136e+01
I0515 03:13:42.980621 140128494741248 run_lib.py:152] step: 338850, training_loss: 4.05275e+01
I0515 03:13:49.184681 140128494741248 run_lib.py:152] step: 338900, training_loss: 3.16152e+01
I0515 03:13:49.236256 140128494741248 run_lib.py:165] step: 338900, eval_loss: 1.43232e+01
I0515 03:13:55.495299 140128494741248 run_lib.py:152] step: 338950, training_loss: 2.85209e+01
I0515 03:14:01.745419 140128494741248 run_lib.py:152] step: 339000, training_loss: 4.41057e+01
I0515 03:14:01.800123 140128494741248 run_lib.py:165] step: 339000, eval_loss: 3.19418e+01
I0515 03:14:08.173447 140128494741248 run_lib.py:152] step: 339050, training_loss: 2.30837e+01
I0515 03:14:14.480303 140128494741248 run_lib.py:152] step: 339100, training_loss: 2.28065e+01
I0515 03:14:14.533327 140128494741248 run_lib.py:165] step: 339100, eval_loss: 3.04906e+01
I0515 03:14:20.707868 140128494741248 run_lib.py:152] step: 339150, training_loss: 3.04479e+01
I0515 03:14:27.116728 140128494741248 run_lib.py:152] step: 339200, training_loss: 3.23064e+01
I0515 03:14:27.172106 140128494741248 run_lib.py:165] step: 339200, eval_loss: 2.72350e+01
I0515 03:14:33.396480 140128494741248 run_lib.py:152] step: 339250, training_loss: 2.40238e+01
I0515 03:14:39.624107 140128494741248 run_lib.py:152] step: 339300, training_loss: 4.28712e+01
I0515 03:14:39.672571 140128494741248 run_lib.py:165] step: 339300, eval_loss: 2.41959e+01
I0515 03:14:45.889729 140128494741248 run_lib.py:152] step: 339350, training_loss: 3.07543e+01
I0515 03:14:52.426638 140128494741248 run_lib.py:152] step: 339400, training_loss: 3.28909e+01
I0515 03:14:52.475242 140128494741248 run_lib.py:165] step: 339400, eval_loss: 3.92281e+01
I0515 03:14:58.708039 140128494741248 run_lib.py:152] step: 339450, training_loss: 3.83655e+01
I0515 03:15:04.963636 140128494741248 run_lib.py:152] step: 339500, training_loss: 2.15883e+01
I0515 03:15:05.019038 140128494741248 run_lib.py:165] step: 339500, eval_loss: 3.51518e+01
I0515 03:15:11.346439 140128494741248 run_lib.py:152] step: 339550, training_loss: 2.36731e+01
I0515 03:15:17.603718 140128494741248 run_lib.py:152] step: 339600, training_loss: 3.11023e+01
I0515 03:15:17.658516 140128494741248 run_lib.py:165] step: 339600, eval_loss: 2.48872e+01
I0515 03:15:23.865252 140128494741248 run_lib.py:152] step: 339650, training_loss: 3.24337e+01
I0515 03:15:30.173383 140128494741248 run_lib.py:152] step: 339700, training_loss: 2.50764e+01
I0515 03:15:30.226535 140128494741248 run_lib.py:165] step: 339700, eval_loss: 2.26596e+01
I0515 03:15:36.683720 140128494741248 run_lib.py:152] step: 339750, training_loss: 2.76873e+01
I0515 03:15:42.868207 140128494741248 run_lib.py:152] step: 339800, training_loss: 4.44138e+01
I0515 03:15:42.920094 140128494741248 run_lib.py:165] step: 339800, eval_loss: 2.47974e+01
I0515 03:15:49.164412 140128494741248 run_lib.py:152] step: 339850, training_loss: 2.47526e+01
I0515 03:15:55.583694 140128494741248 run_lib.py:152] step: 339900, training_loss: 1.28494e+01
I0515 03:15:55.631251 140128494741248 run_lib.py:165] step: 339900, eval_loss: 2.71198e+01
I0515 03:16:01.834441 140128494741248 run_lib.py:152] step: 339950, training_loss: 3.48282e+01
I0515 03:16:07.949068 140128494741248 run_lib.py:152] step: 340000, training_loss: 3.42603e+01
I0515 03:16:08.148789 140128494741248 run_lib.py:165] step: 340000, eval_loss: 2.40776e+01
I0515 03:16:14.407767 140128494741248 run_lib.py:152] step: 340050, training_loss: 2.82401e+01
I0515 03:16:20.900254 140128494741248 run_lib.py:152] step: 340100, training_loss: 4.66896e+01
I0515 03:16:20.952835 140128494741248 run_lib.py:165] step: 340100, eval_loss: 2.01144e+01
I0515 03:16:27.217271 140128494741248 run_lib.py:152] step: 340150, training_loss: 3.01097e+01
I0515 03:16:33.556004 140128494741248 run_lib.py:152] step: 340200, training_loss: 3.43628e+01
I0515 03:16:33.607318 140128494741248 run_lib.py:165] step: 340200, eval_loss: 4.43777e+01
I0515 03:16:40.081446 140128494741248 run_lib.py:152] step: 340250, training_loss: 2.78444e+01
I0515 03:16:46.251653 140128494741248 run_lib.py:152] step: 340300, training_loss: 2.68793e+01
I0515 03:16:46.303325 140128494741248 run_lib.py:165] step: 340300, eval_loss: 3.50551e+01
I0515 03:16:52.503727 140128494741248 run_lib.py:152] step: 340350, training_loss: 3.79301e+01
I0515 03:16:58.669909 140128494741248 run_lib.py:152] step: 340400, training_loss: 2.36802e+01
I0515 03:16:58.722061 140128494741248 run_lib.py:165] step: 340400, eval_loss: 3.90680e+01
I0515 03:17:05.233650 140128494741248 run_lib.py:152] step: 340450, training_loss: 2.99575e+01
I0515 03:17:11.500650 140128494741248 run_lib.py:152] step: 340500, training_loss: 2.38666e+01
I0515 03:17:11.555819 140128494741248 run_lib.py:165] step: 340500, eval_loss: 1.95154e+01
I0515 03:17:17.837382 140128494741248 run_lib.py:152] step: 340550, training_loss: 2.99303e+01
I0515 03:17:24.035171 140128494741248 run_lib.py:152] step: 340600, training_loss: 2.71367e+01
I0515 03:17:24.326620 140128494741248 run_lib.py:165] step: 340600, eval_loss: 3.66066e+01
I0515 03:17:30.534697 140128494741248 run_lib.py:152] step: 340650, training_loss: 2.48915e+01
I0515 03:17:36.708208 140128494741248 run_lib.py:152] step: 340700, training_loss: 3.68957e+01
I0515 03:17:36.770020 140128494741248 run_lib.py:165] step: 340700, eval_loss: 4.93638e+01
I0515 03:17:43.007973 140128494741248 run_lib.py:152] step: 340750, training_loss: 2.87649e+01
I0515 03:17:49.455174 140128494741248 run_lib.py:152] step: 340800, training_loss: 3.53910e+01
I0515 03:17:49.507216 140128494741248 run_lib.py:165] step: 340800, eval_loss: 3.34122e+01
I0515 03:17:55.771030 140128494741248 run_lib.py:152] step: 340850, training_loss: 3.67712e+01
I0515 03:18:01.990203 140128494741248 run_lib.py:152] step: 340900, training_loss: 4.31020e+01
I0515 03:18:02.044274 140128494741248 run_lib.py:165] step: 340900, eval_loss: 2.31914e+01
I0515 03:18:08.391885 140128494741248 run_lib.py:152] step: 340950, training_loss: 2.87864e+01
I0515 03:18:14.613371 140128494741248 run_lib.py:152] step: 341000, training_loss: 4.29015e+01
I0515 03:18:14.662509 140128494741248 run_lib.py:165] step: 341000, eval_loss: 2.40513e+01
I0515 03:18:20.805379 140128494741248 run_lib.py:152] step: 341050, training_loss: 3.49255e+01
I0515 03:18:27.057760 140128494741248 run_lib.py:152] step: 341100, training_loss: 4.77508e+01
I0515 03:18:27.106517 140128494741248 run_lib.py:165] step: 341100, eval_loss: 1.38143e+01
I0515 03:18:33.460680 140128494741248 run_lib.py:152] step: 341150, training_loss: 3.28892e+01
I0515 03:18:39.530797 140128494741248 run_lib.py:152] step: 341200, training_loss: 3.21114e+01
I0515 03:18:39.588186 140128494741248 run_lib.py:165] step: 341200, eval_loss: 3.10460e+01
I0515 03:18:45.797231 140128494741248 run_lib.py:152] step: 341250, training_loss: 3.77172e+01
I0515 03:18:52.330538 140128494741248 run_lib.py:152] step: 341300, training_loss: 2.18986e+01
I0515 03:18:52.383482 140128494741248 run_lib.py:165] step: 341300, eval_loss: 2.73372e+01
I0515 03:18:58.659471 140128494741248 run_lib.py:152] step: 341350, training_loss: 3.46046e+01
I0515 03:19:04.815125 140128494741248 run_lib.py:152] step: 341400, training_loss: 3.12336e+01
I0515 03:19:04.867355 140128494741248 run_lib.py:165] step: 341400, eval_loss: 2.72516e+01
I0515 03:19:11.021114 140128494741248 run_lib.py:152] step: 341450, training_loss: 2.79823e+01
I0515 03:19:17.446683 140128494741248 run_lib.py:152] step: 341500, training_loss: 3.34283e+01
I0515 03:19:17.498459 140128494741248 run_lib.py:165] step: 341500, eval_loss: 3.87312e+01
I0515 03:19:23.639215 140128494741248 run_lib.py:152] step: 341550, training_loss: 2.10787e+01
I0515 03:19:29.805113 140128494741248 run_lib.py:152] step: 341600, training_loss: 4.73277e+01
I0515 03:19:29.856928 140128494741248 run_lib.py:165] step: 341600, eval_loss: 2.72516e+01
I0515 03:19:36.303864 140128494741248 run_lib.py:152] step: 341650, training_loss: 4.94877e+01
I0515 03:19:42.539703 140128494741248 run_lib.py:152] step: 341700, training_loss: 2.58773e+01
I0515 03:19:42.590771 140128494741248 run_lib.py:165] step: 341700, eval_loss: 3.43113e+01
I0515 03:19:48.768219 140128494741248 run_lib.py:152] step: 341750, training_loss: 2.66136e+01
I0515 03:19:55.090046 140128494741248 run_lib.py:152] step: 341800, training_loss: 2.94639e+01
I0515 03:19:55.139478 140128494741248 run_lib.py:165] step: 341800, eval_loss: 3.92699e+01
I0515 03:20:01.597134 140128494741248 run_lib.py:152] step: 341850, training_loss: 1.62098e+01
I0515 03:20:07.713608 140128494741248 run_lib.py:152] step: 341900, training_loss: 2.37403e+01
I0515 03:20:07.770571 140128494741248 run_lib.py:165] step: 341900, eval_loss: 2.70581e+01
I0515 03:20:14.010720 140128494741248 run_lib.py:152] step: 341950, training_loss: 4.03871e+01
I0515 03:20:20.396561 140128494741248 run_lib.py:152] step: 342000, training_loss: 2.81006e+01
I0515 03:20:20.446913 140128494741248 run_lib.py:165] step: 342000, eval_loss: 2.99178e+01
I0515 03:20:26.691977 140128494741248 run_lib.py:152] step: 342050, training_loss: 4.25275e+01
I0515 03:20:32.835978 140128494741248 run_lib.py:152] step: 342100, training_loss: 1.48886e+01
I0515 03:20:32.884662 140128494741248 run_lib.py:165] step: 342100, eval_loss: 1.94993e+01
I0515 03:20:39.095296 140128494741248 run_lib.py:152] step: 342150, training_loss: 3.72515e+01
I0515 03:20:45.645417 140128494741248 run_lib.py:152] step: 342200, training_loss: 3.35885e+01
I0515 03:20:45.699117 140128494741248 run_lib.py:165] step: 342200, eval_loss: 3.07316e+01
I0515 03:20:51.939878 140128494741248 run_lib.py:152] step: 342250, training_loss: 2.06508e+01
I0515 03:20:58.065480 140128494741248 run_lib.py:152] step: 342300, training_loss: 5.00510e+01
I0515 03:20:58.116145 140128494741248 run_lib.py:165] step: 342300, eval_loss: 2.44708e+01
I0515 03:21:04.620721 140128494741248 run_lib.py:152] step: 342350, training_loss: 3.83595e+01
I0515 03:21:10.776743 140128494741248 run_lib.py:152] step: 342400, training_loss: 1.39308e+01
I0515 03:21:10.824943 140128494741248 run_lib.py:165] step: 342400, eval_loss: 2.77027e+01
I0515 03:21:17.054774 140128494741248 run_lib.py:152] step: 342450, training_loss: 2.53398e+01
I0515 03:21:23.325234 140128494741248 run_lib.py:152] step: 342500, training_loss: 4.15333e+01
I0515 03:21:23.386079 140128494741248 run_lib.py:165] step: 342500, eval_loss: 3.36781e+01
I0515 03:21:29.902956 140128494741248 run_lib.py:152] step: 342550, training_loss: 4.39444e+01
I0515 03:21:36.175574 140128494741248 run_lib.py:152] step: 342600, training_loss: 5.06869e+01
I0515 03:21:36.225901 140128494741248 run_lib.py:165] step: 342600, eval_loss: 3.14330e+01
I0515 03:21:42.375196 140128494741248 run_lib.py:152] step: 342650, training_loss: 4.41426e+01
I0515 03:21:48.762399 140128494741248 run_lib.py:152] step: 342700, training_loss: 3.01966e+01
I0515 03:21:48.815433 140128494741248 run_lib.py:165] step: 342700, eval_loss: 2.74529e+01
I0515 03:21:55.075016 140128494741248 run_lib.py:152] step: 342750, training_loss: 3.82411e+01
I0515 03:22:01.434923 140128494741248 run_lib.py:152] step: 342800, training_loss: 1.46737e+01
I0515 03:22:01.490658 140128494741248 run_lib.py:165] step: 342800, eval_loss: 3.05495e+01
I0515 03:22:07.645133 140128494741248 run_lib.py:152] step: 342850, training_loss: 2.99099e+01
I0515 03:22:14.094655 140128494741248 run_lib.py:152] step: 342900, training_loss: 2.71544e+01
I0515 03:22:14.144707 140128494741248 run_lib.py:165] step: 342900, eval_loss: 3.54373e+01
I0515 03:22:20.329563 140128494741248 run_lib.py:152] step: 342950, training_loss: 4.29002e+01
I0515 03:22:26.587786 140128494741248 run_lib.py:152] step: 343000, training_loss: 3.60475e+01
I0515 03:22:26.637213 140128494741248 run_lib.py:165] step: 343000, eval_loss: 3.36454e+01
I0515 03:22:33.169585 140128494741248 run_lib.py:152] step: 343050, training_loss: 2.89469e+01
I0515 03:22:39.364904 140128494741248 run_lib.py:152] step: 343100, training_loss: 3.73248e+01
I0515 03:22:39.413492 140128494741248 run_lib.py:165] step: 343100, eval_loss: 2.69003e+01
I0515 03:22:45.503772 140128494741248 run_lib.py:152] step: 343150, training_loss: 1.97637e+01
I0515 03:22:51.713713 140128494741248 run_lib.py:152] step: 343200, training_loss: 3.14384e+01
I0515 03:22:51.765722 140128494741248 run_lib.py:165] step: 343200, eval_loss: 2.49442e+01
I0515 03:22:58.274258 140128494741248 run_lib.py:152] step: 343250, training_loss: 3.40980e+01
I0515 03:23:04.424041 140128494741248 run_lib.py:152] step: 343300, training_loss: 3.58380e+01
I0515 03:23:04.474816 140128494741248 run_lib.py:165] step: 343300, eval_loss: 2.82848e+01
I0515 03:23:10.561951 140128494741248 run_lib.py:152] step: 343350, training_loss: 2.89682e+01
I0515 03:23:17.099383 140128494741248 run_lib.py:152] step: 343400, training_loss: 2.19508e+01
I0515 03:23:17.153832 140128494741248 run_lib.py:165] step: 343400, eval_loss: 2.18529e+01
I0515 03:23:23.275080 140128494741248 run_lib.py:152] step: 343450, training_loss: 4.04745e+01
I0515 03:23:29.538820 140128494741248 run_lib.py:152] step: 343500, training_loss: 3.15334e+01
I0515 03:23:29.589304 140128494741248 run_lib.py:165] step: 343500, eval_loss: 3.86129e+01
I0515 03:23:35.719732 140128494741248 run_lib.py:152] step: 343550, training_loss: 3.28157e+01
I0515 03:23:42.090229 140128494741248 run_lib.py:152] step: 343600, training_loss: 2.36572e+01
I0515 03:23:42.150506 140128494741248 run_lib.py:165] step: 343600, eval_loss: 5.37599e+01
I0515 03:23:48.176465 140128494741248 run_lib.py:152] step: 343650, training_loss: 2.80639e+01
I0515 03:23:54.290568 140128494741248 run_lib.py:152] step: 343700, training_loss: 3.61327e+01
I0515 03:23:54.342339 140128494741248 run_lib.py:165] step: 343700, eval_loss: 3.26662e+01
I0515 03:24:00.774890 140128494741248 run_lib.py:152] step: 343750, training_loss: 5.20122e+01
I0515 03:24:07.045723 140128494741248 run_lib.py:152] step: 343800, training_loss: 2.52818e+01
I0515 03:24:07.099282 140128494741248 run_lib.py:165] step: 343800, eval_loss: 3.46242e+01
I0515 03:24:13.368431 140128494741248 run_lib.py:152] step: 343850, training_loss: 3.34959e+01
I0515 03:24:19.638590 140128494741248 run_lib.py:152] step: 343900, training_loss: 2.97936e+01
I0515 03:24:19.693953 140128494741248 run_lib.py:165] step: 343900, eval_loss: 2.26153e+01
I0515 03:24:26.150559 140128494741248 run_lib.py:152] step: 343950, training_loss: 4.07258e+01
I0515 03:24:32.297547 140128494741248 run_lib.py:152] step: 344000, training_loss: 2.99475e+01
I0515 03:24:32.346774 140128494741248 run_lib.py:165] step: 344000, eval_loss: 2.34326e+01
I0515 03:24:38.573570 140128494741248 run_lib.py:152] step: 344050, training_loss: 2.36005e+01
I0515 03:24:44.749095 140128494741248 run_lib.py:152] step: 344100, training_loss: 2.98564e+01
I0515 03:24:45.027275 140128494741248 run_lib.py:165] step: 344100, eval_loss: 2.78151e+01
I0515 03:24:51.182625 140128494741248 run_lib.py:152] step: 344150, training_loss: 3.49557e+01
I0515 03:24:57.328728 140128494741248 run_lib.py:152] step: 344200, training_loss: 3.26362e+01
I0515 03:24:57.379068 140128494741248 run_lib.py:165] step: 344200, eval_loss: 2.72994e+01
I0515 03:25:03.664233 140128494741248 run_lib.py:152] step: 344250, training_loss: 3.70587e+01
I0515 03:25:10.091271 140128494741248 run_lib.py:152] step: 344300, training_loss: 2.91871e+01
I0515 03:25:10.143231 140128494741248 run_lib.py:165] step: 344300, eval_loss: 3.55397e+01
I0515 03:25:16.349084 140128494741248 run_lib.py:152] step: 344350, training_loss: 3.62255e+01
I0515 03:25:22.597524 140128494741248 run_lib.py:152] step: 344400, training_loss: 2.46280e+01
I0515 03:25:22.655102 140128494741248 run_lib.py:165] step: 344400, eval_loss: 4.15894e+01
I0515 03:25:29.077935 140128494741248 run_lib.py:152] step: 344450, training_loss: 1.94932e+01
I0515 03:25:35.255397 140128494741248 run_lib.py:152] step: 344500, training_loss: 2.67702e+01
I0515 03:25:35.308396 140128494741248 run_lib.py:165] step: 344500, eval_loss: 4.07254e+01
I0515 03:25:41.604854 140128494741248 run_lib.py:152] step: 344550, training_loss: 4.47155e+01
I0515 03:25:47.786060 140128494741248 run_lib.py:152] step: 344600, training_loss: 1.89526e+01
I0515 03:25:47.839425 140128494741248 run_lib.py:165] step: 344600, eval_loss: 3.95230e+01
I0515 03:25:54.238158 140128494741248 run_lib.py:152] step: 344650, training_loss: 4.15794e+01
I0515 03:26:00.508285 140128494741248 run_lib.py:152] step: 344700, training_loss: 2.81904e+01
I0515 03:26:00.568420 140128494741248 run_lib.py:165] step: 344700, eval_loss: 3.22308e+01
I0515 03:26:06.760114 140128494741248 run_lib.py:152] step: 344750, training_loss: 1.30161e+01
I0515 03:26:13.275474 140128494741248 run_lib.py:152] step: 344800, training_loss: 1.55788e+01
I0515 03:26:13.324385 140128494741248 run_lib.py:165] step: 344800, eval_loss: 2.94343e+01
I0515 03:26:19.396116 140128494741248 run_lib.py:152] step: 344850, training_loss: 3.19887e+01
I0515 03:26:25.663244 140128494741248 run_lib.py:152] step: 344900, training_loss: 3.81621e+01
I0515 03:26:25.715191 140128494741248 run_lib.py:165] step: 344900, eval_loss: 3.43306e+01
I0515 03:26:31.937079 140128494741248 run_lib.py:152] step: 344950, training_loss: 4.22955e+01
I0515 03:26:38.416223 140128494741248 run_lib.py:152] step: 345000, training_loss: 1.65701e+01
I0515 03:26:38.468104 140128494741248 run_lib.py:165] step: 345000, eval_loss: 4.32069e+01
I0515 03:26:44.784945 140128494741248 run_lib.py:152] step: 345050, training_loss: 2.88759e+01
I0515 03:26:50.934241 140128494741248 run_lib.py:152] step: 345100, training_loss: 3.37638e+01
I0515 03:26:50.987326 140128494741248 run_lib.py:165] step: 345100, eval_loss: 1.75664e+01
I0515 03:26:57.434374 140128494741248 run_lib.py:152] step: 345150, training_loss: 2.11941e+01
I0515 03:27:03.823259 140128494741248 run_lib.py:152] step: 345200, training_loss: 2.69841e+01
I0515 03:27:03.875938 140128494741248 run_lib.py:165] step: 345200, eval_loss: 4.01107e+01
I0515 03:27:10.115256 140128494741248 run_lib.py:152] step: 345250, training_loss: 3.60183e+01
I0515 03:27:16.261698 140128494741248 run_lib.py:152] step: 345300, training_loss: 2.44435e+01
I0515 03:27:16.311358 140128494741248 run_lib.py:165] step: 345300, eval_loss: 3.75219e+01
I0515 03:27:22.772622 140128494741248 run_lib.py:152] step: 345350, training_loss: 2.41150e+01
I0515 03:27:28.951023 140128494741248 run_lib.py:152] step: 345400, training_loss: 1.97935e+01
I0515 03:27:29.005367 140128494741248 run_lib.py:165] step: 345400, eval_loss: 4.59650e+01
I0515 03:27:35.217600 140128494741248 run_lib.py:152] step: 345450, training_loss: 3.71196e+01
I0515 03:27:41.531547 140128494741248 run_lib.py:152] step: 345500, training_loss: 3.55480e+01
I0515 03:27:41.585581 140128494741248 run_lib.py:165] step: 345500, eval_loss: 3.08547e+01
I0515 03:27:47.825581 140128494741248 run_lib.py:152] step: 345550, training_loss: 3.41893e+01
I0515 03:27:53.972264 140128494741248 run_lib.py:152] step: 345600, training_loss: 3.75295e+01
I0515 03:27:54.022401 140128494741248 run_lib.py:165] step: 345600, eval_loss: 3.11868e+01
I0515 03:28:00.263790 140128494741248 run_lib.py:152] step: 345650, training_loss: 2.00044e+01
I0515 03:28:06.633870 140128494741248 run_lib.py:152] step: 345700, training_loss: 4.57681e+01
I0515 03:28:06.681269 140128494741248 run_lib.py:165] step: 345700, eval_loss: 2.69057e+01
I0515 03:28:12.859757 140128494741248 run_lib.py:152] step: 345750, training_loss: 3.20644e+01
I0515 03:28:19.059867 140128494741248 run_lib.py:152] step: 345800, training_loss: 2.93425e+01
I0515 03:28:19.113887 140128494741248 run_lib.py:165] step: 345800, eval_loss: 2.86851e+01
I0515 03:28:25.562508 140128494741248 run_lib.py:152] step: 345850, training_loss: 1.51777e+01
I0515 03:28:31.717901 140128494741248 run_lib.py:152] step: 345900, training_loss: 2.03858e+01
I0515 03:28:31.769861 140128494741248 run_lib.py:165] step: 345900, eval_loss: 4.26055e+01
I0515 03:28:37.864758 140128494741248 run_lib.py:152] step: 345950, training_loss: 2.62266e+01
I0515 03:28:44.073718 140128494741248 run_lib.py:152] step: 346000, training_loss: 2.98929e+01
I0515 03:28:44.124456 140128494741248 run_lib.py:165] step: 346000, eval_loss: 2.94014e+01
I0515 03:28:50.489262 140128494741248 run_lib.py:152] step: 346050, training_loss: 4.25546e+01
I0515 03:28:56.756144 140128494741248 run_lib.py:152] step: 346100, training_loss: 1.81375e+01
I0515 03:28:56.804081 140128494741248 run_lib.py:165] step: 346100, eval_loss: 2.65122e+01
I0515 03:29:03.059226 140128494741248 run_lib.py:152] step: 346150, training_loss: 4.71836e+01
I0515 03:29:09.407994 140128494741248 run_lib.py:152] step: 346200, training_loss: 3.78410e+01
I0515 03:29:09.462617 140128494741248 run_lib.py:165] step: 346200, eval_loss: 3.56292e+01
I0515 03:29:15.590146 140128494741248 run_lib.py:152] step: 346250, training_loss: 2.74702e+01
I0515 03:29:21.857881 140128494741248 run_lib.py:152] step: 346300, training_loss: 2.40996e+01
I0515 03:29:21.914280 140128494741248 run_lib.py:165] step: 346300, eval_loss: 3.19443e+01
I0515 03:29:28.097054 140128494741248 run_lib.py:152] step: 346350, training_loss: 3.03231e+01
I0515 03:29:34.476203 140128494741248 run_lib.py:152] step: 346400, training_loss: 2.20368e+01
I0515 03:29:34.529552 140128494741248 run_lib.py:165] step: 346400, eval_loss: 2.32288e+01
I0515 03:29:40.773052 140128494741248 run_lib.py:152] step: 346450, training_loss: 4.84961e+01
I0515 03:29:46.951693 140128494741248 run_lib.py:152] step: 346500, training_loss: 3.12504e+01
I0515 03:29:47.003326 140128494741248 run_lib.py:165] step: 346500, eval_loss: 3.53478e+01
I0515 03:29:53.415739 140128494741248 run_lib.py:152] step: 346550, training_loss: 2.10500e+01
I0515 03:29:59.673562 140128494741248 run_lib.py:152] step: 346600, training_loss: 2.76314e+01
I0515 03:29:59.734780 140128494741248 run_lib.py:165] step: 346600, eval_loss: 4.20480e+01
I0515 03:30:05.931076 140128494741248 run_lib.py:152] step: 346650, training_loss: 2.11153e+01
I0515 03:30:12.048256 140128494741248 run_lib.py:152] step: 346700, training_loss: 4.32940e+01
I0515 03:30:12.097367 140128494741248 run_lib.py:165] step: 346700, eval_loss: 3.30831e+01
I0515 03:30:18.421621 140128494741248 run_lib.py:152] step: 346750, training_loss: 3.07139e+01
I0515 03:30:24.614842 140128494741248 run_lib.py:152] step: 346800, training_loss: 3.12214e+01
I0515 03:30:24.666296 140128494741248 run_lib.py:165] step: 346800, eval_loss: 3.50147e+01
I0515 03:30:30.865449 140128494741248 run_lib.py:152] step: 346850, training_loss: 3.63779e+01
I0515 03:30:37.304453 140128494741248 run_lib.py:152] step: 346900, training_loss: 4.51443e+01
I0515 03:30:37.354082 140128494741248 run_lib.py:165] step: 346900, eval_loss: 4.34544e+01
I0515 03:30:43.498805 140128494741248 run_lib.py:152] step: 346950, training_loss: 3.52372e+01
I0515 03:30:49.760400 140128494741248 run_lib.py:152] step: 347000, training_loss: 3.32813e+01
I0515 03:30:49.811888 140128494741248 run_lib.py:165] step: 347000, eval_loss: 2.08145e+01
I0515 03:30:56.110851 140128494741248 run_lib.py:152] step: 347050, training_loss: 3.99424e+01
I0515 03:31:02.591684 140128494741248 run_lib.py:152] step: 347100, training_loss: 3.45743e+01
I0515 03:31:02.647897 140128494741248 run_lib.py:165] step: 347100, eval_loss: 4.48563e+01
I0515 03:31:08.759149 140128494741248 run_lib.py:152] step: 347150, training_loss: 3.12204e+01
I0515 03:31:14.927058 140128494741248 run_lib.py:152] step: 347200, training_loss: 1.94448e+01
I0515 03:31:14.975878 140128494741248 run_lib.py:165] step: 347200, eval_loss: 3.22864e+01
I0515 03:31:21.481331 140128494741248 run_lib.py:152] step: 347250, training_loss: 1.79114e+01
I0515 03:31:27.631196 140128494741248 run_lib.py:152] step: 347300, training_loss: 3.05835e+01
I0515 03:31:27.682487 140128494741248 run_lib.py:165] step: 347300, eval_loss: 3.16703e+01
I0515 03:31:33.931480 140128494741248 run_lib.py:152] step: 347350, training_loss: 1.23747e+01
I0515 03:31:40.178980 140128494741248 run_lib.py:152] step: 347400, training_loss: 2.68419e+01
I0515 03:31:40.233991 140128494741248 run_lib.py:165] step: 347400, eval_loss: 3.68177e+01
I0515 03:31:46.676369 140128494741248 run_lib.py:152] step: 347450, training_loss: 3.66744e+01
I0515 03:31:52.862185 140128494741248 run_lib.py:152] step: 347500, training_loss: 3.20679e+01
I0515 03:31:52.912297 140128494741248 run_lib.py:165] step: 347500, eval_loss: 2.96679e+01
I0515 03:31:59.161566 140128494741248 run_lib.py:152] step: 347550, training_loss: 2.86222e+01
I0515 03:32:05.301421 140128494741248 run_lib.py:152] step: 347600, training_loss: 2.37670e+01
I0515 03:32:05.630656 140128494741248 run_lib.py:165] step: 347600, eval_loss: 4.38507e+01
I0515 03:32:11.799916 140128494741248 run_lib.py:152] step: 347650, training_loss: 2.62081e+01
I0515 03:32:18.129695 140128494741248 run_lib.py:152] step: 347700, training_loss: 4.87604e+01
I0515 03:32:18.185686 140128494741248 run_lib.py:165] step: 347700, eval_loss: 3.49158e+01
I0515 03:32:24.405101 140128494741248 run_lib.py:152] step: 347750, training_loss: 3.01674e+01
I0515 03:32:30.768421 140128494741248 run_lib.py:152] step: 347800, training_loss: 3.62654e+01
I0515 03:32:30.824476 140128494741248 run_lib.py:165] step: 347800, eval_loss: 2.79277e+01
I0515 03:32:37.039543 140128494741248 run_lib.py:152] step: 347850, training_loss: 2.30466e+01
I0515 03:32:43.222155 140128494741248 run_lib.py:152] step: 347900, training_loss: 3.34349e+01
I0515 03:32:43.273248 140128494741248 run_lib.py:165] step: 347900, eval_loss: 2.96615e+01
I0515 03:32:49.680110 140128494741248 run_lib.py:152] step: 347950, training_loss: 3.39421e+01
I0515 03:32:55.814089 140128494741248 run_lib.py:152] step: 348000, training_loss: 6.12790e+01
I0515 03:32:55.867226 140128494741248 run_lib.py:165] step: 348000, eval_loss: 2.18270e+01
I0515 03:33:01.999703 140128494741248 run_lib.py:152] step: 348050, training_loss: 3.02230e+01
I0515 03:33:08.129278 140128494741248 run_lib.py:152] step: 348100, training_loss: 4.36102e+01
I0515 03:33:08.184555 140128494741248 run_lib.py:165] step: 348100, eval_loss: 2.02417e+01
I0515 03:33:14.549907 140128494741248 run_lib.py:152] step: 348150, training_loss: 2.84784e+01
I0515 03:33:20.733556 140128494741248 run_lib.py:152] step: 348200, training_loss: 2.93296e+01
I0515 03:33:20.791985 140128494741248 run_lib.py:165] step: 348200, eval_loss: 3.90704e+01
I0515 03:33:27.081299 140128494741248 run_lib.py:152] step: 348250, training_loss: 3.36189e+01
I0515 03:33:33.504625 140128494741248 run_lib.py:152] step: 348300, training_loss: 4.53766e+01
I0515 03:33:33.558236 140128494741248 run_lib.py:165] step: 348300, eval_loss: 3.10307e+01
I0515 03:33:39.820748 140128494741248 run_lib.py:152] step: 348350, training_loss: 2.77406e+01
I0515 03:33:45.918581 140128494741248 run_lib.py:152] step: 348400, training_loss: 2.53573e+01
I0515 03:33:45.971329 140128494741248 run_lib.py:165] step: 348400, eval_loss: 3.17429e+01
I0515 03:33:52.174625 140128494741248 run_lib.py:152] step: 348450, training_loss: 3.72599e+01
I0515 03:33:58.606584 140128494741248 run_lib.py:152] step: 348500, training_loss: 2.22907e+01
I0515 03:33:58.657511 140128494741248 run_lib.py:165] step: 348500, eval_loss: 4.80859e+01
I0515 03:34:04.847784 140128494741248 run_lib.py:152] step: 348550, training_loss: 1.48500e+01
I0515 03:34:11.033316 140128494741248 run_lib.py:152] step: 348600, training_loss: 3.09228e+01
I0515 03:34:11.089129 140128494741248 run_lib.py:165] step: 348600, eval_loss: 2.38113e+01
I0515 03:34:17.526785 140128494741248 run_lib.py:152] step: 348650, training_loss: 4.83784e+01
I0515 03:34:23.750605 140128494741248 run_lib.py:152] step: 348700, training_loss: 3.21347e+01
I0515 03:34:23.800217 140128494741248 run_lib.py:165] step: 348700, eval_loss: 2.14928e+01
I0515 03:34:30.025679 140128494741248 run_lib.py:152] step: 348750, training_loss: 2.46659e+01
I0515 03:34:36.181284 140128494741248 run_lib.py:152] step: 348800, training_loss: 1.45321e+01
I0515 03:34:36.231589 140128494741248 run_lib.py:165] step: 348800, eval_loss: 2.60874e+01
I0515 03:34:42.637802 140128494741248 run_lib.py:152] step: 348850, training_loss: 3.32558e+01
I0515 03:34:48.821173 140128494741248 run_lib.py:152] step: 348900, training_loss: 2.95389e+01
I0515 03:34:48.871264 140128494741248 run_lib.py:165] step: 348900, eval_loss: 4.15533e+01
I0515 03:34:55.002711 140128494741248 run_lib.py:152] step: 348950, training_loss: 2.77434e+01
I0515 03:35:01.448043 140128494741248 run_lib.py:152] step: 349000, training_loss: 4.46248e+01
I0515 03:35:01.505454 140128494741248 run_lib.py:165] step: 349000, eval_loss: 2.85382e+01
I0515 03:35:07.687830 140128494741248 run_lib.py:152] step: 349050, training_loss: 3.60019e+01
I0515 03:35:13.857574 140128494741248 run_lib.py:152] step: 349100, training_loss: 2.99145e+01
I0515 03:35:13.918840 140128494741248 run_lib.py:165] step: 349100, eval_loss: 1.48930e+01
I0515 03:35:20.100579 140128494741248 run_lib.py:152] step: 349150, training_loss: 4.37970e+01
I0515 03:35:26.544760 140128494741248 run_lib.py:152] step: 349200, training_loss: 2.83553e+01
I0515 03:35:26.595835 140128494741248 run_lib.py:165] step: 349200, eval_loss: 3.35869e+01
I0515 03:35:32.763260 140128494741248 run_lib.py:152] step: 349250, training_loss: 1.95944e+01
I0515 03:35:38.989388 140128494741248 run_lib.py:152] step: 349300, training_loss: 4.17563e+01
I0515 03:35:39.040093 140128494741248 run_lib.py:165] step: 349300, eval_loss: 3.53290e+01
I0515 03:35:45.487969 140128494741248 run_lib.py:152] step: 349350, training_loss: 2.67398e+01
I0515 03:35:51.693843 140128494741248 run_lib.py:152] step: 349400, training_loss: 3.36515e+01
I0515 03:35:51.741186 140128494741248 run_lib.py:165] step: 349400, eval_loss: 3.42088e+01
I0515 03:35:57.888414 140128494741248 run_lib.py:152] step: 349450, training_loss: 4.20293e+01
I0515 03:36:03.939501 140128494741248 run_lib.py:152] step: 349500, training_loss: 4.16253e+01
I0515 03:36:03.991872 140128494741248 run_lib.py:165] step: 349500, eval_loss: 2.81028e+01
I0515 03:36:10.368927 140128494741248 run_lib.py:152] step: 349550, training_loss: 3.53310e+01
I0515 03:36:16.592459 140128494741248 run_lib.py:152] step: 349600, training_loss: 1.54789e+01
I0515 03:36:16.644361 140128494741248 run_lib.py:165] step: 349600, eval_loss: 2.46376e+01
I0515 03:36:22.835493 140128494741248 run_lib.py:152] step: 349650, training_loss: 3.75953e+01
I0515 03:36:29.222253 140128494741248 run_lib.py:152] step: 349700, training_loss: 4.12940e+01
I0515 03:36:29.276702 140128494741248 run_lib.py:165] step: 349700, eval_loss: 2.94256e+01
I0515 03:36:35.545206 140128494741248 run_lib.py:152] step: 349750, training_loss: 3.52083e+01
I0515 03:36:41.841015 140128494741248 run_lib.py:152] step: 349800, training_loss: 2.51974e+01
I0515 03:36:41.895416 140128494741248 run_lib.py:165] step: 349800, eval_loss: 4.03903e+01
I0515 03:36:48.066071 140128494741248 run_lib.py:152] step: 349850, training_loss: 3.20314e+01
I0515 03:36:54.540462 140128494741248 run_lib.py:152] step: 349900, training_loss: 4.05311e+01
I0515 03:36:54.591737 140128494741248 run_lib.py:165] step: 349900, eval_loss: 3.37186e+01
I0515 03:37:00.748605 140128494741248 run_lib.py:152] step: 349950, training_loss: 5.45342e+01
I0515 03:37:06.890842 140128494741248 run_lib.py:152] step: 350000, training_loss: 2.98106e+01
I0515 03:37:07.092323 140128494741248 run_lib.py:165] step: 350000, eval_loss: 2.32218e+01
I0515 03:38:27.648493 140128494741248 run_lib.py:152] step: 350050, training_loss: 3.75618e+01
I0515 03:38:33.814951 140128494741248 run_lib.py:152] step: 350100, training_loss: 3.56740e+01
I0515 03:38:33.865207 140128494741248 run_lib.py:165] step: 350100, eval_loss: 1.96454e+01
I0515 03:38:40.226422 140128494741248 run_lib.py:152] step: 350150, training_loss: 2.49012e+01
I0515 03:38:46.628052 140128494741248 run_lib.py:152] step: 350200, training_loss: 2.23172e+01
I0515 03:38:46.680381 140128494741248 run_lib.py:165] step: 350200, eval_loss: 2.54760e+01
I0515 03:38:52.960163 140128494741248 run_lib.py:152] step: 350250, training_loss: 3.13375e+01
I0515 03:38:59.128136 140128494741248 run_lib.py:152] step: 350300, training_loss: 2.82589e+01
I0515 03:38:59.179787 140128494741248 run_lib.py:165] step: 350300, eval_loss: 2.21210e+01
I0515 03:39:05.410054 140128494741248 run_lib.py:152] step: 350350, training_loss: 2.68346e+01
I0515 03:39:11.865530 140128494741248 run_lib.py:152] step: 350400, training_loss: 3.61216e+01
I0515 03:39:11.918414 140128494741248 run_lib.py:165] step: 350400, eval_loss: 3.01658e+01
I0515 03:39:18.208479 140128494741248 run_lib.py:152] step: 350450, training_loss: 3.86116e+01
I0515 03:39:24.424695 140128494741248 run_lib.py:152] step: 350500, training_loss: 4.71353e+01
I0515 03:39:24.480517 140128494741248 run_lib.py:165] step: 350500, eval_loss: 2.18190e+01
I0515 03:39:30.886471 140128494741248 run_lib.py:152] step: 350550, training_loss: 2.98264e+01
I0515 03:39:37.009028 140128494741248 run_lib.py:152] step: 350600, training_loss: 4.22713e+01
I0515 03:39:37.056732 140128494741248 run_lib.py:165] step: 350600, eval_loss: 2.52739e+01
I0515 03:39:43.329038 140128494741248 run_lib.py:152] step: 350650, training_loss: 3.91212e+01
I0515 03:39:49.455025 140128494741248 run_lib.py:152] step: 350700, training_loss: 3.12249e+01
I0515 03:39:49.506903 140128494741248 run_lib.py:165] step: 350700, eval_loss: 2.59303e+01
I0515 03:39:56.050839 140128494741248 run_lib.py:152] step: 350750, training_loss: 3.20187e+01
I0515 03:40:02.217856 140128494741248 run_lib.py:152] step: 350800, training_loss: 3.42398e+01
I0515 03:40:02.264951 140128494741248 run_lib.py:165] step: 350800, eval_loss: 2.44771e+01
I0515 03:40:08.388757 140128494741248 run_lib.py:152] step: 350850, training_loss: 1.85553e+01
I0515 03:40:14.860084 140128494741248 run_lib.py:152] step: 350900, training_loss: 2.92360e+01
I0515 03:40:14.906743 140128494741248 run_lib.py:165] step: 350900, eval_loss: 2.25657e+01
I0515 03:40:21.149833 140128494741248 run_lib.py:152] step: 350950, training_loss: 2.57434e+01
I0515 03:40:27.336390 140128494741248 run_lib.py:152] step: 351000, training_loss: 2.98746e+01
I0515 03:40:27.391698 140128494741248 run_lib.py:165] step: 351000, eval_loss: 2.85534e+01
I0515 03:40:33.657704 140128494741248 run_lib.py:152] step: 351050, training_loss: 2.43076e+01
I0515 03:40:40.063185 140128494741248 run_lib.py:152] step: 351100, training_loss: 3.37792e+01
I0515 03:40:40.112759 140128494741248 run_lib.py:165] step: 351100, eval_loss: 3.08986e+01
I0515 03:40:46.297875 140128494741248 run_lib.py:152] step: 351150, training_loss: 2.84459e+01
I0515 03:40:52.547107 140128494741248 run_lib.py:152] step: 351200, training_loss: 2.97430e+01
I0515 03:40:52.599997 140128494741248 run_lib.py:165] step: 351200, eval_loss: 2.60323e+01
I0515 03:40:58.925400 140128494741248 run_lib.py:152] step: 351250, training_loss: 3.59007e+01
I0515 03:41:05.201268 140128494741248 run_lib.py:152] step: 351300, training_loss: 2.95885e+01
I0515 03:41:05.255744 140128494741248 run_lib.py:165] step: 351300, eval_loss: 4.35417e+01
I0515 03:41:11.582652 140128494741248 run_lib.py:152] step: 351350, training_loss: 2.33189e+01
I0515 03:41:17.721747 140128494741248 run_lib.py:152] step: 351400, training_loss: 2.54959e+01
I0515 03:41:17.774964 140128494741248 run_lib.py:165] step: 351400, eval_loss: 1.72609e+01
I0515 03:41:24.185376 140128494741248 run_lib.py:152] step: 351450, training_loss: 2.30786e+01
I0515 03:41:30.363057 140128494741248 run_lib.py:152] step: 351500, training_loss: 3.95383e+01
I0515 03:41:30.413679 140128494741248 run_lib.py:165] step: 351500, eval_loss: 3.38038e+01
I0515 03:41:36.603302 140128494741248 run_lib.py:152] step: 351550, training_loss: 3.76708e+01
I0515 03:41:43.118367 140128494741248 run_lib.py:152] step: 351600, training_loss: 2.34915e+01
I0515 03:41:43.174813 140128494741248 run_lib.py:165] step: 351600, eval_loss: 2.40735e+01
I0515 03:41:49.383306 140128494741248 run_lib.py:152] step: 351650, training_loss: 2.06813e+01
I0515 03:41:55.635941 140128494741248 run_lib.py:152] step: 351700, training_loss: 4.44266e+01
I0515 03:41:55.687842 140128494741248 run_lib.py:165] step: 351700, eval_loss: 2.00646e+01
I0515 03:42:01.915693 140128494741248 run_lib.py:152] step: 351750, training_loss: 3.51041e+01
I0515 03:42:08.291215 140128494741248 run_lib.py:152] step: 351800, training_loss: 2.96188e+01
I0515 03:42:08.342740 140128494741248 run_lib.py:165] step: 351800, eval_loss: 1.85322e+01
I0515 03:42:14.591843 140128494741248 run_lib.py:152] step: 351850, training_loss: 1.67986e+01
I0515 03:42:20.732747 140128494741248 run_lib.py:152] step: 351900, training_loss: 1.91470e+01
I0515 03:42:20.785279 140128494741248 run_lib.py:165] step: 351900, eval_loss: 2.20635e+01
I0515 03:42:27.163357 140128494741248 run_lib.py:152] step: 351950, training_loss: 3.90137e+01
I0515 03:42:33.400758 140128494741248 run_lib.py:152] step: 352000, training_loss: 2.83401e+01
I0515 03:42:33.457227 140128494741248 run_lib.py:165] step: 352000, eval_loss: 3.33076e+01
I0515 03:42:39.642880 140128494741248 run_lib.py:152] step: 352050, training_loss: 3.92689e+01
I0515 03:42:45.877905 140128494741248 run_lib.py:152] step: 352100, training_loss: 3.48690e+01
I0515 03:42:45.933220 140128494741248 run_lib.py:165] step: 352100, eval_loss: 3.95216e+01
I0515 03:42:52.303340 140128494741248 run_lib.py:152] step: 352150, training_loss: 4.02643e+01
I0515 03:42:58.452526 140128494741248 run_lib.py:152] step: 352200, training_loss: 3.37223e+01
I0515 03:42:58.506174 140128494741248 run_lib.py:165] step: 352200, eval_loss: 4.87487e+01
I0515 03:43:04.757453 140128494741248 run_lib.py:152] step: 352250, training_loss: 2.20238e+01
I0515 03:43:11.216880 140128494741248 run_lib.py:152] step: 352300, training_loss: 2.74064e+01
I0515 03:43:11.270777 140128494741248 run_lib.py:165] step: 352300, eval_loss: 3.12407e+01
I0515 03:43:17.476423 140128494741248 run_lib.py:152] step: 352350, training_loss: 4.25343e+01
I0515 03:43:23.671262 140128494741248 run_lib.py:152] step: 352400, training_loss: 3.43474e+01
I0515 03:43:23.726700 140128494741248 run_lib.py:165] step: 352400, eval_loss: 3.66495e+01
I0515 03:43:29.937285 140128494741248 run_lib.py:152] step: 352450, training_loss: 1.75786e+01
I0515 03:43:36.392276 140128494741248 run_lib.py:152] step: 352500, training_loss: 2.86923e+01
I0515 03:43:36.455322 140128494741248 run_lib.py:165] step: 352500, eval_loss: 2.44126e+01
I0515 03:43:42.643702 140128494741248 run_lib.py:152] step: 352550, training_loss: 2.47979e+01
I0515 03:43:48.804280 140128494741248 run_lib.py:152] step: 352600, training_loss: 2.63982e+01
I0515 03:43:48.861611 140128494741248 run_lib.py:165] step: 352600, eval_loss: 3.78158e+01
I0515 03:43:55.275336 140128494741248 run_lib.py:152] step: 352650, training_loss: 3.39889e+01
I0515 03:44:01.519073 140128494741248 run_lib.py:152] step: 352700, training_loss: 2.95506e+01
I0515 03:44:01.569906 140128494741248 run_lib.py:165] step: 352700, eval_loss: 2.93512e+01
I0515 03:44:07.756455 140128494741248 run_lib.py:152] step: 352750, training_loss: 2.96258e+01
I0515 03:44:13.925263 140128494741248 run_lib.py:152] step: 352800, training_loss: 5.97716e+01
I0515 03:44:13.974427 140128494741248 run_lib.py:165] step: 352800, eval_loss: 3.38840e+01
I0515 03:44:20.376633 140128494741248 run_lib.py:152] step: 352850, training_loss: 2.86747e+01
I0515 03:44:26.610871 140128494741248 run_lib.py:152] step: 352900, training_loss: 2.76393e+01
I0515 03:44:26.660372 140128494741248 run_lib.py:165] step: 352900, eval_loss: 2.42191e+01
I0515 03:44:32.722846 140128494741248 run_lib.py:152] step: 352950, training_loss: 1.88965e+01
I0515 03:44:39.165014 140128494741248 run_lib.py:152] step: 353000, training_loss: 4.35386e+01
I0515 03:44:39.216857 140128494741248 run_lib.py:165] step: 353000, eval_loss: 1.73420e+01
I0515 03:44:45.365129 140128494741248 run_lib.py:152] step: 353050, training_loss: 2.60171e+01
I0515 03:44:51.597451 140128494741248 run_lib.py:152] step: 353100, training_loss: 3.78511e+01
I0515 03:44:51.649385 140128494741248 run_lib.py:165] step: 353100, eval_loss: 3.00223e+01
I0515 03:44:57.903199 140128494741248 run_lib.py:152] step: 353150, training_loss: 3.81521e+01
I0515 03:45:04.341578 140128494741248 run_lib.py:152] step: 353200, training_loss: 2.22649e+01
I0515 03:45:04.392207 140128494741248 run_lib.py:165] step: 353200, eval_loss: 3.74966e+01
I0515 03:45:10.602179 140128494741248 run_lib.py:152] step: 353250, training_loss: 2.07399e+01
I0515 03:45:16.898678 140128494741248 run_lib.py:152] step: 353300, training_loss: 4.28249e+01
I0515 03:45:16.953979 140128494741248 run_lib.py:165] step: 353300, eval_loss: 3.82724e+01
I0515 03:45:23.315209 140128494741248 run_lib.py:152] step: 353350, training_loss: 3.33639e+01
I0515 03:45:29.531610 140128494741248 run_lib.py:152] step: 353400, training_loss: 2.42263e+01
I0515 03:45:29.589740 140128494741248 run_lib.py:165] step: 353400, eval_loss: 1.86297e+01
I0515 03:45:35.813986 140128494741248 run_lib.py:152] step: 353450, training_loss: 2.52150e+01
I0515 03:45:41.926131 140128494741248 run_lib.py:152] step: 353500, training_loss: 1.87346e+01
I0515 03:45:41.975116 140128494741248 run_lib.py:165] step: 353500, eval_loss: 3.45732e+01
I0515 03:45:48.403485 140128494741248 run_lib.py:152] step: 353550, training_loss: 4.23995e+01
I0515 03:45:54.580378 140128494741248 run_lib.py:152] step: 353600, training_loss: 3.90914e+01
I0515 03:45:54.627799 140128494741248 run_lib.py:165] step: 353600, eval_loss: 2.52630e+01
I0515 03:46:00.885735 140128494741248 run_lib.py:152] step: 353650, training_loss: 3.04158e+01
I0515 03:46:07.189058 140128494741248 run_lib.py:152] step: 353700, training_loss: 3.27995e+01
I0515 03:46:07.242592 140128494741248 run_lib.py:165] step: 353700, eval_loss: 2.91196e+01
I0515 03:46:13.401213 140128494741248 run_lib.py:152] step: 353750, training_loss: 3.28514e+01
I0515 03:46:19.589363 140128494741248 run_lib.py:152] step: 353800, training_loss: 2.18119e+01
I0515 03:46:19.637876 140128494741248 run_lib.py:165] step: 353800, eval_loss: 1.91486e+01
I0515 03:46:25.895377 140128494741248 run_lib.py:152] step: 353850, training_loss: 1.88127e+01
I0515 03:46:32.303797 140128494741248 run_lib.py:152] step: 353900, training_loss: 2.86459e+01
I0515 03:46:32.356291 140128494741248 run_lib.py:165] step: 353900, eval_loss: 3.41427e+01
I0515 03:46:38.427137 140128494741248 run_lib.py:152] step: 353950, training_loss: 3.50829e+01
I0515 03:46:44.583817 140128494741248 run_lib.py:152] step: 354000, training_loss: 4.70625e+01
I0515 03:46:44.630434 140128494741248 run_lib.py:165] step: 354000, eval_loss: 1.79617e+01
I0515 03:46:51.066291 140128494741248 run_lib.py:152] step: 354050, training_loss: 3.43679e+01
I0515 03:46:57.198344 140128494741248 run_lib.py:152] step: 354100, training_loss: 2.02010e+01
I0515 03:46:57.247050 140128494741248 run_lib.py:165] step: 354100, eval_loss: 3.98784e+01
I0515 03:47:03.487037 140128494741248 run_lib.py:152] step: 354150, training_loss: 3.69624e+01
I0515 03:47:09.718672 140128494741248 run_lib.py:152] step: 354200, training_loss: 3.28622e+01
I0515 03:47:09.770990 140128494741248 run_lib.py:165] step: 354200, eval_loss: 3.18022e+01
I0515 03:47:16.292996 140128494741248 run_lib.py:152] step: 354250, training_loss: 2.75962e+01
I0515 03:47:22.394532 140128494741248 run_lib.py:152] step: 354300, training_loss: 3.88000e+01
I0515 03:47:22.449546 140128494741248 run_lib.py:165] step: 354300, eval_loss: 4.32796e+01
I0515 03:47:28.621737 140128494741248 run_lib.py:152] step: 354350, training_loss: 2.65549e+01
I0515 03:47:35.072627 140128494741248 run_lib.py:152] step: 354400, training_loss: 2.88875e+01
I0515 03:47:35.122283 140128494741248 run_lib.py:165] step: 354400, eval_loss: 2.18701e+01
I0515 03:47:41.309443 140128494741248 run_lib.py:152] step: 354450, training_loss: 2.76088e+01
I0515 03:47:47.415550 140128494741248 run_lib.py:152] step: 354500, training_loss: 1.46430e+01
I0515 03:47:47.468898 140128494741248 run_lib.py:165] step: 354500, eval_loss: 3.33311e+01
I0515 03:47:53.723338 140128494741248 run_lib.py:152] step: 354550, training_loss: 2.72799e+01
I0515 03:48:00.181165 140128494741248 run_lib.py:152] step: 354600, training_loss: 3.24598e+01
I0515 03:48:00.232116 140128494741248 run_lib.py:165] step: 354600, eval_loss: 1.92697e+01
I0515 03:48:06.324005 140128494741248 run_lib.py:152] step: 354650, training_loss: 2.72862e+01
I0515 03:48:12.541384 140128494741248 run_lib.py:152] step: 354700, training_loss: 3.04161e+01
I0515 03:48:12.594184 140128494741248 run_lib.py:165] step: 354700, eval_loss: 3.28972e+01
I0515 03:48:19.043179 140128494741248 run_lib.py:152] step: 354750, training_loss: 3.38381e+01
I0515 03:48:25.153463 140128494741248 run_lib.py:152] step: 354800, training_loss: 3.20684e+01
I0515 03:48:25.210416 140128494741248 run_lib.py:165] step: 354800, eval_loss: 2.73094e+01
I0515 03:48:31.420495 140128494741248 run_lib.py:152] step: 354850, training_loss: 3.33517e+01
I0515 03:48:37.644851 140128494741248 run_lib.py:152] step: 354900, training_loss: 4.61128e+01
I0515 03:48:37.693515 140128494741248 run_lib.py:165] step: 354900, eval_loss: 1.82982e+01
I0515 03:48:44.241250 140128494741248 run_lib.py:152] step: 354950, training_loss: 3.72031e+01
I0515 03:48:50.481281 140128494741248 run_lib.py:152] step: 355000, training_loss: 1.83857e+01
I0515 03:48:50.532364 140128494741248 run_lib.py:165] step: 355000, eval_loss: 3.07287e+01
I0515 03:48:56.756765 140128494741248 run_lib.py:152] step: 355050, training_loss: 2.34263e+01
I0515 03:49:03.190287 140128494741248 run_lib.py:152] step: 355100, training_loss: 3.43917e+01
I0515 03:49:03.250089 140128494741248 run_lib.py:165] step: 355100, eval_loss: 3.45226e+01
I0515 03:49:09.438814 140128494741248 run_lib.py:152] step: 355150, training_loss: 2.92707e+01
I0515 03:49:15.626419 140128494741248 run_lib.py:152] step: 355200, training_loss: 2.72141e+01
I0515 03:49:15.679146 140128494741248 run_lib.py:165] step: 355200, eval_loss: 2.68169e+01
I0515 03:49:21.919348 140128494741248 run_lib.py:152] step: 355250, training_loss: 4.30484e+01
I0515 03:49:28.265893 140128494741248 run_lib.py:152] step: 355300, training_loss: 1.94724e+01
I0515 03:49:28.319496 140128494741248 run_lib.py:165] step: 355300, eval_loss: 3.85461e+01
I0515 03:49:34.576778 140128494741248 run_lib.py:152] step: 355350, training_loss: 2.76868e+01
I0515 03:49:40.713851 140128494741248 run_lib.py:152] step: 355400, training_loss: 3.77465e+01
I0515 03:49:40.764320 140128494741248 run_lib.py:165] step: 355400, eval_loss: 3.02653e+01
I0515 03:49:47.223762 140128494741248 run_lib.py:152] step: 355450, training_loss: 3.89986e+01
I0515 03:49:53.419286 140128494741248 run_lib.py:152] step: 355500, training_loss: 2.97242e+01
I0515 03:49:53.479995 140128494741248 run_lib.py:165] step: 355500, eval_loss: 2.64670e+01
I0515 03:49:59.658917 140128494741248 run_lib.py:152] step: 355550, training_loss: 3.55422e+01
I0515 03:50:05.861931 140128494741248 run_lib.py:152] step: 355600, training_loss: 2.77672e+01
I0515 03:50:05.917135 140128494741248 run_lib.py:165] step: 355600, eval_loss: 3.30921e+01
I0515 03:50:12.415630 140128494741248 run_lib.py:152] step: 355650, training_loss: 3.43998e+01
I0515 03:50:18.596709 140128494741248 run_lib.py:152] step: 355700, training_loss: 4.28942e+01
I0515 03:50:18.645246 140128494741248 run_lib.py:165] step: 355700, eval_loss: 2.69754e+01
I0515 03:50:24.863833 140128494741248 run_lib.py:152] step: 355750, training_loss: 2.66772e+01
I0515 03:50:31.177659 140128494741248 run_lib.py:152] step: 355800, training_loss: 1.94302e+01
I0515 03:50:31.228331 140128494741248 run_lib.py:165] step: 355800, eval_loss: 3.60043e+01
I0515 03:50:37.449451 140128494741248 run_lib.py:152] step: 355850, training_loss: 1.88014e+01
I0515 03:50:43.585702 140128494741248 run_lib.py:152] step: 355900, training_loss: 2.05663e+01
I0515 03:50:43.635853 140128494741248 run_lib.py:165] step: 355900, eval_loss: 3.40917e+01
I0515 03:50:49.960824 140128494741248 run_lib.py:152] step: 355950, training_loss: 3.76016e+01
I0515 03:50:56.323195 140128494741248 run_lib.py:152] step: 356000, training_loss: 4.48928e+01
I0515 03:50:56.380594 140128494741248 run_lib.py:165] step: 356000, eval_loss: 4.05468e+01
I0515 03:51:02.656359 140128494741248 run_lib.py:152] step: 356050, training_loss: 3.00653e+01
I0515 03:51:08.908151 140128494741248 run_lib.py:152] step: 356100, training_loss: 2.68130e+01
I0515 03:51:08.959152 140128494741248 run_lib.py:165] step: 356100, eval_loss: 2.29888e+01
I0515 03:51:15.444309 140128494741248 run_lib.py:152] step: 356150, training_loss: 3.73839e+01
I0515 03:51:21.516414 140128494741248 run_lib.py:152] step: 356200, training_loss: 2.62045e+01
I0515 03:51:21.565661 140128494741248 run_lib.py:165] step: 356200, eval_loss: 2.53767e+01
I0515 03:51:27.667749 140128494741248 run_lib.py:152] step: 356250, training_loss: 4.07011e+01
I0515 03:51:33.634149 140128494741248 run_lib.py:152] step: 356300, training_loss: 2.87556e+01
I0515 03:51:33.684004 140128494741248 run_lib.py:165] step: 356300, eval_loss: 2.99062e+01
I0515 03:51:40.206602 140128494741248 run_lib.py:152] step: 356350, training_loss: 3.74634e+01
I0515 03:51:46.568185 140128494741248 run_lib.py:152] step: 356400, training_loss: 2.26763e+01
I0515 03:51:46.619858 140128494741248 run_lib.py:165] step: 356400, eval_loss: 4.43660e+01
I0515 03:51:52.982620 140128494741248 run_lib.py:152] step: 356450, training_loss: 2.51369e+01
I0515 03:51:59.470067 140128494741248 run_lib.py:152] step: 356500, training_loss: 2.96731e+01
I0515 03:51:59.522594 140128494741248 run_lib.py:165] step: 356500, eval_loss: 2.18142e+01
I0515 03:52:05.811401 140128494741248 run_lib.py:152] step: 356550, training_loss: 2.92465e+01
I0515 03:52:11.996749 140128494741248 run_lib.py:152] step: 356600, training_loss: 4.27115e+01
I0515 03:52:12.051327 140128494741248 run_lib.py:165] step: 356600, eval_loss: 2.58428e+01
I0515 03:52:18.329707 140128494741248 run_lib.py:152] step: 356650, training_loss: 3.91350e+01
I0515 03:52:24.827214 140128494741248 run_lib.py:152] step: 356700, training_loss: 3.85537e+01
I0515 03:52:24.879903 140128494741248 run_lib.py:165] step: 356700, eval_loss: 2.57291e+01
I0515 03:52:31.110327 140128494741248 run_lib.py:152] step: 356750, training_loss: 2.91213e+01
I0515 03:52:37.390527 140128494741248 run_lib.py:152] step: 356800, training_loss: 3.13459e+01
I0515 03:52:37.446277 140128494741248 run_lib.py:165] step: 356800, eval_loss: 2.21810e+01
I0515 03:52:43.801578 140128494741248 run_lib.py:152] step: 356850, training_loss: 2.72648e+01
I0515 03:52:50.110470 140128494741248 run_lib.py:152] step: 356900, training_loss: 3.74931e+01
I0515 03:52:50.163210 140128494741248 run_lib.py:165] step: 356900, eval_loss: 3.02635e+01
I0515 03:52:56.427157 140128494741248 run_lib.py:152] step: 356950, training_loss: 2.97551e+01
I0515 03:53:02.612565 140128494741248 run_lib.py:152] step: 357000, training_loss: 2.42454e+01
I0515 03:53:02.661557 140128494741248 run_lib.py:165] step: 357000, eval_loss: 3.07841e+01
I0515 03:53:09.137450 140128494741248 run_lib.py:152] step: 357050, training_loss: 4.89258e+01
I0515 03:53:15.289329 140128494741248 run_lib.py:152] step: 357100, training_loss: 3.44457e+01
I0515 03:53:15.337859 140128494741248 run_lib.py:165] step: 357100, eval_loss: 2.68201e+01
I0515 03:53:21.556415 140128494741248 run_lib.py:152] step: 357150, training_loss: 3.17573e+01
I0515 03:53:27.956575 140128494741248 run_lib.py:152] step: 357200, training_loss: 2.84445e+01
I0515 03:53:28.007547 140128494741248 run_lib.py:165] step: 357200, eval_loss: 1.76876e+01
I0515 03:53:34.255433 140128494741248 run_lib.py:152] step: 357250, training_loss: 3.07289e+01
I0515 03:53:40.524265 140128494741248 run_lib.py:152] step: 357300, training_loss: 3.19452e+01
I0515 03:53:40.573769 140128494741248 run_lib.py:165] step: 357300, eval_loss: 3.33071e+01
I0515 03:53:46.882510 140128494741248 run_lib.py:152] step: 357350, training_loss: 3.15355e+01
I0515 03:53:53.322926 140128494741248 run_lib.py:152] step: 357400, training_loss: 3.78477e+01
I0515 03:53:53.376805 140128494741248 run_lib.py:165] step: 357400, eval_loss: 2.72915e+01
I0515 03:53:59.618249 140128494741248 run_lib.py:152] step: 357450, training_loss: 3.32687e+01
I0515 03:54:05.903231 140128494741248 run_lib.py:152] step: 357500, training_loss: 1.85783e+01
I0515 03:54:05.954150 140128494741248 run_lib.py:165] step: 357500, eval_loss: 3.64274e+01
I0515 03:54:12.411512 140128494741248 run_lib.py:152] step: 357550, training_loss: 4.22871e+01
I0515 03:54:18.607739 140128494741248 run_lib.py:152] step: 357600, training_loss: 2.87575e+01
I0515 03:54:18.663054 140128494741248 run_lib.py:165] step: 357600, eval_loss: 2.43047e+01
I0515 03:54:24.757606 140128494741248 run_lib.py:152] step: 357650, training_loss: 2.54619e+01
I0515 03:54:31.069792 140128494741248 run_lib.py:152] step: 357700, training_loss: 3.66136e+01
I0515 03:54:31.128029 140128494741248 run_lib.py:165] step: 357700, eval_loss: 4.04454e+01
I0515 03:54:37.669464 140128494741248 run_lib.py:152] step: 357750, training_loss: 3.04792e+01
I0515 03:54:43.910417 140128494741248 run_lib.py:152] step: 357800, training_loss: 3.21466e+01
I0515 03:54:43.970436 140128494741248 run_lib.py:165] step: 357800, eval_loss: 3.54679e+01
I0515 03:54:50.187745 140128494741248 run_lib.py:152] step: 357850, training_loss: 2.85789e+01
I0515 03:54:56.715923 140128494741248 run_lib.py:152] step: 357900, training_loss: 2.19108e+01
I0515 03:54:56.768003 140128494741248 run_lib.py:165] step: 357900, eval_loss: 3.21976e+01
I0515 03:55:02.931213 140128494741248 run_lib.py:152] step: 357950, training_loss: 2.79606e+01
I0515 03:55:09.200649 140128494741248 run_lib.py:152] step: 358000, training_loss: 2.96778e+01
I0515 03:55:09.260881 140128494741248 run_lib.py:165] step: 358000, eval_loss: 2.77321e+01
I0515 03:55:15.494009 140128494741248 run_lib.py:152] step: 358050, training_loss: 3.35853e+01
I0515 03:55:21.969400 140128494741248 run_lib.py:152] step: 358100, training_loss: 2.96423e+01
I0515 03:55:22.018340 140128494741248 run_lib.py:165] step: 358100, eval_loss: 1.74878e+01
I0515 03:55:28.273619 140128494741248 run_lib.py:152] step: 358150, training_loss: 4.22953e+01
I0515 03:55:34.448021 140128494741248 run_lib.py:152] step: 358200, training_loss: 3.78899e+01
I0515 03:55:34.496591 140128494741248 run_lib.py:165] step: 358200, eval_loss: 2.48852e+01
I0515 03:55:40.885521 140128494741248 run_lib.py:152] step: 358250, training_loss: 3.00882e+01
I0515 03:55:47.145615 140128494741248 run_lib.py:152] step: 358300, training_loss: 3.12085e+01
I0515 03:55:47.200403 140128494741248 run_lib.py:165] step: 358300, eval_loss: 2.33527e+01
I0515 03:55:53.472136 140128494741248 run_lib.py:152] step: 358350, training_loss: 2.68242e+01
I0515 03:55:59.631596 140128494741248 run_lib.py:152] step: 358400, training_loss: 2.85461e+01
I0515 03:55:59.683818 140128494741248 run_lib.py:165] step: 358400, eval_loss: 2.71841e+01
I0515 03:56:06.092417 140128494741248 run_lib.py:152] step: 358450, training_loss: 2.86708e+01
I0515 03:56:12.309810 140128494741248 run_lib.py:152] step: 358500, training_loss: 3.11555e+01
I0515 03:56:12.357239 140128494741248 run_lib.py:165] step: 358500, eval_loss: 3.19219e+01
I0515 03:56:18.638037 140128494741248 run_lib.py:152] step: 358550, training_loss: 2.88175e+01
I0515 03:56:25.104426 140128494741248 run_lib.py:152] step: 358600, training_loss: 2.11471e+01
I0515 03:56:25.159819 140128494741248 run_lib.py:165] step: 358600, eval_loss: 2.25345e+01
I0515 03:56:31.437056 140128494741248 run_lib.py:152] step: 358650, training_loss: 4.19549e+01
I0515 03:56:37.712396 140128494741248 run_lib.py:152] step: 358700, training_loss: 2.04434e+01
I0515 03:56:37.762717 140128494741248 run_lib.py:165] step: 358700, eval_loss: 2.97133e+01
I0515 03:56:43.979304 140128494741248 run_lib.py:152] step: 358750, training_loss: 1.93179e+01
I0515 03:56:50.462211 140128494741248 run_lib.py:152] step: 358800, training_loss: 2.65721e+01
I0515 03:56:50.518369 140128494741248 run_lib.py:165] step: 358800, eval_loss: 3.46458e+01
I0515 03:56:56.759576 140128494741248 run_lib.py:152] step: 358850, training_loss: 2.47331e+01
I0515 03:57:02.931188 140128494741248 run_lib.py:152] step: 358900, training_loss: 4.67109e+01
I0515 03:57:02.986180 140128494741248 run_lib.py:165] step: 358900, eval_loss: 2.66242e+01
I0515 03:57:09.380158 140128494741248 run_lib.py:152] step: 358950, training_loss: 1.84203e+01
I0515 03:57:15.579408 140128494741248 run_lib.py:152] step: 359000, training_loss: 3.33874e+01
I0515 03:57:15.631036 140128494741248 run_lib.py:165] step: 359000, eval_loss: 2.61279e+01
I0515 03:57:21.787187 140128494741248 run_lib.py:152] step: 359050, training_loss: 2.96248e+01
I0515 03:57:27.910021 140128494741248 run_lib.py:152] step: 359100, training_loss: 2.54753e+01
I0515 03:57:27.960114 140128494741248 run_lib.py:165] step: 359100, eval_loss: 3.77839e+01
I0515 03:57:34.422083 140128494741248 run_lib.py:152] step: 359150, training_loss: 2.20367e+01
I0515 03:57:40.690972 140128494741248 run_lib.py:152] step: 359200, training_loss: 3.35335e+01
I0515 03:57:40.741946 140128494741248 run_lib.py:165] step: 359200, eval_loss: 2.36491e+01
I0515 03:57:46.876601 140128494741248 run_lib.py:152] step: 359250, training_loss: 3.28357e+01
I0515 03:57:53.309642 140128494741248 run_lib.py:152] step: 359300, training_loss: 3.15879e+01
I0515 03:57:53.357234 140128494741248 run_lib.py:165] step: 359300, eval_loss: 3.06183e+01
I0515 03:57:59.606731 140128494741248 run_lib.py:152] step: 359350, training_loss: 4.00139e+01
I0515 03:58:05.731707 140128494741248 run_lib.py:152] step: 359400, training_loss: 3.86114e+01
I0515 03:58:05.783914 140128494741248 run_lib.py:165] step: 359400, eval_loss: 2.33730e+01
I0515 03:58:12.002016 140128494741248 run_lib.py:152] step: 359450, training_loss: 2.04587e+01
I0515 03:58:18.438855 140128494741248 run_lib.py:152] step: 359500, training_loss: 3.65095e+01
I0515 03:58:18.492040 140128494741248 run_lib.py:165] step: 359500, eval_loss: 3.75555e+01
I0515 03:58:24.676977 140128494741248 run_lib.py:152] step: 359550, training_loss: 2.02868e+01
I0515 03:58:30.861319 140128494741248 run_lib.py:152] step: 359600, training_loss: 3.30893e+01
I0515 03:58:30.915851 140128494741248 run_lib.py:165] step: 359600, eval_loss: 1.84499e+01
I0515 03:58:37.308954 140128494741248 run_lib.py:152] step: 359650, training_loss: 2.67388e+01
I0515 03:58:43.505354 140128494741248 run_lib.py:152] step: 359700, training_loss: 5.36837e+01
I0515 03:58:43.563135 140128494741248 run_lib.py:165] step: 359700, eval_loss: 2.50848e+01
I0515 03:58:49.701632 140128494741248 run_lib.py:152] step: 359750, training_loss: 3.07221e+01
I0515 03:58:56.027444 140128494741248 run_lib.py:152] step: 359800, training_loss: 1.90907e+01
I0515 03:58:56.076460 140128494741248 run_lib.py:165] step: 359800, eval_loss: 4.91290e+01
I0515 03:59:02.570214 140128494741248 run_lib.py:152] step: 359850, training_loss: 3.84707e+01
I0515 03:59:08.756281 140128494741248 run_lib.py:152] step: 359900, training_loss: 2.87508e+01
I0515 03:59:08.810352 140128494741248 run_lib.py:165] step: 359900, eval_loss: 2.71045e+01
I0515 03:59:15.086686 140128494741248 run_lib.py:152] step: 359950, training_loss: 2.82097e+01
I0515 03:59:21.648494 140128494741248 run_lib.py:152] step: 360000, training_loss: 2.25829e+01
I0515 03:59:21.853585 140128494741248 run_lib.py:165] step: 360000, eval_loss: 3.43472e+01
I0515 03:59:28.071532 140128494741248 run_lib.py:152] step: 360050, training_loss: 4.04000e+01
I0515 03:59:34.314472 140128494741248 run_lib.py:152] step: 360100, training_loss: 3.11911e+01
I0515 03:59:34.366337 140128494741248 run_lib.py:165] step: 360100, eval_loss: 3.86835e+01
I0515 03:59:40.578542 140128494741248 run_lib.py:152] step: 360150, training_loss: 2.10826e+01
I0515 03:59:47.026959 140128494741248 run_lib.py:152] step: 360200, training_loss: 2.28700e+01
I0515 03:59:47.080186 140128494741248 run_lib.py:165] step: 360200, eval_loss: 1.87019e+01
I0515 03:59:53.198939 140128494741248 run_lib.py:152] step: 360250, training_loss: 3.01333e+01
I0515 03:59:59.402338 140128494741248 run_lib.py:152] step: 360300, training_loss: 2.44515e+01
I0515 03:59:59.457001 140128494741248 run_lib.py:165] step: 360300, eval_loss: 2.83077e+01
I0515 04:00:05.906265 140128494741248 run_lib.py:152] step: 360350, training_loss: 2.94319e+01
I0515 04:00:12.100284 140128494741248 run_lib.py:152] step: 360400, training_loss: 1.75980e+01
I0515 04:00:12.152253 140128494741248 run_lib.py:165] step: 360400, eval_loss: 4.19975e+01
I0515 04:00:18.362940 140128494741248 run_lib.py:152] step: 360450, training_loss: 3.93617e+01
I0515 04:00:24.572212 140128494741248 run_lib.py:152] step: 360500, training_loss: 3.00926e+01
I0515 04:00:24.627081 140128494741248 run_lib.py:165] step: 360500, eval_loss: 3.82043e+01
I0515 04:00:30.996538 140128494741248 run_lib.py:152] step: 360550, training_loss: 3.69901e+01
I0515 04:00:37.185217 140128494741248 run_lib.py:152] step: 360600, training_loss: 2.29692e+01
I0515 04:00:37.237911 140128494741248 run_lib.py:165] step: 360600, eval_loss: 2.00057e+01
I0515 04:00:43.477231 140128494741248 run_lib.py:152] step: 360650, training_loss: 1.82086e+01
I0515 04:00:50.008329 140128494741248 run_lib.py:152] step: 360700, training_loss: 2.82255e+01
I0515 04:00:50.063588 140128494741248 run_lib.py:165] step: 360700, eval_loss: 3.66676e+01
I0515 04:00:56.276360 140128494741248 run_lib.py:152] step: 360750, training_loss: 2.87604e+01
I0515 04:01:02.522023 140128494741248 run_lib.py:152] step: 360800, training_loss: 2.43096e+01
I0515 04:01:02.581859 140128494741248 run_lib.py:165] step: 360800, eval_loss: 3.39562e+01
I0515 04:01:08.930696 140128494741248 run_lib.py:152] step: 360850, training_loss: 3.99230e+01
I0515 04:01:15.394891 140128494741248 run_lib.py:152] step: 360900, training_loss: 1.58222e+01
I0515 04:01:15.452372 140128494741248 run_lib.py:165] step: 360900, eval_loss: 2.24330e+01
I0515 04:01:21.658960 140128494741248 run_lib.py:152] step: 360950, training_loss: 2.68718e+01
I0515 04:01:27.883271 140128494741248 run_lib.py:152] step: 361000, training_loss: 3.57308e+01
I0515 04:01:27.936705 140128494741248 run_lib.py:165] step: 361000, eval_loss: 3.01916e+01
I0515 04:01:34.413229 140128494741248 run_lib.py:152] step: 361050, training_loss: 2.93912e+01
I0515 04:01:40.565200 140128494741248 run_lib.py:152] step: 361100, training_loss: 4.06660e+01
I0515 04:01:40.618248 140128494741248 run_lib.py:165] step: 361100, eval_loss: 2.91572e+01
I0515 04:01:46.813089 140128494741248 run_lib.py:152] step: 361150, training_loss: 2.51940e+01
I0515 04:01:53.076338 140128494741248 run_lib.py:152] step: 361200, training_loss: 3.07502e+01
I0515 04:01:53.126411 140128494741248 run_lib.py:165] step: 361200, eval_loss: 2.34930e+01
I0515 04:01:59.547178 140128494741248 run_lib.py:152] step: 361250, training_loss: 4.04303e+01
I0515 04:02:05.714053 140128494741248 run_lib.py:152] step: 361300, training_loss: 3.88465e+01
I0515 04:02:05.764593 140128494741248 run_lib.py:165] step: 361300, eval_loss: 3.34010e+01
I0515 04:02:11.974709 140128494741248 run_lib.py:152] step: 361350, training_loss: 2.54363e+01
I0515 04:02:18.552872 140128494741248 run_lib.py:152] step: 361400, training_loss: 1.46735e+01
I0515 04:02:18.610538 140128494741248 run_lib.py:165] step: 361400, eval_loss: 2.56089e+01
I0515 04:02:24.753433 140128494741248 run_lib.py:152] step: 361450, training_loss: 3.12993e+01
I0515 04:02:30.933444 140128494741248 run_lib.py:152] step: 361500, training_loss: 1.79989e+01
I0515 04:02:30.983429 140128494741248 run_lib.py:165] step: 361500, eval_loss: 4.28360e+01
I0515 04:02:37.196132 140128494741248 run_lib.py:152] step: 361550, training_loss: 3.54621e+01
I0515 04:02:43.646087 140128494741248 run_lib.py:152] step: 361600, training_loss: 2.48313e+01
I0515 04:02:43.701815 140128494741248 run_lib.py:165] step: 361600, eval_loss: 1.97404e+01
I0515 04:02:49.910534 140128494741248 run_lib.py:152] step: 361650, training_loss: 2.44667e+01
I0515 04:02:56.139549 140128494741248 run_lib.py:152] step: 361700, training_loss: 2.70821e+01
I0515 04:02:56.194257 140128494741248 run_lib.py:165] step: 361700, eval_loss: 3.53398e+01
I0515 04:03:02.678427 140128494741248 run_lib.py:152] step: 361750, training_loss: 3.39384e+01
I0515 04:03:08.862046 140128494741248 run_lib.py:152] step: 361800, training_loss: 2.54398e+01
I0515 04:03:08.909683 140128494741248 run_lib.py:165] step: 361800, eval_loss: 2.63009e+01
I0515 04:03:15.089797 140128494741248 run_lib.py:152] step: 361850, training_loss: 1.76035e+01
I0515 04:03:21.293606 140128494741248 run_lib.py:152] step: 361900, training_loss: 3.00886e+01
I0515 04:03:21.347958 140128494741248 run_lib.py:165] step: 361900, eval_loss: 4.02785e+01
I0515 04:03:27.678263 140128494741248 run_lib.py:152] step: 361950, training_loss: 2.53102e+01
I0515 04:03:33.933398 140128494741248 run_lib.py:152] step: 362000, training_loss: 2.25823e+01
I0515 04:03:33.983674 140128494741248 run_lib.py:165] step: 362000, eval_loss: 2.56226e+01
I0515 04:03:40.214744 140128494741248 run_lib.py:152] step: 362050, training_loss: 2.50777e+01
I0515 04:03:46.739910 140128494741248 run_lib.py:152] step: 362100, training_loss: 2.26756e+01
I0515 04:03:46.796440 140128494741248 run_lib.py:165] step: 362100, eval_loss: 4.48670e+01
I0515 04:03:52.994981 140128494741248 run_lib.py:152] step: 362150, training_loss: 3.04144e+01
I0515 04:03:59.239040 140128494741248 run_lib.py:152] step: 362200, training_loss: 4.91453e+01
I0515 04:03:59.291408 140128494741248 run_lib.py:165] step: 362200, eval_loss: 1.81170e+01
I0515 04:04:05.485090 140128494741248 run_lib.py:152] step: 362250, training_loss: 3.78522e+01
I0515 04:04:11.993427 140128494741248 run_lib.py:152] step: 362300, training_loss: 4.14245e+01
I0515 04:04:12.041924 140128494741248 run_lib.py:165] step: 362300, eval_loss: 2.74142e+01
I0515 04:04:18.200149 140128494741248 run_lib.py:152] step: 362350, training_loss: 4.77503e+01
I0515 04:04:24.325865 140128494741248 run_lib.py:152] step: 362400, training_loss: 4.62103e+01
I0515 04:04:24.378309 140128494741248 run_lib.py:165] step: 362400, eval_loss: 2.96601e+01
I0515 04:04:30.893536 140128494741248 run_lib.py:152] step: 362450, training_loss: 2.51915e+01
I0515 04:04:37.038496 140128494741248 run_lib.py:152] step: 362500, training_loss: 3.33934e+01
I0515 04:04:37.088063 140128494741248 run_lib.py:165] step: 362500, eval_loss: 2.12186e+01
I0515 04:04:43.307407 140128494741248 run_lib.py:152] step: 362550, training_loss: 2.71623e+01
I0515 04:04:49.545948 140128494741248 run_lib.py:152] step: 362600, training_loss: 2.11570e+01
I0515 04:04:49.599200 140128494741248 run_lib.py:165] step: 362600, eval_loss: 2.71844e+01
I0515 04:04:56.112246 140128494741248 run_lib.py:152] step: 362650, training_loss: 2.55190e+01
I0515 04:05:02.401524 140128494741248 run_lib.py:152] step: 362700, training_loss: 3.12383e+01
I0515 04:05:02.458451 140128494741248 run_lib.py:165] step: 362700, eval_loss: 3.14812e+01
I0515 04:05:08.621863 140128494741248 run_lib.py:152] step: 362750, training_loss: 2.44585e+01
I0515 04:05:15.124959 140128494741248 run_lib.py:152] step: 362800, training_loss: 2.92973e+01
I0515 04:05:15.176593 140128494741248 run_lib.py:165] step: 362800, eval_loss: 2.47494e+01
I0515 04:05:21.312983 140128494741248 run_lib.py:152] step: 362850, training_loss: 4.23162e+01
I0515 04:05:27.548348 140128494741248 run_lib.py:152] step: 362900, training_loss: 3.48289e+01
I0515 04:05:27.600451 140128494741248 run_lib.py:165] step: 362900, eval_loss: 2.37430e+01
I0515 04:05:33.706345 140128494741248 run_lib.py:152] step: 362950, training_loss: 1.92852e+01
I0515 04:05:40.232541 140128494741248 run_lib.py:152] step: 363000, training_loss: 3.55733e+01
I0515 04:05:40.288393 140128494741248 run_lib.py:165] step: 363000, eval_loss: 2.27260e+01
I0515 04:05:46.382147 140128494741248 run_lib.py:152] step: 363050, training_loss: 3.69022e+01
I0515 04:05:52.661345 140128494741248 run_lib.py:152] step: 363100, training_loss: 3.22566e+01
I0515 04:05:52.710512 140128494741248 run_lib.py:165] step: 363100, eval_loss: 3.19012e+01
I0515 04:05:59.141974 140128494741248 run_lib.py:152] step: 363150, training_loss: 3.24684e+01
I0515 04:06:05.439889 140128494741248 run_lib.py:152] step: 363200, training_loss: 3.60289e+01
I0515 04:06:05.490342 140128494741248 run_lib.py:165] step: 363200, eval_loss: 4.23071e+01
I0515 04:06:11.708341 140128494741248 run_lib.py:152] step: 363250, training_loss: 2.42448e+01
I0515 04:06:18.022261 140128494741248 run_lib.py:152] step: 363300, training_loss: 4.82376e+01
I0515 04:06:18.076532 140128494741248 run_lib.py:165] step: 363300, eval_loss: 3.61970e+01
I0515 04:06:24.469951 140128494741248 run_lib.py:152] step: 363350, training_loss: 2.87649e+01
I0515 04:06:30.684666 140128494741248 run_lib.py:152] step: 363400, training_loss: 2.60145e+01
I0515 04:06:30.739398 140128494741248 run_lib.py:165] step: 363400, eval_loss: 3.58322e+01
I0515 04:06:36.906318 140128494741248 run_lib.py:152] step: 363450, training_loss: 3.64560e+01
I0515 04:06:43.446079 140128494741248 run_lib.py:152] step: 363500, training_loss: 2.99717e+01
I0515 04:06:43.500187 140128494741248 run_lib.py:165] step: 363500, eval_loss: 2.82264e+01
I0515 04:06:49.838318 140128494741248 run_lib.py:152] step: 363550, training_loss: 4.78639e+01
I0515 04:06:56.017013 140128494741248 run_lib.py:152] step: 363600, training_loss: 2.53425e+01
I0515 04:06:56.063356 140128494741248 run_lib.py:165] step: 363600, eval_loss: 2.60908e+01
I0515 04:07:02.250095 140128494741248 run_lib.py:152] step: 363650, training_loss: 2.04661e+01
I0515 04:07:08.606779 140128494741248 run_lib.py:152] step: 363700, training_loss: 4.71836e+01
I0515 04:07:08.659923 140128494741248 run_lib.py:165] step: 363700, eval_loss: 4.49062e+01
I0515 04:07:14.908263 140128494741248 run_lib.py:152] step: 363750, training_loss: 5.14230e+01
I0515 04:07:21.185068 140128494741248 run_lib.py:152] step: 363800, training_loss: 3.36110e+01
I0515 04:07:21.238862 140128494741248 run_lib.py:165] step: 363800, eval_loss: 2.84823e+01
I0515 04:07:27.628850 140128494741248 run_lib.py:152] step: 363850, training_loss: 2.97705e+01
I0515 04:07:33.859192 140128494741248 run_lib.py:152] step: 363900, training_loss: 4.39992e+01
I0515 04:07:33.909642 140128494741248 run_lib.py:165] step: 363900, eval_loss: 1.58979e+01
I0515 04:07:40.114007 140128494741248 run_lib.py:152] step: 363950, training_loss: 2.44492e+01
I0515 04:07:46.335564 140128494741248 run_lib.py:152] step: 364000, training_loss: 2.97222e+01
I0515 04:07:46.387893 140128494741248 run_lib.py:165] step: 364000, eval_loss: 2.93435e+01
I0515 04:07:52.827014 140128494741248 run_lib.py:152] step: 364050, training_loss: 2.45101e+01
I0515 04:07:59.079339 140128494741248 run_lib.py:152] step: 364100, training_loss: 1.93790e+01
I0515 04:07:59.127272 140128494741248 run_lib.py:165] step: 364100, eval_loss: 3.81233e+01
I0515 04:08:05.268886 140128494741248 run_lib.py:152] step: 364150, training_loss: 3.23755e+01
I0515 04:08:11.703311 140128494741248 run_lib.py:152] step: 364200, training_loss: 3.96681e+01
I0515 04:08:11.755746 140128494741248 run_lib.py:165] step: 364200, eval_loss: 3.44012e+01
I0515 04:08:17.962966 140128494741248 run_lib.py:152] step: 364250, training_loss: 3.26772e+01
I0515 04:08:24.110630 140128494741248 run_lib.py:152] step: 364300, training_loss: 3.56520e+01
I0515 04:08:24.160104 140128494741248 run_lib.py:165] step: 364300, eval_loss: 1.01297e+01
I0515 04:08:30.418187 140128494741248 run_lib.py:152] step: 364350, training_loss: 3.96483e+01
I0515 04:08:36.746166 140128494741248 run_lib.py:152] step: 364400, training_loss: 3.47079e+01
I0515 04:08:36.791520 140128494741248 run_lib.py:165] step: 364400, eval_loss: 2.54936e+01
I0515 04:08:43.057030 140128494741248 run_lib.py:152] step: 364450, training_loss: 3.78169e+01
I0515 04:08:49.185035 140128494741248 run_lib.py:152] step: 364500, training_loss: 3.07124e+01
I0515 04:08:49.235639 140128494741248 run_lib.py:165] step: 364500, eval_loss: 2.22426e+01
I0515 04:08:55.708133 140128494741248 run_lib.py:152] step: 364550, training_loss: 4.54267e+01
I0515 04:09:01.881282 140128494741248 run_lib.py:152] step: 364600, training_loss: 2.97761e+01
I0515 04:09:01.932526 140128494741248 run_lib.py:165] step: 364600, eval_loss: 3.29978e+01
I0515 04:09:08.121808 140128494741248 run_lib.py:152] step: 364650, training_loss: 2.80187e+01
I0515 04:09:14.198023 140128494741248 run_lib.py:152] step: 364700, training_loss: 1.66462e+01
I0515 04:09:14.247423 140128494741248 run_lib.py:165] step: 364700, eval_loss: 2.86800e+01
I0515 04:09:20.718475 140128494741248 run_lib.py:152] step: 364750, training_loss: 3.46375e+01
I0515 04:09:26.860268 140128494741248 run_lib.py:152] step: 364800, training_loss: 3.26216e+01
I0515 04:09:26.916148 140128494741248 run_lib.py:165] step: 364800, eval_loss: 4.08692e+01
I0515 04:09:33.087542 140128494741248 run_lib.py:152] step: 364850, training_loss: 2.74182e+01
I0515 04:09:39.553509 140128494741248 run_lib.py:152] step: 364900, training_loss: 4.07709e+01
I0515 04:09:39.608790 140128494741248 run_lib.py:165] step: 364900, eval_loss: 3.12585e+01
I0515 04:09:45.788143 140128494741248 run_lib.py:152] step: 364950, training_loss: 2.50614e+01
I0515 04:09:52.007689 140128494741248 run_lib.py:152] step: 365000, training_loss: 2.18037e+01
I0515 04:09:52.059665 140128494741248 run_lib.py:165] step: 365000, eval_loss: 2.23993e+01
I0515 04:09:58.369819 140128494741248 run_lib.py:152] step: 365050, training_loss: 4.00351e+01
I0515 04:10:04.824629 140128494741248 run_lib.py:152] step: 365100, training_loss: 2.85445e+01
I0515 04:10:04.879909 140128494741248 run_lib.py:165] step: 365100, eval_loss: 3.95193e+01
I0515 04:10:11.122140 140128494741248 run_lib.py:152] step: 365150, training_loss: 3.91022e+01
I0515 04:10:17.326021 140128494741248 run_lib.py:152] step: 365200, training_loss: 3.55126e+01
I0515 04:10:17.380373 140128494741248 run_lib.py:165] step: 365200, eval_loss: 3.01433e+01
I0515 04:10:23.899039 140128494741248 run_lib.py:152] step: 365250, training_loss: 2.38988e+01
I0515 04:10:30.013577 140128494741248 run_lib.py:152] step: 365300, training_loss: 3.91604e+01
I0515 04:10:30.064212 140128494741248 run_lib.py:165] step: 365300, eval_loss: 4.18932e+01
I0515 04:10:36.263954 140128494741248 run_lib.py:152] step: 365350, training_loss: 3.02275e+01
I0515 04:10:42.432287 140128494741248 run_lib.py:152] step: 365400, training_loss: 4.43544e+01
I0515 04:10:42.488823 140128494741248 run_lib.py:165] step: 365400, eval_loss: 3.88446e+01
I0515 04:10:48.960986 140128494741248 run_lib.py:152] step: 365450, training_loss: 3.45277e+01
I0515 04:10:55.102715 140128494741248 run_lib.py:152] step: 365500, training_loss: 2.37185e+01
I0515 04:10:55.164906 140128494741248 run_lib.py:165] step: 365500, eval_loss: 1.90484e+01
I0515 04:11:01.406255 140128494741248 run_lib.py:152] step: 365550, training_loss: 2.86683e+01
I0515 04:11:07.933207 140128494741248 run_lib.py:152] step: 365600, training_loss: 2.58342e+01
I0515 04:11:07.987671 140128494741248 run_lib.py:165] step: 365600, eval_loss: 3.06418e+01
I0515 04:11:14.212122 140128494741248 run_lib.py:152] step: 365650, training_loss: 2.65770e+01
I0515 04:11:20.361937 140128494741248 run_lib.py:152] step: 365700, training_loss: 2.85785e+01
I0515 04:11:20.413763 140128494741248 run_lib.py:165] step: 365700, eval_loss: 4.12001e+01
I0515 04:11:26.581281 140128494741248 run_lib.py:152] step: 365750, training_loss: 2.33733e+01
I0515 04:11:32.987310 140128494741248 run_lib.py:152] step: 365800, training_loss: 2.83654e+01
I0515 04:11:33.046753 140128494741248 run_lib.py:165] step: 365800, eval_loss: 2.19794e+01
I0515 04:11:39.358960 140128494741248 run_lib.py:152] step: 365850, training_loss: 3.06899e+01
I0515 04:11:45.604825 140128494741248 run_lib.py:152] step: 365900, training_loss: 3.57359e+01
I0515 04:11:45.658095 140128494741248 run_lib.py:165] step: 365900, eval_loss: 3.54598e+01
I0515 04:11:52.138460 140128494741248 run_lib.py:152] step: 365950, training_loss: 2.57086e+01
I0515 04:11:58.447150 140128494741248 run_lib.py:152] step: 366000, training_loss: 4.39427e+01
I0515 04:11:58.497777 140128494741248 run_lib.py:165] step: 366000, eval_loss: 2.17662e+01
I0515 04:12:04.627051 140128494741248 run_lib.py:152] step: 366050, training_loss: 2.45407e+01
I0515 04:12:10.776441 140128494741248 run_lib.py:152] step: 366100, training_loss: 2.04758e+01
I0515 04:12:10.826015 140128494741248 run_lib.py:165] step: 366100, eval_loss: 4.69250e+01
I0515 04:12:17.288061 140128494741248 run_lib.py:152] step: 366150, training_loss: 3.82384e+01
I0515 04:12:23.510249 140128494741248 run_lib.py:152] step: 366200, training_loss: 4.99652e+01
I0515 04:12:23.565561 140128494741248 run_lib.py:165] step: 366200, eval_loss: 3.52342e+01
I0515 04:12:29.723775 140128494741248 run_lib.py:152] step: 366250, training_loss: 4.48631e+01
I0515 04:12:36.284330 140128494741248 run_lib.py:152] step: 366300, training_loss: 4.90248e+01
I0515 04:12:36.334016 140128494741248 run_lib.py:165] step: 366300, eval_loss: 2.07642e+01
I0515 04:12:42.619180 140128494741248 run_lib.py:152] step: 366350, training_loss: 1.52641e+01
I0515 04:12:48.783482 140128494741248 run_lib.py:152] step: 366400, training_loss: 3.15861e+01
I0515 04:12:48.835990 140128494741248 run_lib.py:165] step: 366400, eval_loss: 2.40198e+01
I0515 04:12:54.956600 140128494741248 run_lib.py:152] step: 366450, training_loss: 3.69057e+01
I0515 04:13:01.367218 140128494741248 run_lib.py:152] step: 366500, training_loss: 3.06054e+01
I0515 04:13:01.426029 140128494741248 run_lib.py:165] step: 366500, eval_loss: 2.05617e+01
I0515 04:13:07.544304 140128494741248 run_lib.py:152] step: 366550, training_loss: 3.05396e+01
I0515 04:13:13.754683 140128494741248 run_lib.py:152] step: 366600, training_loss: 4.34514e+01
I0515 04:13:13.806434 140128494741248 run_lib.py:165] step: 366600, eval_loss: 2.53304e+01
I0515 04:13:20.265371 140128494741248 run_lib.py:152] step: 366650, training_loss: 4.52376e+01
I0515 04:13:26.397934 140128494741248 run_lib.py:152] step: 366700, training_loss: 1.18093e+01
I0515 04:13:26.454470 140128494741248 run_lib.py:165] step: 366700, eval_loss: 3.75193e+01
I0515 04:13:32.700187 140128494741248 run_lib.py:152] step: 366750, training_loss: 4.11852e+01
I0515 04:13:38.890345 140128494741248 run_lib.py:152] step: 366800, training_loss: 3.54059e+01
I0515 04:13:38.950359 140128494741248 run_lib.py:165] step: 366800, eval_loss: 3.27044e+01
I0515 04:13:45.356070 140128494741248 run_lib.py:152] step: 366850, training_loss: 2.44004e+01
I0515 04:13:51.539606 140128494741248 run_lib.py:152] step: 366900, training_loss: 3.09532e+01
I0515 04:13:51.596350 140128494741248 run_lib.py:165] step: 366900, eval_loss: 2.57385e+01
I0515 04:13:57.774346 140128494741248 run_lib.py:152] step: 366950, training_loss: 3.97307e+01
I0515 04:14:04.191502 140128494741248 run_lib.py:152] step: 367000, training_loss: 2.54453e+01
I0515 04:14:04.246147 140128494741248 run_lib.py:165] step: 367000, eval_loss: 1.87799e+01
I0515 04:14:10.362496 140128494741248 run_lib.py:152] step: 367050, training_loss: 3.54030e+01
I0515 04:14:16.619251 140128494741248 run_lib.py:152] step: 367100, training_loss: 2.55930e+01
I0515 04:14:16.676675 140128494741248 run_lib.py:165] step: 367100, eval_loss: 2.58760e+01
I0515 04:14:22.830586 140128494741248 run_lib.py:152] step: 367150, training_loss: 2.86765e+01
I0515 04:14:29.314713 140128494741248 run_lib.py:152] step: 367200, training_loss: 4.55706e+01
I0515 04:14:29.368265 140128494741248 run_lib.py:165] step: 367200, eval_loss: 1.65427e+01
I0515 04:14:35.521238 140128494741248 run_lib.py:152] step: 367250, training_loss: 3.21242e+01
I0515 04:14:41.778436 140128494741248 run_lib.py:152] step: 367300, training_loss: 3.30028e+01
I0515 04:14:41.830420 140128494741248 run_lib.py:165] step: 367300, eval_loss: 3.09218e+01
I0515 04:14:48.284779 140128494741248 run_lib.py:152] step: 367350, training_loss: 1.22867e+01
I0515 04:14:54.455842 140128494741248 run_lib.py:152] step: 367400, training_loss: 3.44637e+01
I0515 04:14:54.507678 140128494741248 run_lib.py:165] step: 367400, eval_loss: 2.48155e+01
I0515 04:15:00.653900 140128494741248 run_lib.py:152] step: 367450, training_loss: 3.61245e+01
I0515 04:15:06.882911 140128494741248 run_lib.py:152] step: 367500, training_loss: 2.62724e+01
I0515 04:15:06.938049 140128494741248 run_lib.py:165] step: 367500, eval_loss: 3.63589e+01
I0515 04:15:13.388149 140128494741248 run_lib.py:152] step: 367550, training_loss: 2.47662e+01
I0515 04:15:19.524225 140128494741248 run_lib.py:152] step: 367600, training_loss: 3.66118e+01
I0515 04:15:19.579292 140128494741248 run_lib.py:165] step: 367600, eval_loss: 2.78480e+01
I0515 04:15:25.779615 140128494741248 run_lib.py:152] step: 367650, training_loss: 3.15238e+01
I0515 04:15:32.183939 140128494741248 run_lib.py:152] step: 367700, training_loss: 3.11856e+01
I0515 04:15:32.232720 140128494741248 run_lib.py:165] step: 367700, eval_loss: 2.56766e+01
I0515 04:15:38.485789 140128494741248 run_lib.py:152] step: 367750, training_loss: 2.97889e+01
I0515 04:15:44.650206 140128494741248 run_lib.py:152] step: 367800, training_loss: 1.91663e+01
I0515 04:15:44.701404 140128494741248 run_lib.py:165] step: 367800, eval_loss: 3.21977e+01
I0515 04:15:50.867492 140128494741248 run_lib.py:152] step: 367850, training_loss: 3.00849e+01
I0515 04:15:57.286510 140128494741248 run_lib.py:152] step: 367900, training_loss: 3.27577e+01
I0515 04:15:57.337597 140128494741248 run_lib.py:165] step: 367900, eval_loss: 3.38013e+01
I0515 04:16:03.405121 140128494741248 run_lib.py:152] step: 367950, training_loss: 5.40090e+01
I0515 04:16:09.735908 140128494741248 run_lib.py:152] step: 368000, training_loss: 3.84449e+01
I0515 04:16:09.788216 140128494741248 run_lib.py:165] step: 368000, eval_loss: 3.08181e+01
I0515 04:16:16.190673 140128494741248 run_lib.py:152] step: 368050, training_loss: 2.75188e+01
I0515 04:16:22.434919 140128494741248 run_lib.py:152] step: 368100, training_loss: 1.85230e+01
I0515 04:16:22.491006 140128494741248 run_lib.py:165] step: 368100, eval_loss: 3.24268e+01
I0515 04:16:28.711019 140128494741248 run_lib.py:152] step: 368150, training_loss: 3.93347e+01
I0515 04:16:34.893059 140128494741248 run_lib.py:152] step: 368200, training_loss: 2.49356e+01
I0515 04:16:34.943135 140128494741248 run_lib.py:165] step: 368200, eval_loss: 2.87543e+01
I0515 04:16:41.303401 140128494741248 run_lib.py:152] step: 368250, training_loss: 2.22753e+01
I0515 04:16:47.542311 140128494741248 run_lib.py:152] step: 368300, training_loss: 1.90056e+01
I0515 04:16:47.598223 140128494741248 run_lib.py:165] step: 368300, eval_loss: 2.29281e+01
I0515 04:16:53.836165 140128494741248 run_lib.py:152] step: 368350, training_loss: 3.45775e+01
I0515 04:17:00.211588 140128494741248 run_lib.py:152] step: 368400, training_loss: 3.10895e+01
I0515 04:17:00.266957 140128494741248 run_lib.py:165] step: 368400, eval_loss: 4.01739e+01
I0515 04:17:06.528135 140128494741248 run_lib.py:152] step: 368450, training_loss: 2.29699e+01
I0515 04:17:12.705536 140128494741248 run_lib.py:152] step: 368500, training_loss: 3.60066e+01
I0515 04:17:12.761996 140128494741248 run_lib.py:165] step: 368500, eval_loss: 3.64986e+01
I0515 04:17:18.931281 140128494741248 run_lib.py:152] step: 368550, training_loss: 2.85915e+01
I0515 04:17:25.370937 140128494741248 run_lib.py:152] step: 368600, training_loss: 2.40124e+01
I0515 04:17:25.422047 140128494741248 run_lib.py:165] step: 368600, eval_loss: 3.47496e+01
I0515 04:17:31.563684 140128494741248 run_lib.py:152] step: 368650, training_loss: 3.09133e+01
I0515 04:17:37.669719 140128494741248 run_lib.py:152] step: 368700, training_loss: 3.53533e+01
I0515 04:17:37.726372 140128494741248 run_lib.py:165] step: 368700, eval_loss: 3.39505e+01
I0515 04:17:44.217349 140128494741248 run_lib.py:152] step: 368750, training_loss: 5.10678e+01
I0515 04:17:50.420523 140128494741248 run_lib.py:152] step: 368800, training_loss: 2.93154e+01
I0515 04:17:50.470547 140128494741248 run_lib.py:165] step: 368800, eval_loss: 4.05811e+01
I0515 04:17:56.663470 140128494741248 run_lib.py:152] step: 368850, training_loss: 2.77557e+01
I0515 04:18:02.925995 140128494741248 run_lib.py:152] step: 368900, training_loss: 2.70452e+01
I0515 04:18:02.981577 140128494741248 run_lib.py:165] step: 368900, eval_loss: 3.66421e+01
I0515 04:18:09.392132 140128494741248 run_lib.py:152] step: 368950, training_loss: 1.92488e+01
I0515 04:18:15.635605 140128494741248 run_lib.py:152] step: 369000, training_loss: 2.50818e+01
I0515 04:18:15.685007 140128494741248 run_lib.py:165] step: 369000, eval_loss: 3.95348e+01
I0515 04:18:21.844255 140128494741248 run_lib.py:152] step: 369050, training_loss: 2.86709e+01
I0515 04:18:28.276339 140128494741248 run_lib.py:152] step: 369100, training_loss: 3.82389e+01
I0515 04:18:28.327292 140128494741248 run_lib.py:165] step: 369100, eval_loss: 2.77255e+01
I0515 04:18:34.478621 140128494741248 run_lib.py:152] step: 369150, training_loss: 3.73163e+01
I0515 04:18:40.671309 140128494741248 run_lib.py:152] step: 369200, training_loss: 3.04249e+01
I0515 04:18:40.725480 140128494741248 run_lib.py:165] step: 369200, eval_loss: 2.27663e+01
I0515 04:18:46.816749 140128494741248 run_lib.py:152] step: 369250, training_loss: 3.82816e+01
I0515 04:18:53.296221 140128494741248 run_lib.py:152] step: 369300, training_loss: 2.38973e+01
I0515 04:18:53.347980 140128494741248 run_lib.py:165] step: 369300, eval_loss: 1.82211e+01
I0515 04:18:59.499249 140128494741248 run_lib.py:152] step: 369350, training_loss: 4.32121e+01
I0515 04:19:05.781345 140128494741248 run_lib.py:152] step: 369400, training_loss: 3.70602e+01
I0515 04:19:05.832620 140128494741248 run_lib.py:165] step: 369400, eval_loss: 3.30088e+01
I0515 04:19:12.257010 140128494741248 run_lib.py:152] step: 369450, training_loss: 3.79992e+01
I0515 04:19:18.515113 140128494741248 run_lib.py:152] step: 369500, training_loss: 2.08594e+01
I0515 04:19:18.571878 140128494741248 run_lib.py:165] step: 369500, eval_loss: 2.36783e+01
I0515 04:19:24.762694 140128494741248 run_lib.py:152] step: 369550, training_loss: 2.04514e+01
I0515 04:19:30.894621 140128494741248 run_lib.py:152] step: 369600, training_loss: 3.01090e+01
I0515 04:19:30.944200 140128494741248 run_lib.py:165] step: 369600, eval_loss: 2.09909e+01
I0515 04:19:37.403553 140128494741248 run_lib.py:152] step: 369650, training_loss: 3.03570e+01
I0515 04:19:43.560057 140128494741248 run_lib.py:152] step: 369700, training_loss: 2.96241e+01
I0515 04:19:43.615451 140128494741248 run_lib.py:165] step: 369700, eval_loss: 3.58131e+01
I0515 04:19:49.861042 140128494741248 run_lib.py:152] step: 369750, training_loss: 2.39202e+01
I0515 04:19:56.209955 140128494741248 run_lib.py:152] step: 369800, training_loss: 3.45879e+01
I0515 04:19:56.258344 140128494741248 run_lib.py:165] step: 369800, eval_loss: 3.61257e+01
I0515 04:20:02.499974 140128494741248 run_lib.py:152] step: 369850, training_loss: 3.68042e+01
I0515 04:20:08.661956 140128494741248 run_lib.py:152] step: 369900, training_loss: 3.94276e+01
I0515 04:20:08.715461 140128494741248 run_lib.py:165] step: 369900, eval_loss: 1.82204e+01
I0515 04:20:14.944025 140128494741248 run_lib.py:152] step: 369950, training_loss: 3.42665e+01
I0515 04:20:21.389544 140128494741248 run_lib.py:152] step: 370000, training_loss: 2.62004e+01
I0515 04:20:21.588585 140128494741248 run_lib.py:165] step: 370000, eval_loss: 5.69140e+01
I0515 04:20:27.745251 140128494741248 run_lib.py:152] step: 370050, training_loss: 3.00234e+01
I0515 04:20:33.975141 140128494741248 run_lib.py:152] step: 370100, training_loss: 3.74586e+01
I0515 04:20:34.025253 140128494741248 run_lib.py:165] step: 370100, eval_loss: 1.41788e+01
I0515 04:20:40.458917 140128494741248 run_lib.py:152] step: 370150, training_loss: 2.90186e+01
I0515 04:20:46.651706 140128494741248 run_lib.py:152] step: 370200, training_loss: 4.15460e+01
I0515 04:20:46.707498 140128494741248 run_lib.py:165] step: 370200, eval_loss: 2.18450e+01
I0515 04:20:52.935556 140128494741248 run_lib.py:152] step: 370250, training_loss: 2.88020e+01
I0515 04:20:59.113533 140128494741248 run_lib.py:152] step: 370300, training_loss: 2.54210e+01
I0515 04:20:59.163169 140128494741248 run_lib.py:165] step: 370300, eval_loss: 3.10354e+01
I0515 04:21:05.595849 140128494741248 run_lib.py:152] step: 370350, training_loss: 3.09131e+01
I0515 04:21:11.749099 140128494741248 run_lib.py:152] step: 370400, training_loss: 3.45077e+01
I0515 04:21:11.797111 140128494741248 run_lib.py:165] step: 370400, eval_loss: 2.10127e+01
I0515 04:21:18.046268 140128494741248 run_lib.py:152] step: 370450, training_loss: 3.20222e+01
I0515 04:21:24.459381 140128494741248 run_lib.py:152] step: 370500, training_loss: 2.26079e+01
I0515 04:21:24.510180 140128494741248 run_lib.py:165] step: 370500, eval_loss: 2.04942e+01
I0515 04:21:30.677078 140128494741248 run_lib.py:152] step: 370550, training_loss: 4.11417e+01
I0515 04:21:36.914087 140128494741248 run_lib.py:152] step: 370600, training_loss: 3.30612e+01
I0515 04:21:36.970480 140128494741248 run_lib.py:165] step: 370600, eval_loss: 3.33103e+01
I0515 04:21:43.091837 140128494741248 run_lib.py:152] step: 370650, training_loss: 2.73421e+01
I0515 04:21:49.580897 140128494741248 run_lib.py:152] step: 370700, training_loss: 2.71971e+01
I0515 04:21:49.638212 140128494741248 run_lib.py:165] step: 370700, eval_loss: 2.59704e+01
I0515 04:21:55.834795 140128494741248 run_lib.py:152] step: 370750, training_loss: 2.00005e+01
I0515 04:22:02.072407 140128494741248 run_lib.py:152] step: 370800, training_loss: 3.26060e+01
I0515 04:22:02.126460 140128494741248 run_lib.py:165] step: 370800, eval_loss: 2.17837e+01
I0515 04:22:08.655659 140128494741248 run_lib.py:152] step: 370850, training_loss: 2.50065e+01
I0515 04:22:14.781677 140128494741248 run_lib.py:152] step: 370900, training_loss: 2.67233e+01
I0515 04:22:14.838839 140128494741248 run_lib.py:165] step: 370900, eval_loss: 4.40312e+01
I0515 04:22:21.025009 140128494741248 run_lib.py:152] step: 370950, training_loss: 3.09012e+01
I0515 04:22:27.130764 140128494741248 run_lib.py:152] step: 371000, training_loss: 3.80157e+01
I0515 04:22:27.185040 140128494741248 run_lib.py:165] step: 371000, eval_loss: 2.84967e+01
I0515 04:22:33.623851 140128494741248 run_lib.py:152] step: 371050, training_loss: 3.04988e+01
I0515 04:22:39.875285 140128494741248 run_lib.py:152] step: 371100, training_loss: 3.34785e+01
I0515 04:22:39.933608 140128494741248 run_lib.py:165] step: 371100, eval_loss: 3.01817e+01
I0515 04:22:46.188954 140128494741248 run_lib.py:152] step: 371150, training_loss: 2.90985e+01
I0515 04:22:52.710723 140128494741248 run_lib.py:152] step: 371200, training_loss: 3.03405e+01
I0515 04:22:52.762658 140128494741248 run_lib.py:165] step: 371200, eval_loss: 3.04228e+01
I0515 04:22:58.861122 140128494741248 run_lib.py:152] step: 371250, training_loss: 3.06539e+01
I0515 04:23:05.065214 140128494741248 run_lib.py:152] step: 371300, training_loss: 3.13019e+01
I0515 04:23:05.113924 140128494741248 run_lib.py:165] step: 371300, eval_loss: 1.82132e+01
I0515 04:23:11.211925 140128494741248 run_lib.py:152] step: 371350, training_loss: 3.17915e+01
I0515 04:23:17.626973 140128494741248 run_lib.py:152] step: 371400, training_loss: 2.34671e+01
I0515 04:23:17.679542 140128494741248 run_lib.py:165] step: 371400, eval_loss: 2.96951e+01
I0515 04:23:23.816239 140128494741248 run_lib.py:152] step: 371450, training_loss: 3.69801e+01
I0515 04:23:29.987545 140128494741248 run_lib.py:152] step: 371500, training_loss: 2.33623e+01
I0515 04:23:30.039159 140128494741248 run_lib.py:165] step: 371500, eval_loss: 2.75495e+01
I0515 04:23:36.421556 140128494741248 run_lib.py:152] step: 371550, training_loss: 4.41431e+01
I0515 04:23:42.587815 140128494741248 run_lib.py:152] step: 371600, training_loss: 2.41273e+01
I0515 04:23:42.639068 140128494741248 run_lib.py:165] step: 371600, eval_loss: 2.76261e+01
I0515 04:23:48.851384 140128494741248 run_lib.py:152] step: 371650, training_loss: 2.76013e+01
I0515 04:23:55.063903 140128494741248 run_lib.py:152] step: 371700, training_loss: 3.65015e+01
I0515 04:23:55.120192 140128494741248 run_lib.py:165] step: 371700, eval_loss: 2.89771e+01
I0515 04:24:01.487904 140128494741248 run_lib.py:152] step: 371750, training_loss: 3.25815e+01
I0515 04:24:07.706825 140128494741248 run_lib.py:152] step: 371800, training_loss: 5.06533e+01
I0515 04:24:07.758913 140128494741248 run_lib.py:165] step: 371800, eval_loss: 3.42417e+01
I0515 04:24:13.863090 140128494741248 run_lib.py:152] step: 371850, training_loss: 4.28844e+01
I0515 04:24:20.302567 140128494741248 run_lib.py:152] step: 371900, training_loss: 1.23146e+01
I0515 04:24:20.357297 140128494741248 run_lib.py:165] step: 371900, eval_loss: 2.03168e+01
I0515 04:24:26.504879 140128494741248 run_lib.py:152] step: 371950, training_loss: 4.32651e+01
I0515 04:24:32.694345 140128494741248 run_lib.py:152] step: 372000, training_loss: 3.06184e+01
I0515 04:24:32.756676 140128494741248 run_lib.py:165] step: 372000, eval_loss: 3.57937e+01
I0515 04:24:38.858051 140128494741248 run_lib.py:152] step: 372050, training_loss: 2.90009e+01
I0515 04:24:45.287917 140128494741248 run_lib.py:152] step: 372100, training_loss: 4.40817e+01
I0515 04:24:45.337398 140128494741248 run_lib.py:165] step: 372100, eval_loss: 2.36863e+01
I0515 04:24:51.555805 140128494741248 run_lib.py:152] step: 372150, training_loss: 3.61994e+01
I0515 04:24:57.745295 140128494741248 run_lib.py:152] step: 372200, training_loss: 2.43050e+01
I0515 04:24:57.799624 140128494741248 run_lib.py:165] step: 372200, eval_loss: 2.75045e+01
I0515 04:25:04.152369 140128494741248 run_lib.py:152] step: 372250, training_loss: 1.77640e+01
I0515 04:25:10.394814 140128494741248 run_lib.py:152] step: 372300, training_loss: 2.25685e+01
I0515 04:25:10.444366 140128494741248 run_lib.py:165] step: 372300, eval_loss: 2.42962e+01
I0515 04:25:16.565052 140128494741248 run_lib.py:152] step: 372350, training_loss: 5.18431e+01
I0515 04:25:22.826605 140128494741248 run_lib.py:152] step: 372400, training_loss: 2.76363e+01
I0515 04:25:22.878199 140128494741248 run_lib.py:165] step: 372400, eval_loss: 3.61475e+01
I0515 04:25:29.311161 140128494741248 run_lib.py:152] step: 372450, training_loss: 2.91798e+01
I0515 04:25:35.504003 140128494741248 run_lib.py:152] step: 372500, training_loss: 4.32834e+01
I0515 04:25:35.554131 140128494741248 run_lib.py:165] step: 372500, eval_loss: 3.00825e+01
I0515 04:25:41.693339 140128494741248 run_lib.py:152] step: 372550, training_loss: 1.79435e+01
I0515 04:25:48.194728 140128494741248 run_lib.py:152] step: 372600, training_loss: 3.60407e+01
I0515 04:25:48.247667 140128494741248 run_lib.py:165] step: 372600, eval_loss: 3.60104e+01
I0515 04:25:54.479567 140128494741248 run_lib.py:152] step: 372650, training_loss: 2.06193e+01
I0515 04:26:00.730807 140128494741248 run_lib.py:152] step: 372700, training_loss: 3.75174e+01
I0515 04:26:00.787416 140128494741248 run_lib.py:165] step: 372700, eval_loss: 3.68972e+01
I0515 04:26:06.978819 140128494741248 run_lib.py:152] step: 372750, training_loss: 3.04037e+01
I0515 04:26:13.370758 140128494741248 run_lib.py:152] step: 372800, training_loss: 3.47531e+01
I0515 04:26:13.426233 140128494741248 run_lib.py:165] step: 372800, eval_loss: 2.22213e+01
I0515 04:26:19.680168 140128494741248 run_lib.py:152] step: 372850, training_loss: 2.75615e+01
I0515 04:26:25.917933 140128494741248 run_lib.py:152] step: 372900, training_loss: 2.77576e+01
I0515 04:26:25.972622 140128494741248 run_lib.py:165] step: 372900, eval_loss: 1.99455e+01
I0515 04:26:32.477093 140128494741248 run_lib.py:152] step: 372950, training_loss: 2.76086e+01
I0515 04:26:38.694849 140128494741248 run_lib.py:152] step: 373000, training_loss: 3.85093e+01
I0515 04:26:38.744241 140128494741248 run_lib.py:165] step: 373000, eval_loss: 3.13654e+01
I0515 04:26:44.944286 140128494741248 run_lib.py:152] step: 373050, training_loss: 1.72079e+01
I0515 04:26:51.058847 140128494741248 run_lib.py:152] step: 373100, training_loss: 3.34862e+01
I0515 04:26:51.111768 140128494741248 run_lib.py:165] step: 373100, eval_loss: 3.70393e+01
I0515 04:26:57.584446 140128494741248 run_lib.py:152] step: 373150, training_loss: 2.56254e+01
I0515 04:27:03.818201 140128494741248 run_lib.py:152] step: 373200, training_loss: 3.67246e+01
I0515 04:27:03.869795 140128494741248 run_lib.py:165] step: 373200, eval_loss: 1.73816e+01
I0515 04:27:09.987399 140128494741248 run_lib.py:152] step: 373250, training_loss: 2.19234e+01
I0515 04:27:16.385511 140128494741248 run_lib.py:152] step: 373300, training_loss: 3.47452e+01
I0515 04:27:16.436727 140128494741248 run_lib.py:165] step: 373300, eval_loss: 4.46318e+01
I0515 04:27:22.560510 140128494741248 run_lib.py:152] step: 373350, training_loss: 2.39877e+01
I0515 04:27:28.706147 140128494741248 run_lib.py:152] step: 373400, training_loss: 3.67447e+01
I0515 04:27:28.754587 140128494741248 run_lib.py:165] step: 373400, eval_loss: 3.52767e+01
I0515 04:27:34.906887 140128494741248 run_lib.py:152] step: 373450, training_loss: 4.59342e+01
I0515 04:27:41.300366 140128494741248 run_lib.py:152] step: 373500, training_loss: 3.58928e+01
I0515 04:27:41.350136 140128494741248 run_lib.py:165] step: 373500, eval_loss: 2.92627e+01
I0515 04:27:47.391046 140128494741248 run_lib.py:152] step: 373550, training_loss: 3.51963e+01
I0515 04:27:53.616727 140128494741248 run_lib.py:152] step: 373600, training_loss: 3.18148e+01
I0515 04:27:53.678732 140128494741248 run_lib.py:165] step: 373600, eval_loss: 3.69787e+01
I0515 04:28:00.103995 140128494741248 run_lib.py:152] step: 373650, training_loss: 3.53405e+01
I0515 04:28:06.246383 140128494741248 run_lib.py:152] step: 373700, training_loss: 2.68294e+01
I0515 04:28:06.295187 140128494741248 run_lib.py:165] step: 373700, eval_loss: 2.10553e+01
I0515 04:28:12.490752 140128494741248 run_lib.py:152] step: 373750, training_loss: 3.76233e+01
I0515 04:28:18.654493 140128494741248 run_lib.py:152] step: 373800, training_loss: 4.38142e+01
I0515 04:28:18.705264 140128494741248 run_lib.py:165] step: 373800, eval_loss: 3.65035e+01
I0515 04:28:25.160639 140128494741248 run_lib.py:152] step: 373850, training_loss: 3.16971e+01
I0515 04:28:31.496704 140128494741248 run_lib.py:152] step: 373900, training_loss: 2.64957e+01
I0515 04:28:31.551830 140128494741248 run_lib.py:165] step: 373900, eval_loss: 4.05120e+01
I0515 04:28:37.702030 140128494741248 run_lib.py:152] step: 373950, training_loss: 2.77272e+01
I0515 04:28:44.075378 140128494741248 run_lib.py:152] step: 374000, training_loss: 3.74292e+01
I0515 04:28:44.126050 140128494741248 run_lib.py:165] step: 374000, eval_loss: 2.70863e+01
I0515 04:28:50.337260 140128494741248 run_lib.py:152] step: 374050, training_loss: 2.25870e+01
I0515 04:28:56.449724 140128494741248 run_lib.py:152] step: 374100, training_loss: 2.89394e+01
I0515 04:28:56.501588 140128494741248 run_lib.py:165] step: 374100, eval_loss: 2.77181e+01
I0515 04:29:02.694733 140128494741248 run_lib.py:152] step: 374150, training_loss: 2.03336e+01
I0515 04:29:09.081855 140128494741248 run_lib.py:152] step: 374200, training_loss: 1.90689e+01
I0515 04:29:09.133533 140128494741248 run_lib.py:165] step: 374200, eval_loss: 3.51794e+01
I0515 04:29:15.268716 140128494741248 run_lib.py:152] step: 374250, training_loss: 3.52158e+01
I0515 04:29:21.454175 140128494741248 run_lib.py:152] step: 374300, training_loss: 2.97074e+01
I0515 04:29:21.510071 140128494741248 run_lib.py:165] step: 374300, eval_loss: 3.12778e+01
I0515 04:29:28.016534 140128494741248 run_lib.py:152] step: 374350, training_loss: 2.74321e+01
I0515 04:29:34.337498 140128494741248 run_lib.py:152] step: 374400, training_loss: 2.27111e+01
I0515 04:29:34.392969 140128494741248 run_lib.py:165] step: 374400, eval_loss: 3.06605e+01
I0515 04:29:40.549103 140128494741248 run_lib.py:152] step: 374450, training_loss: 3.03726e+01
I0515 04:29:46.724383 140128494741248 run_lib.py:152] step: 374500, training_loss: 4.59065e+01
I0515 04:29:46.778430 140128494741248 run_lib.py:165] step: 374500, eval_loss: 2.35100e+01
I0515 04:29:53.228602 140128494741248 run_lib.py:152] step: 374550, training_loss: 2.66649e+01
I0515 04:29:59.382090 140128494741248 run_lib.py:152] step: 374600, training_loss: 2.49886e+01
I0515 04:29:59.433467 140128494741248 run_lib.py:165] step: 374600, eval_loss: 3.30023e+01
I0515 04:30:05.589121 140128494741248 run_lib.py:152] step: 374650, training_loss: 2.64917e+01
I0515 04:30:12.078441 140128494741248 run_lib.py:152] step: 374700, training_loss: 2.86510e+01
I0515 04:30:12.139616 140128494741248 run_lib.py:165] step: 374700, eval_loss: 3.17923e+01
I0515 04:30:18.258715 140128494741248 run_lib.py:152] step: 374750, training_loss: 3.33358e+01
I0515 04:30:24.524110 140128494741248 run_lib.py:152] step: 374800, training_loss: 2.68223e+01
I0515 04:30:24.579391 140128494741248 run_lib.py:165] step: 374800, eval_loss: 2.44905e+01
I0515 04:30:30.845259 140128494741248 run_lib.py:152] step: 374850, training_loss: 4.09188e+01
I0515 04:30:37.274071 140128494741248 run_lib.py:152] step: 374900, training_loss: 4.94565e+01
I0515 04:30:37.324520 140128494741248 run_lib.py:165] step: 374900, eval_loss: 3.99620e+01
I0515 04:30:43.505580 140128494741248 run_lib.py:152] step: 374950, training_loss: 2.01013e+01
I0515 04:30:49.673809 140128494741248 run_lib.py:152] step: 375000, training_loss: 2.36404e+01
I0515 04:30:49.732095 140128494741248 run_lib.py:165] step: 375000, eval_loss: 3.18737e+01
I0515 04:30:56.147427 140128494741248 run_lib.py:152] step: 375050, training_loss: 2.87286e+01
I0515 04:31:02.375192 140128494741248 run_lib.py:152] step: 375100, training_loss: 3.03233e+01
I0515 04:31:02.425940 140128494741248 run_lib.py:165] step: 375100, eval_loss: 2.36954e+01
I0515 04:31:08.744547 140128494741248 run_lib.py:152] step: 375150, training_loss: 3.52426e+01
I0515 04:31:14.926256 140128494741248 run_lib.py:152] step: 375200, training_loss: 3.55655e+01
I0515 04:31:14.979312 140128494741248 run_lib.py:165] step: 375200, eval_loss: 4.04577e+01
I0515 04:31:21.543141 140128494741248 run_lib.py:152] step: 375250, training_loss: 2.58516e+01
I0515 04:31:27.752484 140128494741248 run_lib.py:152] step: 375300, training_loss: 3.04633e+01
I0515 04:31:27.803055 140128494741248 run_lib.py:165] step: 375300, eval_loss: 3.62927e+01
I0515 04:31:33.968683 140128494741248 run_lib.py:152] step: 375350, training_loss: 3.79563e+01
I0515 04:31:40.299913 140128494741248 run_lib.py:152] step: 375400, training_loss: 2.38626e+01
I0515 04:31:40.350396 140128494741248 run_lib.py:165] step: 375400, eval_loss: 4.31258e+01
I0515 04:31:46.594506 140128494741248 run_lib.py:152] step: 375450, training_loss: 3.36444e+01
I0515 04:31:52.844507 140128494741248 run_lib.py:152] step: 375500, training_loss: 2.99325e+01
I0515 04:31:52.896120 140128494741248 run_lib.py:165] step: 375500, eval_loss: 4.17662e+01
I0515 04:31:59.203991 140128494741248 run_lib.py:152] step: 375550, training_loss: 2.42915e+01
I0515 04:32:05.673014 140128494741248 run_lib.py:152] step: 375600, training_loss: 3.29907e+01
I0515 04:32:05.725747 140128494741248 run_lib.py:165] step: 375600, eval_loss: 3.06221e+01
I0515 04:32:11.883861 140128494741248 run_lib.py:152] step: 375650, training_loss: 2.37489e+01
I0515 04:32:18.135454 140128494741248 run_lib.py:152] step: 375700, training_loss: 5.58757e+01
I0515 04:32:18.187833 140128494741248 run_lib.py:165] step: 375700, eval_loss: 3.79619e+01
I0515 04:32:24.572060 140128494741248 run_lib.py:152] step: 375750, training_loss: 1.87301e+01
I0515 04:32:30.968254 140128494741248 run_lib.py:152] step: 375800, training_loss: 4.15501e+01
I0515 04:32:31.016207 140128494741248 run_lib.py:165] step: 375800, eval_loss: 3.11307e+01
I0515 04:32:37.291734 140128494741248 run_lib.py:152] step: 375850, training_loss: 2.53291e+01
I0515 04:32:43.490602 140128494741248 run_lib.py:152] step: 375900, training_loss: 3.43813e+01
I0515 04:32:43.542412 140128494741248 run_lib.py:165] step: 375900, eval_loss: 3.84711e+01
I0515 04:32:49.957155 140128494741248 run_lib.py:152] step: 375950, training_loss: 1.26631e+01
I0515 04:32:56.155059 140128494741248 run_lib.py:152] step: 376000, training_loss: 3.68420e+01
I0515 04:32:56.209234 140128494741248 run_lib.py:165] step: 376000, eval_loss: 3.45365e+01
I0515 04:33:02.429212 140128494741248 run_lib.py:152] step: 376050, training_loss: 5.62800e+01
I0515 04:33:08.904615 140128494741248 run_lib.py:152] step: 376100, training_loss: 3.45995e+01
I0515 04:33:08.956145 140128494741248 run_lib.py:165] step: 376100, eval_loss: 3.57424e+01
I0515 04:33:15.176425 140128494741248 run_lib.py:152] step: 376150, training_loss: 3.20101e+01
I0515 04:33:21.317194 140128494741248 run_lib.py:152] step: 376200, training_loss: 3.61949e+01
I0515 04:33:21.371483 140128494741248 run_lib.py:165] step: 376200, eval_loss: 3.17394e+01
I0515 04:33:27.630149 140128494741248 run_lib.py:152] step: 376250, training_loss: 3.33077e+01
I0515 04:33:34.080681 140128494741248 run_lib.py:152] step: 376300, training_loss: 3.06893e+01
I0515 04:33:34.130138 140128494741248 run_lib.py:165] step: 376300, eval_loss: 2.91357e+01
I0515 04:33:40.414437 140128494741248 run_lib.py:152] step: 376350, training_loss: 2.81921e+01
I0515 04:33:46.625888 140128494741248 run_lib.py:152] step: 376400, training_loss: 3.03815e+01
I0515 04:33:46.676637 140128494741248 run_lib.py:165] step: 376400, eval_loss: 2.49924e+01
I0515 04:33:53.081111 140128494741248 run_lib.py:152] step: 376450, training_loss: 3.25368e+01
I0515 04:33:59.299844 140128494741248 run_lib.py:152] step: 376500, training_loss: 4.87412e+01
I0515 04:33:59.352180 140128494741248 run_lib.py:165] step: 376500, eval_loss: 2.76261e+01
I0515 04:34:05.476140 140128494741248 run_lib.py:152] step: 376550, training_loss: 3.15048e+01
I0515 04:34:11.732240 140128494741248 run_lib.py:152] step: 376600, training_loss: 3.09210e+01
I0515 04:34:11.787047 140128494741248 run_lib.py:165] step: 376600, eval_loss: 1.72100e+01
I0515 04:34:18.140818 140128494741248 run_lib.py:152] step: 376650, training_loss: 2.71483e+01
I0515 04:34:24.393556 140128494741248 run_lib.py:152] step: 376700, training_loss: 1.97855e+01
I0515 04:34:24.444526 140128494741248 run_lib.py:165] step: 376700, eval_loss: 2.73692e+01
I0515 04:34:30.625427 140128494741248 run_lib.py:152] step: 376750, training_loss: 4.38941e+01
I0515 04:34:37.007219 140128494741248 run_lib.py:152] step: 376800, training_loss: 2.15888e+01
I0515 04:34:37.059637 140128494741248 run_lib.py:165] step: 376800, eval_loss: 3.36757e+01
I0515 04:34:43.270483 140128494741248 run_lib.py:152] step: 376850, training_loss: 3.29819e+01
I0515 04:34:49.444998 140128494741248 run_lib.py:152] step: 376900, training_loss: 2.73572e+01
I0515 04:34:49.495744 140128494741248 run_lib.py:165] step: 376900, eval_loss: 3.60891e+01
I0515 04:34:55.669666 140128494741248 run_lib.py:152] step: 376950, training_loss: 4.04778e+01
I0515 04:35:02.219262 140128494741248 run_lib.py:152] step: 377000, training_loss: 2.22124e+01
I0515 04:35:02.277102 140128494741248 run_lib.py:165] step: 377000, eval_loss: 2.43581e+01
I0515 04:35:08.486773 140128494741248 run_lib.py:152] step: 377050, training_loss: 3.46243e+01
I0515 04:35:14.620750 140128494741248 run_lib.py:152] step: 377100, training_loss: 2.31179e+01
I0515 04:35:14.677065 140128494741248 run_lib.py:165] step: 377100, eval_loss: 3.50468e+01
I0515 04:35:21.014760 140128494741248 run_lib.py:152] step: 377150, training_loss: 4.76120e+01
I0515 04:35:27.225660 140128494741248 run_lib.py:152] step: 377200, training_loss: 2.23457e+01
I0515 04:35:27.275298 140128494741248 run_lib.py:165] step: 377200, eval_loss: 1.46775e+01
I0515 04:35:33.446228 140128494741248 run_lib.py:152] step: 377250, training_loss: 4.62780e+01
I0515 04:35:39.639875 140128494741248 run_lib.py:152] step: 377300, training_loss: 1.41586e+01
I0515 04:35:39.691494 140128494741248 run_lib.py:165] step: 377300, eval_loss: 3.11824e+01
I0515 04:35:46.116593 140128494741248 run_lib.py:152] step: 377350, training_loss: 3.66710e+01
I0515 04:35:52.409161 140128494741248 run_lib.py:152] step: 377400, training_loss: 3.15244e+01
I0515 04:35:52.467507 140128494741248 run_lib.py:165] step: 377400, eval_loss: 1.86717e+01
I0515 04:35:58.599245 140128494741248 run_lib.py:152] step: 377450, training_loss: 2.94306e+01
I0515 04:36:04.966825 140128494741248 run_lib.py:152] step: 377500, training_loss: 3.48317e+01
I0515 04:36:05.018176 140128494741248 run_lib.py:165] step: 377500, eval_loss: 2.82506e+01
I0515 04:36:11.184531 140128494741248 run_lib.py:152] step: 377550, training_loss: 2.18725e+01
I0515 04:36:17.397184 140128494741248 run_lib.py:152] step: 377600, training_loss: 4.73764e+01
I0515 04:36:17.465635 140128494741248 run_lib.py:165] step: 377600, eval_loss: 2.36343e+01
I0515 04:36:23.669654 140128494741248 run_lib.py:152] step: 377650, training_loss: 2.43703e+01
I0515 04:36:30.105716 140128494741248 run_lib.py:152] step: 377700, training_loss: 3.26290e+01
I0515 04:36:30.155981 140128494741248 run_lib.py:165] step: 377700, eval_loss: 2.25992e+01
I0515 04:36:36.431301 140128494741248 run_lib.py:152] step: 377750, training_loss: 3.66575e+01
I0515 04:36:42.553100 140128494741248 run_lib.py:152] step: 377800, training_loss: 2.63426e+01
I0515 04:36:42.604162 140128494741248 run_lib.py:165] step: 377800, eval_loss: 3.59353e+01
I0515 04:36:49.023697 140128494741248 run_lib.py:152] step: 377850, training_loss: 3.68618e+01
I0515 04:36:55.182202 140128494741248 run_lib.py:152] step: 377900, training_loss: 2.76920e+01
I0515 04:36:55.234851 140128494741248 run_lib.py:165] step: 377900, eval_loss: 1.40883e+01
I0515 04:37:01.528391 140128494741248 run_lib.py:152] step: 377950, training_loss: 2.23894e+01
I0515 04:37:07.670684 140128494741248 run_lib.py:152] step: 378000, training_loss: 3.29532e+01
I0515 04:37:07.719350 140128494741248 run_lib.py:165] step: 378000, eval_loss: 2.67267e+01
I0515 04:37:14.179342 140128494741248 run_lib.py:152] step: 378050, training_loss: 1.56259e+01
I0515 04:37:20.287395 140128494741248 run_lib.py:152] step: 378100, training_loss: 4.02159e+01
I0515 04:37:20.337203 140128494741248 run_lib.py:165] step: 378100, eval_loss: 2.22932e+01
I0515 04:37:26.534096 140128494741248 run_lib.py:152] step: 378150, training_loss: 1.95978e+01
I0515 04:37:33.049268 140128494741248 run_lib.py:152] step: 378200, training_loss: 2.71334e+01
I0515 04:37:33.100369 140128494741248 run_lib.py:165] step: 378200, eval_loss: 3.32359e+01
I0515 04:37:39.297528 140128494741248 run_lib.py:152] step: 378250, training_loss: 3.13788e+01
I0515 04:37:45.435906 140128494741248 run_lib.py:152] step: 378300, training_loss: 2.59068e+01
I0515 04:37:45.490825 140128494741248 run_lib.py:165] step: 378300, eval_loss: 2.03399e+01
I0515 04:37:51.723457 140128494741248 run_lib.py:152] step: 378350, training_loss: 3.04399e+01
I0515 04:37:58.185137 140128494741248 run_lib.py:152] step: 378400, training_loss: 4.14038e+01
I0515 04:37:58.235211 140128494741248 run_lib.py:165] step: 378400, eval_loss: 2.71288e+01
I0515 04:38:04.487219 140128494741248 run_lib.py:152] step: 378450, training_loss: 3.26805e+01
I0515 04:38:10.757207 140128494741248 run_lib.py:152] step: 378500, training_loss: 2.78764e+01
I0515 04:38:10.805933 140128494741248 run_lib.py:165] step: 378500, eval_loss: 2.59092e+01
I0515 04:38:17.210075 140128494741248 run_lib.py:152] step: 378550, training_loss: 2.08968e+01
I0515 04:38:23.545538 140128494741248 run_lib.py:152] step: 378600, training_loss: 2.79280e+01
I0515 04:38:23.598098 140128494741248 run_lib.py:165] step: 378600, eval_loss: 2.32534e+01
I0515 04:38:29.779518 140128494741248 run_lib.py:152] step: 378650, training_loss: 3.48579e+01
I0515 04:38:36.047073 140128494741248 run_lib.py:152] step: 378700, training_loss: 3.02863e+01
I0515 04:38:36.102297 140128494741248 run_lib.py:165] step: 378700, eval_loss: 2.85031e+01
I0515 04:38:42.625373 140128494741248 run_lib.py:152] step: 378750, training_loss: 3.13347e+01
I0515 04:38:48.790677 140128494741248 run_lib.py:152] step: 378800, training_loss: 3.66063e+01
I0515 04:38:48.838837 140128494741248 run_lib.py:165] step: 378800, eval_loss: 3.20199e+01
I0515 04:38:55.056958 140128494741248 run_lib.py:152] step: 378850, training_loss: 5.85590e+01
I0515 04:39:01.585865 140128494741248 run_lib.py:152] step: 378900, training_loss: 4.72520e+01
I0515 04:39:01.639960 140128494741248 run_lib.py:165] step: 378900, eval_loss: 4.11189e+01
I0515 04:39:07.837434 140128494741248 run_lib.py:152] step: 378950, training_loss: 1.72965e+01
I0515 04:39:14.091569 140128494741248 run_lib.py:152] step: 379000, training_loss: 3.48483e+01
I0515 04:39:14.146277 140128494741248 run_lib.py:165] step: 379000, eval_loss: 2.69791e+01
I0515 04:39:20.315183 140128494741248 run_lib.py:152] step: 379050, training_loss: 3.81402e+01
I0515 04:39:26.812592 140128494741248 run_lib.py:152] step: 379100, training_loss: 3.93743e+01
I0515 04:39:26.860474 140128494741248 run_lib.py:165] step: 379100, eval_loss: 2.82544e+01
I0515 04:39:33.023373 140128494741248 run_lib.py:152] step: 379150, training_loss: 2.40157e+01
I0515 04:39:39.281618 140128494741248 run_lib.py:152] step: 379200, training_loss: 4.57561e+01
I0515 04:39:39.333723 140128494741248 run_lib.py:165] step: 379200, eval_loss: 3.08584e+01
I0515 04:39:45.737745 140128494741248 run_lib.py:152] step: 379250, training_loss: 1.92493e+01
I0515 04:39:51.909080 140128494741248 run_lib.py:152] step: 379300, training_loss: 2.55349e+01
I0515 04:39:51.959050 140128494741248 run_lib.py:165] step: 379300, eval_loss: 1.47194e+01
I0515 04:39:58.127578 140128494741248 run_lib.py:152] step: 379350, training_loss: 2.94190e+01
I0515 04:40:04.228913 140128494741248 run_lib.py:152] step: 379400, training_loss: 3.77658e+01
I0515 04:40:04.284946 140128494741248 run_lib.py:165] step: 379400, eval_loss: 2.08332e+01
I0515 04:40:10.659100 140128494741248 run_lib.py:152] step: 379450, training_loss: 3.36703e+01
I0515 04:40:16.812463 140128494741248 run_lib.py:152] step: 379500, training_loss: 2.08090e+01
I0515 04:40:16.862742 140128494741248 run_lib.py:165] step: 379500, eval_loss: 2.65045e+01
I0515 04:40:23.075627 140128494741248 run_lib.py:152] step: 379550, training_loss: 2.99189e+01
I0515 04:40:29.583650 140128494741248 run_lib.py:152] step: 379600, training_loss: 3.61465e+01
I0515 04:40:29.637287 140128494741248 run_lib.py:165] step: 379600, eval_loss: 3.50845e+01
I0515 04:40:35.726006 140128494741248 run_lib.py:152] step: 379650, training_loss: 4.02537e+01
I0515 04:40:41.813089 140128494741248 run_lib.py:152] step: 379700, training_loss: 2.80023e+01
I0515 04:40:41.867834 140128494741248 run_lib.py:165] step: 379700, eval_loss: 2.45492e+01
I0515 04:40:48.146096 140128494741248 run_lib.py:152] step: 379750, training_loss: 2.72727e+01
I0515 04:40:54.681920 140128494741248 run_lib.py:152] step: 379800, training_loss: 4.21112e+01
I0515 04:40:54.731428 140128494741248 run_lib.py:165] step: 379800, eval_loss: 4.26540e+01
I0515 04:41:00.859131 140128494741248 run_lib.py:152] step: 379850, training_loss: 2.44111e+01
I0515 04:41:07.041046 140128494741248 run_lib.py:152] step: 379900, training_loss: 2.57953e+01
I0515 04:41:07.091839 140128494741248 run_lib.py:165] step: 379900, eval_loss: 4.08825e+01
I0515 04:41:13.437193 140128494741248 run_lib.py:152] step: 379950, training_loss: 2.46564e+01
I0515 04:41:19.619659 140128494741248 run_lib.py:152] step: 380000, training_loss: 3.18367e+01
I0515 04:41:19.823146 140128494741248 run_lib.py:165] step: 380000, eval_loss: 2.67435e+01
I0515 04:41:25.985773 140128494741248 run_lib.py:152] step: 380050, training_loss: 3.41698e+01
I0515 04:41:32.263043 140128494741248 run_lib.py:152] step: 380100, training_loss: 2.22335e+01
I0515 04:41:32.314869 140128494741248 run_lib.py:165] step: 380100, eval_loss: 1.77955e+01
I0515 04:41:38.696568 140128494741248 run_lib.py:152] step: 380150, training_loss: 2.38478e+01
I0515 04:41:44.886229 140128494741248 run_lib.py:152] step: 380200, training_loss: 3.33940e+01
I0515 04:41:44.941122 140128494741248 run_lib.py:165] step: 380200, eval_loss: 4.23178e+01
I0515 04:41:51.086119 140128494741248 run_lib.py:152] step: 380250, training_loss: 3.44422e+01
I0515 04:41:57.579391 140128494741248 run_lib.py:152] step: 380300, training_loss: 2.66805e+01
I0515 04:41:57.632308 140128494741248 run_lib.py:165] step: 380300, eval_loss: 3.81800e+01
I0515 04:42:03.753316 140128494741248 run_lib.py:152] step: 380350, training_loss: 2.93584e+01
I0515 04:42:09.929821 140128494741248 run_lib.py:152] step: 380400, training_loss: 4.59849e+01
I0515 04:42:09.985189 140128494741248 run_lib.py:165] step: 380400, eval_loss: 4.66665e+01
I0515 04:42:16.183367 140128494741248 run_lib.py:152] step: 380450, training_loss: 2.89831e+01
I0515 04:42:22.643671 140128494741248 run_lib.py:152] step: 380500, training_loss: 4.30181e+01
I0515 04:42:22.702058 140128494741248 run_lib.py:165] step: 380500, eval_loss: 3.32327e+01
I0515 04:42:28.847564 140128494741248 run_lib.py:152] step: 380550, training_loss: 3.01525e+01
I0515 04:42:35.059002 140128494741248 run_lib.py:152] step: 380600, training_loss: 3.03772e+01
I0515 04:42:35.109317 140128494741248 run_lib.py:165] step: 380600, eval_loss: 2.33338e+01
I0515 04:42:41.469262 140128494741248 run_lib.py:152] step: 380650, training_loss: 2.87667e+01
I0515 04:42:47.686996 140128494741248 run_lib.py:152] step: 380700, training_loss: 3.74173e+01
I0515 04:42:47.738085 140128494741248 run_lib.py:165] step: 380700, eval_loss: 3.24179e+01
I0515 04:42:53.809286 140128494741248 run_lib.py:152] step: 380750, training_loss: 3.25897e+01
I0515 04:42:59.999729 140128494741248 run_lib.py:152] step: 380800, training_loss: 4.21914e+01
I0515 04:43:00.049502 140128494741248 run_lib.py:165] step: 380800, eval_loss: 2.55794e+01
I0515 04:43:06.473506 140128494741248 run_lib.py:152] step: 380850, training_loss: 4.00906e+01
I0515 04:43:12.727748 140128494741248 run_lib.py:152] step: 380900, training_loss: 1.85640e+01
I0515 04:43:12.779937 140128494741248 run_lib.py:165] step: 380900, eval_loss: 3.39103e+01
I0515 04:43:19.033653 140128494741248 run_lib.py:152] step: 380950, training_loss: 3.96157e+01
I0515 04:43:25.511998 140128494741248 run_lib.py:152] step: 381000, training_loss: 3.38559e+01
I0515 04:43:25.561290 140128494741248 run_lib.py:165] step: 381000, eval_loss: 2.79136e+01
I0515 04:43:31.794646 140128494741248 run_lib.py:152] step: 381050, training_loss: 4.35612e+01
I0515 04:43:38.045985 140128494741248 run_lib.py:152] step: 381100, training_loss: 2.72238e+01
I0515 04:43:38.098117 140128494741248 run_lib.py:165] step: 381100, eval_loss: 3.81040e+01
I0515 04:43:44.508792 140128494741248 run_lib.py:152] step: 381150, training_loss: 2.16077e+01
I0515 04:43:50.717052 140128494741248 run_lib.py:152] step: 381200, training_loss: 3.06672e+01
I0515 04:43:50.771646 140128494741248 run_lib.py:165] step: 381200, eval_loss: 2.78315e+01
I0515 04:43:56.948378 140128494741248 run_lib.py:152] step: 381250, training_loss: 2.29663e+01
I0515 04:44:03.228240 140128494741248 run_lib.py:152] step: 381300, training_loss: 2.43680e+01
I0515 04:44:03.279582 140128494741248 run_lib.py:165] step: 381300, eval_loss: 3.03539e+01
I0515 04:44:09.736335 140128494741248 run_lib.py:152] step: 381350, training_loss: 3.93170e+01
I0515 04:44:16.000662 140128494741248 run_lib.py:152] step: 381400, training_loss: 2.64610e+01
I0515 04:44:16.056931 140128494741248 run_lib.py:165] step: 381400, eval_loss: 3.81936e+01
I0515 04:44:22.321457 140128494741248 run_lib.py:152] step: 381450, training_loss: 2.07748e+01
I0515 04:44:28.743115 140128494741248 run_lib.py:152] step: 381500, training_loss: 2.07252e+01
I0515 04:44:28.797979 140128494741248 run_lib.py:165] step: 381500, eval_loss: 3.70290e+01
I0515 04:44:35.002848 140128494741248 run_lib.py:152] step: 381550, training_loss: 3.77516e+01
I0515 04:44:41.219711 140128494741248 run_lib.py:152] step: 381600, training_loss: 3.15192e+01
I0515 04:44:41.274365 140128494741248 run_lib.py:165] step: 381600, eval_loss: 2.93108e+01
I0515 04:44:47.479747 140128494741248 run_lib.py:152] step: 381650, training_loss: 2.98635e+01
I0515 04:44:53.875090 140128494741248 run_lib.py:152] step: 381700, training_loss: 4.30356e+01
I0515 04:44:53.925790 140128494741248 run_lib.py:165] step: 381700, eval_loss: 3.09242e+01
I0515 04:45:00.190130 140128494741248 run_lib.py:152] step: 381750, training_loss: 2.79612e+01
I0515 04:45:06.373384 140128494741248 run_lib.py:152] step: 381800, training_loss: 3.41429e+01
I0515 04:45:06.427902 140128494741248 run_lib.py:165] step: 381800, eval_loss: 3.58412e+01
I0515 04:45:12.895527 140128494741248 run_lib.py:152] step: 381850, training_loss: 3.39566e+01
I0515 04:45:19.153054 140128494741248 run_lib.py:152] step: 381900, training_loss: 2.99152e+01
I0515 04:45:19.207021 140128494741248 run_lib.py:165] step: 381900, eval_loss: 2.00898e+01
I0515 04:45:25.438636 140128494741248 run_lib.py:152] step: 381950, training_loss: 2.51279e+01
I0515 04:45:31.665505 140128494741248 run_lib.py:152] step: 382000, training_loss: 3.31885e+01
I0515 04:45:31.715408 140128494741248 run_lib.py:165] step: 382000, eval_loss: 3.31581e+01
I0515 04:45:38.118018 140128494741248 run_lib.py:152] step: 382050, training_loss: 1.62366e+01
I0515 04:45:44.368168 140128494741248 run_lib.py:152] step: 382100, training_loss: 2.44020e+01
I0515 04:45:44.415053 140128494741248 run_lib.py:165] step: 382100, eval_loss: 3.33727e+01
I0515 04:45:50.770119 140128494741248 run_lib.py:152] step: 382150, training_loss: 3.82317e+01
I0515 04:45:57.200239 140128494741248 run_lib.py:152] step: 382200, training_loss: 4.44695e+01
I0515 04:45:57.256028 140128494741248 run_lib.py:165] step: 382200, eval_loss: 2.93474e+01
I0515 04:46:03.520475 140128494741248 run_lib.py:152] step: 382250, training_loss: 3.50774e+01
I0515 04:46:09.673413 140128494741248 run_lib.py:152] step: 382300, training_loss: 3.52902e+01
I0515 04:46:09.725966 140128494741248 run_lib.py:165] step: 382300, eval_loss: 2.60492e+01
I0515 04:46:16.044545 140128494741248 run_lib.py:152] step: 382350, training_loss: 3.19374e+01
I0515 04:46:22.453756 140128494741248 run_lib.py:152] step: 382400, training_loss: 3.56631e+01
I0515 04:46:22.505367 140128494741248 run_lib.py:165] step: 382400, eval_loss: 3.43425e+01
I0515 04:46:28.829553 140128494741248 run_lib.py:152] step: 382450, training_loss: 2.25742e+01
I0515 04:46:35.007738 140128494741248 run_lib.py:152] step: 382500, training_loss: 2.58123e+01
I0515 04:46:35.061574 140128494741248 run_lib.py:165] step: 382500, eval_loss: 2.71158e+01
I0515 04:46:41.562082 140128494741248 run_lib.py:152] step: 382550, training_loss: 2.21278e+01
I0515 04:46:47.760971 140128494741248 run_lib.py:152] step: 382600, training_loss: 2.25697e+01
I0515 04:46:47.809789 140128494741248 run_lib.py:165] step: 382600, eval_loss: 3.06954e+01
I0515 04:46:54.065675 140128494741248 run_lib.py:152] step: 382650, training_loss: 2.64507e+01
I0515 04:47:00.350125 140128494741248 run_lib.py:152] step: 382700, training_loss: 2.70210e+01
I0515 04:47:00.404680 140128494741248 run_lib.py:165] step: 382700, eval_loss: 1.78322e+01
I0515 04:47:06.901511 140128494741248 run_lib.py:152] step: 382750, training_loss: 1.82630e+01
I0515 04:47:13.213905 140128494741248 run_lib.py:152] step: 382800, training_loss: 3.88476e+01
I0515 04:47:13.267845 140128494741248 run_lib.py:165] step: 382800, eval_loss: 3.68778e+01
I0515 04:47:19.414794 140128494741248 run_lib.py:152] step: 382850, training_loss: 1.97620e+01
I0515 04:47:25.985682 140128494741248 run_lib.py:152] step: 382900, training_loss: 1.20561e+01
I0515 04:47:26.034984 140128494741248 run_lib.py:165] step: 382900, eval_loss: 4.06136e+01
I0515 04:47:32.194664 140128494741248 run_lib.py:152] step: 382950, training_loss: 3.08142e+01
I0515 04:47:38.469814 140128494741248 run_lib.py:152] step: 383000, training_loss: 3.76329e+01
I0515 04:47:38.525592 140128494741248 run_lib.py:165] step: 383000, eval_loss: 3.60319e+01
I0515 04:47:44.653541 140128494741248 run_lib.py:152] step: 383050, training_loss: 3.06953e+01
I0515 04:47:51.064692 140128494741248 run_lib.py:152] step: 383100, training_loss: 3.07182e+01
I0515 04:47:51.115417 140128494741248 run_lib.py:165] step: 383100, eval_loss: 2.17889e+01
I0515 04:47:57.255303 140128494741248 run_lib.py:152] step: 383150, training_loss: 4.27086e+01
I0515 04:48:03.532456 140128494741248 run_lib.py:152] step: 383200, training_loss: 2.78661e+01
I0515 04:48:03.582667 140128494741248 run_lib.py:165] step: 383200, eval_loss: 1.32295e+01
I0515 04:48:09.947790 140128494741248 run_lib.py:152] step: 383250, training_loss: 2.63182e+01
I0515 04:48:16.143286 140128494741248 run_lib.py:152] step: 383300, training_loss: 2.82571e+01
I0515 04:48:16.198804 140128494741248 run_lib.py:165] step: 383300, eval_loss: 3.59819e+01
I0515 04:48:22.491350 140128494741248 run_lib.py:152] step: 383350, training_loss: 2.94381e+01
I0515 04:48:28.627524 140128494741248 run_lib.py:152] step: 383400, training_loss: 2.32100e+01
I0515 04:48:28.676293 140128494741248 run_lib.py:165] step: 383400, eval_loss: 2.70204e+01
I0515 04:48:35.150768 140128494741248 run_lib.py:152] step: 383450, training_loss: 2.16401e+01
I0515 04:48:41.374742 140128494741248 run_lib.py:152] step: 383500, training_loss: 4.38489e+01
I0515 04:48:41.424314 140128494741248 run_lib.py:165] step: 383500, eval_loss: 3.60543e+01
I0515 04:48:47.598765 140128494741248 run_lib.py:152] step: 383550, training_loss: 4.04786e+01
I0515 04:48:53.867869 140128494741248 run_lib.py:152] step: 383600, training_loss: 4.74325e+01
I0515 04:48:54.147429 140128494741248 run_lib.py:165] step: 383600, eval_loss: 3.00511e+01
I0515 04:49:00.412566 140128494741248 run_lib.py:152] step: 383650, training_loss: 2.43980e+01
I0515 04:49:06.743637 140128494741248 run_lib.py:152] step: 383700, training_loss: 1.38845e+01
I0515 04:49:06.796404 140128494741248 run_lib.py:165] step: 383700, eval_loss: 2.73719e+01
I0515 04:49:13.026817 140128494741248 run_lib.py:152] step: 383750, training_loss: 3.34692e+01
I0515 04:49:19.474600 140128494741248 run_lib.py:152] step: 383800, training_loss: 4.18442e+01
I0515 04:49:19.532516 140128494741248 run_lib.py:165] step: 383800, eval_loss: 2.60332e+01
I0515 04:49:25.793397 140128494741248 run_lib.py:152] step: 383850, training_loss: 4.06429e+01
I0515 04:49:31.978905 140128494741248 run_lib.py:152] step: 383900, training_loss: 4.74608e+01
I0515 04:49:32.034763 140128494741248 run_lib.py:165] step: 383900, eval_loss: 3.44785e+01
I0515 04:49:38.499401 140128494741248 run_lib.py:152] step: 383950, training_loss: 3.47492e+01
I0515 04:49:44.692206 140128494741248 run_lib.py:152] step: 384000, training_loss: 2.65017e+01
I0515 04:49:44.745389 140128494741248 run_lib.py:165] step: 384000, eval_loss: 1.96586e+01
I0515 04:49:50.962512 140128494741248 run_lib.py:152] step: 384050, training_loss: 3.97117e+01
I0515 04:49:57.156645 140128494741248 run_lib.py:152] step: 384100, training_loss: 3.24354e+01
I0515 04:49:57.208144 140128494741248 run_lib.py:165] step: 384100, eval_loss: 3.00668e+01
I0515 04:50:03.668165 140128494741248 run_lib.py:152] step: 384150, training_loss: 2.51244e+01
I0515 04:50:09.835042 140128494741248 run_lib.py:152] step: 384200, training_loss: 4.22347e+01
I0515 04:50:09.886406 140128494741248 run_lib.py:165] step: 384200, eval_loss: 3.09879e+01
I0515 04:50:16.157863 140128494741248 run_lib.py:152] step: 384250, training_loss: 3.04188e+01
I0515 04:50:22.608367 140128494741248 run_lib.py:152] step: 384300, training_loss: 3.29179e+01
I0515 04:50:22.659546 140128494741248 run_lib.py:165] step: 384300, eval_loss: 2.92947e+01
I0515 04:50:28.807850 140128494741248 run_lib.py:152] step: 384350, training_loss: 2.99031e+01
I0515 04:50:35.033046 140128494741248 run_lib.py:152] step: 384400, training_loss: 3.68871e+01
I0515 04:50:35.084832 140128494741248 run_lib.py:165] step: 384400, eval_loss: 3.80063e+01
I0515 04:50:41.291260 140128494741248 run_lib.py:152] step: 384450, training_loss: 1.74928e+01
I0515 04:50:47.736346 140128494741248 run_lib.py:152] step: 384500, training_loss: 3.29371e+01
I0515 04:50:47.786459 140128494741248 run_lib.py:165] step: 384500, eval_loss: 3.10310e+01
I0515 04:50:54.135819 140128494741248 run_lib.py:152] step: 384550, training_loss: 3.53211e+01
I0515 04:51:00.361231 140128494741248 run_lib.py:152] step: 384600, training_loss: 4.15944e+01
I0515 04:51:00.420002 140128494741248 run_lib.py:165] step: 384600, eval_loss: 2.33859e+01
I0515 04:51:06.839406 140128494741248 run_lib.py:152] step: 384650, training_loss: 4.29159e+01
I0515 04:51:13.033175 140128494741248 run_lib.py:152] step: 384700, training_loss: 2.62817e+01
I0515 04:51:13.082894 140128494741248 run_lib.py:165] step: 384700, eval_loss: 2.76891e+01
I0515 04:51:19.307572 140128494741248 run_lib.py:152] step: 384750, training_loss: 2.89537e+01
I0515 04:51:25.486487 140128494741248 run_lib.py:152] step: 384800, training_loss: 3.14771e+01
I0515 04:51:25.542995 140128494741248 run_lib.py:165] step: 384800, eval_loss: 2.69026e+01
I0515 04:51:32.057635 140128494741248 run_lib.py:152] step: 384850, training_loss: 3.94316e+01
I0515 04:51:38.253682 140128494741248 run_lib.py:152] step: 384900, training_loss: 3.58458e+01
I0515 04:51:38.304767 140128494741248 run_lib.py:165] step: 384900, eval_loss: 4.68022e+01
I0515 04:51:44.413057 140128494741248 run_lib.py:152] step: 384950, training_loss: 3.35166e+01
I0515 04:51:50.953106 140128494741248 run_lib.py:152] step: 385000, training_loss: 2.52732e+01
I0515 04:51:51.006318 140128494741248 run_lib.py:165] step: 385000, eval_loss: 2.57728e+01
I0515 04:51:57.237183 140128494741248 run_lib.py:152] step: 385050, training_loss: 3.40963e+01
I0515 04:52:03.400360 140128494741248 run_lib.py:152] step: 385100, training_loss: 4.59916e+01
I0515 04:52:03.451286 140128494741248 run_lib.py:165] step: 385100, eval_loss: 1.28121e+01
I0515 04:52:09.647342 140128494741248 run_lib.py:152] step: 385150, training_loss: 3.66520e+01
I0515 04:52:16.221700 140128494741248 run_lib.py:152] step: 385200, training_loss: 2.62485e+01
I0515 04:52:16.275646 140128494741248 run_lib.py:165] step: 385200, eval_loss: 2.41796e+01
I0515 04:52:22.524775 140128494741248 run_lib.py:152] step: 385250, training_loss: 2.52500e+01
I0515 04:52:28.620167 140128494741248 run_lib.py:152] step: 385300, training_loss: 2.85807e+01
I0515 04:52:28.669964 140128494741248 run_lib.py:165] step: 385300, eval_loss: 4.45126e+01
I0515 04:52:34.969480 140128494741248 run_lib.py:152] step: 385350, training_loss: 3.99939e+01
I0515 04:52:40.962965 140128494741248 run_lib.py:152] step: 385400, training_loss: 4.38157e+01
I0515 04:52:41.021524 140128494741248 run_lib.py:165] step: 385400, eval_loss: 3.26913e+01
I0515 04:52:47.128404 140128494741248 run_lib.py:152] step: 385450, training_loss: 4.58057e+01
I0515 04:52:53.283462 140128494741248 run_lib.py:152] step: 385500, training_loss: 3.23895e+01
I0515 04:52:53.341869 140128494741248 run_lib.py:165] step: 385500, eval_loss: 2.90090e+01
I0515 04:52:59.874349 140128494741248 run_lib.py:152] step: 385550, training_loss: 4.13516e+01
I0515 04:53:06.020138 140128494741248 run_lib.py:152] step: 385600, training_loss: 3.36936e+01
I0515 04:53:06.075659 140128494741248 run_lib.py:165] step: 385600, eval_loss: 2.51282e+01
I0515 04:53:12.358753 140128494741248 run_lib.py:152] step: 385650, training_loss: 3.58304e+01
I0515 04:53:18.868911 140128494741248 run_lib.py:152] step: 385700, training_loss: 1.82508e+01
I0515 04:53:18.925703 140128494741248 run_lib.py:165] step: 385700, eval_loss: 3.81976e+01
I0515 04:53:25.253319 140128494741248 run_lib.py:152] step: 385750, training_loss: 3.24695e+01
I0515 04:53:31.432241 140128494741248 run_lib.py:152] step: 385800, training_loss: 4.18733e+01
I0515 04:53:31.486664 140128494741248 run_lib.py:165] step: 385800, eval_loss: 2.68911e+01
I0515 04:53:37.712603 140128494741248 run_lib.py:152] step: 385850, training_loss: 2.31501e+01
I0515 04:53:44.288180 140128494741248 run_lib.py:152] step: 385900, training_loss: 3.89102e+01
I0515 04:53:44.336875 140128494741248 run_lib.py:165] step: 385900, eval_loss: 3.18944e+01
I0515 04:53:50.486800 140128494741248 run_lib.py:152] step: 385950, training_loss: 3.54349e+01
I0515 04:53:56.765319 140128494741248 run_lib.py:152] step: 386000, training_loss: 3.42053e+01
I0515 04:53:56.819058 140128494741248 run_lib.py:165] step: 386000, eval_loss: 2.91648e+01
I0515 04:54:03.187870 140128494741248 run_lib.py:152] step: 386050, training_loss: 1.62143e+01
I0515 04:54:09.439246 140128494741248 run_lib.py:152] step: 386100, training_loss: 2.60452e+01
I0515 04:54:09.495280 140128494741248 run_lib.py:165] step: 386100, eval_loss: 2.99193e+01
I0515 04:54:15.782076 140128494741248 run_lib.py:152] step: 386150, training_loss: 4.01415e+01
I0515 04:54:21.970273 140128494741248 run_lib.py:152] step: 386200, training_loss: 3.39922e+01
I0515 04:54:22.021476 140128494741248 run_lib.py:165] step: 386200, eval_loss: 3.84649e+01
I0515 04:54:28.526066 140128494741248 run_lib.py:152] step: 386250, training_loss: 1.90710e+01
I0515 04:54:34.719596 140128494741248 run_lib.py:152] step: 386300, training_loss: 4.11549e+01
I0515 04:54:34.773203 140128494741248 run_lib.py:165] step: 386300, eval_loss: 3.68917e+01
I0515 04:54:41.073503 140128494741248 run_lib.py:152] step: 386350, training_loss: 2.24943e+01
I0515 04:54:47.579812 140128494741248 run_lib.py:152] step: 386400, training_loss: 3.79327e+01
I0515 04:54:47.626392 140128494741248 run_lib.py:165] step: 386400, eval_loss: 3.82090e+01
I0515 04:54:53.890997 140128494741248 run_lib.py:152] step: 386450, training_loss: 1.26315e+01
I0515 04:55:00.097924 140128494741248 run_lib.py:152] step: 386500, training_loss: 3.73618e+01
I0515 04:55:00.154959 140128494741248 run_lib.py:165] step: 386500, eval_loss: 3.11626e+01
I0515 04:55:06.344914 140128494741248 run_lib.py:152] step: 386550, training_loss: 2.81992e+01
I0515 04:55:12.844184 140128494741248 run_lib.py:152] step: 386600, training_loss: 2.33491e+01
I0515 04:55:12.893704 140128494741248 run_lib.py:165] step: 386600, eval_loss: 1.37904e+01
I0515 04:55:19.150919 140128494741248 run_lib.py:152] step: 386650, training_loss: 3.01348e+01
I0515 04:55:25.466457 140128494741248 run_lib.py:152] step: 386700, training_loss: 2.60273e+01
I0515 04:55:25.515887 140128494741248 run_lib.py:165] step: 386700, eval_loss: 3.36308e+01
I0515 04:55:31.921499 140128494741248 run_lib.py:152] step: 386750, training_loss: 2.15930e+01
I0515 04:55:38.227057 140128494741248 run_lib.py:152] step: 386800, training_loss: 2.37104e+01
I0515 04:55:38.280589 140128494741248 run_lib.py:165] step: 386800, eval_loss: 3.35079e+01
I0515 04:55:44.586736 140128494741248 run_lib.py:152] step: 386850, training_loss: 3.27886e+01
I0515 04:55:50.739126 140128494741248 run_lib.py:152] step: 386900, training_loss: 3.47263e+01
I0515 04:55:50.793851 140128494741248 run_lib.py:165] step: 386900, eval_loss: 2.37196e+01
I0515 04:55:57.268937 140128494741248 run_lib.py:152] step: 386950, training_loss: 2.79099e+01
I0515 04:56:03.372785 140128494741248 run_lib.py:152] step: 387000, training_loss: 4.61582e+01
I0515 04:56:03.423640 140128494741248 run_lib.py:165] step: 387000, eval_loss: 2.52971e+01
I0515 04:56:09.673849 140128494741248 run_lib.py:152] step: 387050, training_loss: 3.81411e+01
I0515 04:56:15.920202 140128494741248 run_lib.py:152] step: 387100, training_loss: 2.98167e+01
I0515 04:56:16.206592 140128494741248 run_lib.py:165] step: 387100, eval_loss: 3.36285e+01
I0515 04:56:22.296434 140128494741248 run_lib.py:152] step: 387150, training_loss: 3.15631e+01
I0515 04:56:28.500750 140128494741248 run_lib.py:152] step: 387200, training_loss: 3.23949e+01
I0515 04:56:28.549921 140128494741248 run_lib.py:165] step: 387200, eval_loss: 2.44522e+01
I0515 04:56:34.739286 140128494741248 run_lib.py:152] step: 387250, training_loss: 2.66751e+01
I0515 04:56:41.345229 140128494741248 run_lib.py:152] step: 387300, training_loss: 3.84353e+01
I0515 04:56:41.396544 140128494741248 run_lib.py:165] step: 387300, eval_loss: 2.00736e+01
I0515 04:56:47.557745 140128494741248 run_lib.py:152] step: 387350, training_loss: 3.48816e+01
I0515 04:56:53.812704 140128494741248 run_lib.py:152] step: 387400, training_loss: 3.58692e+01
I0515 04:56:53.865582 140128494741248 run_lib.py:165] step: 387400, eval_loss: 4.48285e+01
I0515 04:57:00.216535 140128494741248 run_lib.py:152] step: 387450, training_loss: 4.49640e+01
I0515 04:57:06.373588 140128494741248 run_lib.py:152] step: 387500, training_loss: 3.34386e+01
I0515 04:57:06.422332 140128494741248 run_lib.py:165] step: 387500, eval_loss: 2.59340e+01
I0515 04:57:12.597316 140128494741248 run_lib.py:152] step: 387550, training_loss: 2.63895e+01
I0515 04:57:18.888586 140128494741248 run_lib.py:152] step: 387600, training_loss: 4.29377e+01
I0515 04:57:18.945487 140128494741248 run_lib.py:165] step: 387600, eval_loss: 3.31883e+01
I0515 04:57:25.334261 140128494741248 run_lib.py:152] step: 387650, training_loss: 2.41530e+01
I0515 04:57:31.551712 140128494741248 run_lib.py:152] step: 387700, training_loss: 2.92970e+01
I0515 04:57:31.608674 140128494741248 run_lib.py:165] step: 387700, eval_loss: 3.62600e+01
I0515 04:57:37.804957 140128494741248 run_lib.py:152] step: 387750, training_loss: 3.18102e+01
I0515 04:57:44.279802 140128494741248 run_lib.py:152] step: 387800, training_loss: 3.58223e+01
I0515 04:57:44.330414 140128494741248 run_lib.py:165] step: 387800, eval_loss: 4.00474e+01
I0515 04:57:50.583376 140128494741248 run_lib.py:152] step: 387850, training_loss: 4.73439e+01
I0515 04:57:56.820636 140128494741248 run_lib.py:152] step: 387900, training_loss: 2.73288e+01
I0515 04:57:56.875758 140128494741248 run_lib.py:165] step: 387900, eval_loss: 2.60349e+01
I0515 04:58:03.067754 140128494741248 run_lib.py:152] step: 387950, training_loss: 4.54287e+01
I0515 04:58:09.517187 140128494741248 run_lib.py:152] step: 388000, training_loss: 2.64634e+01
I0515 04:58:09.567468 140128494741248 run_lib.py:165] step: 388000, eval_loss: 2.18181e+01
I0515 04:58:15.852796 140128494741248 run_lib.py:152] step: 388050, training_loss: 2.25290e+01
I0515 04:58:22.007415 140128494741248 run_lib.py:152] step: 388100, training_loss: 2.33204e+01
I0515 04:58:22.059048 140128494741248 run_lib.py:165] step: 388100, eval_loss: 3.51979e+01
I0515 04:58:28.406660 140128494741248 run_lib.py:152] step: 388150, training_loss: 4.62583e+01
I0515 04:58:34.682395 140128494741248 run_lib.py:152] step: 388200, training_loss: 4.11702e+01
I0515 04:58:34.737935 140128494741248 run_lib.py:165] step: 388200, eval_loss: 4.07593e+01
I0515 04:58:40.950201 140128494741248 run_lib.py:152] step: 388250, training_loss: 2.46345e+01
I0515 04:58:47.173933 140128494741248 run_lib.py:152] step: 388300, training_loss: 3.58594e+01
I0515 04:58:47.225764 140128494741248 run_lib.py:165] step: 388300, eval_loss: 2.51695e+01
I0515 04:58:53.690022 140128494741248 run_lib.py:152] step: 388350, training_loss: 2.14645e+01
I0515 04:58:59.920121 140128494741248 run_lib.py:152] step: 388400, training_loss: 2.94413e+01
I0515 04:58:59.971907 140128494741248 run_lib.py:165] step: 388400, eval_loss: 2.12546e+01
I0515 04:59:06.112807 140128494741248 run_lib.py:152] step: 388450, training_loss: 2.80180e+01
I0515 04:59:12.604555 140128494741248 run_lib.py:152] step: 388500, training_loss: 2.67279e+01
I0515 04:59:12.656263 140128494741248 run_lib.py:165] step: 388500, eval_loss: 3.57057e+01
I0515 04:59:18.839059 140128494741248 run_lib.py:152] step: 388550, training_loss: 3.63799e+01
I0515 04:59:24.987619 140128494741248 run_lib.py:152] step: 388600, training_loss: 2.97093e+01
I0515 04:59:25.041562 140128494741248 run_lib.py:165] step: 388600, eval_loss: 1.81076e+01
I0515 04:59:31.263047 140128494741248 run_lib.py:152] step: 388650, training_loss: 2.99644e+01
I0515 04:59:37.651103 140128494741248 run_lib.py:152] step: 388700, training_loss: 2.71996e+01
I0515 04:59:37.701961 140128494741248 run_lib.py:165] step: 388700, eval_loss: 2.53966e+01
I0515 04:59:44.005565 140128494741248 run_lib.py:152] step: 388750, training_loss: 2.95312e+01
I0515 04:59:50.244955 140128494741248 run_lib.py:152] step: 388800, training_loss: 3.26956e+01
I0515 04:59:50.296482 140128494741248 run_lib.py:165] step: 388800, eval_loss: 3.44402e+01
I0515 04:59:56.775063 140128494741248 run_lib.py:152] step: 388850, training_loss: 2.85817e+01
I0515 05:00:02.983645 140128494741248 run_lib.py:152] step: 388900, training_loss: 2.57493e+01
I0515 05:00:03.035517 140128494741248 run_lib.py:165] step: 388900, eval_loss: 3.19562e+01
I0515 05:00:09.338355 140128494741248 run_lib.py:152] step: 388950, training_loss: 2.02381e+01
I0515 05:00:15.518311 140128494741248 run_lib.py:152] step: 389000, training_loss: 3.01166e+01
I0515 05:00:15.573856 140128494741248 run_lib.py:165] step: 389000, eval_loss: 2.09555e+01
I0515 05:00:22.036724 140128494741248 run_lib.py:152] step: 389050, training_loss: 3.57674e+01
I0515 05:00:28.243527 140128494741248 run_lib.py:152] step: 389100, training_loss: 1.97675e+01
I0515 05:00:28.290452 140128494741248 run_lib.py:165] step: 389100, eval_loss: 3.11037e+01
I0515 05:00:34.577485 140128494741248 run_lib.py:152] step: 389150, training_loss: 3.01704e+01
I0515 05:00:40.994979 140128494741248 run_lib.py:152] step: 389200, training_loss: 3.84337e+01
I0515 05:00:41.041957 140128494741248 run_lib.py:165] step: 389200, eval_loss: 1.02981e+01
I0515 05:00:47.236097 140128494741248 run_lib.py:152] step: 389250, training_loss: 2.14041e+01
I0515 05:00:53.479833 140128494741248 run_lib.py:152] step: 389300, training_loss: 3.12564e+01
I0515 05:00:53.529250 140128494741248 run_lib.py:165] step: 389300, eval_loss: 2.39891e+01
I0515 05:00:59.760547 140128494741248 run_lib.py:152] step: 389350, training_loss: 2.49560e+01
I0515 05:01:06.195394 140128494741248 run_lib.py:152] step: 389400, training_loss: 3.99236e+01
I0515 05:01:06.242266 140128494741248 run_lib.py:165] step: 389400, eval_loss: 3.54623e+01
I0515 05:01:12.389469 140128494741248 run_lib.py:152] step: 389450, training_loss: 3.30558e+01
I0515 05:01:18.524441 140128494741248 run_lib.py:152] step: 389500, training_loss: 2.29790e+01
I0515 05:01:18.572445 140128494741248 run_lib.py:165] step: 389500, eval_loss: 3.90748e+01
I0515 05:01:25.102325 140128494741248 run_lib.py:152] step: 389550, training_loss: 3.29724e+01
I0515 05:01:31.258977 140128494741248 run_lib.py:152] step: 389600, training_loss: 4.17395e+01
I0515 05:01:31.315488 140128494741248 run_lib.py:165] step: 389600, eval_loss: 5.05822e+01
I0515 05:01:37.582491 140128494741248 run_lib.py:152] step: 389650, training_loss: 2.96830e+01
I0515 05:01:43.788080 140128494741248 run_lib.py:152] step: 389700, training_loss: 2.11353e+01
I0515 05:01:43.835933 140128494741248 run_lib.py:165] step: 389700, eval_loss: 3.17274e+01
I0515 05:01:50.352880 140128494741248 run_lib.py:152] step: 389750, training_loss: 4.36633e+01
I0515 05:01:56.690749 140128494741248 run_lib.py:152] step: 389800, training_loss: 2.01441e+01
I0515 05:01:56.743275 140128494741248 run_lib.py:165] step: 389800, eval_loss: 4.33202e+01
I0515 05:02:02.831034 140128494741248 run_lib.py:152] step: 389850, training_loss: 2.44920e+01
I0515 05:02:09.359162 140128494741248 run_lib.py:152] step: 389900, training_loss: 4.29137e+01
I0515 05:02:09.415845 140128494741248 run_lib.py:165] step: 389900, eval_loss: 3.28479e+01
I0515 05:02:15.537599 140128494741248 run_lib.py:152] step: 389950, training_loss: 3.78061e+01
I0515 05:02:21.724771 140128494741248 run_lib.py:152] step: 390000, training_loss: 3.53443e+01
I0515 05:02:21.922475 140128494741248 run_lib.py:165] step: 390000, eval_loss: 3.20862e+01
I0515 05:02:28.073887 140128494741248 run_lib.py:152] step: 390050, training_loss: 3.71801e+01
I0515 05:02:34.565961 140128494741248 run_lib.py:152] step: 390100, training_loss: 2.60974e+01
I0515 05:02:34.620206 140128494741248 run_lib.py:165] step: 390100, eval_loss: 2.60512e+01
I0515 05:02:40.738341 140128494741248 run_lib.py:152] step: 390150, training_loss: 3.83052e+01
I0515 05:02:47.020805 140128494741248 run_lib.py:152] step: 390200, training_loss: 2.48843e+01
I0515 05:02:47.072151 140128494741248 run_lib.py:165] step: 390200, eval_loss: 3.71153e+01
I0515 05:02:53.475791 140128494741248 run_lib.py:152] step: 390250, training_loss: 3.30067e+01
I0515 05:02:59.621573 140128494741248 run_lib.py:152] step: 390300, training_loss: 4.94418e+01
I0515 05:02:59.670988 140128494741248 run_lib.py:165] step: 390300, eval_loss: 3.27851e+01
I0515 05:03:05.948641 140128494741248 run_lib.py:152] step: 390350, training_loss: 2.31905e+01
I0515 05:03:12.108608 140128494741248 run_lib.py:152] step: 390400, training_loss: 3.11462e+01
I0515 05:03:12.158219 140128494741248 run_lib.py:165] step: 390400, eval_loss: 3.33813e+01
I0515 05:03:18.577849 140128494741248 run_lib.py:152] step: 390450, training_loss: 4.00495e+01
I0515 05:03:24.764660 140128494741248 run_lib.py:152] step: 390500, training_loss: 3.44738e+01
I0515 05:03:24.815105 140128494741248 run_lib.py:165] step: 390500, eval_loss: 2.90397e+01
I0515 05:03:30.955919 140128494741248 run_lib.py:152] step: 390550, training_loss: 3.96445e+01
I0515 05:03:37.205903 140128494741248 run_lib.py:152] step: 390600, training_loss: 3.72645e+01
I0515 05:03:37.497674 140128494741248 run_lib.py:165] step: 390600, eval_loss: 2.38645e+01
I0515 05:03:43.689083 140128494741248 run_lib.py:152] step: 390650, training_loss: 3.74398e+01
I0515 05:03:49.864787 140128494741248 run_lib.py:152] step: 390700, training_loss: 2.81971e+01
I0515 05:03:49.912306 140128494741248 run_lib.py:165] step: 390700, eval_loss: 2.55750e+01
I0515 05:03:56.234098 140128494741248 run_lib.py:152] step: 390750, training_loss: 3.17331e+01
I0515 05:04:02.609919 140128494741248 run_lib.py:152] step: 390800, training_loss: 4.82500e+01
I0515 05:04:02.669184 140128494741248 run_lib.py:165] step: 390800, eval_loss: 2.92389e+01
I0515 05:04:08.991686 140128494741248 run_lib.py:152] step: 390850, training_loss: 2.52500e+01
I0515 05:04:15.190834 140128494741248 run_lib.py:152] step: 390900, training_loss: 4.29535e+01
I0515 05:04:15.242065 140128494741248 run_lib.py:165] step: 390900, eval_loss: 3.00743e+01
I0515 05:04:21.715612 140128494741248 run_lib.py:152] step: 390950, training_loss: 4.19795e+01
I0515 05:04:27.873166 140128494741248 run_lib.py:152] step: 391000, training_loss: 3.51658e+01
I0515 05:04:27.928308 140128494741248 run_lib.py:165] step: 391000, eval_loss: 3.29801e+01
I0515 05:04:34.127703 140128494741248 run_lib.py:152] step: 391050, training_loss: 4.51502e+01
I0515 05:04:40.318759 140128494741248 run_lib.py:152] step: 391100, training_loss: 1.44659e+01
I0515 05:04:40.371746 140128494741248 run_lib.py:165] step: 391100, eval_loss: 5.66075e+01
I0515 05:04:46.853322 140128494741248 run_lib.py:152] step: 391150, training_loss: 5.05441e+01
I0515 05:04:53.158380 140128494741248 run_lib.py:152] step: 391200, training_loss: 3.09295e+01
I0515 05:04:53.210577 140128494741248 run_lib.py:165] step: 391200, eval_loss: 2.42455e+01
I0515 05:04:59.467382 140128494741248 run_lib.py:152] step: 391250, training_loss: 3.18006e+01
I0515 05:05:05.887885 140128494741248 run_lib.py:152] step: 391300, training_loss: 1.63989e+01
I0515 05:05:05.939857 140128494741248 run_lib.py:165] step: 391300, eval_loss: 2.75547e+01
I0515 05:05:12.194966 140128494741248 run_lib.py:152] step: 391350, training_loss: 2.51328e+01
I0515 05:05:18.372371 140128494741248 run_lib.py:152] step: 391400, training_loss: 3.43724e+01
I0515 05:05:18.426955 140128494741248 run_lib.py:165] step: 391400, eval_loss: 4.52523e+01
I0515 05:05:24.723541 140128494741248 run_lib.py:152] step: 391450, training_loss: 2.93130e+01
I0515 05:05:31.204908 140128494741248 run_lib.py:152] step: 391500, training_loss: 1.86193e+01
I0515 05:05:31.254410 140128494741248 run_lib.py:165] step: 391500, eval_loss: 4.02537e+01
I0515 05:05:37.393036 140128494741248 run_lib.py:152] step: 391550, training_loss: 2.12337e+01
I0515 05:05:43.566158 140128494741248 run_lib.py:152] step: 391600, training_loss: 1.26965e+01
I0515 05:05:43.624638 140128494741248 run_lib.py:165] step: 391600, eval_loss: 3.37400e+01
I0515 05:05:50.059638 140128494741248 run_lib.py:152] step: 391650, training_loss: 3.25159e+01
I0515 05:05:56.248620 140128494741248 run_lib.py:152] step: 391700, training_loss: 3.37530e+01
I0515 05:05:56.303504 140128494741248 run_lib.py:165] step: 391700, eval_loss: 2.72491e+01
I0515 05:06:02.594555 140128494741248 run_lib.py:152] step: 391750, training_loss: 4.07935e+01
I0515 05:06:08.809628 140128494741248 run_lib.py:152] step: 391800, training_loss: 4.51886e+01
I0515 05:06:08.865746 140128494741248 run_lib.py:165] step: 391800, eval_loss: 2.74346e+01
I0515 05:06:15.220885 140128494741248 run_lib.py:152] step: 391850, training_loss: 2.39757e+01
I0515 05:06:21.464669 140128494741248 run_lib.py:152] step: 391900, training_loss: 3.04066e+01
I0515 05:06:21.517934 140128494741248 run_lib.py:165] step: 391900, eval_loss: 4.25562e+01
I0515 05:06:27.711239 140128494741248 run_lib.py:152] step: 391950, training_loss: 1.72486e+01
I0515 05:06:34.263740 140128494741248 run_lib.py:152] step: 392000, training_loss: 4.05851e+01
I0515 05:06:34.316609 140128494741248 run_lib.py:165] step: 392000, eval_loss: 2.42706e+01
I0515 05:06:40.477938 140128494741248 run_lib.py:152] step: 392050, training_loss: 2.97396e+01
I0515 05:06:46.724578 140128494741248 run_lib.py:152] step: 392100, training_loss: 3.04630e+01
I0515 05:06:46.774215 140128494741248 run_lib.py:165] step: 392100, eval_loss: 4.54585e+01
I0515 05:06:53.036097 140128494741248 run_lib.py:152] step: 392150, training_loss: 1.83981e+01
I0515 05:06:59.447525 140128494741248 run_lib.py:152] step: 392200, training_loss: 1.69111e+01
I0515 05:06:59.502552 140128494741248 run_lib.py:165] step: 392200, eval_loss: 2.12104e+01
I0515 05:07:05.659297 140128494741248 run_lib.py:152] step: 392250, training_loss: 2.88712e+01
I0515 05:07:11.899769 140128494741248 run_lib.py:152] step: 392300, training_loss: 3.23900e+01
I0515 05:07:11.953679 140128494741248 run_lib.py:165] step: 392300, eval_loss: 3.37034e+01
I0515 05:07:18.465012 140128494741248 run_lib.py:152] step: 392350, training_loss: 2.98990e+01
I0515 05:07:24.678376 140128494741248 run_lib.py:152] step: 392400, training_loss: 3.86355e+01
I0515 05:07:24.727750 140128494741248 run_lib.py:165] step: 392400, eval_loss: 2.49472e+01
I0515 05:07:30.937638 140128494741248 run_lib.py:152] step: 392450, training_loss: 2.88767e+01
I0515 05:07:37.212091 140128494741248 run_lib.py:152] step: 392500, training_loss: 1.78678e+01
I0515 05:07:37.261608 140128494741248 run_lib.py:165] step: 392500, eval_loss: 2.15351e+01
I0515 05:07:43.593294 140128494741248 run_lib.py:152] step: 392550, training_loss: 2.19145e+01
I0515 05:07:49.816548 140128494741248 run_lib.py:152] step: 392600, training_loss: 1.70448e+01
I0515 05:07:49.869676 140128494741248 run_lib.py:165] step: 392600, eval_loss: 3.21188e+01
I0515 05:07:56.107229 140128494741248 run_lib.py:152] step: 392650, training_loss: 2.73898e+01
I0515 05:08:02.588902 140128494741248 run_lib.py:152] step: 392700, training_loss: 2.87562e+01
I0515 05:08:02.639725 140128494741248 run_lib.py:165] step: 392700, eval_loss: 4.34495e+01
I0515 05:08:08.781463 140128494741248 run_lib.py:152] step: 392750, training_loss: 3.42355e+01
I0515 05:08:14.990571 140128494741248 run_lib.py:152] step: 392800, training_loss: 2.46070e+01
I0515 05:08:15.045160 140128494741248 run_lib.py:165] step: 392800, eval_loss: 2.99832e+01
I0515 05:08:21.203650 140128494741248 run_lib.py:152] step: 392850, training_loss: 3.47978e+01
I0515 05:08:27.555245 140128494741248 run_lib.py:152] step: 392900, training_loss: 2.89509e+01
I0515 05:08:27.621238 140128494741248 run_lib.py:165] step: 392900, eval_loss: 2.63195e+01
I0515 05:08:33.920170 140128494741248 run_lib.py:152] step: 392950, training_loss: 2.76001e+01
I0515 05:08:40.189172 140128494741248 run_lib.py:152] step: 393000, training_loss: 3.01393e+01
I0515 05:08:40.247951 140128494741248 run_lib.py:165] step: 393000, eval_loss: 1.85702e+01
I0515 05:08:46.769761 140128494741248 run_lib.py:152] step: 393050, training_loss: 4.31128e+01
I0515 05:08:53.038076 140128494741248 run_lib.py:152] step: 393100, training_loss: 3.09599e+01
I0515 05:08:53.091392 140128494741248 run_lib.py:165] step: 393100, eval_loss: 2.75809e+01
I0515 05:08:59.305035 140128494741248 run_lib.py:152] step: 393150, training_loss: 3.37264e+01
I0515 05:09:05.447121 140128494741248 run_lib.py:152] step: 393200, training_loss: 2.55458e+01
I0515 05:09:05.499872 140128494741248 run_lib.py:165] step: 393200, eval_loss: 2.22549e+01
I0515 05:09:12.087929 140128494741248 run_lib.py:152] step: 393250, training_loss: 3.37915e+01
I0515 05:09:18.213410 140128494741248 run_lib.py:152] step: 393300, training_loss: 4.87057e+01
I0515 05:09:18.263160 140128494741248 run_lib.py:165] step: 393300, eval_loss: 2.68754e+01
I0515 05:09:24.443769 140128494741248 run_lib.py:152] step: 393350, training_loss: 2.85899e+01
I0515 05:09:30.826147 140128494741248 run_lib.py:152] step: 393400, training_loss: 3.00386e+01
I0515 05:09:30.874989 140128494741248 run_lib.py:165] step: 393400, eval_loss: 2.95593e+01
I0515 05:09:37.149146 140128494741248 run_lib.py:152] step: 393450, training_loss: 2.41429e+01
I0515 05:09:43.416871 140128494741248 run_lib.py:152] step: 393500, training_loss: 3.28751e+01
I0515 05:09:43.472165 140128494741248 run_lib.py:165] step: 393500, eval_loss: 5.42647e+01
I0515 05:09:49.666792 140128494741248 run_lib.py:152] step: 393550, training_loss: 3.23989e+01
I0515 05:09:56.062887 140128494741248 run_lib.py:152] step: 393600, training_loss: 4.31934e+01
I0515 05:09:56.117478 140128494741248 run_lib.py:165] step: 393600, eval_loss: 2.23670e+01
I0515 05:10:02.343936 140128494741248 run_lib.py:152] step: 393650, training_loss: 2.46960e+01
I0515 05:10:08.615542 140128494741248 run_lib.py:152] step: 393700, training_loss: 5.02427e+01
I0515 05:10:08.665081 140128494741248 run_lib.py:165] step: 393700, eval_loss: 3.28671e+01
I0515 05:10:15.218773 140128494741248 run_lib.py:152] step: 393750, training_loss: 4.65222e+01
I0515 05:10:21.369320 140128494741248 run_lib.py:152] step: 393800, training_loss: 4.38966e+01
I0515 05:10:21.422139 140128494741248 run_lib.py:165] step: 393800, eval_loss: 3.32313e+01
I0515 05:10:27.691282 140128494741248 run_lib.py:152] step: 393850, training_loss: 4.51433e+01
I0515 05:10:33.873726 140128494741248 run_lib.py:152] step: 393900, training_loss: 1.60608e+01
I0515 05:10:33.938693 140128494741248 run_lib.py:165] step: 393900, eval_loss: 2.54849e+01
I0515 05:10:40.309859 140128494741248 run_lib.py:152] step: 393950, training_loss: 3.90546e+01
I0515 05:10:46.444278 140128494741248 run_lib.py:152] step: 394000, training_loss: 3.77106e+01
I0515 05:10:46.501107 140128494741248 run_lib.py:165] step: 394000, eval_loss: 4.84835e+01
I0515 05:10:52.699442 140128494741248 run_lib.py:152] step: 394050, training_loss: 3.06997e+01
I0515 05:10:58.940218 140128494741248 run_lib.py:152] step: 394100, training_loss: 3.50430e+01
I0515 05:10:59.232796 140128494741248 run_lib.py:165] step: 394100, eval_loss: 3.68593e+01
I0515 05:11:05.367390 140128494741248 run_lib.py:152] step: 394150, training_loss: 3.05803e+01
I0515 05:11:11.589401 140128494741248 run_lib.py:152] step: 394200, training_loss: 2.96883e+01
I0515 05:11:11.642892 140128494741248 run_lib.py:165] step: 394200, eval_loss: 2.96155e+01
I0515 05:11:17.817198 140128494741248 run_lib.py:152] step: 394250, training_loss: 1.78898e+01
I0515 05:11:24.277948 140128494741248 run_lib.py:152] step: 394300, training_loss: 1.93202e+01
I0515 05:11:24.331295 140128494741248 run_lib.py:165] step: 394300, eval_loss: 2.72562e+01
I0515 05:11:30.419393 140128494741248 run_lib.py:152] step: 394350, training_loss: 3.91256e+01
I0515 05:11:36.620979 140128494741248 run_lib.py:152] step: 394400, training_loss: 1.88784e+01
I0515 05:11:36.679533 140128494741248 run_lib.py:165] step: 394400, eval_loss: 2.91808e+01
I0515 05:11:43.011630 140128494741248 run_lib.py:152] step: 394450, training_loss: 3.65339e+01
I0515 05:11:49.251205 140128494741248 run_lib.py:152] step: 394500, training_loss: 3.61910e+01
I0515 05:11:49.310253 140128494741248 run_lib.py:165] step: 394500, eval_loss: 4.79864e+01
I0515 05:11:55.459828 140128494741248 run_lib.py:152] step: 394550, training_loss: 2.59862e+01
I0515 05:12:01.749509 140128494741248 run_lib.py:152] step: 394600, training_loss: 2.60794e+01
I0515 05:12:01.801149 140128494741248 run_lib.py:165] step: 394600, eval_loss: 3.04044e+01
I0515 05:12:08.220638 140128494741248 run_lib.py:152] step: 394650, training_loss: 3.35101e+01
I0515 05:12:14.423075 140128494741248 run_lib.py:152] step: 394700, training_loss: 3.67037e+01
I0515 05:12:14.475038 140128494741248 run_lib.py:165] step: 394700, eval_loss: 2.18160e+01
I0515 05:12:20.652450 140128494741248 run_lib.py:152] step: 394750, training_loss: 4.02723e+01
I0515 05:12:27.010261 140128494741248 run_lib.py:152] step: 394800, training_loss: 2.66189e+01
I0515 05:12:27.067965 140128494741248 run_lib.py:165] step: 394800, eval_loss: 1.66944e+01
I0515 05:12:33.295763 140128494741248 run_lib.py:152] step: 394850, training_loss: 2.14162e+01
I0515 05:12:39.498409 140128494741248 run_lib.py:152] step: 394900, training_loss: 2.51589e+01
I0515 05:12:39.553139 140128494741248 run_lib.py:165] step: 394900, eval_loss: 2.16246e+01
I0515 05:12:45.740877 140128494741248 run_lib.py:152] step: 394950, training_loss: 3.26727e+01
I0515 05:12:52.159838 140128494741248 run_lib.py:152] step: 395000, training_loss: 3.26026e+01
I0515 05:12:52.217227 140128494741248 run_lib.py:165] step: 395000, eval_loss: 4.13021e+01
I0515 05:12:58.369022 140128494741248 run_lib.py:152] step: 395050, training_loss: 2.66608e+01
I0515 05:13:04.617347 140128494741248 run_lib.py:152] step: 395100, training_loss: 3.57921e+01
I0515 05:13:04.671651 140128494741248 run_lib.py:165] step: 395100, eval_loss: 2.67414e+01
I0515 05:13:11.081671 140128494741248 run_lib.py:152] step: 395150, training_loss: 3.38524e+01
I0515 05:13:17.245048 140128494741248 run_lib.py:152] step: 395200, training_loss: 4.43077e+01
I0515 05:13:17.298020 140128494741248 run_lib.py:165] step: 395200, eval_loss: 2.70050e+01
I0515 05:13:23.609035 140128494741248 run_lib.py:152] step: 395250, training_loss: 3.86377e+01
I0515 05:13:29.834168 140128494741248 run_lib.py:152] step: 395300, training_loss: 2.97244e+01
I0515 05:13:29.884599 140128494741248 run_lib.py:165] step: 395300, eval_loss: 3.56459e+01
I0515 05:13:36.373414 140128494741248 run_lib.py:152] step: 395350, training_loss: 3.42092e+01
I0515 05:13:42.605257 140128494741248 run_lib.py:152] step: 395400, training_loss: 3.71020e+01
I0515 05:13:42.660901 140128494741248 run_lib.py:165] step: 395400, eval_loss: 4.44740e+01
I0515 05:13:48.948101 140128494741248 run_lib.py:152] step: 395450, training_loss: 5.31969e+01
I0515 05:13:55.334666 140128494741248 run_lib.py:152] step: 395500, training_loss: 2.64523e+01
I0515 05:13:55.392092 140128494741248 run_lib.py:165] step: 395500, eval_loss: 3.28887e+01
I0515 05:14:01.638006 140128494741248 run_lib.py:152] step: 395550, training_loss: 3.75325e+01
I0515 05:14:07.921795 140128494741248 run_lib.py:152] step: 395600, training_loss: 1.92570e+01
I0515 05:14:07.969790 140128494741248 run_lib.py:165] step: 395600, eval_loss: 3.75000e+01
I0515 05:14:14.167399 140128494741248 run_lib.py:152] step: 395650, training_loss: 2.46433e+01
I0515 05:14:20.624679 140128494741248 run_lib.py:152] step: 395700, training_loss: 3.97833e+01
I0515 05:14:20.674366 140128494741248 run_lib.py:165] step: 395700, eval_loss: 2.70465e+01
I0515 05:14:26.823413 140128494741248 run_lib.py:152] step: 395750, training_loss: 3.47151e+01
I0515 05:14:33.075027 140128494741248 run_lib.py:152] step: 395800, training_loss: 3.55973e+01
I0515 05:14:33.130704 140128494741248 run_lib.py:165] step: 395800, eval_loss: 3.53761e+01
I0515 05:14:39.492068 140128494741248 run_lib.py:152] step: 395850, training_loss: 3.32385e+01
I0515 05:14:45.792418 140128494741248 run_lib.py:152] step: 395900, training_loss: 3.28497e+01
I0515 05:14:45.841798 140128494741248 run_lib.py:165] step: 395900, eval_loss: 2.55005e+01
I0515 05:14:51.960327 140128494741248 run_lib.py:152] step: 395950, training_loss: 3.66606e+01
I0515 05:14:58.147705 140128494741248 run_lib.py:152] step: 396000, training_loss: 3.02383e+01
I0515 05:14:58.203625 140128494741248 run_lib.py:165] step: 396000, eval_loss: 3.99600e+01
I0515 05:15:04.654733 140128494741248 run_lib.py:152] step: 396050, training_loss: 3.00134e+01
I0515 05:15:10.814761 140128494741248 run_lib.py:152] step: 396100, training_loss: 3.79685e+01
I0515 05:15:10.866001 140128494741248 run_lib.py:165] step: 396100, eval_loss: 2.93477e+01
I0515 05:15:17.059496 140128494741248 run_lib.py:152] step: 396150, training_loss: 2.77230e+01
I0515 05:15:23.588652 140128494741248 run_lib.py:152] step: 396200, training_loss: 3.65950e+01
I0515 05:15:23.639905 140128494741248 run_lib.py:165] step: 396200, eval_loss: 2.95597e+01
I0515 05:15:29.865994 140128494741248 run_lib.py:152] step: 396250, training_loss: 4.17437e+01
I0515 05:15:36.017255 140128494741248 run_lib.py:152] step: 396300, training_loss: 2.24568e+01
I0515 05:15:36.069383 140128494741248 run_lib.py:165] step: 396300, eval_loss: 2.39477e+01
I0515 05:15:42.312103 140128494741248 run_lib.py:152] step: 396350, training_loss: 4.10627e+01
I0515 05:15:48.877282 140128494741248 run_lib.py:152] step: 396400, training_loss: 2.06108e+01
I0515 05:15:48.929394 140128494741248 run_lib.py:165] step: 396400, eval_loss: 3.53810e+01
I0515 05:15:55.132861 140128494741248 run_lib.py:152] step: 396450, training_loss: 3.69874e+01
I0515 05:16:01.389160 140128494741248 run_lib.py:152] step: 396500, training_loss: 3.56549e+01
I0515 05:16:01.437467 140128494741248 run_lib.py:165] step: 396500, eval_loss: 2.97457e+01
I0515 05:16:07.869733 140128494741248 run_lib.py:152] step: 396550, training_loss: 3.19837e+01
I0515 05:16:14.113873 140128494741248 run_lib.py:152] step: 396600, training_loss: 4.46217e+01
I0515 05:16:14.169226 140128494741248 run_lib.py:165] step: 396600, eval_loss: 4.40803e+01
I0515 05:16:20.394859 140128494741248 run_lib.py:152] step: 396650, training_loss: 2.75805e+01
I0515 05:16:26.648264 140128494741248 run_lib.py:152] step: 396700, training_loss: 5.42494e+01
I0515 05:16:26.698559 140128494741248 run_lib.py:165] step: 396700, eval_loss: 3.08350e+01
I0515 05:16:33.179477 140128494741248 run_lib.py:152] step: 396750, training_loss: 2.24982e+01
I0515 05:16:39.467202 140128494741248 run_lib.py:152] step: 396800, training_loss: 2.56341e+01
I0515 05:16:39.519995 140128494741248 run_lib.py:165] step: 396800, eval_loss: 2.52432e+01
I0515 05:16:45.711412 140128494741248 run_lib.py:152] step: 396850, training_loss: 2.73840e+01
I0515 05:16:52.212230 140128494741248 run_lib.py:152] step: 396900, training_loss: 3.74003e+01
I0515 05:16:52.260546 140128494741248 run_lib.py:165] step: 396900, eval_loss: 3.92071e+01
I0515 05:16:58.330695 140128494741248 run_lib.py:152] step: 396950, training_loss: 2.54285e+01
I0515 05:17:04.502718 140128494741248 run_lib.py:152] step: 397000, training_loss: 3.36319e+01
I0515 05:17:04.554454 140128494741248 run_lib.py:165] step: 397000, eval_loss: 4.36101e+01
I0515 05:17:10.813446 140128494741248 run_lib.py:152] step: 397050, training_loss: 4.42712e+01
I0515 05:17:17.268596 140128494741248 run_lib.py:152] step: 397100, training_loss: 3.57904e+01
I0515 05:17:17.318868 140128494741248 run_lib.py:165] step: 397100, eval_loss: 2.90004e+01
I0515 05:17:23.493217 140128494741248 run_lib.py:152] step: 397150, training_loss: 3.17904e+01
I0515 05:17:29.759434 140128494741248 run_lib.py:152] step: 397200, training_loss: 2.78087e+01
I0515 05:17:29.812551 140128494741248 run_lib.py:165] step: 397200, eval_loss: 3.20502e+01
I0515 05:17:36.169958 140128494741248 run_lib.py:152] step: 397250, training_loss: 2.83898e+01
I0515 05:17:42.404038 140128494741248 run_lib.py:152] step: 397300, training_loss: 2.88493e+01
I0515 05:17:42.454009 140128494741248 run_lib.py:165] step: 397300, eval_loss: 4.65200e+01
I0515 05:17:48.572137 140128494741248 run_lib.py:152] step: 397350, training_loss: 2.56553e+01
I0515 05:17:54.751719 140128494741248 run_lib.py:152] step: 397400, training_loss: 4.08208e+01
I0515 05:17:54.803859 140128494741248 run_lib.py:165] step: 397400, eval_loss: 4.29503e+01
I0515 05:18:01.230758 140128494741248 run_lib.py:152] step: 397450, training_loss: 3.48449e+01
I0515 05:18:07.343420 140128494741248 run_lib.py:152] step: 397500, training_loss: 3.52121e+01
I0515 05:18:07.396304 140128494741248 run_lib.py:165] step: 397500, eval_loss: 3.78454e+01
I0515 05:18:13.696479 140128494741248 run_lib.py:152] step: 397550, training_loss: 3.23095e+01
I0515 05:18:19.913761 140128494741248 run_lib.py:152] step: 397600, training_loss: 1.25790e+01
I0515 05:18:20.210619 140128494741248 run_lib.py:165] step: 397600, eval_loss: 3.09571e+01
I0515 05:18:26.433326 140128494741248 run_lib.py:152] step: 397650, training_loss: 3.56207e+01
I0515 05:18:32.653093 140128494741248 run_lib.py:152] step: 397700, training_loss: 4.36051e+01
I0515 05:18:32.706415 140128494741248 run_lib.py:165] step: 397700, eval_loss: 3.03686e+01
I0515 05:18:38.843667 140128494741248 run_lib.py:152] step: 397750, training_loss: 3.41353e+01
I0515 05:18:45.192572 140128494741248 run_lib.py:152] step: 397800, training_loss: 2.63052e+01
I0515 05:18:45.251151 140128494741248 run_lib.py:165] step: 397800, eval_loss: 2.92078e+01
I0515 05:18:51.477329 140128494741248 run_lib.py:152] step: 397850, training_loss: 1.67326e+01
I0515 05:18:57.638307 140128494741248 run_lib.py:152] step: 397900, training_loss: 1.87331e+01
I0515 05:18:57.693834 140128494741248 run_lib.py:165] step: 397900, eval_loss: 2.33067e+01
I0515 05:19:04.181710 140128494741248 run_lib.py:152] step: 397950, training_loss: 3.06232e+01
I0515 05:19:10.376749 140128494741248 run_lib.py:152] step: 398000, training_loss: 3.07696e+01
I0515 05:19:10.426563 140128494741248 run_lib.py:165] step: 398000, eval_loss: 3.23156e+01
I0515 05:19:16.648107 140128494741248 run_lib.py:152] step: 398050, training_loss: 3.26755e+01
I0515 05:19:22.749801 140128494741248 run_lib.py:152] step: 398100, training_loss: 4.42587e+01
I0515 05:19:22.799021 140128494741248 run_lib.py:165] step: 398100, eval_loss: 2.57096e+01
I0515 05:19:29.241027 140128494741248 run_lib.py:152] step: 398150, training_loss: 2.40102e+01
I0515 05:19:35.468421 140128494741248 run_lib.py:152] step: 398200, training_loss: 3.02100e+01
I0515 05:19:35.522282 140128494741248 run_lib.py:165] step: 398200, eval_loss: 3.13270e+01
I0515 05:19:41.654075 140128494741248 run_lib.py:152] step: 398250, training_loss: 2.89874e+01
I0515 05:19:48.016914 140128494741248 run_lib.py:152] step: 398300, training_loss: 2.18548e+01
I0515 05:19:48.070224 140128494741248 run_lib.py:165] step: 398300, eval_loss: 2.31320e+01
I0515 05:19:54.300204 140128494741248 run_lib.py:152] step: 398350, training_loss: 2.79051e+01
I0515 05:20:00.562655 140128494741248 run_lib.py:152] step: 398400, training_loss: 4.05021e+01
I0515 05:20:00.613806 140128494741248 run_lib.py:165] step: 398400, eval_loss: 3.52763e+01
I0515 05:20:06.732662 140128494741248 run_lib.py:152] step: 398450, training_loss: 3.17193e+01
I0515 05:20:13.293345 140128494741248 run_lib.py:152] step: 398500, training_loss: 2.10468e+01
I0515 05:20:13.347588 140128494741248 run_lib.py:165] step: 398500, eval_loss: 1.65602e+01
I0515 05:20:19.499222 140128494741248 run_lib.py:152] step: 398550, training_loss: 4.00756e+01
I0515 05:20:25.732651 140128494741248 run_lib.py:152] step: 398600, training_loss: 2.68469e+01
I0515 05:20:25.781400 140128494741248 run_lib.py:165] step: 398600, eval_loss: 2.18150e+01
I0515 05:20:32.188977 140128494741248 run_lib.py:152] step: 398650, training_loss: 2.93898e+01
I0515 05:20:38.377809 140128494741248 run_lib.py:152] step: 398700, training_loss: 2.92642e+01
I0515 05:20:38.435329 140128494741248 run_lib.py:165] step: 398700, eval_loss: 3.19599e+01
I0515 05:20:44.644470 140128494741248 run_lib.py:152] step: 398750, training_loss: 4.13343e+01
I0515 05:20:50.865196 140128494741248 run_lib.py:152] step: 398800, training_loss: 3.03286e+01
I0515 05:20:50.920647 140128494741248 run_lib.py:165] step: 398800, eval_loss: 2.73006e+01
I0515 05:20:57.329223 140128494741248 run_lib.py:152] step: 398850, training_loss: 3.16768e+01
I0515 05:21:03.443416 140128494741248 run_lib.py:152] step: 398900, training_loss: 2.82063e+01
I0515 05:21:03.497582 140128494741248 run_lib.py:165] step: 398900, eval_loss: 3.18005e+01
I0515 05:21:09.675416 140128494741248 run_lib.py:152] step: 398950, training_loss: 2.05322e+01
I0515 05:21:16.062461 140128494741248 run_lib.py:152] step: 399000, training_loss: 2.75618e+01
I0515 05:21:16.117332 140128494741248 run_lib.py:165] step: 399000, eval_loss: 1.87938e+01
I0515 05:21:22.376986 140128494741248 run_lib.py:152] step: 399050, training_loss: 1.96808e+01
I0515 05:21:28.646897 140128494741248 run_lib.py:152] step: 399100, training_loss: 4.09592e+01
I0515 05:21:28.698886 140128494741248 run_lib.py:165] step: 399100, eval_loss: 4.51216e+01
I0515 05:21:34.872576 140128494741248 run_lib.py:152] step: 399150, training_loss: 3.85758e+01
I0515 05:21:41.346407 140128494741248 run_lib.py:152] step: 399200, training_loss: 3.65364e+01
I0515 05:21:41.402263 140128494741248 run_lib.py:165] step: 399200, eval_loss: 3.14863e+01
I0515 05:21:47.680358 140128494741248 run_lib.py:152] step: 399250, training_loss: 2.39321e+01
I0515 05:21:53.867599 140128494741248 run_lib.py:152] step: 399300, training_loss: 3.71550e+01
I0515 05:21:53.922743 140128494741248 run_lib.py:165] step: 399300, eval_loss: 3.14121e+01
I0515 05:22:00.400311 140128494741248 run_lib.py:152] step: 399350, training_loss: 2.23546e+01
I0515 05:22:06.553847 140128494741248 run_lib.py:152] step: 399400, training_loss: 3.93437e+01
I0515 05:22:06.604379 140128494741248 run_lib.py:165] step: 399400, eval_loss: 2.74291e+01
I0515 05:22:12.801765 140128494741248 run_lib.py:152] step: 399450, training_loss: 5.85636e+01
I0515 05:22:19.066852 140128494741248 run_lib.py:152] step: 399500, training_loss: 2.48444e+01
I0515 05:22:19.119590 140128494741248 run_lib.py:165] step: 399500, eval_loss: 3.64852e+01
I0515 05:22:25.549660 140128494741248 run_lib.py:152] step: 399550, training_loss: 3.60851e+01
I0515 05:22:31.830855 140128494741248 run_lib.py:152] step: 399600, training_loss: 2.79918e+01
I0515 05:22:31.880467 140128494741248 run_lib.py:165] step: 399600, eval_loss: 1.65342e+01
I0515 05:22:38.123838 140128494741248 run_lib.py:152] step: 399650, training_loss: 3.92070e+01
I0515 05:22:44.599184 140128494741248 run_lib.py:152] step: 399700, training_loss: 3.51588e+01
I0515 05:22:44.650535 140128494741248 run_lib.py:165] step: 399700, eval_loss: 2.70015e+01
I0515 05:22:50.866701 140128494741248 run_lib.py:152] step: 399750, training_loss: 3.43600e+01
I0515 05:22:57.194374 140128494741248 run_lib.py:152] step: 399800, training_loss: 2.95482e+01
I0515 05:22:57.252340 140128494741248 run_lib.py:165] step: 399800, eval_loss: 3.08221e+01
I0515 05:23:03.454650 140128494741248 run_lib.py:152] step: 399850, training_loss: 4.08232e+01
I0515 05:23:09.846688 140128494741248 run_lib.py:152] step: 399900, training_loss: 3.02539e+01
I0515 05:23:09.898428 140128494741248 run_lib.py:165] step: 399900, eval_loss: 2.09681e+01
I0515 05:23:16.138666 140128494741248 run_lib.py:152] step: 399950, training_loss: 3.50135e+01
I0515 05:23:22.329942 140128494741248 run_lib.py:152] step: 400000, training_loss: 2.05877e+01
I0515 05:23:22.530229 140128494741248 run_lib.py:165] step: 400000, eval_loss: 2.46287e+01
I0515 05:24:43.252178 140128494741248 run_lib.py:152] step: 400050, training_loss: 3.49907e+01
I0515 05:24:49.395078 140128494741248 run_lib.py:152] step: 400100, training_loss: 2.73498e+01
I0515 05:24:49.447905 140128494741248 run_lib.py:165] step: 400100, eval_loss: 2.02387e+01
I0515 05:24:55.640119 140128494741248 run_lib.py:152] step: 400150, training_loss: 2.50876e+01
I0515 05:25:02.199604 140128494741248 run_lib.py:152] step: 400200, training_loss: 2.59572e+01
I0515 05:25:02.254895 140128494741248 run_lib.py:165] step: 400200, eval_loss: 4.52704e+01
I0515 05:25:08.479829 140128494741248 run_lib.py:152] step: 400250, training_loss: 3.16619e+01
I0515 05:25:14.757250 140128494741248 run_lib.py:152] step: 400300, training_loss: 2.45641e+01
I0515 05:25:14.821067 140128494741248 run_lib.py:165] step: 400300, eval_loss: 1.99511e+01
I0515 05:25:21.085680 140128494741248 run_lib.py:152] step: 400350, training_loss: 2.32867e+01
I0515 05:25:27.470861 140128494741248 run_lib.py:152] step: 400400, training_loss: 2.58738e+01
I0515 05:25:27.523079 140128494741248 run_lib.py:165] step: 400400, eval_loss: 3.35863e+01
I0515 05:25:33.793924 140128494741248 run_lib.py:152] step: 400450, training_loss: 3.24629e+01
I0515 05:25:40.029271 140128494741248 run_lib.py:152] step: 400500, training_loss: 1.09783e+01
I0515 05:25:40.079422 140128494741248 run_lib.py:165] step: 400500, eval_loss: 2.92333e+01
I0515 05:25:46.497486 140128494741248 run_lib.py:152] step: 400550, training_loss: 4.19926e+01
I0515 05:25:52.726980 140128494741248 run_lib.py:152] step: 400600, training_loss: 2.17963e+01
I0515 05:25:52.777674 140128494741248 run_lib.py:165] step: 400600, eval_loss: 3.57380e+01
I0515 05:25:58.909718 140128494741248 run_lib.py:152] step: 400650, training_loss: 2.68074e+01
I0515 05:26:05.116406 140128494741248 run_lib.py:152] step: 400700, training_loss: 3.09221e+01
I0515 05:26:05.168588 140128494741248 run_lib.py:165] step: 400700, eval_loss: 3.13127e+01
I0515 05:26:11.613159 140128494741248 run_lib.py:152] step: 400750, training_loss: 1.70264e+01
I0515 05:26:17.867803 140128494741248 run_lib.py:152] step: 400800, training_loss: 2.53633e+01
I0515 05:26:17.919430 140128494741248 run_lib.py:165] step: 400800, eval_loss: 3.02215e+01
I0515 05:26:24.147004 140128494741248 run_lib.py:152] step: 400850, training_loss: 3.46057e+01
I0515 05:26:30.563880 140128494741248 run_lib.py:152] step: 400900, training_loss: 2.68865e+01
I0515 05:26:30.616702 140128494741248 run_lib.py:165] step: 400900, eval_loss: 2.64811e+01
I0515 05:26:36.812560 140128494741248 run_lib.py:152] step: 400950, training_loss: 3.71135e+01
I0515 05:26:42.926908 140128494741248 run_lib.py:152] step: 401000, training_loss: 3.28173e+01
I0515 05:26:42.976406 140128494741248 run_lib.py:165] step: 401000, eval_loss: 2.06820e+01
I0515 05:26:49.075999 140128494741248 run_lib.py:152] step: 401050, training_loss: 3.80070e+01
I0515 05:26:55.611168 140128494741248 run_lib.py:152] step: 401100, training_loss: 2.73726e+01
I0515 05:26:55.667564 140128494741248 run_lib.py:165] step: 401100, eval_loss: 3.07162e+01
I0515 05:27:01.828095 140128494741248 run_lib.py:152] step: 401150, training_loss: 3.27605e+01
I0515 05:27:08.093227 140128494741248 run_lib.py:152] step: 401200, training_loss: 2.63077e+01
I0515 05:27:08.141545 140128494741248 run_lib.py:165] step: 401200, eval_loss: 3.37110e+01
I0515 05:27:14.641264 140128494741248 run_lib.py:152] step: 401250, training_loss: 3.49608e+01
I0515 05:27:20.878618 140128494741248 run_lib.py:152] step: 401300, training_loss: 4.05428e+01
I0515 05:27:20.938663 140128494741248 run_lib.py:165] step: 401300, eval_loss: 3.64859e+01
I0515 05:27:27.248553 140128494741248 run_lib.py:152] step: 401350, training_loss: 3.88038e+01
I0515 05:27:33.367721 140128494741248 run_lib.py:152] step: 401400, training_loss: 3.41491e+01
I0515 05:27:33.422990 140128494741248 run_lib.py:165] step: 401400, eval_loss: 3.56063e+01
I0515 05:27:39.869288 140128494741248 run_lib.py:152] step: 401450, training_loss: 2.29186e+01
I0515 05:27:46.082214 140128494741248 run_lib.py:152] step: 401500, training_loss: 3.33365e+01
I0515 05:27:46.135361 140128494741248 run_lib.py:165] step: 401500, eval_loss: 4.55808e+01
I0515 05:27:52.328214 140128494741248 run_lib.py:152] step: 401550, training_loss: 2.59379e+01
I0515 05:27:58.887240 140128494741248 run_lib.py:152] step: 401600, training_loss: 3.56764e+01
I0515 05:27:58.943819 140128494741248 run_lib.py:165] step: 401600, eval_loss: 2.14769e+01
I0515 05:28:05.081330 140128494741248 run_lib.py:152] step: 401650, training_loss: 2.34576e+01
I0515 05:28:11.336119 140128494741248 run_lib.py:152] step: 401700, training_loss: 3.20815e+01
I0515 05:28:11.384597 140128494741248 run_lib.py:165] step: 401700, eval_loss: 3.11983e+01
I0515 05:28:17.605187 140128494741248 run_lib.py:152] step: 401750, training_loss: 3.00265e+01
I0515 05:28:23.910859 140128494741248 run_lib.py:152] step: 401800, training_loss: 2.46367e+01
I0515 05:28:23.962730 140128494741248 run_lib.py:165] step: 401800, eval_loss: 2.45166e+01
I0515 05:28:30.265427 140128494741248 run_lib.py:152] step: 401850, training_loss: 4.53185e+01
I0515 05:28:36.438231 140128494741248 run_lib.py:152] step: 401900, training_loss: 3.41935e+01
I0515 05:28:36.489960 140128494741248 run_lib.py:165] step: 401900, eval_loss: 4.05440e+01
I0515 05:28:42.897144 140128494741248 run_lib.py:152] step: 401950, training_loss: 5.05321e+01
I0515 05:28:49.079879 140128494741248 run_lib.py:152] step: 402000, training_loss: 2.92516e+01
I0515 05:28:49.133132 140128494741248 run_lib.py:165] step: 402000, eval_loss: 2.76809e+01
I0515 05:28:55.391013 140128494741248 run_lib.py:152] step: 402050, training_loss: 2.18349e+01
I0515 05:29:01.576576 140128494741248 run_lib.py:152] step: 402100, training_loss: 3.99743e+01
I0515 05:29:01.633120 140128494741248 run_lib.py:165] step: 402100, eval_loss: 2.46247e+01
I0515 05:29:08.132984 140128494741248 run_lib.py:152] step: 402150, training_loss: 1.94329e+01
I0515 05:29:14.405122 140128494741248 run_lib.py:152] step: 402200, training_loss: 5.11313e+01
I0515 05:29:14.457304 140128494741248 run_lib.py:165] step: 402200, eval_loss: 2.42407e+01
I0515 05:29:20.730657 140128494741248 run_lib.py:152] step: 402250, training_loss: 3.88607e+01
I0515 05:29:27.142887 140128494741248 run_lib.py:152] step: 402300, training_loss: 2.55329e+01
I0515 05:29:27.193924 140128494741248 run_lib.py:165] step: 402300, eval_loss: 2.65830e+01
I0515 05:29:33.440361 140128494741248 run_lib.py:152] step: 402350, training_loss: 3.03866e+01
I0515 05:29:39.572628 140128494741248 run_lib.py:152] step: 402400, training_loss: 2.84619e+01
I0515 05:29:39.628507 140128494741248 run_lib.py:165] step: 402400, eval_loss: 3.88049e+01
I0515 05:29:45.809066 140128494741248 run_lib.py:152] step: 402450, training_loss: 2.96331e+01
I0515 05:29:52.257179 140128494741248 run_lib.py:152] step: 402500, training_loss: 3.55137e+01
I0515 05:29:52.306783 140128494741248 run_lib.py:165] step: 402500, eval_loss: 4.15089e+01
I0515 05:29:58.487745 140128494741248 run_lib.py:152] step: 402550, training_loss: 2.53759e+01
I0515 05:30:04.747302 140128494741248 run_lib.py:152] step: 402600, training_loss: 4.08521e+01
I0515 05:30:04.798510 140128494741248 run_lib.py:165] step: 402600, eval_loss: 2.60557e+01
I0515 05:30:11.188749 140128494741248 run_lib.py:152] step: 402650, training_loss: 4.56796e+01
I0515 05:30:17.305432 140128494741248 run_lib.py:152] step: 402700, training_loss: 2.88121e+01
I0515 05:30:17.359506 140128494741248 run_lib.py:165] step: 402700, eval_loss: 3.30423e+01
I0515 05:30:23.691304 140128494741248 run_lib.py:152] step: 402750, training_loss: 1.64721e+01
I0515 05:30:29.829329 140128494741248 run_lib.py:152] step: 402800, training_loss: 2.91652e+01
I0515 05:30:29.881182 140128494741248 run_lib.py:165] step: 402800, eval_loss: 3.06563e+01
I0515 05:30:36.286557 140128494741248 run_lib.py:152] step: 402850, training_loss: 2.92229e+01
I0515 05:30:42.434471 140128494741248 run_lib.py:152] step: 402900, training_loss: 5.32159e+01
I0515 05:30:42.487725 140128494741248 run_lib.py:165] step: 402900, eval_loss: 2.34801e+01
I0515 05:30:48.727286 140128494741248 run_lib.py:152] step: 402950, training_loss: 2.32490e+01
I0515 05:30:55.093054 140128494741248 run_lib.py:152] step: 403000, training_loss: 3.65195e+01
I0515 05:30:55.141816 140128494741248 run_lib.py:165] step: 403000, eval_loss: 3.17019e+01
I0515 05:31:01.290570 140128494741248 run_lib.py:152] step: 403050, training_loss: 4.33178e+01
I0515 05:31:07.481721 140128494741248 run_lib.py:152] step: 403100, training_loss: 3.27679e+01
I0515 05:31:07.535242 140128494741248 run_lib.py:165] step: 403100, eval_loss: 3.50506e+01
I0515 05:31:13.727643 140128494741248 run_lib.py:152] step: 403150, training_loss: 2.12351e+01
I0515 05:31:20.219291 140128494741248 run_lib.py:152] step: 403200, training_loss: 3.94256e+01
I0515 05:31:20.278290 140128494741248 run_lib.py:165] step: 403200, eval_loss: 3.48072e+01
I0515 05:31:26.465572 140128494741248 run_lib.py:152] step: 403250, training_loss: 2.49584e+01
I0515 05:31:32.738772 140128494741248 run_lib.py:152] step: 403300, training_loss: 3.26122e+01
I0515 05:31:32.795469 140128494741248 run_lib.py:165] step: 403300, eval_loss: 3.75727e+01
I0515 05:31:39.216362 140128494741248 run_lib.py:152] step: 403350, training_loss: 1.95380e+01
I0515 05:31:45.446258 140128494741248 run_lib.py:152] step: 403400, training_loss: 2.41818e+01
I0515 05:31:45.499584 140128494741248 run_lib.py:165] step: 403400, eval_loss: 4.86997e+01
I0515 05:31:51.679053 140128494741248 run_lib.py:152] step: 403450, training_loss: 3.43999e+01
I0515 05:31:57.846521 140128494741248 run_lib.py:152] step: 403500, training_loss: 3.47044e+01
I0515 05:31:57.898117 140128494741248 run_lib.py:165] step: 403500, eval_loss: 2.33309e+01
I0515 05:32:04.343520 140128494741248 run_lib.py:152] step: 403550, training_loss: 2.68730e+01
I0515 05:32:10.453259 140128494741248 run_lib.py:152] step: 403600, training_loss: 3.09366e+01
I0515 05:32:10.499440 140128494741248 run_lib.py:165] step: 403600, eval_loss: 2.00458e+01
I0515 05:32:16.693702 140128494741248 run_lib.py:152] step: 403650, training_loss: 2.03700e+01
I0515 05:32:23.037505 140128494741248 run_lib.py:152] step: 403700, training_loss: 3.41356e+01
I0515 05:32:23.089479 140128494741248 run_lib.py:165] step: 403700, eval_loss: 2.28620e+01
I0515 05:32:29.259645 140128494741248 run_lib.py:152] step: 403750, training_loss: 1.60168e+01
I0515 05:32:35.524198 140128494741248 run_lib.py:152] step: 403800, training_loss: 2.30519e+01
I0515 05:32:35.576130 140128494741248 run_lib.py:165] step: 403800, eval_loss: 3.79021e+01
I0515 05:32:41.750360 140128494741248 run_lib.py:152] step: 403850, training_loss: 1.51334e+01
I0515 05:32:48.154462 140128494741248 run_lib.py:152] step: 403900, training_loss: 4.72236e+01
I0515 05:32:48.205075 140128494741248 run_lib.py:165] step: 403900, eval_loss: 3.19644e+01
I0515 05:32:54.363404 140128494741248 run_lib.py:152] step: 403950, training_loss: 3.73811e+01
I0515 05:33:00.537250 140128494741248 run_lib.py:152] step: 404000, training_loss: 2.70506e+01
I0515 05:33:00.587505 140128494741248 run_lib.py:165] step: 404000, eval_loss: 3.94396e+01
I0515 05:33:07.127905 140128494741248 run_lib.py:152] step: 404050, training_loss: 3.15373e+01
I0515 05:33:13.245057 140128494741248 run_lib.py:152] step: 404100, training_loss: 3.61361e+01
I0515 05:33:13.300046 140128494741248 run_lib.py:165] step: 404100, eval_loss: 3.39983e+01
I0515 05:33:19.554715 140128494741248 run_lib.py:152] step: 404150, training_loss: 4.66369e+01
I0515 05:33:25.723891 140128494741248 run_lib.py:152] step: 404200, training_loss: 5.21141e+01
I0515 05:33:25.775637 140128494741248 run_lib.py:165] step: 404200, eval_loss: 2.75383e+01
I0515 05:33:32.161107 140128494741248 run_lib.py:152] step: 404250, training_loss: 3.85266e+01
I0515 05:33:38.371680 140128494741248 run_lib.py:152] step: 404300, training_loss: 2.11054e+01
I0515 05:33:38.424171 140128494741248 run_lib.py:165] step: 404300, eval_loss: 3.47103e+01
I0515 05:33:44.624625 140128494741248 run_lib.py:152] step: 404350, training_loss: 4.60364e+01
I0515 05:33:51.029480 140128494741248 run_lib.py:152] step: 404400, training_loss: 3.57585e+01
I0515 05:33:51.079429 140128494741248 run_lib.py:165] step: 404400, eval_loss: 4.80925e+01
I0515 05:33:57.228474 140128494741248 run_lib.py:152] step: 404450, training_loss: 3.37381e+01
I0515 05:34:03.353311 140128494741248 run_lib.py:152] step: 404500, training_loss: 3.87486e+01
I0515 05:34:03.403702 140128494741248 run_lib.py:165] step: 404500, eval_loss: 4.07314e+01
I0515 05:34:09.579389 140128494741248 run_lib.py:152] step: 404550, training_loss: 2.99419e+01
I0515 05:34:16.020624 140128494741248 run_lib.py:152] step: 404600, training_loss: 2.42375e+01
I0515 05:34:16.074215 140128494741248 run_lib.py:165] step: 404600, eval_loss: 2.45746e+01
I0515 05:34:22.301353 140128494741248 run_lib.py:152] step: 404650, training_loss: 2.07651e+01
I0515 05:34:28.502644 140128494741248 run_lib.py:152] step: 404700, training_loss: 2.60110e+01
I0515 05:34:28.554494 140128494741248 run_lib.py:165] step: 404700, eval_loss: 1.36289e+01
I0515 05:34:34.950720 140128494741248 run_lib.py:152] step: 404750, training_loss: 4.30309e+01
I0515 05:34:41.158976 140128494741248 run_lib.py:152] step: 404800, training_loss: 3.85934e+01
I0515 05:34:41.213990 140128494741248 run_lib.py:165] step: 404800, eval_loss: 3.54614e+01
I0515 05:34:47.444315 140128494741248 run_lib.py:152] step: 404850, training_loss: 1.92159e+01
I0515 05:34:53.565875 140128494741248 run_lib.py:152] step: 404900, training_loss: 3.95637e+01
I0515 05:34:53.619064 140128494741248 run_lib.py:165] step: 404900, eval_loss: 2.04830e+01
I0515 05:35:00.114687 140128494741248 run_lib.py:152] step: 404950, training_loss: 4.29213e+01
I0515 05:35:06.313785 140128494741248 run_lib.py:152] step: 405000, training_loss: 2.09489e+01
I0515 05:35:06.361597 140128494741248 run_lib.py:165] step: 405000, eval_loss: 2.65707e+01
I0515 05:35:12.649868 140128494741248 run_lib.py:152] step: 405050, training_loss: 2.88989e+01
I0515 05:35:19.044370 140128494741248 run_lib.py:152] step: 405100, training_loss: 2.96799e+01
I0515 05:35:19.098096 140128494741248 run_lib.py:165] step: 405100, eval_loss: 3.63315e+01
I0515 05:35:25.354946 140128494741248 run_lib.py:152] step: 405150, training_loss: 2.69664e+01
I0515 05:35:31.694722 140128494741248 run_lib.py:152] step: 405200, training_loss: 2.19086e+01
I0515 05:35:31.750162 140128494741248 run_lib.py:165] step: 405200, eval_loss: 3.30858e+01
I0515 05:35:37.958565 140128494741248 run_lib.py:152] step: 405250, training_loss: 4.34409e+01
I0515 05:35:44.501940 140128494741248 run_lib.py:152] step: 405300, training_loss: 1.58059e+01
I0515 05:35:44.557837 140128494741248 run_lib.py:165] step: 405300, eval_loss: 2.57451e+01
I0515 05:35:50.784685 140128494741248 run_lib.py:152] step: 405350, training_loss: 3.63377e+01
I0515 05:35:56.941536 140128494741248 run_lib.py:152] step: 405400, training_loss: 1.88687e+01
I0515 05:35:56.990471 140128494741248 run_lib.py:165] step: 405400, eval_loss: 1.91781e+01
I0515 05:36:03.430363 140128494741248 run_lib.py:152] step: 405450, training_loss: 3.06948e+01
I0515 05:36:09.567653 140128494741248 run_lib.py:152] step: 405500, training_loss: 3.22343e+01
I0515 05:36:09.616240 140128494741248 run_lib.py:165] step: 405500, eval_loss: 2.44494e+01
I0515 05:36:15.856239 140128494741248 run_lib.py:152] step: 405550, training_loss: 2.59564e+01
I0515 05:36:22.043808 140128494741248 run_lib.py:152] step: 405600, training_loss: 1.65962e+01
I0515 05:36:22.093843 140128494741248 run_lib.py:165] step: 405600, eval_loss: 3.54675e+01
I0515 05:36:28.556357 140128494741248 run_lib.py:152] step: 405650, training_loss: 3.66560e+01
I0515 05:36:34.785391 140128494741248 run_lib.py:152] step: 405700, training_loss: 3.82123e+01
I0515 05:36:34.843814 140128494741248 run_lib.py:165] step: 405700, eval_loss: 2.51230e+01
I0515 05:36:41.032026 140128494741248 run_lib.py:152] step: 405750, training_loss: 1.93542e+01
I0515 05:36:47.438379 140128494741248 run_lib.py:152] step: 405800, training_loss: 2.53145e+01
I0515 05:36:47.488531 140128494741248 run_lib.py:165] step: 405800, eval_loss: 2.20205e+01
I0515 05:36:53.571558 140128494741248 run_lib.py:152] step: 405850, training_loss: 2.71739e+01
I0515 05:36:59.829092 140128494741248 run_lib.py:152] step: 405900, training_loss: 2.19473e+01
I0515 05:36:59.879893 140128494741248 run_lib.py:165] step: 405900, eval_loss: 3.27793e+01
I0515 05:37:06.035745 140128494741248 run_lib.py:152] step: 405950, training_loss: 3.10834e+01
I0515 05:37:12.490959 140128494741248 run_lib.py:152] step: 406000, training_loss: 1.37731e+01
I0515 05:37:12.543395 140128494741248 run_lib.py:165] step: 406000, eval_loss: 4.26633e+01
I0515 05:37:18.672246 140128494741248 run_lib.py:152] step: 406050, training_loss: 3.30443e+01
I0515 05:37:24.739634 140128494741248 run_lib.py:152] step: 406100, training_loss: 2.40281e+01
I0515 05:37:24.793234 140128494741248 run_lib.py:165] step: 406100, eval_loss: 3.66541e+01
I0515 05:37:31.292385 140128494741248 run_lib.py:152] step: 406150, training_loss: 2.56971e+01
I0515 05:37:37.429497 140128494741248 run_lib.py:152] step: 406200, training_loss: 3.01864e+01
I0515 05:37:37.482344 140128494741248 run_lib.py:165] step: 406200, eval_loss: 2.65804e+01
I0515 05:37:43.733581 140128494741248 run_lib.py:152] step: 406250, training_loss: 4.47837e+01
I0515 05:37:49.894840 140128494741248 run_lib.py:152] step: 406300, training_loss: 3.25297e+01
I0515 05:37:49.946201 140128494741248 run_lib.py:165] step: 406300, eval_loss: 2.03184e+01
I0515 05:37:56.451555 140128494741248 run_lib.py:152] step: 406350, training_loss: 2.86421e+01
I0515 05:38:02.653217 140128494741248 run_lib.py:152] step: 406400, training_loss: 3.36972e+01
I0515 05:38:02.705846 140128494741248 run_lib.py:165] step: 406400, eval_loss: 2.53605e+01
I0515 05:38:08.977987 140128494741248 run_lib.py:152] step: 406450, training_loss: 2.02105e+01
I0515 05:38:15.346366 140128494741248 run_lib.py:152] step: 406500, training_loss: 4.00437e+01
I0515 05:38:15.402045 140128494741248 run_lib.py:165] step: 406500, eval_loss: 3.11335e+01
I0515 05:38:21.665527 140128494741248 run_lib.py:152] step: 406550, training_loss: 4.21300e+01
I0515 05:38:27.864571 140128494741248 run_lib.py:152] step: 406600, training_loss: 4.32797e+01
I0515 05:38:27.919343 140128494741248 run_lib.py:165] step: 406600, eval_loss: 3.62759e+01
I0515 05:38:34.120502 140128494741248 run_lib.py:152] step: 406650, training_loss: 1.59557e+01
I0515 05:38:40.665635 140128494741248 run_lib.py:152] step: 406700, training_loss: 2.45717e+01
I0515 05:38:40.724127 140128494741248 run_lib.py:165] step: 406700, eval_loss: 3.84883e+01
I0515 05:38:46.842236 140128494741248 run_lib.py:152] step: 406750, training_loss: 4.04717e+01
I0515 05:38:53.021654 140128494741248 run_lib.py:152] step: 406800, training_loss: 3.07902e+01
I0515 05:38:53.074236 140128494741248 run_lib.py:165] step: 406800, eval_loss: 3.29459e+01
I0515 05:38:59.490354 140128494741248 run_lib.py:152] step: 406850, training_loss: 3.91881e+01
I0515 05:39:05.639602 140128494741248 run_lib.py:152] step: 406900, training_loss: 1.53049e+01
I0515 05:39:05.686537 140128494741248 run_lib.py:165] step: 406900, eval_loss: 1.27989e+01
I0515 05:39:11.994166 140128494741248 run_lib.py:152] step: 406950, training_loss: 2.81566e+01
I0515 05:39:18.162508 140128494741248 run_lib.py:152] step: 407000, training_loss: 4.03396e+01
I0515 05:39:18.222290 140128494741248 run_lib.py:165] step: 407000, eval_loss: 2.48024e+01
I0515 05:39:24.712767 140128494741248 run_lib.py:152] step: 407050, training_loss: 3.35834e+01
I0515 05:39:30.778603 140128494741248 run_lib.py:152] step: 407100, training_loss: 2.78234e+01
I0515 05:39:30.832303 140128494741248 run_lib.py:165] step: 407100, eval_loss: 4.58972e+01
I0515 05:39:37.023986 140128494741248 run_lib.py:152] step: 407150, training_loss: 2.61358e+01
I0515 05:39:43.382358 140128494741248 run_lib.py:152] step: 407200, training_loss: 2.33613e+01
I0515 05:39:43.430771 140128494741248 run_lib.py:165] step: 407200, eval_loss: 1.65908e+01
I0515 05:39:49.788661 140128494741248 run_lib.py:152] step: 407250, training_loss: 2.44690e+01
I0515 05:39:55.973464 140128494741248 run_lib.py:152] step: 407300, training_loss: 4.16556e+01
I0515 05:39:56.024520 140128494741248 run_lib.py:165] step: 407300, eval_loss: 4.16644e+01
I0515 05:40:02.337256 140128494741248 run_lib.py:152] step: 407350, training_loss: 2.94260e+01
I0515 05:40:08.864589 140128494741248 run_lib.py:152] step: 407400, training_loss: 4.32509e+01
I0515 05:40:08.915249 140128494741248 run_lib.py:165] step: 407400, eval_loss: 1.82580e+01
I0515 05:40:15.077174 140128494741248 run_lib.py:152] step: 407450, training_loss: 2.87714e+01
I0515 05:40:21.253095 140128494741248 run_lib.py:152] step: 407500, training_loss: 1.86445e+01
I0515 05:40:21.308150 140128494741248 run_lib.py:165] step: 407500, eval_loss: 2.93419e+01
I0515 05:40:27.736077 140128494741248 run_lib.py:152] step: 407550, training_loss: 2.49445e+01
I0515 05:40:33.916111 140128494741248 run_lib.py:152] step: 407600, training_loss: 3.01112e+01
I0515 05:40:33.970663 140128494741248 run_lib.py:165] step: 407600, eval_loss: 3.70619e+01
I0515 05:40:40.271028 140128494741248 run_lib.py:152] step: 407650, training_loss: 2.37951e+01
I0515 05:40:46.444723 140128494741248 run_lib.py:152] step: 407700, training_loss: 3.82820e+01
I0515 05:40:46.501166 140128494741248 run_lib.py:165] step: 407700, eval_loss: 3.83930e+01
I0515 05:40:53.013203 140128494741248 run_lib.py:152] step: 407750, training_loss: 2.68093e+01
I0515 05:40:59.092354 140128494741248 run_lib.py:152] step: 407800, training_loss: 3.05509e+01
I0515 05:40:59.142961 140128494741248 run_lib.py:165] step: 407800, eval_loss: 2.93387e+01
I0515 05:41:05.375141 140128494741248 run_lib.py:152] step: 407850, training_loss: 3.56716e+01
I0515 05:41:11.774276 140128494741248 run_lib.py:152] step: 407900, training_loss: 1.78837e+01
I0515 05:41:11.822812 140128494741248 run_lib.py:165] step: 407900, eval_loss: 3.39923e+01
I0515 05:41:18.020646 140128494741248 run_lib.py:152] step: 407950, training_loss: 5.32479e+01
I0515 05:41:24.292671 140128494741248 run_lib.py:152] step: 408000, training_loss: 4.10878e+01
I0515 05:41:24.340556 140128494741248 run_lib.py:165] step: 408000, eval_loss: 3.00657e+01
I0515 05:41:30.542803 140128494741248 run_lib.py:152] step: 408050, training_loss: 4.74046e+01
I0515 05:41:36.916236 140128494741248 run_lib.py:152] step: 408100, training_loss: 4.23700e+01
I0515 05:41:36.968693 140128494741248 run_lib.py:165] step: 408100, eval_loss: 2.98196e+01
I0515 05:41:43.252013 140128494741248 run_lib.py:152] step: 408150, training_loss: 3.07590e+01
I0515 05:41:49.546051 140128494741248 run_lib.py:152] step: 408200, training_loss: 2.44421e+01
I0515 05:41:49.606802 140128494741248 run_lib.py:165] step: 408200, eval_loss: 1.42054e+01
I0515 05:41:56.003340 140128494741248 run_lib.py:152] step: 408250, training_loss: 2.38252e+01
I0515 05:42:02.241775 140128494741248 run_lib.py:152] step: 408300, training_loss: 3.54612e+01
I0515 05:42:02.296027 140128494741248 run_lib.py:165] step: 408300, eval_loss: 3.07543e+01
I0515 05:42:08.497029 140128494741248 run_lib.py:152] step: 408350, training_loss: 3.72939e+01
I0515 05:42:14.750442 140128494741248 run_lib.py:152] step: 408400, training_loss: 4.10178e+01
I0515 05:42:14.802796 140128494741248 run_lib.py:165] step: 408400, eval_loss: 2.82591e+01
I0515 05:42:21.188863 140128494741248 run_lib.py:152] step: 408450, training_loss: 4.21041e+01
I0515 05:42:27.398929 140128494741248 run_lib.py:152] step: 408500, training_loss: 3.65124e+01
I0515 05:42:27.452380 140128494741248 run_lib.py:165] step: 408500, eval_loss: 1.49142e+01
I0515 05:42:33.711635 140128494741248 run_lib.py:152] step: 408550, training_loss: 2.72453e+01
I0515 05:42:40.132712 140128494741248 run_lib.py:152] step: 408600, training_loss: 3.36330e+01
I0515 05:42:40.182597 140128494741248 run_lib.py:165] step: 408600, eval_loss: 4.45059e+01
I0515 05:42:46.337330 140128494741248 run_lib.py:152] step: 408650, training_loss: 3.02740e+01
I0515 05:42:52.569962 140128494741248 run_lib.py:152] step: 408700, training_loss: 2.69096e+01
I0515 05:42:52.629652 140128494741248 run_lib.py:165] step: 408700, eval_loss: 2.64331e+01
I0515 05:42:58.737749 140128494741248 run_lib.py:152] step: 408750, training_loss: 2.49759e+01
I0515 05:43:05.206401 140128494741248 run_lib.py:152] step: 408800, training_loss: 4.33035e+01
I0515 05:43:05.258545 140128494741248 run_lib.py:165] step: 408800, eval_loss: 3.98638e+01
I0515 05:43:11.411265 140128494741248 run_lib.py:152] step: 408850, training_loss: 3.06943e+01
I0515 05:43:17.608894 140128494741248 run_lib.py:152] step: 408900, training_loss: 3.41863e+01
I0515 05:43:17.658513 140128494741248 run_lib.py:165] step: 408900, eval_loss: 3.43215e+01
I0515 05:43:24.059072 140128494741248 run_lib.py:152] step: 408950, training_loss: 3.09465e+01
I0515 05:43:30.331194 140128494741248 run_lib.py:152] step: 409000, training_loss: 2.35882e+01
I0515 05:43:30.385319 140128494741248 run_lib.py:165] step: 409000, eval_loss: 2.69197e+01
I0515 05:43:36.534833 140128494741248 run_lib.py:152] step: 409050, training_loss: 3.93271e+01
I0515 05:43:42.743733 140128494741248 run_lib.py:152] step: 409100, training_loss: 2.88471e+01
I0515 05:43:42.796009 140128494741248 run_lib.py:165] step: 409100, eval_loss: 2.55998e+01
I0515 05:43:49.321204 140128494741248 run_lib.py:152] step: 409150, training_loss: 4.65392e+01
I0515 05:43:55.442249 140128494741248 run_lib.py:152] step: 409200, training_loss: 3.07781e+01
I0515 05:43:55.503027 140128494741248 run_lib.py:165] step: 409200, eval_loss: 4.79055e+01
I0515 05:44:01.736989 140128494741248 run_lib.py:152] step: 409250, training_loss: 3.21209e+01
I0515 05:44:08.143567 140128494741248 run_lib.py:152] step: 409300, training_loss: 3.92512e+01
I0515 05:44:08.196480 140128494741248 run_lib.py:165] step: 409300, eval_loss: 4.77231e+01
I0515 05:44:14.379779 140128494741248 run_lib.py:152] step: 409350, training_loss: 3.89999e+01
I0515 05:44:20.592528 140128494741248 run_lib.py:152] step: 409400, training_loss: 3.81170e+01
I0515 05:44:20.641389 140128494741248 run_lib.py:165] step: 409400, eval_loss: 1.78723e+01
I0515 05:44:26.839986 140128494741248 run_lib.py:152] step: 409450, training_loss: 4.52619e+01
I0515 05:44:33.199777 140128494741248 run_lib.py:152] step: 409500, training_loss: 3.41543e+01
I0515 05:44:33.255993 140128494741248 run_lib.py:165] step: 409500, eval_loss: 2.60722e+01
I0515 05:44:39.483929 140128494741248 run_lib.py:152] step: 409550, training_loss: 3.81936e+01
I0515 05:44:45.722997 140128494741248 run_lib.py:152] step: 409600, training_loss: 3.04313e+01
I0515 05:44:45.780607 140128494741248 run_lib.py:165] step: 409600, eval_loss: 2.84112e+01
I0515 05:44:52.233757 140128494741248 run_lib.py:152] step: 409650, training_loss: 1.96460e+01
I0515 05:44:58.432094 140128494741248 run_lib.py:152] step: 409700, training_loss: 2.36104e+01
I0515 05:44:58.485042 140128494741248 run_lib.py:165] step: 409700, eval_loss: 3.25183e+01
I0515 05:45:04.750229 140128494741248 run_lib.py:152] step: 409750, training_loss: 2.04203e+01
I0515 05:45:10.873336 140128494741248 run_lib.py:152] step: 409800, training_loss: 2.74131e+01
I0515 05:45:10.928313 140128494741248 run_lib.py:165] step: 409800, eval_loss: 3.20902e+01
I0515 05:45:17.371361 140128494741248 run_lib.py:152] step: 409850, training_loss: 2.47131e+01
I0515 05:45:23.514295 140128494741248 run_lib.py:152] step: 409900, training_loss: 2.73627e+01
I0515 05:45:23.567825 140128494741248 run_lib.py:165] step: 409900, eval_loss: 2.15371e+01
I0515 05:45:29.795097 140128494741248 run_lib.py:152] step: 409950, training_loss: 2.31253e+01
I0515 05:45:36.211560 140128494741248 run_lib.py:152] step: 410000, training_loss: 3.21563e+01
I0515 05:45:36.417987 140128494741248 run_lib.py:165] step: 410000, eval_loss: 2.57707e+01
I0515 05:45:42.661428 140128494741248 run_lib.py:152] step: 410050, training_loss: 3.50089e+01
I0515 05:45:48.769795 140128494741248 run_lib.py:152] step: 410100, training_loss: 1.87113e+01
I0515 05:45:48.824106 140128494741248 run_lib.py:165] step: 410100, eval_loss: 3.63882e+01
I0515 05:45:55.043984 140128494741248 run_lib.py:152] step: 410150, training_loss: 4.03195e+01
I0515 05:46:01.426927 140128494741248 run_lib.py:152] step: 410200, training_loss: 3.04903e+01
I0515 05:46:01.474646 140128494741248 run_lib.py:165] step: 410200, eval_loss: 2.05716e+01
I0515 05:46:07.719201 140128494741248 run_lib.py:152] step: 410250, training_loss: 2.48178e+01
I0515 05:46:13.849412 140128494741248 run_lib.py:152] step: 410300, training_loss: 2.07543e+01
I0515 05:46:13.899840 140128494741248 run_lib.py:165] step: 410300, eval_loss: 2.09020e+01
I0515 05:46:20.385462 140128494741248 run_lib.py:152] step: 410350, training_loss: 3.36721e+01
I0515 05:46:26.524089 140128494741248 run_lib.py:152] step: 410400, training_loss: 3.25562e+01
I0515 05:46:26.578150 140128494741248 run_lib.py:165] step: 410400, eval_loss: 1.34675e+01
I0515 05:46:32.800427 140128494741248 run_lib.py:152] step: 410450, training_loss: 2.46533e+01
I0515 05:46:38.905244 140128494741248 run_lib.py:152] step: 410500, training_loss: 3.30828e+01
I0515 05:46:38.958714 140128494741248 run_lib.py:165] step: 410500, eval_loss: 2.32816e+01
I0515 05:46:45.519011 140128494741248 run_lib.py:152] step: 410550, training_loss: 2.16393e+01
I0515 05:46:51.814166 140128494741248 run_lib.py:152] step: 410600, training_loss: 1.96422e+01
I0515 05:46:51.873407 140128494741248 run_lib.py:165] step: 410600, eval_loss: 3.40720e+01
I0515 05:46:58.079981 140128494741248 run_lib.py:152] step: 410650, training_loss: 4.16577e+01
I0515 05:47:04.609199 140128494741248 run_lib.py:152] step: 410700, training_loss: 3.06049e+01
I0515 05:47:04.661242 140128494741248 run_lib.py:165] step: 410700, eval_loss: 2.60991e+01
I0515 05:47:10.883514 140128494741248 run_lib.py:152] step: 410750, training_loss: 3.31581e+01
I0515 05:47:17.003359 140128494741248 run_lib.py:152] step: 410800, training_loss: 2.17955e+01
I0515 05:47:17.058529 140128494741248 run_lib.py:165] step: 410800, eval_loss: 1.97171e+01
I0515 05:47:23.260666 140128494741248 run_lib.py:152] step: 410850, training_loss: 1.42826e+01
I0515 05:47:29.723616 140128494741248 run_lib.py:152] step: 410900, training_loss: 2.76449e+01
I0515 05:47:29.779497 140128494741248 run_lib.py:165] step: 410900, eval_loss: 3.42935e+01
I0515 05:47:36.032083 140128494741248 run_lib.py:152] step: 410950, training_loss: 4.22057e+01
I0515 05:47:42.305652 140128494741248 run_lib.py:152] step: 411000, training_loss: 3.38230e+01
I0515 05:47:42.359669 140128494741248 run_lib.py:165] step: 411000, eval_loss: 1.84112e+01
I0515 05:47:48.844892 140128494741248 run_lib.py:152] step: 411050, training_loss: 3.15156e+01
I0515 05:47:55.032065 140128494741248 run_lib.py:152] step: 411100, training_loss: 4.60562e+01
I0515 05:47:55.085912 140128494741248 run_lib.py:165] step: 411100, eval_loss: 3.11460e+01
I0515 05:48:01.245101 140128494741248 run_lib.py:152] step: 411150, training_loss: 3.08225e+01
I0515 05:48:07.484973 140128494741248 run_lib.py:152] step: 411200, training_loss: 2.34560e+01
I0515 05:48:07.538279 140128494741248 run_lib.py:165] step: 411200, eval_loss: 4.61229e+01
I0515 05:48:13.977757 140128494741248 run_lib.py:152] step: 411250, training_loss: 3.79907e+01
I0515 05:48:20.214958 140128494741248 run_lib.py:152] step: 411300, training_loss: 3.79418e+01
I0515 05:48:20.270991 140128494741248 run_lib.py:165] step: 411300, eval_loss: 3.16766e+01
I0515 05:48:26.500354 140128494741248 run_lib.py:152] step: 411350, training_loss: 4.29065e+01
I0515 05:48:32.865126 140128494741248 run_lib.py:152] step: 411400, training_loss: 2.40218e+01
I0515 05:48:32.914997 140128494741248 run_lib.py:165] step: 411400, eval_loss: 2.70488e+01
I0515 05:48:39.164610 140128494741248 run_lib.py:152] step: 411450, training_loss: 2.78476e+01
I0515 05:48:45.352706 140128494741248 run_lib.py:152] step: 411500, training_loss: 2.47301e+01
I0515 05:48:45.401199 140128494741248 run_lib.py:165] step: 411500, eval_loss: 2.37283e+01
I0515 05:48:51.612608 140128494741248 run_lib.py:152] step: 411550, training_loss: 3.72554e+01
I0515 05:48:58.048025 140128494741248 run_lib.py:152] step: 411600, training_loss: 3.73338e+01
I0515 05:48:58.098745 140128494741248 run_lib.py:165] step: 411600, eval_loss: 1.92477e+01
I0515 05:49:04.384154 140128494741248 run_lib.py:152] step: 411650, training_loss: 2.76866e+01
I0515 05:49:10.517562 140128494741248 run_lib.py:152] step: 411700, training_loss: 1.55117e+01
I0515 05:49:10.568424 140128494741248 run_lib.py:165] step: 411700, eval_loss: 3.71673e+01
I0515 05:49:17.024973 140128494741248 run_lib.py:152] step: 411750, training_loss: 3.08037e+01
I0515 05:49:23.229617 140128494741248 run_lib.py:152] step: 411800, training_loss: 1.95951e+01
I0515 05:49:23.282575 140128494741248 run_lib.py:165] step: 411800, eval_loss: 3.08801e+01
I0515 05:49:29.435420 140128494741248 run_lib.py:152] step: 411850, training_loss: 2.29524e+01
I0515 05:49:35.682551 140128494741248 run_lib.py:152] step: 411900, training_loss: 4.22420e+01
I0515 05:49:35.733116 140128494741248 run_lib.py:165] step: 411900, eval_loss: 1.73062e+01
I0515 05:49:42.222418 140128494741248 run_lib.py:152] step: 411950, training_loss: 1.84170e+01
I0515 05:49:48.515286 140128494741248 run_lib.py:152] step: 412000, training_loss: 3.03641e+01
I0515 05:49:48.567912 140128494741248 run_lib.py:165] step: 412000, eval_loss: 2.40960e+01
I0515 05:49:54.801453 140128494741248 run_lib.py:152] step: 412050, training_loss: 2.20786e+01
I0515 05:50:01.355495 140128494741248 run_lib.py:152] step: 412100, training_loss: 2.20157e+01
I0515 05:50:01.413437 140128494741248 run_lib.py:165] step: 412100, eval_loss: 4.29930e+01
I0515 05:50:07.634229 140128494741248 run_lib.py:152] step: 412150, training_loss: 2.53554e+01
I0515 05:50:13.871829 140128494741248 run_lib.py:152] step: 412200, training_loss: 3.41140e+01
I0515 05:50:13.927161 140128494741248 run_lib.py:165] step: 412200, eval_loss: 3.64729e+01
I0515 05:50:20.135159 140128494741248 run_lib.py:152] step: 412250, training_loss: 3.20790e+01
I0515 05:50:26.520860 140128494741248 run_lib.py:152] step: 412300, training_loss: 3.04287e+01
I0515 05:50:26.570215 140128494741248 run_lib.py:165] step: 412300, eval_loss: 2.56532e+01
I0515 05:50:32.750063 140128494741248 run_lib.py:152] step: 412350, training_loss: 2.52047e+01
I0515 05:50:38.878973 140128494741248 run_lib.py:152] step: 412400, training_loss: 2.47273e+01
I0515 05:50:38.932336 140128494741248 run_lib.py:165] step: 412400, eval_loss: 1.92421e+01
I0515 05:50:45.447531 140128494741248 run_lib.py:152] step: 412450, training_loss: 2.99812e+01
I0515 05:50:51.677946 140128494741248 run_lib.py:152] step: 412500, training_loss: 4.02041e+01
I0515 05:50:51.729127 140128494741248 run_lib.py:165] step: 412500, eval_loss: 4.71517e+01
I0515 05:50:57.951620 140128494741248 run_lib.py:152] step: 412550, training_loss: 2.89774e+01
I0515 05:51:04.240513 140128494741248 run_lib.py:152] step: 412600, training_loss: 2.11951e+01
I0515 05:51:04.292062 140128494741248 run_lib.py:165] step: 412600, eval_loss: 3.01122e+01
I0515 05:51:10.714358 140128494741248 run_lib.py:152] step: 412650, training_loss: 2.58581e+01
I0515 05:51:16.947059 140128494741248 run_lib.py:152] step: 412700, training_loss: 2.37557e+01
I0515 05:51:16.999804 140128494741248 run_lib.py:165] step: 412700, eval_loss: 2.63133e+01
I0515 05:51:23.237799 140128494741248 run_lib.py:152] step: 412750, training_loss: 3.11028e+01
I0515 05:51:29.632746 140128494741248 run_lib.py:152] step: 412800, training_loss: 3.37442e+01
I0515 05:51:29.683407 140128494741248 run_lib.py:165] step: 412800, eval_loss: 2.98113e+01
I0515 05:51:35.881922 140128494741248 run_lib.py:152] step: 412850, training_loss: 2.88221e+01
I0515 05:51:42.095650 140128494741248 run_lib.py:152] step: 412900, training_loss: 3.14642e+01
I0515 05:51:42.145062 140128494741248 run_lib.py:165] step: 412900, eval_loss: 2.73501e+01
I0515 05:51:48.373117 140128494741248 run_lib.py:152] step: 412950, training_loss: 3.09997e+01
I0515 05:51:54.824684 140128494741248 run_lib.py:152] step: 413000, training_loss: 2.01764e+01
I0515 05:51:54.875912 140128494741248 run_lib.py:165] step: 413000, eval_loss: 4.25916e+01
I0515 05:52:01.145253 140128494741248 run_lib.py:152] step: 413050, training_loss: 2.77798e+01
I0515 05:52:07.198222 140128494741248 run_lib.py:152] step: 413100, training_loss: 2.29778e+01
I0515 05:52:07.248092 140128494741248 run_lib.py:165] step: 413100, eval_loss: 4.30682e+01
I0515 05:52:13.710229 140128494741248 run_lib.py:152] step: 413150, training_loss: 3.56976e+01
I0515 05:52:19.940319 140128494741248 run_lib.py:152] step: 413200, training_loss: 3.39713e+01
I0515 05:52:19.989408 140128494741248 run_lib.py:165] step: 413200, eval_loss: 3.95041e+01
I0515 05:52:26.231101 140128494741248 run_lib.py:152] step: 413250, training_loss: 3.26226e+01
I0515 05:52:32.383325 140128494741248 run_lib.py:152] step: 413300, training_loss: 2.64208e+01
I0515 05:52:32.437475 140128494741248 run_lib.py:165] step: 413300, eval_loss: 2.21575e+01
I0515 05:52:38.849308 140128494741248 run_lib.py:152] step: 413350, training_loss: 3.91370e+01
I0515 05:52:44.988799 140128494741248 run_lib.py:152] step: 413400, training_loss: 2.44355e+01
I0515 05:52:45.040596 140128494741248 run_lib.py:165] step: 413400, eval_loss: 2.77398e+01
I0515 05:52:51.310341 140128494741248 run_lib.py:152] step: 413450, training_loss: 4.17150e+01
I0515 05:52:57.681185 140128494741248 run_lib.py:152] step: 413500, training_loss: 3.23242e+01
I0515 05:52:57.737156 140128494741248 run_lib.py:165] step: 413500, eval_loss: 4.12535e+01
I0515 05:53:03.993901 140128494741248 run_lib.py:152] step: 413550, training_loss: 2.31927e+01
I0515 05:53:10.141058 140128494741248 run_lib.py:152] step: 413600, training_loss: 4.48333e+01
I0515 05:53:10.200364 140128494741248 run_lib.py:165] step: 413600, eval_loss: 2.45281e+01
I0515 05:53:16.411673 140128494741248 run_lib.py:152] step: 413650, training_loss: 2.32373e+01
I0515 05:53:22.891795 140128494741248 run_lib.py:152] step: 413700, training_loss: 3.18956e+01
I0515 05:53:22.940514 140128494741248 run_lib.py:165] step: 413700, eval_loss: 4.42197e+01
I0515 05:53:29.170817 140128494741248 run_lib.py:152] step: 413750, training_loss: 3.31703e+01
I0515 05:53:35.409317 140128494741248 run_lib.py:152] step: 413800, training_loss: 4.13608e+01
I0515 05:53:35.467602 140128494741248 run_lib.py:165] step: 413800, eval_loss: 3.04953e+01
I0515 05:53:41.936148 140128494741248 run_lib.py:152] step: 413850, training_loss: 3.41400e+01
I0515 05:53:48.067967 140128494741248 run_lib.py:152] step: 413900, training_loss: 3.73826e+01
I0515 05:53:48.118998 140128494741248 run_lib.py:165] step: 413900, eval_loss: 3.02155e+01
I0515 05:53:54.409958 140128494741248 run_lib.py:152] step: 413950, training_loss: 2.84218e+01
I0515 05:54:00.662159 140128494741248 run_lib.py:152] step: 414000, training_loss: 1.79910e+01
I0515 05:54:00.714383 140128494741248 run_lib.py:165] step: 414000, eval_loss: 2.43854e+01
I0515 05:54:07.214737 140128494741248 run_lib.py:152] step: 414050, training_loss: 4.69507e+01
I0515 05:54:13.364990 140128494741248 run_lib.py:152] step: 414100, training_loss: 4.96737e+01
I0515 05:54:13.412472 140128494741248 run_lib.py:165] step: 414100, eval_loss: 2.05207e+01
I0515 05:54:19.640524 140128494741248 run_lib.py:152] step: 414150, training_loss: 3.68831e+01
I0515 05:54:26.222234 140128494741248 run_lib.py:152] step: 414200, training_loss: 1.76989e+01
I0515 05:54:26.268591 140128494741248 run_lib.py:165] step: 414200, eval_loss: 2.21689e+01
I0515 05:54:32.392618 140128494741248 run_lib.py:152] step: 414250, training_loss: 2.73824e+01
I0515 05:54:38.610785 140128494741248 run_lib.py:152] step: 414300, training_loss: 3.84946e+01
I0515 05:54:38.666061 140128494741248 run_lib.py:165] step: 414300, eval_loss: 2.85008e+01
I0515 05:54:44.797814 140128494741248 run_lib.py:152] step: 414350, training_loss: 3.09107e+01
I0515 05:54:51.284535 140128494741248 run_lib.py:152] step: 414400, training_loss: 3.54542e+01
I0515 05:54:51.342469 140128494741248 run_lib.py:165] step: 414400, eval_loss: 1.71110e+01
I0515 05:54:57.590281 140128494741248 run_lib.py:152] step: 414450, training_loss: 3.65338e+01
I0515 05:55:03.851707 140128494741248 run_lib.py:152] step: 414500, training_loss: 4.07217e+01
I0515 05:55:03.900340 140128494741248 run_lib.py:165] step: 414500, eval_loss: 1.78866e+01
I0515 05:55:10.298741 140128494741248 run_lib.py:152] step: 414550, training_loss: 3.14503e+01
I0515 05:55:16.495723 140128494741248 run_lib.py:152] step: 414600, training_loss: 2.87334e+01
I0515 05:55:16.554429 140128494741248 run_lib.py:165] step: 414600, eval_loss: 2.29183e+01
I0515 05:55:22.711541 140128494741248 run_lib.py:152] step: 414650, training_loss: 3.76164e+01
I0515 05:55:28.943086 140128494741248 run_lib.py:152] step: 414700, training_loss: 2.58708e+01
I0515 05:55:28.992710 140128494741248 run_lib.py:165] step: 414700, eval_loss: 3.57465e+01
I0515 05:55:35.582791 140128494741248 run_lib.py:152] step: 414750, training_loss: 3.53710e+01
I0515 05:55:41.796835 140128494741248 run_lib.py:152] step: 414800, training_loss: 3.01099e+01
I0515 05:55:41.847921 140128494741248 run_lib.py:165] step: 414800, eval_loss: 4.22269e+01
I0515 05:55:48.015795 140128494741248 run_lib.py:152] step: 414850, training_loss: 3.35232e+01
I0515 05:55:54.535281 140128494741248 run_lib.py:152] step: 414900, training_loss: 2.91192e+01
I0515 05:55:54.587614 140128494741248 run_lib.py:165] step: 414900, eval_loss: 4.62120e+01
I0515 05:56:00.722371 140128494741248 run_lib.py:152] step: 414950, training_loss: 3.78451e+01
I0515 05:56:06.896087 140128494741248 run_lib.py:152] step: 415000, training_loss: 2.31853e+01
I0515 05:56:06.959308 140128494741248 run_lib.py:165] step: 415000, eval_loss: 2.98035e+01
I0515 05:56:13.129687 140128494741248 run_lib.py:152] step: 415050, training_loss: 4.52433e+01
I0515 05:56:19.550563 140128494741248 run_lib.py:152] step: 415100, training_loss: 1.92635e+01
I0515 05:56:19.603959 140128494741248 run_lib.py:165] step: 415100, eval_loss: 4.57408e+01
I0515 05:56:25.839603 140128494741248 run_lib.py:152] step: 415150, training_loss: 2.54818e+01
I0515 05:56:32.066661 140128494741248 run_lib.py:152] step: 415200, training_loss: 2.30916e+01
I0515 05:56:32.117437 140128494741248 run_lib.py:165] step: 415200, eval_loss: 2.58003e+01
I0515 05:56:38.602226 140128494741248 run_lib.py:152] step: 415250, training_loss: 3.83134e+01
I0515 05:56:44.845383 140128494741248 run_lib.py:152] step: 415300, training_loss: 2.17097e+01
I0515 05:56:44.898320 140128494741248 run_lib.py:165] step: 415300, eval_loss: 2.11833e+01
I0515 05:56:51.141365 140128494741248 run_lib.py:152] step: 415350, training_loss: 2.28157e+01
I0515 05:56:57.356326 140128494741248 run_lib.py:152] step: 415400, training_loss: 1.59072e+01
I0515 05:56:57.406040 140128494741248 run_lib.py:165] step: 415400, eval_loss: 3.02528e+01
I0515 05:57:03.940516 140128494741248 run_lib.py:152] step: 415450, training_loss: 3.04060e+01
I0515 05:57:10.214697 140128494741248 run_lib.py:152] step: 415500, training_loss: 2.71620e+01
I0515 05:57:10.267435 140128494741248 run_lib.py:165] step: 415500, eval_loss: 2.80187e+01
I0515 05:57:16.551589 140128494741248 run_lib.py:152] step: 415550, training_loss: 2.26908e+01
I0515 05:57:23.032710 140128494741248 run_lib.py:152] step: 415600, training_loss: 3.77215e+01
I0515 05:57:23.083061 140128494741248 run_lib.py:165] step: 415600, eval_loss: 1.68808e+01
I0515 05:57:29.268226 140128494741248 run_lib.py:152] step: 415650, training_loss: 4.19109e+01
I0515 05:57:35.468727 140128494741248 run_lib.py:152] step: 415700, training_loss: 2.40760e+01
I0515 05:57:35.529424 140128494741248 run_lib.py:165] step: 415700, eval_loss: 3.22554e+01
I0515 05:57:41.741080 140128494741248 run_lib.py:152] step: 415750, training_loss: 2.31542e+01
I0515 05:57:48.125952 140128494741248 run_lib.py:152] step: 415800, training_loss: 2.64789e+01
I0515 05:57:48.177028 140128494741248 run_lib.py:165] step: 415800, eval_loss: 3.89662e+01
I0515 05:57:54.426513 140128494741248 run_lib.py:152] step: 415850, training_loss: 2.92247e+01
I0515 05:58:00.607468 140128494741248 run_lib.py:152] step: 415900, training_loss: 2.62502e+01
I0515 05:58:00.659410 140128494741248 run_lib.py:165] step: 415900, eval_loss: 2.50917e+01
I0515 05:58:07.094907 140128494741248 run_lib.py:152] step: 415950, training_loss: 3.34257e+01
I0515 05:58:13.322401 140128494741248 run_lib.py:152] step: 416000, training_loss: 2.62807e+01
I0515 05:58:13.377754 140128494741248 run_lib.py:165] step: 416000, eval_loss: 2.17984e+01
I0515 05:58:19.621903 140128494741248 run_lib.py:152] step: 416050, training_loss: 2.85837e+01
I0515 05:58:25.927337 140128494741248 run_lib.py:152] step: 416100, training_loss: 2.53769e+01
I0515 05:58:25.976083 140128494741248 run_lib.py:165] step: 416100, eval_loss: 3.58670e+01
I0515 05:58:32.457237 140128494741248 run_lib.py:152] step: 416150, training_loss: 2.24931e+01
I0515 05:58:38.667273 140128494741248 run_lib.py:152] step: 416200, training_loss: 3.10778e+01
I0515 05:58:38.716533 140128494741248 run_lib.py:165] step: 416200, eval_loss: 1.62173e+01
I0515 05:58:44.878200 140128494741248 run_lib.py:152] step: 416250, training_loss: 3.82861e+01
I0515 05:58:51.250215 140128494741248 run_lib.py:152] step: 416300, training_loss: 3.09640e+01
I0515 05:58:51.306930 140128494741248 run_lib.py:165] step: 416300, eval_loss: 4.38530e+01
I0515 05:58:57.428923 140128494741248 run_lib.py:152] step: 416350, training_loss: 3.35867e+01
I0515 05:59:03.625298 140128494741248 run_lib.py:152] step: 416400, training_loss: 2.17433e+01
I0515 05:59:03.684680 140128494741248 run_lib.py:165] step: 416400, eval_loss: 3.38303e+01
I0515 05:59:09.854578 140128494741248 run_lib.py:152] step: 416450, training_loss: 3.02782e+01
I0515 05:59:16.186896 140128494741248 run_lib.py:152] step: 416500, training_loss: 4.44463e+01
I0515 05:59:16.237298 140128494741248 run_lib.py:165] step: 416500, eval_loss: 2.73829e+01
I0515 05:59:22.426162 140128494741248 run_lib.py:152] step: 416550, training_loss: 3.41227e+01
I0515 05:59:28.637654 140128494741248 run_lib.py:152] step: 416600, training_loss: 3.22242e+01
I0515 05:59:28.691300 140128494741248 run_lib.py:165] step: 416600, eval_loss: 2.63858e+01
I0515 05:59:35.082049 140128494741248 run_lib.py:152] step: 416650, training_loss: 2.26308e+01
I0515 05:59:41.333971 140128494741248 run_lib.py:152] step: 416700, training_loss: 2.61108e+01
I0515 05:59:41.386368 140128494741248 run_lib.py:165] step: 416700, eval_loss: 2.54962e+01
I0515 05:59:47.681314 140128494741248 run_lib.py:152] step: 416750, training_loss: 3.21552e+01
I0515 05:59:53.856328 140128494741248 run_lib.py:152] step: 416800, training_loss: 1.94681e+01
I0515 05:59:53.907689 140128494741248 run_lib.py:165] step: 416800, eval_loss: 3.42562e+01
I0515 06:00:00.300401 140128494741248 run_lib.py:152] step: 416850, training_loss: 2.94867e+01
I0515 06:00:06.579382 140128494741248 run_lib.py:152] step: 416900, training_loss: 2.86341e+01
I0515 06:00:06.630214 140128494741248 run_lib.py:165] step: 416900, eval_loss: 4.01438e+01
I0515 06:00:12.822738 140128494741248 run_lib.py:152] step: 416950, training_loss: 3.05470e+01
I0515 06:00:19.175376 140128494741248 run_lib.py:152] step: 417000, training_loss: 3.90443e+01
I0515 06:00:19.225416 140128494741248 run_lib.py:165] step: 417000, eval_loss: 1.90891e+01
I0515 06:00:25.462488 140128494741248 run_lib.py:152] step: 417050, training_loss: 4.23650e+01
I0515 06:00:31.651408 140128494741248 run_lib.py:152] step: 417100, training_loss: 3.06513e+01
I0515 06:00:31.701117 140128494741248 run_lib.py:165] step: 417100, eval_loss: 3.54163e+01
I0515 06:00:37.937896 140128494741248 run_lib.py:152] step: 417150, training_loss: 4.41190e+01
I0515 06:00:44.308248 140128494741248 run_lib.py:152] step: 417200, training_loss: 3.34604e+01
I0515 06:00:44.359220 140128494741248 run_lib.py:165] step: 417200, eval_loss: 4.65553e+01
I0515 06:00:50.626022 140128494741248 run_lib.py:152] step: 417250, training_loss: 3.12287e+01
I0515 06:00:56.755069 140128494741248 run_lib.py:152] step: 417300, training_loss: 2.64872e+01
I0515 06:00:56.807695 140128494741248 run_lib.py:165] step: 417300, eval_loss: 2.72398e+01
I0515 06:01:03.335351 140128494741248 run_lib.py:152] step: 417350, training_loss: 4.56177e+01
I0515 06:01:09.597905 140128494741248 run_lib.py:152] step: 417400, training_loss: 4.02655e+01
I0515 06:01:09.654453 140128494741248 run_lib.py:165] step: 417400, eval_loss: 2.13747e+01
I0515 06:01:15.920655 140128494741248 run_lib.py:152] step: 417450, training_loss: 3.40262e+01
I0515 06:01:22.087386 140128494741248 run_lib.py:152] step: 417500, training_loss: 3.38490e+01
I0515 06:01:22.140012 140128494741248 run_lib.py:165] step: 417500, eval_loss: 1.50102e+01
I0515 06:01:28.568279 140128494741248 run_lib.py:152] step: 417550, training_loss: 3.72620e+01
I0515 06:01:34.810952 140128494741248 run_lib.py:152] step: 417600, training_loss: 3.23984e+01
I0515 06:01:34.866377 140128494741248 run_lib.py:165] step: 417600, eval_loss: 3.04999e+01
I0515 06:01:41.122087 140128494741248 run_lib.py:152] step: 417650, training_loss: 3.77014e+01
I0515 06:01:47.509145 140128494741248 run_lib.py:152] step: 417700, training_loss: 2.80430e+01
I0515 06:01:47.562126 140128494741248 run_lib.py:165] step: 417700, eval_loss: 2.97528e+01
I0515 06:01:53.735990 140128494741248 run_lib.py:152] step: 417750, training_loss: 4.16692e+01
I0515 06:01:59.928270 140128494741248 run_lib.py:152] step: 417800, training_loss: 2.85159e+01
I0515 06:01:59.981387 140128494741248 run_lib.py:165] step: 417800, eval_loss: 2.78657e+01
I0515 06:02:06.173130 140128494741248 run_lib.py:152] step: 417850, training_loss: 2.16296e+01
I0515 06:02:12.650707 140128494741248 run_lib.py:152] step: 417900, training_loss: 3.06740e+01
I0515 06:02:12.705519 140128494741248 run_lib.py:165] step: 417900, eval_loss: 3.45248e+01
I0515 06:02:18.838125 140128494741248 run_lib.py:152] step: 417950, training_loss: 2.85925e+01
I0515 06:02:25.038892 140128494741248 run_lib.py:152] step: 418000, training_loss: 3.15517e+01
I0515 06:02:25.097849 140128494741248 run_lib.py:165] step: 418000, eval_loss: 2.87592e+01
I0515 06:02:31.591312 140128494741248 run_lib.py:152] step: 418050, training_loss: 4.53351e+01
I0515 06:02:37.713605 140128494741248 run_lib.py:152] step: 418100, training_loss: 3.29425e+01
I0515 06:02:37.761364 140128494741248 run_lib.py:165] step: 418100, eval_loss: 3.91415e+01
I0515 06:02:43.849092 140128494741248 run_lib.py:152] step: 418150, training_loss: 3.10255e+01
I0515 06:02:50.063026 140128494741248 run_lib.py:152] step: 418200, training_loss: 2.35230e+01
I0515 06:02:50.114253 140128494741248 run_lib.py:165] step: 418200, eval_loss: 3.99118e+01
I0515 06:02:56.502380 140128494741248 run_lib.py:152] step: 418250, training_loss: 3.88383e+01
I0515 06:03:02.724294 140128494741248 run_lib.py:152] step: 418300, training_loss: 4.09642e+01
I0515 06:03:02.779468 140128494741248 run_lib.py:165] step: 418300, eval_loss: 2.44443e+01
I0515 06:03:09.012798 140128494741248 run_lib.py:152] step: 418350, training_loss: 1.79290e+01
I0515 06:03:15.429657 140128494741248 run_lib.py:152] step: 418400, training_loss: 2.29279e+01
I0515 06:03:15.476321 140128494741248 run_lib.py:165] step: 418400, eval_loss: 3.11065e+01
I0515 06:03:21.560970 140128494741248 run_lib.py:152] step: 418450, training_loss: 1.54475e+01
I0515 06:03:27.867209 140128494741248 run_lib.py:152] step: 418500, training_loss: 2.69712e+01
I0515 06:03:27.918150 140128494741248 run_lib.py:165] step: 418500, eval_loss: 2.45231e+01
I0515 06:03:34.055591 140128494741248 run_lib.py:152] step: 418550, training_loss: 2.81943e+01
I0515 06:03:40.499024 140128494741248 run_lib.py:152] step: 418600, training_loss: 2.74206e+01
I0515 06:03:40.546385 140128494741248 run_lib.py:165] step: 418600, eval_loss: 2.29990e+01
I0515 06:03:46.608893 140128494741248 run_lib.py:152] step: 418650, training_loss: 3.10885e+01
I0515 06:03:52.857920 140128494741248 run_lib.py:152] step: 418700, training_loss: 3.82717e+01
I0515 06:03:52.908199 140128494741248 run_lib.py:165] step: 418700, eval_loss: 3.44106e+01
I0515 06:03:59.318566 140128494741248 run_lib.py:152] step: 418750, training_loss: 3.19703e+01
I0515 06:04:05.489126 140128494741248 run_lib.py:152] step: 418800, training_loss: 2.51853e+01
I0515 06:04:05.547388 140128494741248 run_lib.py:165] step: 418800, eval_loss: 4.02007e+01
I0515 06:04:11.732887 140128494741248 run_lib.py:152] step: 418850, training_loss: 2.54270e+01
I0515 06:04:18.022141 140128494741248 run_lib.py:152] step: 418900, training_loss: 2.35665e+01
I0515 06:04:18.074464 140128494741248 run_lib.py:165] step: 418900, eval_loss: 1.32377e+01
I0515 06:04:24.499619 140128494741248 run_lib.py:152] step: 418950, training_loss: 2.85771e+01
I0515 06:04:30.708454 140128494741248 run_lib.py:152] step: 419000, training_loss: 3.14740e+01
I0515 06:04:30.763707 140128494741248 run_lib.py:165] step: 419000, eval_loss: 3.51962e+01
I0515 06:04:36.924708 140128494741248 run_lib.py:152] step: 419050, training_loss: 2.22131e+01
I0515 06:04:43.386072 140128494741248 run_lib.py:152] step: 419100, training_loss: 2.64737e+01
I0515 06:04:43.436501 140128494741248 run_lib.py:165] step: 419100, eval_loss: 2.80448e+01
I0515 06:04:49.683653 140128494741248 run_lib.py:152] step: 419150, training_loss: 2.53976e+01
I0515 06:04:55.821167 140128494741248 run_lib.py:152] step: 419200, training_loss: 2.41102e+01
I0515 06:04:55.870287 140128494741248 run_lib.py:165] step: 419200, eval_loss: 2.46829e+01
I0515 06:05:02.188677 140128494741248 run_lib.py:152] step: 419250, training_loss: 2.74435e+01
I0515 06:05:08.769873 140128494741248 run_lib.py:152] step: 419300, training_loss: 3.07167e+01
I0515 06:05:08.823915 140128494741248 run_lib.py:165] step: 419300, eval_loss: 3.16946e+01
I0515 06:05:15.112947 140128494741248 run_lib.py:152] step: 419350, training_loss: 2.62398e+01
I0515 06:05:21.447113 140128494741248 run_lib.py:152] step: 419400, training_loss: 3.55779e+01
I0515 06:05:21.500844 140128494741248 run_lib.py:165] step: 419400, eval_loss: 2.39036e+01
I0515 06:05:27.932840 140128494741248 run_lib.py:152] step: 419450, training_loss: 2.75608e+01
I0515 06:05:34.113672 140128494741248 run_lib.py:152] step: 419500, training_loss: 3.19834e+01
I0515 06:05:34.170768 140128494741248 run_lib.py:165] step: 419500, eval_loss: 2.94202e+01
I0515 06:05:40.391229 140128494741248 run_lib.py:152] step: 419550, training_loss: 3.19597e+01
I0515 06:05:46.622454 140128494741248 run_lib.py:152] step: 419600, training_loss: 3.38776e+01
I0515 06:05:46.671024 140128494741248 run_lib.py:165] step: 419600, eval_loss: 3.15402e+01
I0515 06:05:53.176211 140128494741248 run_lib.py:152] step: 419650, training_loss: 1.93940e+01
I0515 06:05:59.385730 140128494741248 run_lib.py:152] step: 419700, training_loss: 2.38398e+01
I0515 06:05:59.442989 140128494741248 run_lib.py:165] step: 419700, eval_loss: 3.77074e+01
I0515 06:06:05.596571 140128494741248 run_lib.py:152] step: 419750, training_loss: 4.26457e+01
I0515 06:06:12.034602 140128494741248 run_lib.py:152] step: 419800, training_loss: 2.67032e+01
I0515 06:06:12.086894 140128494741248 run_lib.py:165] step: 419800, eval_loss: 1.46753e+01
I0515 06:06:18.301145 140128494741248 run_lib.py:152] step: 419850, training_loss: 4.76063e+01
I0515 06:06:24.515208 140128494741248 run_lib.py:152] step: 419900, training_loss: 3.69782e+01
I0515 06:06:24.564059 140128494741248 run_lib.py:165] step: 419900, eval_loss: 2.75401e+01
I0515 06:06:30.776685 140128494741248 run_lib.py:152] step: 419950, training_loss: 2.69968e+01
I0515 06:06:37.217880 140128494741248 run_lib.py:152] step: 420000, training_loss: 2.57855e+01
I0515 06:06:37.422461 140128494741248 run_lib.py:165] step: 420000, eval_loss: 4.34731e+01
I0515 06:06:43.672921 140128494741248 run_lib.py:152] step: 420050, training_loss: 3.11237e+01
I0515 06:06:49.882715 140128494741248 run_lib.py:152] step: 420100, training_loss: 4.46133e+01
I0515 06:06:49.936007 140128494741248 run_lib.py:165] step: 420100, eval_loss: 5.52235e+01
I0515 06:06:56.375234 140128494741248 run_lib.py:152] step: 420150, training_loss: 4.72514e+01
I0515 06:07:02.599462 140128494741248 run_lib.py:152] step: 420200, training_loss: 4.00042e+01
I0515 06:07:02.650287 140128494741248 run_lib.py:165] step: 420200, eval_loss: 5.05613e+01
I0515 06:07:08.817146 140128494741248 run_lib.py:152] step: 420250, training_loss: 2.18152e+01
I0515 06:07:14.976149 140128494741248 run_lib.py:152] step: 420300, training_loss: 3.56085e+01
I0515 06:07:15.027150 140128494741248 run_lib.py:165] step: 420300, eval_loss: 2.73037e+01
I0515 06:07:21.357638 140128494741248 run_lib.py:152] step: 420350, training_loss: 2.50043e+01
I0515 06:07:27.566034 140128494741248 run_lib.py:152] step: 420400, training_loss: 3.60328e+01
I0515 06:07:27.617674 140128494741248 run_lib.py:165] step: 420400, eval_loss: 3.99790e+01
I0515 06:07:33.721851 140128494741248 run_lib.py:152] step: 420450, training_loss: 3.19692e+01
I0515 06:07:40.202561 140128494741248 run_lib.py:152] step: 420500, training_loss: 2.99946e+01
I0515 06:07:40.259249 140128494741248 run_lib.py:165] step: 420500, eval_loss: 2.00621e+01
I0515 06:07:46.409238 140128494741248 run_lib.py:152] step: 420550, training_loss: 2.70023e+01
I0515 06:07:52.670173 140128494741248 run_lib.py:152] step: 420600, training_loss: 2.30253e+01
I0515 06:07:52.721958 140128494741248 run_lib.py:165] step: 420600, eval_loss: 3.38017e+01
I0515 06:07:58.837504 140128494741248 run_lib.py:152] step: 420650, training_loss: 3.93171e+01
I0515 06:08:05.318015 140128494741248 run_lib.py:152] step: 420700, training_loss: 3.29324e+01
I0515 06:08:05.373460 140128494741248 run_lib.py:165] step: 420700, eval_loss: 2.91922e+01
I0515 06:08:11.563045 140128494741248 run_lib.py:152] step: 420750, training_loss: 3.87470e+01
I0515 06:08:17.794528 140128494741248 run_lib.py:152] step: 420800, training_loss: 3.14823e+01
I0515 06:08:17.848290 140128494741248 run_lib.py:165] step: 420800, eval_loss: 4.28408e+01
I0515 06:08:24.282236 140128494741248 run_lib.py:152] step: 420850, training_loss: 2.70140e+01
I0515 06:08:30.489974 140128494741248 run_lib.py:152] step: 420900, training_loss: 2.86011e+01
I0515 06:08:30.543436 140128494741248 run_lib.py:165] step: 420900, eval_loss: 2.43460e+01
I0515 06:08:36.673372 140128494741248 run_lib.py:152] step: 420950, training_loss: 3.12546e+01
I0515 06:08:42.838121 140128494741248 run_lib.py:152] step: 421000, training_loss: 3.39930e+01
I0515 06:08:42.885795 140128494741248 run_lib.py:165] step: 421000, eval_loss: 1.50219e+01
I0515 06:08:49.379733 140128494741248 run_lib.py:152] step: 421050, training_loss: 2.66083e+01
I0515 06:08:55.500612 140128494741248 run_lib.py:152] step: 421100, training_loss: 5.16669e+01
I0515 06:08:55.556210 140128494741248 run_lib.py:165] step: 421100, eval_loss: 3.47374e+01
I0515 06:09:01.788315 140128494741248 run_lib.py:152] step: 421150, training_loss: 3.17358e+01
I0515 06:09:08.167226 140128494741248 run_lib.py:152] step: 421200, training_loss: 3.12181e+01
I0515 06:09:08.218581 140128494741248 run_lib.py:165] step: 421200, eval_loss: 2.86603e+01
I0515 06:09:14.373737 140128494741248 run_lib.py:152] step: 421250, training_loss: 3.26034e+01
I0515 06:09:20.555542 140128494741248 run_lib.py:152] step: 421300, training_loss: 4.10981e+01
I0515 06:09:20.605789 140128494741248 run_lib.py:165] step: 421300, eval_loss: 1.29779e+01
I0515 06:09:26.873351 140128494741248 run_lib.py:152] step: 421350, training_loss: 2.72710e+01
I0515 06:09:33.288501 140128494741248 run_lib.py:152] step: 421400, training_loss: 2.00316e+01
I0515 06:09:33.342478 140128494741248 run_lib.py:165] step: 421400, eval_loss: 3.21971e+01
I0515 06:09:39.548294 140128494741248 run_lib.py:152] step: 421450, training_loss: 3.91003e+01
I0515 06:09:45.652623 140128494741248 run_lib.py:152] step: 421500, training_loss: 3.50149e+01
I0515 06:09:45.699357 140128494741248 run_lib.py:165] step: 421500, eval_loss: 2.60695e+01
I0515 06:09:52.171273 140128494741248 run_lib.py:152] step: 421550, training_loss: 4.05351e+01
I0515 06:09:58.387977 140128494741248 run_lib.py:152] step: 421600, training_loss: 3.78830e+01
I0515 06:09:58.437758 140128494741248 run_lib.py:165] step: 421600, eval_loss: 2.97058e+01
I0515 06:10:04.676457 140128494741248 run_lib.py:152] step: 421650, training_loss: 3.98723e+01
I0515 06:10:10.814440 140128494741248 run_lib.py:152] step: 421700, training_loss: 1.78244e+01
I0515 06:10:10.868760 140128494741248 run_lib.py:165] step: 421700, eval_loss: 2.10632e+01
I0515 06:10:17.367863 140128494741248 run_lib.py:152] step: 421750, training_loss: 2.60723e+01
I0515 06:10:23.661260 140128494741248 run_lib.py:152] step: 421800, training_loss: 3.12886e+01
I0515 06:10:23.711394 140128494741248 run_lib.py:165] step: 421800, eval_loss: 2.19252e+01
I0515 06:10:29.942604 140128494741248 run_lib.py:152] step: 421850, training_loss: 3.35132e+01
I0515 06:10:36.403017 140128494741248 run_lib.py:152] step: 421900, training_loss: 2.57472e+01
I0515 06:10:36.457418 140128494741248 run_lib.py:165] step: 421900, eval_loss: 3.29910e+01
I0515 06:10:42.645312 140128494741248 run_lib.py:152] step: 421950, training_loss: 3.12345e+01
I0515 06:10:48.824424 140128494741248 run_lib.py:152] step: 422000, training_loss: 4.11177e+01
I0515 06:10:48.876048 140128494741248 run_lib.py:165] step: 422000, eval_loss: 3.21830e+01
I0515 06:10:54.981789 140128494741248 run_lib.py:152] step: 422050, training_loss: 2.29372e+01
I0515 06:11:01.437727 140128494741248 run_lib.py:152] step: 422100, training_loss: 2.36957e+01
I0515 06:11:01.487308 140128494741248 run_lib.py:165] step: 422100, eval_loss: 4.61138e+01
I0515 06:11:07.712066 140128494741248 run_lib.py:152] step: 422150, training_loss: 3.01665e+01
I0515 06:11:13.902865 140128494741248 run_lib.py:152] step: 422200, training_loss: 3.46934e+01
I0515 06:11:13.951896 140128494741248 run_lib.py:165] step: 422200, eval_loss: 3.37796e+01
I0515 06:11:20.336895 140128494741248 run_lib.py:152] step: 422250, training_loss: 3.52346e+01
I0515 06:11:26.403928 140128494741248 run_lib.py:152] step: 422300, training_loss: 3.33902e+01
I0515 06:11:26.457138 140128494741248 run_lib.py:165] step: 422300, eval_loss: 2.69517e+01
I0515 06:11:32.665027 140128494741248 run_lib.py:152] step: 422350, training_loss: 2.87074e+01
I0515 06:11:38.906176 140128494741248 run_lib.py:152] step: 422400, training_loss: 1.98109e+01
I0515 06:11:38.956542 140128494741248 run_lib.py:165] step: 422400, eval_loss: 3.16842e+01
I0515 06:11:45.273411 140128494741248 run_lib.py:152] step: 422450, training_loss: 1.96708e+01
I0515 06:11:51.493409 140128494741248 run_lib.py:152] step: 422500, training_loss: 4.28171e+01
I0515 06:11:51.549112 140128494741248 run_lib.py:165] step: 422500, eval_loss: 3.92287e+01
I0515 06:11:57.771152 140128494741248 run_lib.py:152] step: 422550, training_loss: 2.82466e+01
I0515 06:12:04.151791 140128494741248 run_lib.py:152] step: 422600, training_loss: 2.81941e+01
I0515 06:12:04.199452 140128494741248 run_lib.py:165] step: 422600, eval_loss: 2.96653e+01
I0515 06:12:10.376581 140128494741248 run_lib.py:152] step: 422650, training_loss: 4.11269e+01
I0515 06:12:16.595074 140128494741248 run_lib.py:152] step: 422700, training_loss: 3.23460e+01
I0515 06:12:16.645427 140128494741248 run_lib.py:165] step: 422700, eval_loss: 3.28664e+01
I0515 06:12:22.932412 140128494741248 run_lib.py:152] step: 422750, training_loss: 3.71465e+01
I0515 06:12:29.397249 140128494741248 run_lib.py:152] step: 422800, training_loss: 3.24478e+01
I0515 06:12:29.454621 140128494741248 run_lib.py:165] step: 422800, eval_loss: 2.22941e+01
I0515 06:12:35.538912 140128494741248 run_lib.py:152] step: 422850, training_loss: 2.44263e+01
I0515 06:12:41.761749 140128494741248 run_lib.py:152] step: 422900, training_loss: 3.34683e+01
I0515 06:12:41.811890 140128494741248 run_lib.py:165] step: 422900, eval_loss: 3.21560e+01
I0515 06:12:48.223628 140128494741248 run_lib.py:152] step: 422950, training_loss: 3.36372e+01
I0515 06:12:54.384535 140128494741248 run_lib.py:152] step: 423000, training_loss: 2.85631e+01
I0515 06:12:54.435412 140128494741248 run_lib.py:165] step: 423000, eval_loss: 3.85605e+01
I0515 06:13:00.520308 140128494741248 run_lib.py:152] step: 423050, training_loss: 3.19726e+01
I0515 06:13:06.744977 140128494741248 run_lib.py:152] step: 423100, training_loss: 1.73319e+01
I0515 06:13:06.805769 140128494741248 run_lib.py:165] step: 423100, eval_loss: 4.19341e+01
I0515 06:13:13.214450 140128494741248 run_lib.py:152] step: 423150, training_loss: 3.14693e+01
I0515 06:13:19.391881 140128494741248 run_lib.py:152] step: 423200, training_loss: 3.39998e+01
I0515 06:13:19.445969 140128494741248 run_lib.py:165] step: 423200, eval_loss: 3.18919e+01
I0515 06:13:25.584654 140128494741248 run_lib.py:152] step: 423250, training_loss: 3.24930e+01
I0515 06:13:31.989593 140128494741248 run_lib.py:152] step: 423300, training_loss: 2.54025e+01
I0515 06:13:32.043308 140128494741248 run_lib.py:165] step: 423300, eval_loss: 2.42862e+01
I0515 06:13:38.228199 140128494741248 run_lib.py:152] step: 423350, training_loss: 1.84231e+01
I0515 06:13:44.479962 140128494741248 run_lib.py:152] step: 423400, training_loss: 2.68491e+01
I0515 06:13:44.532022 140128494741248 run_lib.py:165] step: 423400, eval_loss: 3.57303e+01
I0515 06:13:50.747870 140128494741248 run_lib.py:152] step: 423450, training_loss: 3.66744e+01
I0515 06:13:57.224427 140128494741248 run_lib.py:152] step: 423500, training_loss: 2.89797e+01
I0515 06:13:57.279621 140128494741248 run_lib.py:165] step: 423500, eval_loss: 4.06798e+01
I0515 06:14:03.495823 140128494741248 run_lib.py:152] step: 423550, training_loss: 3.10563e+01
I0515 06:14:09.623419 140128494741248 run_lib.py:152] step: 423600, training_loss: 3.81617e+01
I0515 06:14:09.677523 140128494741248 run_lib.py:165] step: 423600, eval_loss: 2.36019e+01
I0515 06:14:16.079583 140128494741248 run_lib.py:152] step: 423650, training_loss: 2.15852e+01
I0515 06:14:22.263070 140128494741248 run_lib.py:152] step: 423700, training_loss: 2.62870e+01
I0515 06:14:22.311668 140128494741248 run_lib.py:165] step: 423700, eval_loss: 2.26370e+01
I0515 06:14:28.483436 140128494741248 run_lib.py:152] step: 423750, training_loss: 1.77808e+01
I0515 06:14:34.583334 140128494741248 run_lib.py:152] step: 423800, training_loss: 3.48286e+01
I0515 06:14:34.633878 140128494741248 run_lib.py:165] step: 423800, eval_loss: 4.22654e+01
I0515 06:14:41.058174 140128494741248 run_lib.py:152] step: 423850, training_loss: 2.84443e+01
I0515 06:14:47.272269 140128494741248 run_lib.py:152] step: 423900, training_loss: 2.39598e+01
I0515 06:14:47.325356 140128494741248 run_lib.py:165] step: 423900, eval_loss: 4.82003e+01
I0515 06:14:53.449891 140128494741248 run_lib.py:152] step: 423950, training_loss: 3.36190e+01
I0515 06:14:59.910905 140128494741248 run_lib.py:152] step: 424000, training_loss: 2.90516e+01
I0515 06:14:59.963092 140128494741248 run_lib.py:165] step: 424000, eval_loss: 5.35113e+01
I0515 06:15:06.122973 140128494741248 run_lib.py:152] step: 424050, training_loss: 2.91524e+01
I0515 06:15:12.351733 140128494741248 run_lib.py:152] step: 424100, training_loss: 2.92701e+01
I0515 06:15:12.409256 140128494741248 run_lib.py:165] step: 424100, eval_loss: 4.09678e+01
I0515 06:15:18.609509 140128494741248 run_lib.py:152] step: 424150, training_loss: 2.21736e+01
I0515 06:15:25.022931 140128494741248 run_lib.py:152] step: 424200, training_loss: 4.40337e+01
I0515 06:15:25.077384 140128494741248 run_lib.py:165] step: 424200, eval_loss: 3.36977e+01
I0515 06:15:31.255575 140128494741248 run_lib.py:152] step: 424250, training_loss: 2.46390e+01
I0515 06:15:37.489315 140128494741248 run_lib.py:152] step: 424300, training_loss: 2.29213e+01
I0515 06:15:37.542914 140128494741248 run_lib.py:165] step: 424300, eval_loss: 1.74811e+01
I0515 06:15:44.044314 140128494741248 run_lib.py:152] step: 424350, training_loss: 2.58387e+01
I0515 06:15:50.302855 140128494741248 run_lib.py:152] step: 424400, training_loss: 4.39941e+01
I0515 06:15:50.354838 140128494741248 run_lib.py:165] step: 424400, eval_loss: 4.37943e+01
I0515 06:15:56.613442 140128494741248 run_lib.py:152] step: 424450, training_loss: 3.69089e+01
I0515 06:16:02.709040 140128494741248 run_lib.py:152] step: 424500, training_loss: 2.17199e+01
I0515 06:16:02.755760 140128494741248 run_lib.py:165] step: 424500, eval_loss: 2.86358e+01
I0515 06:16:09.277637 140128494741248 run_lib.py:152] step: 424550, training_loss: 2.35786e+01
I0515 06:16:15.441868 140128494741248 run_lib.py:152] step: 424600, training_loss: 3.03770e+01
I0515 06:16:15.492134 140128494741248 run_lib.py:165] step: 424600, eval_loss: 2.08894e+01
I0515 06:16:21.737037 140128494741248 run_lib.py:152] step: 424650, training_loss: 2.69808e+01
I0515 06:16:28.198690 140128494741248 run_lib.py:152] step: 424700, training_loss: 3.98363e+01
I0515 06:16:28.253771 140128494741248 run_lib.py:165] step: 424700, eval_loss: 3.39977e+01
I0515 06:16:34.572649 140128494741248 run_lib.py:152] step: 424750, training_loss: 3.64925e+01
I0515 06:16:40.805567 140128494741248 run_lib.py:152] step: 424800, training_loss: 3.62770e+01
I0515 06:16:40.857016 140128494741248 run_lib.py:165] step: 424800, eval_loss: 3.50274e+01
I0515 06:16:47.191959 140128494741248 run_lib.py:152] step: 424850, training_loss: 3.01744e+01
I0515 06:16:53.644020 140128494741248 run_lib.py:152] step: 424900, training_loss: 1.46530e+01
I0515 06:16:53.698832 140128494741248 run_lib.py:165] step: 424900, eval_loss: 3.02384e+01
I0515 06:16:59.997287 140128494741248 run_lib.py:152] step: 424950, training_loss: 1.86524e+01
I0515 06:17:06.225519 140128494741248 run_lib.py:152] step: 425000, training_loss: 3.27851e+01
I0515 06:17:06.274757 140128494741248 run_lib.py:165] step: 425000, eval_loss: 4.56066e+01
I0515 06:17:12.593717 140128494741248 run_lib.py:152] step: 425050, training_loss: 2.76256e+01
I0515 06:17:18.785609 140128494741248 run_lib.py:152] step: 425100, training_loss: 3.15087e+01
I0515 06:17:18.844389 140128494741248 run_lib.py:165] step: 425100, eval_loss: 2.78645e+01
I0515 06:17:25.122563 140128494741248 run_lib.py:152] step: 425150, training_loss: 3.39162e+01
I0515 06:17:31.244674 140128494741248 run_lib.py:152] step: 425200, training_loss: 4.60298e+01
I0515 06:17:31.307405 140128494741248 run_lib.py:165] step: 425200, eval_loss: 2.16626e+01
I0515 06:17:37.767706 140128494741248 run_lib.py:152] step: 425250, training_loss: 1.98612e+01
I0515 06:17:43.959896 140128494741248 run_lib.py:152] step: 425300, training_loss: 1.60406e+01
I0515 06:17:44.013841 140128494741248 run_lib.py:165] step: 425300, eval_loss: 3.18774e+01
I0515 06:17:50.251726 140128494741248 run_lib.py:152] step: 425350, training_loss: 3.95766e+01
I0515 06:17:56.691584 140128494741248 run_lib.py:152] step: 425400, training_loss: 4.62550e+01
I0515 06:17:56.739867 140128494741248 run_lib.py:165] step: 425400, eval_loss: 2.46238e+01
I0515 06:18:02.964760 140128494741248 run_lib.py:152] step: 425450, training_loss: 4.85555e+01
I0515 06:18:09.214620 140128494741248 run_lib.py:152] step: 425500, training_loss: 3.73795e+01
I0515 06:18:09.270462 140128494741248 run_lib.py:165] step: 425500, eval_loss: 1.72169e+01
I0515 06:18:15.553830 140128494741248 run_lib.py:152] step: 425550, training_loss: 2.32858e+01
I0515 06:18:22.036577 140128494741248 run_lib.py:152] step: 425600, training_loss: 3.17836e+01
I0515 06:18:22.087256 140128494741248 run_lib.py:165] step: 425600, eval_loss: 3.28037e+01
I0515 06:18:28.356265 140128494741248 run_lib.py:152] step: 425650, training_loss: 3.66890e+01
I0515 06:18:34.644800 140128494741248 run_lib.py:152] step: 425700, training_loss: 3.31891e+01
I0515 06:18:34.702908 140128494741248 run_lib.py:165] step: 425700, eval_loss: 2.84479e+01
I0515 06:18:41.109298 140128494741248 run_lib.py:152] step: 425750, training_loss: 4.16519e+01
I0515 06:18:47.280375 140128494741248 run_lib.py:152] step: 425800, training_loss: 2.68414e+01
I0515 06:18:47.328382 140128494741248 run_lib.py:165] step: 425800, eval_loss: 2.57961e+01
I0515 06:18:53.520964 140128494741248 run_lib.py:152] step: 425850, training_loss: 1.97267e+01
I0515 06:18:59.586660 140128494741248 run_lib.py:152] step: 425900, training_loss: 2.98085e+01
I0515 06:18:59.636899 140128494741248 run_lib.py:165] step: 425900, eval_loss: 3.38756e+01
I0515 06:19:06.202651 140128494741248 run_lib.py:152] step: 425950, training_loss: 4.11531e+01
I0515 06:19:12.461515 140128494741248 run_lib.py:152] step: 426000, training_loss: 3.10003e+01
I0515 06:19:12.515917 140128494741248 run_lib.py:165] step: 426000, eval_loss: 2.80113e+01
I0515 06:19:18.738336 140128494741248 run_lib.py:152] step: 426050, training_loss: 3.37223e+01
I0515 06:19:25.106907 140128494741248 run_lib.py:152] step: 426100, training_loss: 2.44243e+01
I0515 06:19:25.160633 140128494741248 run_lib.py:165] step: 426100, eval_loss: 2.80970e+01
I0515 06:19:31.280430 140128494741248 run_lib.py:152] step: 426150, training_loss: 3.68255e+01
I0515 06:19:37.391867 140128494741248 run_lib.py:152] step: 426200, training_loss: 4.66255e+01
I0515 06:19:37.441691 140128494741248 run_lib.py:165] step: 426200, eval_loss: 1.47129e+01
I0515 06:19:43.609992 140128494741248 run_lib.py:152] step: 426250, training_loss: 4.38682e+01
I0515 06:19:50.130890 140128494741248 run_lib.py:152] step: 426300, training_loss: 2.64829e+01
I0515 06:19:50.185557 140128494741248 run_lib.py:165] step: 426300, eval_loss: 3.03352e+01
I0515 06:19:56.409463 140128494741248 run_lib.py:152] step: 426350, training_loss: 3.90559e+01
I0515 06:20:02.637272 140128494741248 run_lib.py:152] step: 426400, training_loss: 5.43616e+01
I0515 06:20:02.691705 140128494741248 run_lib.py:165] step: 426400, eval_loss: 3.58041e+01
I0515 06:20:09.102284 140128494741248 run_lib.py:152] step: 426450, training_loss: 2.40693e+01
I0515 06:20:15.341040 140128494741248 run_lib.py:152] step: 426500, training_loss: 1.65901e+01
I0515 06:20:15.391067 140128494741248 run_lib.py:165] step: 426500, eval_loss: 3.83641e+01
I0515 06:20:21.553781 140128494741248 run_lib.py:152] step: 426550, training_loss: 2.67287e+01
I0515 06:20:27.837247 140128494741248 run_lib.py:152] step: 426600, training_loss: 2.98498e+01
I0515 06:20:27.890543 140128494741248 run_lib.py:165] step: 426600, eval_loss: 4.92741e+01
I0515 06:20:34.284714 140128494741248 run_lib.py:152] step: 426650, training_loss: 3.71015e+01
I0515 06:20:40.459678 140128494741248 run_lib.py:152] step: 426700, training_loss: 4.25936e+01
I0515 06:20:40.509147 140128494741248 run_lib.py:165] step: 426700, eval_loss: 3.24578e+01
I0515 06:20:46.706797 140128494741248 run_lib.py:152] step: 426750, training_loss: 4.34742e+01
I0515 06:20:53.046181 140128494741248 run_lib.py:152] step: 426800, training_loss: 1.96882e+01
I0515 06:20:53.097893 140128494741248 run_lib.py:165] step: 426800, eval_loss: 3.97168e+01
I0515 06:20:59.195312 140128494741248 run_lib.py:152] step: 426850, training_loss: 2.03884e+01
I0515 06:21:05.489666 140128494741248 run_lib.py:152] step: 426900, training_loss: 2.75523e+01
I0515 06:21:05.541358 140128494741248 run_lib.py:165] step: 426900, eval_loss: 3.44877e+01
I0515 06:21:11.696895 140128494741248 run_lib.py:152] step: 426950, training_loss: 2.74834e+01
I0515 06:21:18.172012 140128494741248 run_lib.py:152] step: 427000, training_loss: 4.46825e+01
I0515 06:21:18.224766 140128494741248 run_lib.py:165] step: 427000, eval_loss: 2.74100e+01
I0515 06:21:24.360782 140128494741248 run_lib.py:152] step: 427050, training_loss: 2.40219e+01
I0515 06:21:30.544884 140128494741248 run_lib.py:152] step: 427100, training_loss: 2.39243e+01
I0515 06:21:30.606282 140128494741248 run_lib.py:165] step: 427100, eval_loss: 2.72195e+01
I0515 06:21:37.127768 140128494741248 run_lib.py:152] step: 427150, training_loss: 4.15301e+01
I0515 06:21:43.256719 140128494741248 run_lib.py:152] step: 427200, training_loss: 4.05396e+01
I0515 06:21:43.309667 140128494741248 run_lib.py:165] step: 427200, eval_loss: 2.49635e+01
I0515 06:21:49.520558 140128494741248 run_lib.py:152] step: 427250, training_loss: 2.42173e+01
I0515 06:21:55.786778 140128494741248 run_lib.py:152] step: 427300, training_loss: 2.45859e+01
I0515 06:21:55.839412 140128494741248 run_lib.py:165] step: 427300, eval_loss: 2.67775e+01
I0515 06:22:02.276490 140128494741248 run_lib.py:152] step: 427350, training_loss: 4.10233e+01
I0515 06:22:08.462143 140128494741248 run_lib.py:152] step: 427400, training_loss: 3.26726e+01
I0515 06:22:08.518194 140128494741248 run_lib.py:165] step: 427400, eval_loss: 1.98347e+01
I0515 06:22:14.727354 140128494741248 run_lib.py:152] step: 427450, training_loss: 2.61441e+01
I0515 06:22:21.107991 140128494741248 run_lib.py:152] step: 427500, training_loss: 3.35316e+01
I0515 06:22:21.159866 140128494741248 run_lib.py:165] step: 427500, eval_loss: 3.41462e+01
I0515 06:22:27.434937 140128494741248 run_lib.py:152] step: 427550, training_loss: 3.02629e+01
I0515 06:22:33.556129 140128494741248 run_lib.py:152] step: 427600, training_loss: 2.68844e+01
I0515 06:22:33.609879 140128494741248 run_lib.py:165] step: 427600, eval_loss: 4.00397e+01
I0515 06:22:39.821551 140128494741248 run_lib.py:152] step: 427650, training_loss: 2.84678e+01
I0515 06:22:46.316114 140128494741248 run_lib.py:152] step: 427700, training_loss: 3.52917e+01
I0515 06:22:46.366773 140128494741248 run_lib.py:165] step: 427700, eval_loss: 2.58822e+01
I0515 06:22:52.584349 140128494741248 run_lib.py:152] step: 427750, training_loss: 4.68338e+01
I0515 06:22:58.864275 140128494741248 run_lib.py:152] step: 427800, training_loss: 2.52140e+01
I0515 06:22:58.915982 140128494741248 run_lib.py:165] step: 427800, eval_loss: 3.52939e+01
I0515 06:23:05.226516 140128494741248 run_lib.py:152] step: 427850, training_loss: 2.99950e+01
I0515 06:23:11.394321 140128494741248 run_lib.py:152] step: 427900, training_loss: 3.21791e+01
I0515 06:23:11.451361 140128494741248 run_lib.py:165] step: 427900, eval_loss: 4.43404e+01
I0515 06:23:17.613721 140128494741248 run_lib.py:152] step: 427950, training_loss: 2.70456e+01
I0515 06:23:23.857013 140128494741248 run_lib.py:152] step: 428000, training_loss: 2.23253e+01
I0515 06:23:23.909537 140128494741248 run_lib.py:165] step: 428000, eval_loss: 2.64546e+01
I0515 06:23:30.278542 140128494741248 run_lib.py:152] step: 428050, training_loss: 3.50827e+01
I0515 06:23:36.455121 140128494741248 run_lib.py:152] step: 428100, training_loss: 2.38531e+01
I0515 06:23:36.507513 140128494741248 run_lib.py:165] step: 428100, eval_loss: 2.87935e+01
I0515 06:23:42.660344 140128494741248 run_lib.py:152] step: 428150, training_loss: 3.30141e+01
I0515 06:23:49.194675 140128494741248 run_lib.py:152] step: 428200, training_loss: 4.02945e+01
I0515 06:23:49.246349 140128494741248 run_lib.py:165] step: 428200, eval_loss: 2.75136e+01
I0515 06:23:55.389626 140128494741248 run_lib.py:152] step: 428250, training_loss: 2.01644e+01
I0515 06:24:01.667886 140128494741248 run_lib.py:152] step: 428300, training_loss: 2.41762e+01
I0515 06:24:01.718763 140128494741248 run_lib.py:165] step: 428300, eval_loss: 2.42222e+01
I0515 06:24:07.957687 140128494741248 run_lib.py:152] step: 428350, training_loss: 2.64502e+01
I0515 06:24:14.292844 140128494741248 run_lib.py:152] step: 428400, training_loss: 3.27150e+01
I0515 06:24:14.340055 140128494741248 run_lib.py:165] step: 428400, eval_loss: 3.92920e+01
I0515 06:24:20.574468 140128494741248 run_lib.py:152] step: 428450, training_loss: 1.79602e+01
I0515 06:24:26.772993 140128494741248 run_lib.py:152] step: 428500, training_loss: 2.65054e+01
I0515 06:24:26.822077 140128494741248 run_lib.py:165] step: 428500, eval_loss: 2.92024e+01
I0515 06:24:33.301194 140128494741248 run_lib.py:152] step: 428550, training_loss: 2.97086e+01
I0515 06:24:39.500170 140128494741248 run_lib.py:152] step: 428600, training_loss: 3.54677e+01
I0515 06:24:39.553193 140128494741248 run_lib.py:165] step: 428600, eval_loss: 3.48387e+01
I0515 06:24:45.775230 140128494741248 run_lib.py:152] step: 428650, training_loss: 2.46750e+01
I0515 06:24:51.837308 140128494741248 run_lib.py:152] step: 428700, training_loss: 3.44466e+01
I0515 06:24:51.891559 140128494741248 run_lib.py:165] step: 428700, eval_loss: 3.24476e+01
I0515 06:24:58.371056 140128494741248 run_lib.py:152] step: 428750, training_loss: 4.17330e+01
I0515 06:25:05.171343 140128494741248 run_lib.py:152] step: 428800, training_loss: 2.38786e+01
I0515 06:25:05.227575 140128494741248 run_lib.py:165] step: 428800, eval_loss: 3.43900e+01
I0515 06:25:11.863186 140128494741248 run_lib.py:152] step: 428850, training_loss: 3.09651e+01
I0515 06:25:18.306345 140128494741248 run_lib.py:152] step: 428900, training_loss: 4.98282e+01
I0515 06:25:18.357262 140128494741248 run_lib.py:165] step: 428900, eval_loss: 2.54073e+01
I0515 06:25:24.682593 140128494741248 run_lib.py:152] step: 428950, training_loss: 3.08113e+01
I0515 06:25:30.878142 140128494741248 run_lib.py:152] step: 429000, training_loss: 2.58858e+01
I0515 06:25:30.935969 140128494741248 run_lib.py:165] step: 429000, eval_loss: 3.41972e+01
I0515 06:25:37.158895 140128494741248 run_lib.py:152] step: 429050, training_loss: 3.86015e+01
I0515 06:25:43.588093 140128494741248 run_lib.py:152] step: 429100, training_loss: 3.47800e+01
I0515 06:25:43.643396 140128494741248 run_lib.py:165] step: 429100, eval_loss: 2.84547e+01
I0515 06:25:49.899387 140128494741248 run_lib.py:152] step: 429150, training_loss: 2.45289e+01
I0515 06:25:56.097877 140128494741248 run_lib.py:152] step: 429200, training_loss: 3.45247e+01
I0515 06:25:56.149112 140128494741248 run_lib.py:165] step: 429200, eval_loss: 3.18308e+01
I0515 06:26:02.529927 140128494741248 run_lib.py:152] step: 429250, training_loss: 4.16401e+01
I0515 06:26:08.804255 140128494741248 run_lib.py:152] step: 429300, training_loss: 4.32443e+01
I0515 06:26:08.861818 140128494741248 run_lib.py:165] step: 429300, eval_loss: 3.79385e+01
I0515 06:26:15.116597 140128494741248 run_lib.py:152] step: 429350, training_loss: 2.85206e+01
I0515 06:26:21.304838 140128494741248 run_lib.py:152] step: 429400, training_loss: 3.30254e+01
I0515 06:26:21.351698 140128494741248 run_lib.py:165] step: 429400, eval_loss: 2.92075e+01
I0515 06:26:27.823205 140128494741248 run_lib.py:152] step: 429450, training_loss: 4.12862e+01
I0515 06:26:33.981278 140128494741248 run_lib.py:152] step: 429500, training_loss: 3.07609e+01
I0515 06:26:34.033930 140128494741248 run_lib.py:165] step: 429500, eval_loss: 2.07252e+01
I0515 06:26:40.210037 140128494741248 run_lib.py:152] step: 429550, training_loss: 3.91703e+01
I0515 06:26:46.495950 140128494741248 run_lib.py:152] step: 429600, training_loss: 3.41933e+01
I0515 06:26:46.546164 140128494741248 run_lib.py:165] step: 429600, eval_loss: 3.56213e+01
I0515 06:26:52.842800 140128494741248 run_lib.py:152] step: 429650, training_loss: 2.80437e+01
I0515 06:26:59.075009 140128494741248 run_lib.py:152] step: 429700, training_loss: 2.01098e+01
I0515 06:26:59.127931 140128494741248 run_lib.py:165] step: 429700, eval_loss: 3.76669e+01
I0515 06:27:05.379557 140128494741248 run_lib.py:152] step: 429750, training_loss: 2.04707e+01
I0515 06:27:11.771372 140128494741248 run_lib.py:152] step: 429800, training_loss: 5.29580e+01
I0515 06:27:11.831909 140128494741248 run_lib.py:165] step: 429800, eval_loss: 2.62969e+01
I0515 06:27:18.013734 140128494741248 run_lib.py:152] step: 429850, training_loss: 2.63684e+01
I0515 06:27:24.289905 140128494741248 run_lib.py:152] step: 429900, training_loss: 3.15008e+01
I0515 06:27:24.341258 140128494741248 run_lib.py:165] step: 429900, eval_loss: 5.28145e+01
I0515 06:27:30.843074 140128494741248 run_lib.py:152] step: 429950, training_loss: 2.81033e+01
I0515 06:27:37.085653 140128494741248 run_lib.py:152] step: 430000, training_loss: 3.40001e+01
I0515 06:27:37.289764 140128494741248 run_lib.py:165] step: 430000, eval_loss: 2.38628e+01
I0515 06:27:43.468520 140128494741248 run_lib.py:152] step: 430050, training_loss: 2.61693e+01
I0515 06:27:49.677790 140128494741248 run_lib.py:152] step: 430100, training_loss: 4.35246e+01
I0515 06:27:49.729820 140128494741248 run_lib.py:165] step: 430100, eval_loss: 4.42950e+01
I0515 06:27:56.170591 140128494741248 run_lib.py:152] step: 430150, training_loss: 2.60006e+01
I0515 06:28:02.395807 140128494741248 run_lib.py:152] step: 430200, training_loss: 2.08319e+01
I0515 06:28:02.443393 140128494741248 run_lib.py:165] step: 430200, eval_loss: 2.99252e+01
I0515 06:28:08.687150 140128494741248 run_lib.py:152] step: 430250, training_loss: 3.11460e+01
I0515 06:28:15.146042 140128494741248 run_lib.py:152] step: 430300, training_loss: 2.12506e+01
I0515 06:28:15.201721 140128494741248 run_lib.py:165] step: 430300, eval_loss: 2.13662e+01
I0515 06:28:21.475718 140128494741248 run_lib.py:152] step: 430350, training_loss: 2.63305e+01
I0515 06:28:27.612135 140128494741248 run_lib.py:152] step: 430400, training_loss: 2.35568e+01
I0515 06:28:27.660579 140128494741248 run_lib.py:165] step: 430400, eval_loss: 2.55823e+01
I0515 06:28:33.871355 140128494741248 run_lib.py:152] step: 430450, training_loss: 2.63630e+01
I0515 06:28:40.256701 140128494741248 run_lib.py:152] step: 430500, training_loss: 2.29230e+01
I0515 06:28:40.307737 140128494741248 run_lib.py:165] step: 430500, eval_loss: 2.71795e+01
I0515 06:28:46.492595 140128494741248 run_lib.py:152] step: 430550, training_loss: 3.25519e+01
I0515 06:28:52.652804 140128494741248 run_lib.py:152] step: 430600, training_loss: 3.79798e+01
I0515 06:28:52.707046 140128494741248 run_lib.py:165] step: 430600, eval_loss: 3.08531e+01
I0515 06:28:59.034421 140128494741248 run_lib.py:152] step: 430650, training_loss: 2.60598e+01
I0515 06:29:05.264230 140128494741248 run_lib.py:152] step: 430700, training_loss: 2.28678e+01
I0515 06:29:05.318732 140128494741248 run_lib.py:165] step: 430700, eval_loss: 3.33854e+01
I0515 06:29:11.501091 140128494741248 run_lib.py:152] step: 430750, training_loss: 3.14587e+01
I0515 06:29:17.771299 140128494741248 run_lib.py:152] step: 430800, training_loss: 3.10403e+01
I0515 06:29:17.822748 140128494741248 run_lib.py:165] step: 430800, eval_loss: 2.64280e+01
I0515 06:29:24.305009 140128494741248 run_lib.py:152] step: 430850, training_loss: 2.24602e+01
I0515 06:29:30.518315 140128494741248 run_lib.py:152] step: 430900, training_loss: 2.38236e+01
I0515 06:29:30.571442 140128494741248 run_lib.py:165] step: 430900, eval_loss: 3.62741e+01
I0515 06:29:36.811321 140128494741248 run_lib.py:152] step: 430950, training_loss: 4.44309e+01
I0515 06:29:43.180548 140128494741248 run_lib.py:152] step: 431000, training_loss: 1.81405e+01
I0515 06:29:43.232432 140128494741248 run_lib.py:165] step: 431000, eval_loss: 2.26651e+01
I0515 06:29:49.394815 140128494741248 run_lib.py:152] step: 431050, training_loss: 4.31760e+01
I0515 06:29:55.574070 140128494741248 run_lib.py:152] step: 431100, training_loss: 2.54361e+01
I0515 06:29:55.625918 140128494741248 run_lib.py:165] step: 431100, eval_loss: 2.15464e+01
I0515 06:30:02.136809 140128494741248 run_lib.py:152] step: 431150, training_loss: 3.42057e+01
I0515 06:30:08.545403 140128494741248 run_lib.py:152] step: 431200, training_loss: 2.58517e+01
I0515 06:30:08.596698 140128494741248 run_lib.py:165] step: 431200, eval_loss: 4.05478e+01
I0515 06:30:14.763796 140128494741248 run_lib.py:152] step: 431250, training_loss: 4.19537e+01
I0515 06:30:21.023458 140128494741248 run_lib.py:152] step: 431300, training_loss: 2.53210e+01
I0515 06:30:21.071115 140128494741248 run_lib.py:165] step: 431300, eval_loss: 3.15653e+01
I0515 06:30:27.550993 140128494741248 run_lib.py:152] step: 431350, training_loss: 2.26026e+01
I0515 06:30:33.709411 140128494741248 run_lib.py:152] step: 431400, training_loss: 3.01971e+01
I0515 06:30:33.762489 140128494741248 run_lib.py:165] step: 431400, eval_loss: 2.06362e+01
I0515 06:30:39.975280 140128494741248 run_lib.py:152] step: 431450, training_loss: 3.65744e+01
I0515 06:30:46.396329 140128494741248 run_lib.py:152] step: 431500, training_loss: 4.15690e+01
I0515 06:30:46.446325 140128494741248 run_lib.py:165] step: 431500, eval_loss: 3.84529e+01
I0515 06:30:52.660238 140128494741248 run_lib.py:152] step: 431550, training_loss: 2.47696e+01
I0515 06:30:58.894565 140128494741248 run_lib.py:152] step: 431600, training_loss: 3.68817e+01
I0515 06:30:58.950900 140128494741248 run_lib.py:165] step: 431600, eval_loss: 2.69960e+01
I0515 06:31:05.192682 140128494741248 run_lib.py:152] step: 431650, training_loss: 3.89965e+01
I0515 06:31:11.641176 140128494741248 run_lib.py:152] step: 431700, training_loss: 1.93407e+01
I0515 06:31:11.698018 140128494741248 run_lib.py:165] step: 431700, eval_loss: 3.09070e+01
I0515 06:31:17.924041 140128494741248 run_lib.py:152] step: 431750, training_loss: 4.43226e+01
I0515 06:31:24.089050 140128494741248 run_lib.py:152] step: 431800, training_loss: 2.57278e+01
I0515 06:31:24.140266 140128494741248 run_lib.py:165] step: 431800, eval_loss: 2.62110e+01
I0515 06:31:30.637518 140128494741248 run_lib.py:152] step: 431850, training_loss: 3.75255e+01
I0515 06:31:36.860353 140128494741248 run_lib.py:152] step: 431900, training_loss: 2.52799e+01
I0515 06:31:36.909351 140128494741248 run_lib.py:165] step: 431900, eval_loss: 3.68972e+01
I0515 06:31:43.174771 140128494741248 run_lib.py:152] step: 431950, training_loss: 2.97854e+01
I0515 06:31:49.417757 140128494741248 run_lib.py:152] step: 432000, training_loss: 4.35995e+01
I0515 06:31:49.476659 140128494741248 run_lib.py:165] step: 432000, eval_loss: 3.42415e+01
I0515 06:31:55.897309 140128494741248 run_lib.py:152] step: 432050, training_loss: 3.55879e+01
I0515 06:32:02.035853 140128494741248 run_lib.py:152] step: 432100, training_loss: 3.82097e+01
I0515 06:32:02.087070 140128494741248 run_lib.py:165] step: 432100, eval_loss: 3.47894e+01
I0515 06:32:08.274890 140128494741248 run_lib.py:152] step: 432150, training_loss: 2.26204e+01
I0515 06:32:14.661834 140128494741248 run_lib.py:152] step: 432200, training_loss: 3.51985e+01
I0515 06:32:14.719916 140128494741248 run_lib.py:165] step: 432200, eval_loss: 3.47122e+01
I0515 06:32:20.904981 140128494741248 run_lib.py:152] step: 432250, training_loss: 3.40242e+01
I0515 06:32:27.188915 140128494741248 run_lib.py:152] step: 432300, training_loss: 4.58850e+01
I0515 06:32:27.241818 140128494741248 run_lib.py:165] step: 432300, eval_loss: 2.33360e+01
I0515 06:32:33.388491 140128494741248 run_lib.py:152] step: 432350, training_loss: 3.06670e+01
I0515 06:32:39.883061 140128494741248 run_lib.py:152] step: 432400, training_loss: 2.41100e+01
I0515 06:32:39.935745 140128494741248 run_lib.py:165] step: 432400, eval_loss: 3.19334e+01
I0515 06:32:46.090389 140128494741248 run_lib.py:152] step: 432450, training_loss: 3.11772e+01
I0515 06:32:52.309579 140128494741248 run_lib.py:152] step: 432500, training_loss: 3.42450e+01
I0515 06:32:52.359944 140128494741248 run_lib.py:165] step: 432500, eval_loss: 3.55491e+01
I0515 06:32:58.813016 140128494741248 run_lib.py:152] step: 432550, training_loss: 2.83786e+01
I0515 06:33:05.025039 140128494741248 run_lib.py:152] step: 432600, training_loss: 3.39898e+01
I0515 06:33:05.077102 140128494741248 run_lib.py:165] step: 432600, eval_loss: 3.41972e+01
I0515 06:33:11.283628 140128494741248 run_lib.py:152] step: 432650, training_loss: 2.62348e+01
I0515 06:33:17.489975 140128494741248 run_lib.py:152] step: 432700, training_loss: 2.43129e+01
I0515 06:33:17.544118 140128494741248 run_lib.py:165] step: 432700, eval_loss: 3.73216e+01
I0515 06:33:24.128865 140128494741248 run_lib.py:152] step: 432750, training_loss: 3.68174e+01
I0515 06:33:30.344358 140128494741248 run_lib.py:152] step: 432800, training_loss: 1.56180e+01
I0515 06:33:30.395323 140128494741248 run_lib.py:165] step: 432800, eval_loss: 2.31733e+01
I0515 06:33:36.478218 140128494741248 run_lib.py:152] step: 432850, training_loss: 2.94112e+01
I0515 06:33:42.941459 140128494741248 run_lib.py:152] step: 432900, training_loss: 3.64660e+01
I0515 06:33:42.991968 140128494741248 run_lib.py:165] step: 432900, eval_loss: 1.55827e+01
I0515 06:33:49.240770 140128494741248 run_lib.py:152] step: 432950, training_loss: 2.84622e+01
I0515 06:33:55.397483 140128494741248 run_lib.py:152] step: 433000, training_loss: 2.69231e+01
I0515 06:33:55.449738 140128494741248 run_lib.py:165] step: 433000, eval_loss: 2.96042e+01
I0515 06:34:01.696393 140128494741248 run_lib.py:152] step: 433050, training_loss: 3.30794e+01
I0515 06:34:08.131102 140128494741248 run_lib.py:152] step: 433100, training_loss: 3.00808e+01
I0515 06:34:08.186187 140128494741248 run_lib.py:165] step: 433100, eval_loss: 2.73535e+01
I0515 06:34:14.419739 140128494741248 run_lib.py:152] step: 433150, training_loss: 3.35738e+01
I0515 06:34:20.737764 140128494741248 run_lib.py:152] step: 433200, training_loss: 2.22210e+01
I0515 06:34:20.787759 140128494741248 run_lib.py:165] step: 433200, eval_loss: 3.70984e+01
I0515 06:34:27.200339 140128494741248 run_lib.py:152] step: 433250, training_loss: 3.12702e+01
I0515 06:34:33.432535 140128494741248 run_lib.py:152] step: 433300, training_loss: 3.75447e+01
I0515 06:34:33.484712 140128494741248 run_lib.py:165] step: 433300, eval_loss: 3.86508e+01
I0515 06:34:39.678284 140128494741248 run_lib.py:152] step: 433350, training_loss: 3.16306e+01
I0515 06:34:45.985509 140128494741248 run_lib.py:152] step: 433400, training_loss: 2.75551e+01
I0515 06:34:46.042248 140128494741248 run_lib.py:165] step: 433400, eval_loss: 3.09822e+01
I0515 06:34:52.477510 140128494741248 run_lib.py:152] step: 433450, training_loss: 2.46069e+01
I0515 06:34:58.709115 140128494741248 run_lib.py:152] step: 433500, training_loss: 2.28400e+01
I0515 06:34:58.761660 140128494741248 run_lib.py:165] step: 433500, eval_loss: 4.26355e+01
I0515 06:35:05.029828 140128494741248 run_lib.py:152] step: 433550, training_loss: 1.58739e+01
I0515 06:35:11.172643 140128494741248 run_lib.py:152] step: 433600, training_loss: 3.73897e+01
I0515 06:35:11.449129 140128494741248 run_lib.py:165] step: 433600, eval_loss: 3.42943e+01
I0515 06:35:17.645749 140128494741248 run_lib.py:152] step: 433650, training_loss: 2.32917e+01
I0515 06:35:23.976212 140128494741248 run_lib.py:152] step: 433700, training_loss: 2.44260e+01
I0515 06:35:24.028023 140128494741248 run_lib.py:165] step: 433700, eval_loss: 2.00003e+01
I0515 06:35:30.230936 140128494741248 run_lib.py:152] step: 433750, training_loss: 2.95227e+01
I0515 06:35:36.684765 140128494741248 run_lib.py:152] step: 433800, training_loss: 3.01408e+01
I0515 06:35:36.737990 140128494741248 run_lib.py:165] step: 433800, eval_loss: 2.71278e+01
I0515 06:35:42.875136 140128494741248 run_lib.py:152] step: 433850, training_loss: 2.28900e+01
I0515 06:35:49.099827 140128494741248 run_lib.py:152] step: 433900, training_loss: 2.45320e+01
I0515 06:35:49.149415 140128494741248 run_lib.py:165] step: 433900, eval_loss: 3.22618e+01
I0515 06:35:55.539783 140128494741248 run_lib.py:152] step: 433950, training_loss: 2.73785e+01
I0515 06:36:01.712578 140128494741248 run_lib.py:152] step: 434000, training_loss: 2.98683e+01
I0515 06:36:01.761604 140128494741248 run_lib.py:165] step: 434000, eval_loss: 2.95858e+01
I0515 06:36:07.911721 140128494741248 run_lib.py:152] step: 434050, training_loss: 3.50340e+01
I0515 06:36:14.217364 140128494741248 run_lib.py:152] step: 434100, training_loss: 1.92441e+01
I0515 06:36:14.271579 140128494741248 run_lib.py:165] step: 434100, eval_loss: 2.53734e+01
I0515 06:36:20.814523 140128494741248 run_lib.py:152] step: 434150, training_loss: 3.06613e+01
I0515 06:36:27.044340 140128494741248 run_lib.py:152] step: 434200, training_loss: 3.62524e+01
I0515 06:36:27.097488 140128494741248 run_lib.py:165] step: 434200, eval_loss: 4.11735e+01
I0515 06:36:33.281630 140128494741248 run_lib.py:152] step: 434250, training_loss: 3.24091e+01
I0515 06:36:39.698830 140128494741248 run_lib.py:152] step: 434300, training_loss: 2.83773e+01
I0515 06:36:39.745192 140128494741248 run_lib.py:165] step: 434300, eval_loss: 3.25186e+01
I0515 06:36:45.944031 140128494741248 run_lib.py:152] step: 434350, training_loss: 3.49722e+01
I0515 06:36:52.231341 140128494741248 run_lib.py:152] step: 434400, training_loss: 2.60096e+01
I0515 06:36:52.282484 140128494741248 run_lib.py:165] step: 434400, eval_loss: 2.94204e+01
I0515 06:36:58.480133 140128494741248 run_lib.py:152] step: 434450, training_loss: 2.24468e+01
I0515 06:37:04.913608 140128494741248 run_lib.py:152] step: 434500, training_loss: 2.43857e+01
I0515 06:37:04.968461 140128494741248 run_lib.py:165] step: 434500, eval_loss: 3.75261e+01
I0515 06:37:11.189248 140128494741248 run_lib.py:152] step: 434550, training_loss: 2.47437e+01
I0515 06:37:17.317203 140128494741248 run_lib.py:152] step: 434600, training_loss: 4.15817e+01
I0515 06:37:17.366879 140128494741248 run_lib.py:165] step: 434600, eval_loss: 3.24017e+01
I0515 06:37:23.775764 140128494741248 run_lib.py:152] step: 434650, training_loss: 4.11951e+01
I0515 06:37:29.928199 140128494741248 run_lib.py:152] step: 434700, training_loss: 4.41833e+01
I0515 06:37:29.984562 140128494741248 run_lib.py:165] step: 434700, eval_loss: 3.01874e+01
I0515 06:37:36.145552 140128494741248 run_lib.py:152] step: 434750, training_loss: 4.20382e+01
I0515 06:37:42.451900 140128494741248 run_lib.py:152] step: 434800, training_loss: 2.18820e+01
I0515 06:37:42.501694 140128494741248 run_lib.py:165] step: 434800, eval_loss: 2.80284e+01
I0515 06:37:48.964398 140128494741248 run_lib.py:152] step: 434850, training_loss: 2.75578e+01
I0515 06:37:55.212255 140128494741248 run_lib.py:152] step: 434900, training_loss: 2.87275e+01
I0515 06:37:55.264609 140128494741248 run_lib.py:165] step: 434900, eval_loss: 3.47511e+01
I0515 06:38:01.470647 140128494741248 run_lib.py:152] step: 434950, training_loss: 3.46026e+01
I0515 06:38:07.924134 140128494741248 run_lib.py:152] step: 435000, training_loss: 4.76079e+01
I0515 06:38:07.982021 140128494741248 run_lib.py:165] step: 435000, eval_loss: 3.13587e+01
I0515 06:38:14.170788 140128494741248 run_lib.py:152] step: 435050, training_loss: 4.50380e+01
I0515 06:38:20.514902 140128494741248 run_lib.py:152] step: 435100, training_loss: 2.47022e+01
I0515 06:38:20.565353 140128494741248 run_lib.py:165] step: 435100, eval_loss: 4.30864e+01
I0515 06:38:26.847253 140128494741248 run_lib.py:152] step: 435150, training_loss: 2.53382e+01
I0515 06:38:33.265724 140128494741248 run_lib.py:152] step: 435200, training_loss: 2.65289e+01
I0515 06:38:33.314658 140128494741248 run_lib.py:165] step: 435200, eval_loss: 2.76754e+01
I0515 06:38:39.515165 140128494741248 run_lib.py:152] step: 435250, training_loss: 3.33665e+01
I0515 06:38:45.679835 140128494741248 run_lib.py:152] step: 435300, training_loss: 2.92195e+01
I0515 06:38:45.728255 140128494741248 run_lib.py:165] step: 435300, eval_loss: 3.50383e+01
I0515 06:38:52.163838 140128494741248 run_lib.py:152] step: 435350, training_loss: 2.91192e+01
I0515 06:38:58.400788 140128494741248 run_lib.py:152] step: 435400, training_loss: 3.61959e+01
I0515 06:38:58.451512 140128494741248 run_lib.py:165] step: 435400, eval_loss: 3.62601e+01
I0515 06:39:04.678196 140128494741248 run_lib.py:152] step: 435450, training_loss: 4.24626e+01
I0515 06:39:10.789365 140128494741248 run_lib.py:152] step: 435500, training_loss: 3.13782e+01
I0515 06:39:10.840445 140128494741248 run_lib.py:165] step: 435500, eval_loss: 3.16196e+01
I0515 06:39:17.307385 140128494741248 run_lib.py:152] step: 435550, training_loss: 2.96017e+01
I0515 06:39:23.460479 140128494741248 run_lib.py:152] step: 435600, training_loss: 4.03669e+01
I0515 06:39:23.508348 140128494741248 run_lib.py:165] step: 435600, eval_loss: 3.39449e+01
I0515 06:39:29.735312 140128494741248 run_lib.py:152] step: 435650, training_loss: 2.74540e+01
I0515 06:39:36.161588 140128494741248 run_lib.py:152] step: 435700, training_loss: 2.79764e+01
I0515 06:39:36.217495 140128494741248 run_lib.py:165] step: 435700, eval_loss: 2.08190e+01
I0515 06:39:42.446726 140128494741248 run_lib.py:152] step: 435750, training_loss: 3.61129e+01
I0515 06:39:48.676321 140128494741248 run_lib.py:152] step: 435800, training_loss: 4.05968e+01
I0515 06:39:48.733071 140128494741248 run_lib.py:165] step: 435800, eval_loss: 3.51700e+01
I0515 06:39:54.879047 140128494741248 run_lib.py:152] step: 435850, training_loss: 3.92162e+01
I0515 06:40:01.248086 140128494741248 run_lib.py:152] step: 435900, training_loss: 2.42879e+01
I0515 06:40:01.301831 140128494741248 run_lib.py:165] step: 435900, eval_loss: 2.77339e+01
I0515 06:40:07.533207 140128494741248 run_lib.py:152] step: 435950, training_loss: 2.86670e+01
I0515 06:40:13.800301 140128494741248 run_lib.py:152] step: 436000, training_loss: 4.39432e+01
I0515 06:40:13.855013 140128494741248 run_lib.py:165] step: 436000, eval_loss: 1.67282e+01
I0515 06:40:20.306248 140128494741248 run_lib.py:152] step: 436050, training_loss: 3.70193e+01
I0515 06:40:26.579522 140128494741248 run_lib.py:152] step: 436100, training_loss: 2.60243e+01
I0515 06:40:26.630726 140128494741248 run_lib.py:165] step: 436100, eval_loss: 3.76775e+01
I0515 06:40:32.824153 140128494741248 run_lib.py:152] step: 436150, training_loss: 4.00155e+01
I0515 06:40:38.982699 140128494741248 run_lib.py:152] step: 436200, training_loss: 4.25555e+01
I0515 06:40:39.033917 140128494741248 run_lib.py:165] step: 436200, eval_loss: 2.63312e+01
I0515 06:40:45.503274 140128494741248 run_lib.py:152] step: 436250, training_loss: 3.24936e+01
I0515 06:40:51.749404 140128494741248 run_lib.py:152] step: 436300, training_loss: 3.54876e+01
I0515 06:40:51.800517 140128494741248 run_lib.py:165] step: 436300, eval_loss: 2.73453e+01
I0515 06:40:57.969071 140128494741248 run_lib.py:152] step: 436350, training_loss: 3.35919e+01
I0515 06:41:04.519978 140128494741248 run_lib.py:152] step: 436400, training_loss: 2.45865e+01
I0515 06:41:04.569704 140128494741248 run_lib.py:165] step: 436400, eval_loss: 2.20270e+01
I0515 06:41:10.747894 140128494741248 run_lib.py:152] step: 436450, training_loss: 1.98824e+01
I0515 06:41:16.937635 140128494741248 run_lib.py:152] step: 436500, training_loss: 1.93727e+01
I0515 06:41:16.993434 140128494741248 run_lib.py:165] step: 436500, eval_loss: 3.80072e+01
I0515 06:41:23.167809 140128494741248 run_lib.py:152] step: 436550, training_loss: 3.45131e+01
I0515 06:41:29.683432 140128494741248 run_lib.py:152] step: 436600, training_loss: 3.31431e+01
I0515 06:41:29.731412 140128494741248 run_lib.py:165] step: 436600, eval_loss: 3.19826e+01
I0515 06:41:35.864031 140128494741248 run_lib.py:152] step: 436650, training_loss: 3.23779e+01
I0515 06:41:42.127394 140128494741248 run_lib.py:152] step: 436700, training_loss: 4.26444e+01
I0515 06:41:42.175378 140128494741248 run_lib.py:165] step: 436700, eval_loss: 3.71382e+01
I0515 06:41:48.612837 140128494741248 run_lib.py:152] step: 436750, training_loss: 3.17628e+01
I0515 06:41:54.824255 140128494741248 run_lib.py:152] step: 436800, training_loss: 2.60626e+01
I0515 06:41:54.873614 140128494741248 run_lib.py:165] step: 436800, eval_loss: 3.63704e+01
I0515 06:42:01.094850 140128494741248 run_lib.py:152] step: 436850, training_loss: 3.68414e+01
I0515 06:42:07.292903 140128494741248 run_lib.py:152] step: 436900, training_loss: 2.32089e+01
I0515 06:42:07.342087 140128494741248 run_lib.py:165] step: 436900, eval_loss: 2.99329e+01
I0515 06:42:13.836465 140128494741248 run_lib.py:152] step: 436950, training_loss: 2.34937e+01
I0515 06:42:19.968692 140128494741248 run_lib.py:152] step: 437000, training_loss: 3.53090e+01
I0515 06:42:20.017847 140128494741248 run_lib.py:165] step: 437000, eval_loss: 2.50481e+01
I0515 06:42:26.250324 140128494741248 run_lib.py:152] step: 437050, training_loss: 3.01240e+01
I0515 06:42:32.401794 140128494741248 run_lib.py:152] step: 437100, training_loss: 1.57862e+01
I0515 06:42:32.682768 140128494741248 run_lib.py:165] step: 437100, eval_loss: 4.07913e+01
I0515 06:42:38.898103 140128494741248 run_lib.py:152] step: 437150, training_loss: 2.04926e+01
I0515 06:42:45.126695 140128494741248 run_lib.py:152] step: 437200, training_loss: 2.49220e+01
I0515 06:42:45.174480 140128494741248 run_lib.py:165] step: 437200, eval_loss: 3.59816e+01
I0515 06:42:51.421053 140128494741248 run_lib.py:152] step: 437250, training_loss: 2.55072e+01
I0515 06:42:57.907223 140128494741248 run_lib.py:152] step: 437300, training_loss: 3.29578e+01
I0515 06:42:57.959831 140128494741248 run_lib.py:165] step: 437300, eval_loss: 1.91653e+01
I0515 06:43:04.145060 140128494741248 run_lib.py:152] step: 437350, training_loss: 4.74225e+01
I0515 06:43:10.336511 140128494741248 run_lib.py:152] step: 437400, training_loss: 3.34851e+01
I0515 06:43:10.392581 140128494741248 run_lib.py:165] step: 437400, eval_loss: 2.48320e+01
I0515 06:43:16.814525 140128494741248 run_lib.py:152] step: 437450, training_loss: 1.73813e+01
I0515 06:43:23.047305 140128494741248 run_lib.py:152] step: 437500, training_loss: 3.27816e+01
I0515 06:43:23.097522 140128494741248 run_lib.py:165] step: 437500, eval_loss: 3.85229e+01
I0515 06:43:29.238043 140128494741248 run_lib.py:152] step: 437550, training_loss: 2.75774e+01
I0515 06:43:35.435276 140128494741248 run_lib.py:152] step: 437600, training_loss: 1.72696e+01
I0515 06:43:35.485516 140128494741248 run_lib.py:165] step: 437600, eval_loss: 2.47906e+01
I0515 06:43:41.904310 140128494741248 run_lib.py:152] step: 437650, training_loss: 2.58403e+01
I0515 06:43:48.104942 140128494741248 run_lib.py:152] step: 437700, training_loss: 1.77118e+01
I0515 06:43:48.158533 140128494741248 run_lib.py:165] step: 437700, eval_loss: 2.97701e+01
I0515 06:43:54.384579 140128494741248 run_lib.py:152] step: 437750, training_loss: 3.18082e+01
I0515 06:44:00.888657 140128494741248 run_lib.py:152] step: 437800, training_loss: 2.26219e+01
I0515 06:44:00.938975 140128494741248 run_lib.py:165] step: 437800, eval_loss: 4.20767e+01
I0515 06:44:07.079939 140128494741248 run_lib.py:152] step: 437850, training_loss: 3.58064e+01
I0515 06:44:13.291463 140128494741248 run_lib.py:152] step: 437900, training_loss: 3.02046e+01
I0515 06:44:13.344083 140128494741248 run_lib.py:165] step: 437900, eval_loss: 3.98432e+01
I0515 06:44:19.467755 140128494741248 run_lib.py:152] step: 437950, training_loss: 4.06923e+01
I0515 06:44:25.946956 140128494741248 run_lib.py:152] step: 438000, training_loss: 2.17044e+01
I0515 06:44:26.000842 140128494741248 run_lib.py:165] step: 438000, eval_loss: 3.65513e+01
I0515 06:44:32.211502 140128494741248 run_lib.py:152] step: 438050, training_loss: 1.88681e+01
I0515 06:44:38.381354 140128494741248 run_lib.py:152] step: 438100, training_loss: 2.22189e+01
I0515 06:44:38.435664 140128494741248 run_lib.py:165] step: 438100, eval_loss: 3.35306e+01
I0515 06:44:44.979994 140128494741248 run_lib.py:152] step: 438150, training_loss: 2.61658e+01
I0515 06:44:51.146771 140128494741248 run_lib.py:152] step: 438200, training_loss: 2.36278e+01
I0515 06:44:51.198543 140128494741248 run_lib.py:165] step: 438200, eval_loss: 3.14499e+01
I0515 06:44:57.446919 140128494741248 run_lib.py:152] step: 438250, training_loss: 1.36741e+01
I0515 06:45:03.669801 140128494741248 run_lib.py:152] step: 438300, training_loss: 2.79740e+01
I0515 06:45:03.718688 140128494741248 run_lib.py:165] step: 438300, eval_loss: 3.53378e+01
I0515 06:45:10.244571 140128494741248 run_lib.py:152] step: 438350, training_loss: 3.48940e+01
I0515 06:45:16.480466 140128494741248 run_lib.py:152] step: 438400, training_loss: 2.51036e+01
I0515 06:45:16.531914 140128494741248 run_lib.py:165] step: 438400, eval_loss: 2.08380e+01
I0515 06:45:22.755609 140128494741248 run_lib.py:152] step: 438450, training_loss: 2.89642e+01
I0515 06:45:29.141680 140128494741248 run_lib.py:152] step: 438500, training_loss: 2.95018e+01
I0515 06:45:29.190939 140128494741248 run_lib.py:165] step: 438500, eval_loss: 3.33850e+01
I0515 06:45:35.430548 140128494741248 run_lib.py:152] step: 438550, training_loss: 2.23748e+01
I0515 06:45:41.658055 140128494741248 run_lib.py:152] step: 438600, training_loss: 4.31123e+01
I0515 06:45:41.709398 140128494741248 run_lib.py:165] step: 438600, eval_loss: 4.21249e+01
I0515 06:45:47.929024 140128494741248 run_lib.py:152] step: 438650, training_loss: 2.63967e+01
I0515 06:45:54.350355 140128494741248 run_lib.py:152] step: 438700, training_loss: 2.74110e+01
I0515 06:45:54.411183 140128494741248 run_lib.py:165] step: 438700, eval_loss: 4.57005e+01
I0515 06:46:00.575117 140128494741248 run_lib.py:152] step: 438750, training_loss: 3.04345e+01
I0515 06:46:06.770413 140128494741248 run_lib.py:152] step: 438800, training_loss: 2.84113e+01
I0515 06:46:06.825309 140128494741248 run_lib.py:165] step: 438800, eval_loss: 1.58063e+01
I0515 06:46:13.217682 140128494741248 run_lib.py:152] step: 438850, training_loss: 2.61352e+01
I0515 06:46:19.476224 140128494741248 run_lib.py:152] step: 438900, training_loss: 3.07306e+01
I0515 06:46:19.525368 140128494741248 run_lib.py:165] step: 438900, eval_loss: 2.45562e+01
I0515 06:46:25.763752 140128494741248 run_lib.py:152] step: 438950, training_loss: 3.61310e+01
I0515 06:46:31.878884 140128494741248 run_lib.py:152] step: 439000, training_loss: 4.09133e+01
I0515 06:46:31.931315 140128494741248 run_lib.py:165] step: 439000, eval_loss: 4.28631e+01
I0515 06:46:38.356974 140128494741248 run_lib.py:152] step: 439050, training_loss: 2.79803e+01
I0515 06:46:44.523071 140128494741248 run_lib.py:152] step: 439100, training_loss: 2.66078e+01
I0515 06:46:44.581669 140128494741248 run_lib.py:165] step: 439100, eval_loss: 3.81586e+01
I0515 06:46:50.837631 140128494741248 run_lib.py:152] step: 439150, training_loss: 3.55011e+01
I0515 06:46:57.291137 140128494741248 run_lib.py:152] step: 439200, training_loss: 3.39221e+01
I0515 06:46:57.340484 140128494741248 run_lib.py:165] step: 439200, eval_loss: 3.67284e+01
I0515 06:47:03.616503 140128494741248 run_lib.py:152] step: 439250, training_loss: 2.49962e+01
I0515 06:47:09.768701 140128494741248 run_lib.py:152] step: 439300, training_loss: 3.32582e+01
I0515 06:47:09.817022 140128494741248 run_lib.py:165] step: 439300, eval_loss: 3.37499e+01
I0515 06:47:16.067723 140128494741248 run_lib.py:152] step: 439350, training_loss: 3.14966e+01
I0515 06:47:22.573929 140128494741248 run_lib.py:152] step: 439400, training_loss: 4.86244e+01
I0515 06:47:22.622072 140128494741248 run_lib.py:165] step: 439400, eval_loss: 3.75335e+01
I0515 06:47:28.857211 140128494741248 run_lib.py:152] step: 439450, training_loss: 3.59472e+01
I0515 06:47:35.054990 140128494741248 run_lib.py:152] step: 439500, training_loss: 3.67075e+01
I0515 06:47:35.107274 140128494741248 run_lib.py:165] step: 439500, eval_loss: 4.03017e+01
I0515 06:47:41.526445 140128494741248 run_lib.py:152] step: 439550, training_loss: 2.07418e+01
I0515 06:47:47.769894 140128494741248 run_lib.py:152] step: 439600, training_loss: 2.96469e+01
I0515 06:47:47.827229 140128494741248 run_lib.py:165] step: 439600, eval_loss: 2.58943e+01
I0515 06:47:54.057363 140128494741248 run_lib.py:152] step: 439650, training_loss: 2.13244e+01
I0515 06:48:00.244286 140128494741248 run_lib.py:152] step: 439700, training_loss: 3.85578e+01
I0515 06:48:00.301856 140128494741248 run_lib.py:165] step: 439700, eval_loss: 1.93196e+01
I0515 06:48:06.889017 140128494741248 run_lib.py:152] step: 439750, training_loss: 1.90948e+01
I0515 06:48:13.038706 140128494741248 run_lib.py:152] step: 439800, training_loss: 2.33600e+01
I0515 06:48:13.093884 140128494741248 run_lib.py:165] step: 439800, eval_loss: 3.71441e+01
I0515 06:48:19.286086 140128494741248 run_lib.py:152] step: 439850, training_loss: 3.53694e+01
I0515 06:48:25.627216 140128494741248 run_lib.py:152] step: 439900, training_loss: 3.09139e+01
I0515 06:48:25.683490 140128494741248 run_lib.py:165] step: 439900, eval_loss: 2.48482e+01
I0515 06:48:31.932108 140128494741248 run_lib.py:152] step: 439950, training_loss: 1.94056e+01
I0515 06:48:38.085944 140128494741248 run_lib.py:152] step: 440000, training_loss: 3.15161e+01
I0515 06:48:38.288587 140128494741248 run_lib.py:165] step: 440000, eval_loss: 3.19807e+01
I0515 06:48:44.599434 140128494741248 run_lib.py:152] step: 440050, training_loss: 2.30924e+01
I0515 06:48:51.018466 140128494741248 run_lib.py:152] step: 440100, training_loss: 3.72335e+01
I0515 06:48:51.072527 140128494741248 run_lib.py:165] step: 440100, eval_loss: 2.93539e+01
I0515 06:48:57.205431 140128494741248 run_lib.py:152] step: 440150, training_loss: 3.29870e+01
I0515 06:49:03.331758 140128494741248 run_lib.py:152] step: 440200, training_loss: 2.99374e+01
I0515 06:49:03.381746 140128494741248 run_lib.py:165] step: 440200, eval_loss: 9.34622e+00
I0515 06:49:09.821680 140128494741248 run_lib.py:152] step: 440250, training_loss: 3.35192e+01
I0515 06:49:15.912600 140128494741248 run_lib.py:152] step: 440300, training_loss: 3.82709e+01
I0515 06:49:15.964348 140128494741248 run_lib.py:165] step: 440300, eval_loss: 3.42685e+01
I0515 06:49:22.113411 140128494741248 run_lib.py:152] step: 440350, training_loss: 5.05832e+01
I0515 06:49:28.411972 140128494741248 run_lib.py:152] step: 440400, training_loss: 3.97085e+01
I0515 06:49:28.471086 140128494741248 run_lib.py:165] step: 440400, eval_loss: 2.92110e+01
I0515 06:49:34.907088 140128494741248 run_lib.py:152] step: 440450, training_loss: 2.84342e+01
I0515 06:49:41.163425 140128494741248 run_lib.py:152] step: 440500, training_loss: 2.77596e+01
I0515 06:49:41.219063 140128494741248 run_lib.py:165] step: 440500, eval_loss: 2.92471e+01
I0515 06:49:47.387885 140128494741248 run_lib.py:152] step: 440550, training_loss: 2.57009e+01
I0515 06:49:53.590057 140128494741248 run_lib.py:152] step: 440600, training_loss: 3.43027e+01
I0515 06:49:53.864290 140128494741248 run_lib.py:165] step: 440600, eval_loss: 2.11810e+01
I0515 06:50:00.065867 140128494741248 run_lib.py:152] step: 440650, training_loss: 2.34080e+01
I0515 06:50:06.351759 140128494741248 run_lib.py:152] step: 440700, training_loss: 2.07427e+01
I0515 06:50:06.404478 140128494741248 run_lib.py:165] step: 440700, eval_loss: 3.63096e+01
I0515 06:50:12.633922 140128494741248 run_lib.py:152] step: 440750, training_loss: 1.66541e+01
I0515 06:50:19.110016 140128494741248 run_lib.py:152] step: 440800, training_loss: 3.49065e+01
I0515 06:50:19.161292 140128494741248 run_lib.py:165] step: 440800, eval_loss: 3.77373e+01
I0515 06:50:25.397284 140128494741248 run_lib.py:152] step: 440850, training_loss: 2.87159e+01
I0515 06:50:31.606504 140128494741248 run_lib.py:152] step: 440900, training_loss: 2.74236e+01
I0515 06:50:31.658090 140128494741248 run_lib.py:165] step: 440900, eval_loss: 3.22287e+01
I0515 06:50:38.117527 140128494741248 run_lib.py:152] step: 440950, training_loss: 2.13099e+01
I0515 06:50:44.358873 140128494741248 run_lib.py:152] step: 441000, training_loss: 3.07644e+01
I0515 06:50:44.419290 140128494741248 run_lib.py:165] step: 441000, eval_loss: 2.71327e+01
I0515 06:50:50.568217 140128494741248 run_lib.py:152] step: 441050, training_loss: 2.58074e+01
I0515 06:50:56.813686 140128494741248 run_lib.py:152] step: 441100, training_loss: 3.76736e+01
I0515 06:50:56.863953 140128494741248 run_lib.py:165] step: 441100, eval_loss: 3.41552e+01
I0515 06:51:03.375384 140128494741248 run_lib.py:152] step: 441150, training_loss: 4.52182e+01
I0515 06:51:09.590038 140128494741248 run_lib.py:152] step: 441200, training_loss: 3.43347e+01
I0515 06:51:09.644390 140128494741248 run_lib.py:165] step: 441200, eval_loss: 2.08737e+01
I0515 06:51:15.776142 140128494741248 run_lib.py:152] step: 441250, training_loss: 1.58514e+01
I0515 06:51:22.235706 140128494741248 run_lib.py:152] step: 441300, training_loss: 3.32972e+01
I0515 06:51:22.285620 140128494741248 run_lib.py:165] step: 441300, eval_loss: 2.05561e+01
I0515 06:51:28.418290 140128494741248 run_lib.py:152] step: 441350, training_loss: 3.06825e+01
I0515 06:51:34.521377 140128494741248 run_lib.py:152] step: 441400, training_loss: 4.27973e+01
I0515 06:51:34.573629 140128494741248 run_lib.py:165] step: 441400, eval_loss: 2.94894e+01
I0515 06:51:40.742404 140128494741248 run_lib.py:152] step: 441450, training_loss: 3.30224e+01
I0515 06:51:47.171483 140128494741248 run_lib.py:152] step: 441500, training_loss: 2.97820e+01
I0515 06:51:47.231319 140128494741248 run_lib.py:165] step: 441500, eval_loss: 2.36746e+01
I0515 06:51:53.472708 140128494741248 run_lib.py:152] step: 441550, training_loss: 3.85540e+01
I0515 06:51:59.645951 140128494741248 run_lib.py:152] step: 441600, training_loss: 2.62570e+01
I0515 06:51:59.696020 140128494741248 run_lib.py:165] step: 441600, eval_loss: 4.06728e+01
I0515 06:52:06.199039 140128494741248 run_lib.py:152] step: 441650, training_loss: 3.04733e+01
I0515 06:52:12.310750 140128494741248 run_lib.py:152] step: 441700, training_loss: 4.08429e+01
I0515 06:52:12.363276 140128494741248 run_lib.py:165] step: 441700, eval_loss: 2.49457e+01
I0515 06:52:18.579185 140128494741248 run_lib.py:152] step: 441750, training_loss: 4.20362e+01
I0515 06:52:24.898325 140128494741248 run_lib.py:152] step: 441800, training_loss: 3.83380e+01
I0515 06:52:24.958798 140128494741248 run_lib.py:165] step: 441800, eval_loss: 3.70028e+01
I0515 06:52:31.452624 140128494741248 run_lib.py:152] step: 441850, training_loss: 4.67708e+01
I0515 06:52:37.606080 140128494741248 run_lib.py:152] step: 441900, training_loss: 2.01423e+01
I0515 06:52:37.655672 140128494741248 run_lib.py:165] step: 441900, eval_loss: 3.10471e+01
I0515 06:52:43.943380 140128494741248 run_lib.py:152] step: 441950, training_loss: 3.15660e+01
I0515 06:52:50.380171 140128494741248 run_lib.py:152] step: 442000, training_loss: 4.08402e+01
I0515 06:52:50.436659 140128494741248 run_lib.py:165] step: 442000, eval_loss: 2.87215e+01
I0515 06:52:56.683455 140128494741248 run_lib.py:152] step: 442050, training_loss: 2.65166e+01
I0515 06:53:03.015462 140128494741248 run_lib.py:152] step: 442100, training_loss: 2.63246e+01
I0515 06:53:03.065785 140128494741248 run_lib.py:165] step: 442100, eval_loss: 3.91198e+01
I0515 06:53:09.192004 140128494741248 run_lib.py:152] step: 442150, training_loss: 2.99156e+01
I0515 06:53:15.667850 140128494741248 run_lib.py:152] step: 442200, training_loss: 2.80776e+01
I0515 06:53:15.720576 140128494741248 run_lib.py:165] step: 442200, eval_loss: 2.94152e+01
I0515 06:53:21.923048 140128494741248 run_lib.py:152] step: 442250, training_loss: 2.67496e+01
I0515 06:53:28.135555 140128494741248 run_lib.py:152] step: 442300, training_loss: 2.15723e+01
I0515 06:53:28.190083 140128494741248 run_lib.py:165] step: 442300, eval_loss: 3.03323e+01
I0515 06:53:34.572024 140128494741248 run_lib.py:152] step: 442350, training_loss: 2.19612e+01
I0515 06:53:40.749671 140128494741248 run_lib.py:152] step: 442400, training_loss: 2.57012e+01
I0515 06:53:40.798244 140128494741248 run_lib.py:165] step: 442400, eval_loss: 2.65720e+01
I0515 06:53:47.019142 140128494741248 run_lib.py:152] step: 442450, training_loss: 4.71450e+01
I0515 06:53:53.331079 140128494741248 run_lib.py:152] step: 442500, training_loss: 2.63534e+01
I0515 06:53:53.384163 140128494741248 run_lib.py:165] step: 442500, eval_loss: 3.30429e+01
I0515 06:53:59.848648 140128494741248 run_lib.py:152] step: 442550, training_loss: 1.97587e+01
I0515 06:54:06.174624 140128494741248 run_lib.py:152] step: 442600, training_loss: 2.82857e+01
I0515 06:54:06.226107 140128494741248 run_lib.py:165] step: 442600, eval_loss: 3.45540e+01
I0515 06:54:12.409530 140128494741248 run_lib.py:152] step: 442650, training_loss: 4.36071e+01
I0515 06:54:18.846243 140128494741248 run_lib.py:152] step: 442700, training_loss: 3.24195e+01
I0515 06:54:18.898079 140128494741248 run_lib.py:165] step: 442700, eval_loss: 3.46028e+01
I0515 06:54:25.090343 140128494741248 run_lib.py:152] step: 442750, training_loss: 2.02940e+01
I0515 06:54:31.331923 140128494741248 run_lib.py:152] step: 442800, training_loss: 1.69311e+01
I0515 06:54:31.383991 140128494741248 run_lib.py:165] step: 442800, eval_loss: 5.46270e+01
I0515 06:54:37.482381 140128494741248 run_lib.py:152] step: 442850, training_loss: 3.46115e+01
I0515 06:54:43.967250 140128494741248 run_lib.py:152] step: 442900, training_loss: 3.49480e+01
I0515 06:54:44.019083 140128494741248 run_lib.py:165] step: 442900, eval_loss: 3.48505e+01
I0515 06:54:50.129983 140128494741248 run_lib.py:152] step: 442950, training_loss: 4.36384e+01
I0515 06:54:56.447280 140128494741248 run_lib.py:152] step: 443000, training_loss: 2.33095e+01
I0515 06:54:56.503227 140128494741248 run_lib.py:165] step: 443000, eval_loss: 2.79880e+01
I0515 06:55:02.929920 140128494741248 run_lib.py:152] step: 443050, training_loss: 3.24175e+01
I0515 06:55:09.071058 140128494741248 run_lib.py:152] step: 443100, training_loss: 3.91238e+01
I0515 06:55:09.122378 140128494741248 run_lib.py:165] step: 443100, eval_loss: 1.97378e+01
I0515 06:55:15.329098 140128494741248 run_lib.py:152] step: 443150, training_loss: 3.95223e+01
I0515 06:55:21.477746 140128494741248 run_lib.py:152] step: 443200, training_loss: 3.88376e+01
I0515 06:55:21.526008 140128494741248 run_lib.py:165] step: 443200, eval_loss: 2.48370e+01
I0515 06:55:27.883299 140128494741248 run_lib.py:152] step: 443250, training_loss: 4.38915e+01
I0515 06:55:33.979317 140128494741248 run_lib.py:152] step: 443300, training_loss: 3.18735e+01
I0515 06:55:34.034480 140128494741248 run_lib.py:165] step: 443300, eval_loss: 1.45893e+01
I0515 06:55:40.201311 140128494741248 run_lib.py:152] step: 443350, training_loss: 2.96829e+01
I0515 06:55:46.569522 140128494741248 run_lib.py:152] step: 443400, training_loss: 4.58230e+01
I0515 06:55:46.619244 140128494741248 run_lib.py:165] step: 443400, eval_loss: 2.35105e+01
I0515 06:55:52.883868 140128494741248 run_lib.py:152] step: 443450, training_loss: 3.30728e+01
I0515 06:55:59.102078 140128494741248 run_lib.py:152] step: 443500, training_loss: 3.02117e+01
I0515 06:55:59.155439 140128494741248 run_lib.py:165] step: 443500, eval_loss: 2.63589e+01
I0515 06:56:05.397407 140128494741248 run_lib.py:152] step: 443550, training_loss: 2.13598e+01
I0515 06:56:11.718894 140128494741248 run_lib.py:152] step: 443600, training_loss: 2.45744e+01
I0515 06:56:11.770766 140128494741248 run_lib.py:165] step: 443600, eval_loss: 1.62045e+01
I0515 06:56:17.960943 140128494741248 run_lib.py:152] step: 443650, training_loss: 1.48873e+01
I0515 06:56:24.135505 140128494741248 run_lib.py:152] step: 443700, training_loss: 2.58104e+01
I0515 06:56:24.191642 140128494741248 run_lib.py:165] step: 443700, eval_loss: 3.22837e+01
I0515 06:56:30.634767 140128494741248 run_lib.py:152] step: 443750, training_loss: 3.47091e+01
I0515 06:56:36.761293 140128494741248 run_lib.py:152] step: 443800, training_loss: 2.83797e+01
I0515 06:56:36.816718 140128494741248 run_lib.py:165] step: 443800, eval_loss: 2.64902e+01
I0515 06:56:43.066258 140128494741248 run_lib.py:152] step: 443850, training_loss: 3.24758e+01
I0515 06:56:49.366129 140128494741248 run_lib.py:152] step: 443900, training_loss: 3.19577e+01
I0515 06:56:49.420303 140128494741248 run_lib.py:165] step: 443900, eval_loss: 2.69529e+01
I0515 06:56:55.830133 140128494741248 run_lib.py:152] step: 443950, training_loss: 2.94012e+01
I0515 06:57:02.078546 140128494741248 run_lib.py:152] step: 444000, training_loss: 3.26940e+01
I0515 06:57:02.134210 140128494741248 run_lib.py:165] step: 444000, eval_loss: 2.80908e+01
I0515 06:57:08.260771 140128494741248 run_lib.py:152] step: 444050, training_loss: 4.10471e+01
I0515 06:57:14.421364 140128494741248 run_lib.py:152] step: 444100, training_loss: 2.35729e+01
I0515 06:57:14.702596 140128494741248 run_lib.py:165] step: 444100, eval_loss: 2.86264e+01
I0515 06:57:20.917198 140128494741248 run_lib.py:152] step: 444150, training_loss: 3.21128e+01
I0515 06:57:27.082437 140128494741248 run_lib.py:152] step: 444200, training_loss: 1.51188e+01
I0515 06:57:27.135858 140128494741248 run_lib.py:165] step: 444200, eval_loss: 4.76993e+01
I0515 06:57:33.383031 140128494741248 run_lib.py:152] step: 444250, training_loss: 2.51160e+01
I0515 06:57:39.739801 140128494741248 run_lib.py:152] step: 444300, training_loss: 3.04053e+01
I0515 06:57:39.791358 140128494741248 run_lib.py:165] step: 444300, eval_loss: 2.57330e+01
I0515 06:57:46.101096 140128494741248 run_lib.py:152] step: 444350, training_loss: 2.91090e+01
I0515 06:57:52.203121 140128494741248 run_lib.py:152] step: 444400, training_loss: 3.37035e+01
I0515 06:57:52.258555 140128494741248 run_lib.py:165] step: 444400, eval_loss: 2.27303e+01
I0515 06:57:58.658212 140128494741248 run_lib.py:152] step: 444450, training_loss: 2.75647e+01
I0515 06:58:04.937549 140128494741248 run_lib.py:152] step: 444500, training_loss: 3.25765e+01
I0515 06:58:04.996223 140128494741248 run_lib.py:165] step: 444500, eval_loss: 1.54368e+01
I0515 06:58:11.170975 140128494741248 run_lib.py:152] step: 444550, training_loss: 2.80327e+01
I0515 06:58:17.434284 140128494741248 run_lib.py:152] step: 444600, training_loss: 2.61565e+01
I0515 06:58:17.486706 140128494741248 run_lib.py:165] step: 444600, eval_loss: 3.49899e+01
I0515 06:58:23.937507 140128494741248 run_lib.py:152] step: 444650, training_loss: 4.19816e+01
I0515 06:58:30.162376 140128494741248 run_lib.py:152] step: 444700, training_loss: 1.74570e+01
I0515 06:58:30.211910 140128494741248 run_lib.py:165] step: 444700, eval_loss: 4.07459e+01
I0515 06:58:36.443529 140128494741248 run_lib.py:152] step: 444750, training_loss: 3.15309e+01
I0515 06:58:42.869837 140128494741248 run_lib.py:152] step: 444800, training_loss: 2.49811e+01
I0515 06:58:42.920761 140128494741248 run_lib.py:165] step: 444800, eval_loss: 3.01619e+01
I0515 06:58:49.193553 140128494741248 run_lib.py:152] step: 444850, training_loss: 2.94690e+01
I0515 06:58:55.437820 140128494741248 run_lib.py:152] step: 444900, training_loss: 2.78564e+01
I0515 06:58:55.489762 140128494741248 run_lib.py:165] step: 444900, eval_loss: 3.69423e+01
I0515 06:59:01.657801 140128494741248 run_lib.py:152] step: 444950, training_loss: 3.37931e+01
I0515 06:59:08.223995 140128494741248 run_lib.py:152] step: 445000, training_loss: 3.72439e+01
I0515 06:59:08.278274 140128494741248 run_lib.py:165] step: 445000, eval_loss: 3.63017e+01
I0515 06:59:14.526345 140128494741248 run_lib.py:152] step: 445050, training_loss: 3.99466e+01
I0515 06:59:20.773078 140128494741248 run_lib.py:152] step: 445100, training_loss: 2.89629e+01
I0515 06:59:20.822848 140128494741248 run_lib.py:165] step: 445100, eval_loss: 2.34041e+01
I0515 06:59:27.398976 140128494741248 run_lib.py:152] step: 445150, training_loss: 3.83565e+01
I0515 06:59:33.630512 140128494741248 run_lib.py:152] step: 445200, training_loss: 2.50302e+01
I0515 06:59:33.682829 140128494741248 run_lib.py:165] step: 445200, eval_loss: 3.57427e+01
I0515 06:59:39.955251 140128494741248 run_lib.py:152] step: 445250, training_loss: 2.49514e+01
I0515 06:59:46.205321 140128494741248 run_lib.py:152] step: 445300, training_loss: 3.11539e+01
I0515 06:59:46.258847 140128494741248 run_lib.py:165] step: 445300, eval_loss: 2.45918e+01
I0515 06:59:52.675399 140128494741248 run_lib.py:152] step: 445350, training_loss: 2.07690e+01
I0515 06:59:58.966570 140128494741248 run_lib.py:152] step: 445400, training_loss: 4.13172e+01
I0515 06:59:59.016642 140128494741248 run_lib.py:165] step: 445400, eval_loss: 1.84700e+01
I0515 07:00:05.171294 140128494741248 run_lib.py:152] step: 445450, training_loss: 2.88147e+01
I0515 07:00:11.622497 140128494741248 run_lib.py:152] step: 445500, training_loss: 3.09064e+01
I0515 07:00:11.675482 140128494741248 run_lib.py:165] step: 445500, eval_loss: 3.45027e+01
I0515 07:00:17.842546 140128494741248 run_lib.py:152] step: 445550, training_loss: 2.27634e+01
I0515 07:00:24.105894 140128494741248 run_lib.py:152] step: 445600, training_loss: 2.05030e+01
I0515 07:00:24.159018 140128494741248 run_lib.py:165] step: 445600, eval_loss: 2.02170e+01
I0515 07:00:30.319210 140128494741248 run_lib.py:152] step: 445650, training_loss: 4.35008e+01
I0515 07:00:36.740280 140128494741248 run_lib.py:152] step: 445700, training_loss: 3.58206e+01
I0515 07:00:36.791815 140128494741248 run_lib.py:165] step: 445700, eval_loss: 3.93776e+01
I0515 07:00:43.046147 140128494741248 run_lib.py:152] step: 445750, training_loss: 3.33196e+01
I0515 07:00:49.260525 140128494741248 run_lib.py:152] step: 445800, training_loss: 2.59944e+01
I0515 07:00:49.319166 140128494741248 run_lib.py:165] step: 445800, eval_loss: 3.06453e+01
I0515 07:00:55.721891 140128494741248 run_lib.py:152] step: 445850, training_loss: 2.98640e+01
I0515 07:01:01.970365 140128494741248 run_lib.py:152] step: 445900, training_loss: 3.35476e+01
I0515 07:01:02.026643 140128494741248 run_lib.py:165] step: 445900, eval_loss: 3.57266e+01
I0515 07:01:08.220463 140128494741248 run_lib.py:152] step: 445950, training_loss: 3.33525e+01
I0515 07:01:14.405452 140128494741248 run_lib.py:152] step: 446000, training_loss: 2.88841e+01
I0515 07:01:14.462040 140128494741248 run_lib.py:165] step: 446000, eval_loss: 3.11761e+01
I0515 07:01:20.872064 140128494741248 run_lib.py:152] step: 446050, training_loss: 3.42251e+01
I0515 07:01:26.995844 140128494741248 run_lib.py:152] step: 446100, training_loss: 3.45232e+01
I0515 07:01:27.048105 140128494741248 run_lib.py:165] step: 446100, eval_loss: 2.83441e+01
I0515 07:01:33.284620 140128494741248 run_lib.py:152] step: 446150, training_loss: 2.02328e+01
I0515 07:01:39.791375 140128494741248 run_lib.py:152] step: 446200, training_loss: 2.82456e+01
I0515 07:01:39.842856 140128494741248 run_lib.py:165] step: 446200, eval_loss: 1.56171e+01
I0515 07:01:46.131159 140128494741248 run_lib.py:152] step: 446250, training_loss: 1.84032e+01
I0515 07:01:52.229647 140128494741248 run_lib.py:152] step: 446300, training_loss: 2.53845e+01
I0515 07:01:52.282713 140128494741248 run_lib.py:165] step: 446300, eval_loss: 2.89632e+01
I0515 07:01:58.473596 140128494741248 run_lib.py:152] step: 446350, training_loss: 3.04942e+01
I0515 07:02:04.843744 140128494741248 run_lib.py:152] step: 446400, training_loss: 3.67011e+01
I0515 07:02:04.900650 140128494741248 run_lib.py:165] step: 446400, eval_loss: 2.96287e+01
I0515 07:02:11.094899 140128494741248 run_lib.py:152] step: 446450, training_loss: 2.99969e+01
I0515 07:02:17.274632 140128494741248 run_lib.py:152] step: 446500, training_loss: 2.16040e+01
I0515 07:02:17.323971 140128494741248 run_lib.py:165] step: 446500, eval_loss: 3.19156e+01
I0515 07:02:23.692201 140128494741248 run_lib.py:152] step: 446550, training_loss: 4.34347e+01
I0515 07:02:29.998787 140128494741248 run_lib.py:152] step: 446600, training_loss: 2.82998e+01
I0515 07:02:30.051184 140128494741248 run_lib.py:165] step: 446600, eval_loss: 2.63187e+01
I0515 07:02:36.263751 140128494741248 run_lib.py:152] step: 446650, training_loss: 4.06188e+01
I0515 07:02:42.530181 140128494741248 run_lib.py:152] step: 446700, training_loss: 2.72668e+01
I0515 07:02:42.584366 140128494741248 run_lib.py:165] step: 446700, eval_loss: 4.24335e+01
I0515 07:02:49.033379 140128494741248 run_lib.py:152] step: 446750, training_loss: 3.15155e+01
I0515 07:02:55.253619 140128494741248 run_lib.py:152] step: 446800, training_loss: 3.47875e+01
I0515 07:02:55.304697 140128494741248 run_lib.py:165] step: 446800, eval_loss: 3.22425e+01
I0515 07:03:01.604261 140128494741248 run_lib.py:152] step: 446850, training_loss: 3.21816e+01
I0515 07:03:08.069528 140128494741248 run_lib.py:152] step: 446900, training_loss: 2.54299e+01
I0515 07:03:08.124313 140128494741248 run_lib.py:165] step: 446900, eval_loss: 4.02064e+01
I0515 07:03:14.340100 140128494741248 run_lib.py:152] step: 446950, training_loss: 4.32303e+01
I0515 07:03:20.585909 140128494741248 run_lib.py:152] step: 447000, training_loss: 4.22674e+01
I0515 07:03:20.635376 140128494741248 run_lib.py:165] step: 447000, eval_loss: 2.60716e+01
I0515 07:03:26.907028 140128494741248 run_lib.py:152] step: 447050, training_loss: 3.37559e+01
I0515 07:03:33.304544 140128494741248 run_lib.py:152] step: 447100, training_loss: 1.93887e+01
I0515 07:03:33.356378 140128494741248 run_lib.py:165] step: 447100, eval_loss: 3.43344e+01
I0515 07:03:39.527637 140128494741248 run_lib.py:152] step: 447150, training_loss: 3.26800e+01
I0515 07:03:45.725031 140128494741248 run_lib.py:152] step: 447200, training_loss: 2.65229e+01
I0515 07:03:45.779298 140128494741248 run_lib.py:165] step: 447200, eval_loss: 2.24374e+01
I0515 07:03:52.279998 140128494741248 run_lib.py:152] step: 447250, training_loss: 4.84059e+01
I0515 07:03:58.437656 140128494741248 run_lib.py:152] step: 447300, training_loss: 3.54037e+01
I0515 07:03:58.484871 140128494741248 run_lib.py:165] step: 447300, eval_loss: 3.96813e+01
I0515 07:04:04.810737 140128494741248 run_lib.py:152] step: 447350, training_loss: 3.22520e+01
I0515 07:04:11.076121 140128494741248 run_lib.py:152] step: 447400, training_loss: 3.69863e+01
I0515 07:04:11.126599 140128494741248 run_lib.py:165] step: 447400, eval_loss: 1.97713e+01
I0515 07:04:17.516093 140128494741248 run_lib.py:152] step: 447450, training_loss: 5.13698e+01
I0515 07:04:23.768732 140128494741248 run_lib.py:152] step: 447500, training_loss: 2.56061e+01
I0515 07:04:23.823015 140128494741248 run_lib.py:165] step: 447500, eval_loss: 4.73331e+01
I0515 07:04:29.986491 140128494741248 run_lib.py:152] step: 447550, training_loss: 4.13604e+01
I0515 07:04:36.208107 140128494741248 run_lib.py:152] step: 447600, training_loss: 2.13121e+01
I0515 07:04:36.485682 140128494741248 run_lib.py:165] step: 447600, eval_loss: 3.60345e+01
I0515 07:04:42.656556 140128494741248 run_lib.py:152] step: 447650, training_loss: 2.94863e+01
I0515 07:04:48.827275 140128494741248 run_lib.py:152] step: 447700, training_loss: 2.69366e+01
I0515 07:04:48.886777 140128494741248 run_lib.py:165] step: 447700, eval_loss: 2.54988e+01
I0515 07:04:55.095545 140128494741248 run_lib.py:152] step: 447750, training_loss: 3.33177e+01
I0515 07:05:01.529308 140128494741248 run_lib.py:152] step: 447800, training_loss: 3.97681e+01
I0515 07:05:01.578676 140128494741248 run_lib.py:165] step: 447800, eval_loss: 2.79180e+01
I0515 07:05:07.717563 140128494741248 run_lib.py:152] step: 447850, training_loss: 3.63159e+01
I0515 07:05:13.902505 140128494741248 run_lib.py:152] step: 447900, training_loss: 2.68578e+01
I0515 07:05:13.959847 140128494741248 run_lib.py:165] step: 447900, eval_loss: 2.41782e+01
I0515 07:05:20.368587 140128494741248 run_lib.py:152] step: 447950, training_loss: 4.15111e+01
I0515 07:05:26.587605 140128494741248 run_lib.py:152] step: 448000, training_loss: 3.12870e+01
I0515 07:05:26.645889 140128494741248 run_lib.py:165] step: 448000, eval_loss: 4.01537e+01
I0515 07:05:32.839250 140128494741248 run_lib.py:152] step: 448050, training_loss: 2.46736e+01
I0515 07:05:39.138833 140128494741248 run_lib.py:152] step: 448100, training_loss: 3.32725e+01
I0515 07:05:39.189741 140128494741248 run_lib.py:165] step: 448100, eval_loss: 4.26192e+01
I0515 07:05:45.625706 140128494741248 run_lib.py:152] step: 448150, training_loss: 2.01696e+01
I0515 07:05:51.817312 140128494741248 run_lib.py:152] step: 448200, training_loss: 3.20186e+01
I0515 07:05:51.867667 140128494741248 run_lib.py:165] step: 448200, eval_loss: 3.23811e+01
I0515 07:05:58.144584 140128494741248 run_lib.py:152] step: 448250, training_loss: 2.77440e+01
I0515 07:06:04.557525 140128494741248 run_lib.py:152] step: 448300, training_loss: 1.76681e+01
I0515 07:06:04.607929 140128494741248 run_lib.py:165] step: 448300, eval_loss: 5.68943e+01
I0515 07:06:10.867274 140128494741248 run_lib.py:152] step: 448350, training_loss: 3.19459e+01
I0515 07:06:16.971405 140128494741248 run_lib.py:152] step: 448400, training_loss: 1.95784e+01
I0515 07:06:17.023776 140128494741248 run_lib.py:165] step: 448400, eval_loss: 4.31207e+01
I0515 07:06:23.316700 140128494741248 run_lib.py:152] step: 448450, training_loss: 2.80128e+01
I0515 07:06:29.795280 140128494741248 run_lib.py:152] step: 448500, training_loss: 3.34235e+01
I0515 07:06:29.847873 140128494741248 run_lib.py:165] step: 448500, eval_loss: 2.50708e+01
I0515 07:06:36.000635 140128494741248 run_lib.py:152] step: 448550, training_loss: 3.20711e+01
I0515 07:06:42.275543 140128494741248 run_lib.py:152] step: 448600, training_loss: 3.05648e+01
I0515 07:06:42.336417 140128494741248 run_lib.py:165] step: 448600, eval_loss: 2.95558e+01
I0515 07:06:48.748759 140128494741248 run_lib.py:152] step: 448650, training_loss: 3.41922e+01
I0515 07:06:55.023002 140128494741248 run_lib.py:152] step: 448700, training_loss: 1.48435e+01
I0515 07:06:55.076232 140128494741248 run_lib.py:165] step: 448700, eval_loss: 3.24267e+01
I0515 07:07:01.280446 140128494741248 run_lib.py:152] step: 448750, training_loss: 2.67963e+01
I0515 07:07:07.556797 140128494741248 run_lib.py:152] step: 448800, training_loss: 2.02945e+01
I0515 07:07:07.614418 140128494741248 run_lib.py:165] step: 448800, eval_loss: 3.62980e+01
I0515 07:07:14.012653 140128494741248 run_lib.py:152] step: 448850, training_loss: 3.24128e+01
I0515 07:07:20.237421 140128494741248 run_lib.py:152] step: 448900, training_loss: 3.87465e+01
I0515 07:07:20.288290 140128494741248 run_lib.py:165] step: 448900, eval_loss: 1.70624e+01
I0515 07:07:26.441449 140128494741248 run_lib.py:152] step: 448950, training_loss: 2.01844e+01
I0515 07:07:32.942229 140128494741248 run_lib.py:152] step: 449000, training_loss: 1.82369e+01
I0515 07:07:32.994788 140128494741248 run_lib.py:165] step: 449000, eval_loss: 3.34715e+01
I0515 07:07:39.178928 140128494741248 run_lib.py:152] step: 449050, training_loss: 3.12470e+01
I0515 07:07:45.398197 140128494741248 run_lib.py:152] step: 449100, training_loss: 2.57527e+01
I0515 07:07:45.456201 140128494741248 run_lib.py:165] step: 449100, eval_loss: 2.95343e+01
I0515 07:07:51.643008 140128494741248 run_lib.py:152] step: 449150, training_loss: 1.74354e+01
I0515 07:07:58.112046 140128494741248 run_lib.py:152] step: 449200, training_loss: 2.95574e+01
I0515 07:07:58.158977 140128494741248 run_lib.py:165] step: 449200, eval_loss: 3.61176e+01
I0515 07:08:04.149402 140128494741248 run_lib.py:152] step: 449250, training_loss: 2.53285e+01
I0515 07:08:10.343664 140128494741248 run_lib.py:152] step: 449300, training_loss: 2.70060e+01
I0515 07:08:10.394696 140128494741248 run_lib.py:165] step: 449300, eval_loss: 3.78944e+01
I0515 07:08:16.762658 140128494741248 run_lib.py:152] step: 449350, training_loss: 3.56615e+01
I0515 07:08:23.076294 140128494741248 run_lib.py:152] step: 449400, training_loss: 4.45537e+01
I0515 07:08:23.131310 140128494741248 run_lib.py:165] step: 449400, eval_loss: 3.79353e+01
I0515 07:08:29.384543 140128494741248 run_lib.py:152] step: 449450, training_loss: 2.41703e+01
I0515 07:08:35.701629 140128494741248 run_lib.py:152] step: 449500, training_loss: 3.84258e+01
I0515 07:08:35.754384 140128494741248 run_lib.py:165] step: 449500, eval_loss: 1.72923e+01
I0515 07:08:42.186237 140128494741248 run_lib.py:152] step: 449550, training_loss: 4.09444e+01
I0515 07:08:48.517167 140128494741248 run_lib.py:152] step: 449600, training_loss: 3.16304e+01
I0515 07:08:48.570489 140128494741248 run_lib.py:165] step: 449600, eval_loss: 4.63250e+01
I0515 07:08:54.821654 140128494741248 run_lib.py:152] step: 449650, training_loss: 3.38702e+01
I0515 07:09:01.286267 140128494741248 run_lib.py:152] step: 449700, training_loss: 2.75226e+01
I0515 07:09:01.339163 140128494741248 run_lib.py:165] step: 449700, eval_loss: 2.80655e+01
I0515 07:09:07.749224 140128494741248 run_lib.py:152] step: 449750, training_loss: 3.15055e+01
I0515 07:09:13.925606 140128494741248 run_lib.py:152] step: 449800, training_loss: 3.08329e+01
I0515 07:09:13.977630 140128494741248 run_lib.py:165] step: 449800, eval_loss: 2.60270e+01
I0515 07:09:20.238584 140128494741248 run_lib.py:152] step: 449850, training_loss: 3.19053e+01
I0515 07:09:26.632871 140128494741248 run_lib.py:152] step: 449900, training_loss: 3.77799e+01
I0515 07:09:26.679296 140128494741248 run_lib.py:165] step: 449900, eval_loss: 4.75489e+01
I0515 07:09:32.986221 140128494741248 run_lib.py:152] step: 449950, training_loss: 2.25557e+01
I0515 07:09:39.191998 140128494741248 run_lib.py:152] step: 450000, training_loss: 4.92005e+01
I0515 07:09:39.397653 140128494741248 run_lib.py:165] step: 450000, eval_loss: 3.04589e+01
I0515 07:11:00.019854 140128494741248 run_lib.py:152] step: 450050, training_loss: 3.64181e+01
I0515 07:11:06.213922 140128494741248 run_lib.py:152] step: 450100, training_loss: 3.33392e+01
I0515 07:11:06.270468 140128494741248 run_lib.py:165] step: 450100, eval_loss: 3.99280e+01
I0515 07:11:12.615050 140128494741248 run_lib.py:152] step: 450150, training_loss: 3.50970e+01
I0515 07:11:19.074556 140128494741248 run_lib.py:152] step: 450200, training_loss: 3.58087e+01
I0515 07:11:19.125099 140128494741248 run_lib.py:165] step: 450200, eval_loss: 2.49530e+01
I0515 07:11:25.305190 140128494741248 run_lib.py:152] step: 450250, training_loss: 2.72843e+01
I0515 07:11:31.555505 140128494741248 run_lib.py:152] step: 450300, training_loss: 3.80735e+01
I0515 07:11:31.611988 140128494741248 run_lib.py:165] step: 450300, eval_loss: 3.61829e+01
I0515 07:11:37.866903 140128494741248 run_lib.py:152] step: 450350, training_loss: 4.01348e+01
I0515 07:11:44.384645 140128494741248 run_lib.py:152] step: 450400, training_loss: 2.56885e+01
I0515 07:11:44.435196 140128494741248 run_lib.py:165] step: 450400, eval_loss: 3.68507e+01
I0515 07:11:50.605336 140128494741248 run_lib.py:152] step: 450450, training_loss: 2.44276e+01
I0515 07:11:56.839802 140128494741248 run_lib.py:152] step: 450500, training_loss: 3.81418e+01
I0515 07:11:56.894304 140128494741248 run_lib.py:165] step: 450500, eval_loss: 3.89084e+01
I0515 07:12:03.343539 140128494741248 run_lib.py:152] step: 450550, training_loss: 4.04104e+01
I0515 07:12:09.642020 140128494741248 run_lib.py:152] step: 450600, training_loss: 3.29179e+01
I0515 07:12:09.697082 140128494741248 run_lib.py:165] step: 450600, eval_loss: 2.08272e+01
I0515 07:12:15.898253 140128494741248 run_lib.py:152] step: 450650, training_loss: 2.94543e+01
I0515 07:12:22.025233 140128494741248 run_lib.py:152] step: 450700, training_loss: 3.64668e+01
I0515 07:12:22.072557 140128494741248 run_lib.py:165] step: 450700, eval_loss: 5.10451e+01
I0515 07:12:28.575882 140128494741248 run_lib.py:152] step: 450750, training_loss: 2.29162e+01
I0515 07:12:34.772089 140128494741248 run_lib.py:152] step: 450800, training_loss: 2.85207e+01
I0515 07:12:34.822816 140128494741248 run_lib.py:165] step: 450800, eval_loss: 1.76553e+01
I0515 07:12:41.054544 140128494741248 run_lib.py:152] step: 450850, training_loss: 3.43082e+01
I0515 07:12:47.437588 140128494741248 run_lib.py:152] step: 450900, training_loss: 3.38013e+01
I0515 07:12:47.489200 140128494741248 run_lib.py:165] step: 450900, eval_loss: 3.72798e+01
I0515 07:12:53.748386 140128494741248 run_lib.py:152] step: 450950, training_loss: 3.85975e+01
I0515 07:12:59.884912 140128494741248 run_lib.py:152] step: 451000, training_loss: 2.65482e+01
I0515 07:12:59.937868 140128494741248 run_lib.py:165] step: 451000, eval_loss: 2.41073e+01
I0515 07:13:06.167820 140128494741248 run_lib.py:152] step: 451050, training_loss: 3.50765e+01
I0515 07:13:12.607219 140128494741248 run_lib.py:152] step: 451100, training_loss: 3.95518e+01
I0515 07:13:12.657822 140128494741248 run_lib.py:165] step: 451100, eval_loss: 2.69211e+01
I0515 07:13:18.838314 140128494741248 run_lib.py:152] step: 451150, training_loss: 2.81561e+01
I0515 07:13:25.095433 140128494741248 run_lib.py:152] step: 451200, training_loss: 2.66468e+01
I0515 07:13:25.151596 140128494741248 run_lib.py:165] step: 451200, eval_loss: 2.57215e+01
I0515 07:13:31.607997 140128494741248 run_lib.py:152] step: 451250, training_loss: 3.37158e+01
I0515 07:13:37.716313 140128494741248 run_lib.py:152] step: 451300, training_loss: 3.93168e+01
I0515 07:13:37.765373 140128494741248 run_lib.py:165] step: 451300, eval_loss: 3.82552e+01
I0515 07:13:43.971806 140128494741248 run_lib.py:152] step: 451350, training_loss: 3.23262e+01
I0515 07:13:50.171893 140128494741248 run_lib.py:152] step: 451400, training_loss: 3.47158e+01
I0515 07:13:50.223782 140128494741248 run_lib.py:165] step: 451400, eval_loss: 3.98301e+01
I0515 07:13:56.721403 140128494741248 run_lib.py:152] step: 451450, training_loss: 3.36990e+01
I0515 07:14:02.962124 140128494741248 run_lib.py:152] step: 451500, training_loss: 4.86190e+01
I0515 07:14:03.014212 140128494741248 run_lib.py:165] step: 451500, eval_loss: 2.24716e+01
I0515 07:14:09.281645 140128494741248 run_lib.py:152] step: 451550, training_loss: 2.75329e+01
I0515 07:14:15.712809 140128494741248 run_lib.py:152] step: 451600, training_loss: 3.54456e+01
I0515 07:14:15.771029 140128494741248 run_lib.py:165] step: 451600, eval_loss: 2.56928e+01
I0515 07:14:21.955016 140128494741248 run_lib.py:152] step: 451650, training_loss: 2.33391e+01
I0515 07:14:28.134100 140128494741248 run_lib.py:152] step: 451700, training_loss: 3.87662e+01
I0515 07:14:28.187929 140128494741248 run_lib.py:165] step: 451700, eval_loss: 2.06672e+01
I0515 07:14:34.473970 140128494741248 run_lib.py:152] step: 451750, training_loss: 3.11758e+01
I0515 07:14:40.843593 140128494741248 run_lib.py:152] step: 451800, training_loss: 2.91027e+01
I0515 07:14:40.895502 140128494741248 run_lib.py:165] step: 451800, eval_loss: 3.49073e+01
I0515 07:14:47.199359 140128494741248 run_lib.py:152] step: 451850, training_loss: 3.37844e+01
I0515 07:14:53.379703 140128494741248 run_lib.py:152] step: 451900, training_loss: 1.93301e+01
I0515 07:14:53.433838 140128494741248 run_lib.py:165] step: 451900, eval_loss: 4.57045e+01
I0515 07:14:59.884942 140128494741248 run_lib.py:152] step: 451950, training_loss: 2.81654e+01
I0515 07:15:06.114603 140128494741248 run_lib.py:152] step: 452000, training_loss: 1.68433e+01
I0515 07:15:06.165622 140128494741248 run_lib.py:165] step: 452000, eval_loss: 3.86512e+01
I0515 07:15:12.464047 140128494741248 run_lib.py:152] step: 452050, training_loss: 4.31379e+01
I0515 07:15:18.598416 140128494741248 run_lib.py:152] step: 452100, training_loss: 4.36320e+01
I0515 07:15:18.651672 140128494741248 run_lib.py:165] step: 452100, eval_loss: 2.35230e+01
I0515 07:15:25.119677 140128494741248 run_lib.py:152] step: 452150, training_loss: 3.94235e+01
I0515 07:15:31.356691 140128494741248 run_lib.py:152] step: 452200, training_loss: 2.86055e+01
I0515 07:15:31.404478 140128494741248 run_lib.py:165] step: 452200, eval_loss: 2.86750e+01
I0515 07:15:37.563185 140128494741248 run_lib.py:152] step: 452250, training_loss: 2.99421e+01
I0515 07:15:44.018734 140128494741248 run_lib.py:152] step: 452300, training_loss: 3.30594e+01
I0515 07:15:44.072410 140128494741248 run_lib.py:165] step: 452300, eval_loss: 3.02010e+01
I0515 07:15:50.227235 140128494741248 run_lib.py:152] step: 452350, training_loss: 2.45317e+01
I0515 07:15:56.406443 140128494741248 run_lib.py:152] step: 452400, training_loss: 3.04751e+01
I0515 07:15:56.460032 140128494741248 run_lib.py:165] step: 452400, eval_loss: 3.11306e+01
I0515 07:16:02.609220 140128494741248 run_lib.py:152] step: 452450, training_loss: 2.77336e+01
I0515 07:16:09.180771 140128494741248 run_lib.py:152] step: 452500, training_loss: 4.37119e+01
I0515 07:16:09.237931 140128494741248 run_lib.py:165] step: 452500, eval_loss: 3.24101e+01
I0515 07:16:15.415235 140128494741248 run_lib.py:152] step: 452550, training_loss: 3.07950e+01
I0515 07:16:21.660777 140128494741248 run_lib.py:152] step: 452600, training_loss: 2.96384e+01
I0515 07:16:21.711973 140128494741248 run_lib.py:165] step: 452600, eval_loss: 2.91858e+01
I0515 07:16:28.122816 140128494741248 run_lib.py:152] step: 452650, training_loss: 3.82567e+01
I0515 07:16:34.347560 140128494741248 run_lib.py:152] step: 452700, training_loss: 2.95285e+01
I0515 07:16:34.399340 140128494741248 run_lib.py:165] step: 452700, eval_loss: 2.91464e+01
I0515 07:16:40.540647 140128494741248 run_lib.py:152] step: 452750, training_loss: 2.47388e+01
I0515 07:16:46.773648 140128494741248 run_lib.py:152] step: 452800, training_loss: 1.51547e+01
I0515 07:16:46.825857 140128494741248 run_lib.py:165] step: 452800, eval_loss: 3.23597e+01
I0515 07:16:53.309512 140128494741248 run_lib.py:152] step: 452850, training_loss: 2.06808e+01
I0515 07:16:59.545860 140128494741248 run_lib.py:152] step: 452900, training_loss: 2.55702e+01
I0515 07:16:59.601881 140128494741248 run_lib.py:165] step: 452900, eval_loss: 2.81135e+01
I0515 07:17:05.803169 140128494741248 run_lib.py:152] step: 452950, training_loss: 3.19128e+01
I0515 07:17:12.303107 140128494741248 run_lib.py:152] step: 453000, training_loss: 2.16739e+01
I0515 07:17:12.356813 140128494741248 run_lib.py:165] step: 453000, eval_loss: 3.19991e+01
I0515 07:17:18.548498 140128494741248 run_lib.py:152] step: 453050, training_loss: 3.65884e+01
I0515 07:17:24.738318 140128494741248 run_lib.py:152] step: 453100, training_loss: 2.75608e+01
I0515 07:17:24.799242 140128494741248 run_lib.py:165] step: 453100, eval_loss: 3.33363e+01
I0515 07:17:31.030882 140128494741248 run_lib.py:152] step: 453150, training_loss: 2.48921e+01
I0515 07:17:37.427430 140128494741248 run_lib.py:152] step: 453200, training_loss: 1.79009e+01
I0515 07:17:37.477051 140128494741248 run_lib.py:165] step: 453200, eval_loss: 2.51792e+01
I0515 07:17:43.806167 140128494741248 run_lib.py:152] step: 453250, training_loss: 2.76161e+01
I0515 07:17:50.100991 140128494741248 run_lib.py:152] step: 453300, training_loss: 4.39932e+01
I0515 07:17:50.154904 140128494741248 run_lib.py:165] step: 453300, eval_loss: 2.24723e+01
I0515 07:17:56.606782 140128494741248 run_lib.py:152] step: 453350, training_loss: 2.78225e+01
I0515 07:18:02.857818 140128494741248 run_lib.py:152] step: 453400, training_loss: 1.92744e+01
I0515 07:18:02.907773 140128494741248 run_lib.py:165] step: 453400, eval_loss: 4.22827e+01
I0515 07:18:09.150291 140128494741248 run_lib.py:152] step: 453450, training_loss: 2.66468e+01
I0515 07:18:15.351641 140128494741248 run_lib.py:152] step: 453500, training_loss: 2.44622e+01
I0515 07:18:15.403055 140128494741248 run_lib.py:165] step: 453500, eval_loss: 2.87508e+01
I0515 07:18:21.882853 140128494741248 run_lib.py:152] step: 453550, training_loss: 2.90196e+01
I0515 07:18:28.135415 140128494741248 run_lib.py:152] step: 453600, training_loss: 2.42525e+01
I0515 07:18:28.189977 140128494741248 run_lib.py:165] step: 453600, eval_loss: 2.42639e+01
I0515 07:18:34.482508 140128494741248 run_lib.py:152] step: 453650, training_loss: 2.36547e+01
I0515 07:18:40.932526 140128494741248 run_lib.py:152] step: 453700, training_loss: 2.65556e+01
I0515 07:18:40.980787 140128494741248 run_lib.py:165] step: 453700, eval_loss: 4.92846e+01
I0515 07:18:47.242551 140128494741248 run_lib.py:152] step: 453750, training_loss: 1.94328e+01
I0515 07:18:53.417641 140128494741248 run_lib.py:152] step: 453800, training_loss: 2.00602e+01
I0515 07:18:53.467990 140128494741248 run_lib.py:165] step: 453800, eval_loss: 3.95727e+01
I0515 07:18:59.672646 140128494741248 run_lib.py:152] step: 453850, training_loss: 2.65295e+01
I0515 07:19:05.999236 140128494741248 run_lib.py:152] step: 453900, training_loss: 2.56507e+01
I0515 07:19:06.053775 140128494741248 run_lib.py:165] step: 453900, eval_loss: 3.44379e+01
I0515 07:19:12.320878 140128494741248 run_lib.py:152] step: 453950, training_loss: 3.30650e+01
I0515 07:19:18.400747 140128494741248 run_lib.py:152] step: 454000, training_loss: 3.63612e+01
I0515 07:19:18.452403 140128494741248 run_lib.py:165] step: 454000, eval_loss: 2.42185e+01
I0515 07:19:24.952252 140128494741248 run_lib.py:152] step: 454050, training_loss: 2.96410e+01
I0515 07:19:31.163173 140128494741248 run_lib.py:152] step: 454100, training_loss: 2.37405e+01
I0515 07:19:31.219843 140128494741248 run_lib.py:165] step: 454100, eval_loss: 2.73101e+01
I0515 07:19:37.433710 140128494741248 run_lib.py:152] step: 454150, training_loss: 3.85800e+01
I0515 07:19:43.655751 140128494741248 run_lib.py:152] step: 454200, training_loss: 2.55052e+01
I0515 07:19:43.704123 140128494741248 run_lib.py:165] step: 454200, eval_loss: 4.31955e+01
I0515 07:19:50.105739 140128494741248 run_lib.py:152] step: 454250, training_loss: 2.34558e+01
I0515 07:19:56.349747 140128494741248 run_lib.py:152] step: 454300, training_loss: 2.96012e+01
I0515 07:19:56.400238 140128494741248 run_lib.py:165] step: 454300, eval_loss: 4.09179e+01
I0515 07:20:02.513101 140128494741248 run_lib.py:152] step: 454350, training_loss: 2.50833e+01
I0515 07:20:09.011893 140128494741248 run_lib.py:152] step: 454400, training_loss: 2.36957e+01
I0515 07:20:09.066454 140128494741248 run_lib.py:165] step: 454400, eval_loss: 2.85852e+01
I0515 07:20:15.269772 140128494741248 run_lib.py:152] step: 454450, training_loss: 5.79668e+01
I0515 07:20:21.515906 140128494741248 run_lib.py:152] step: 454500, training_loss: 3.83890e+01
I0515 07:20:21.573197 140128494741248 run_lib.py:165] step: 454500, eval_loss: 2.56333e+01
I0515 07:20:27.745109 140128494741248 run_lib.py:152] step: 454550, training_loss: 2.51418e+01
I0515 07:20:34.197082 140128494741248 run_lib.py:152] step: 454600, training_loss: 3.73654e+01
I0515 07:20:34.246032 140128494741248 run_lib.py:165] step: 454600, eval_loss: 2.36294e+01
I0515 07:20:40.438829 140128494741248 run_lib.py:152] step: 454650, training_loss: 2.32157e+01
I0515 07:20:46.622386 140128494741248 run_lib.py:152] step: 454700, training_loss: 3.59178e+01
I0515 07:20:46.676805 140128494741248 run_lib.py:165] step: 454700, eval_loss: 3.37814e+01
I0515 07:20:53.058061 140128494741248 run_lib.py:152] step: 454750, training_loss: 2.21538e+01
I0515 07:20:59.203652 140128494741248 run_lib.py:152] step: 454800, training_loss: 6.02883e+01
I0515 07:20:59.257675 140128494741248 run_lib.py:165] step: 454800, eval_loss: 2.73396e+01
I0515 07:21:05.497750 140128494741248 run_lib.py:152] step: 454850, training_loss: 3.68256e+01
I0515 07:21:11.672841 140128494741248 run_lib.py:152] step: 454900, training_loss: 4.50013e+01
I0515 07:21:11.728565 140128494741248 run_lib.py:165] step: 454900, eval_loss: 3.90895e+01
I0515 07:21:18.175359 140128494741248 run_lib.py:152] step: 454950, training_loss: 3.99451e+01
I0515 07:21:24.268662 140128494741248 run_lib.py:152] step: 455000, training_loss: 2.21037e+01
I0515 07:21:24.323212 140128494741248 run_lib.py:165] step: 455000, eval_loss: 3.10458e+01
I0515 07:21:30.624201 140128494741248 run_lib.py:152] step: 455050, training_loss: 2.19173e+01
I0515 07:21:37.072709 140128494741248 run_lib.py:152] step: 455100, training_loss: 2.22565e+01
I0515 07:21:37.124045 140128494741248 run_lib.py:165] step: 455100, eval_loss: 4.82959e+01
I0515 07:21:43.386207 140128494741248 run_lib.py:152] step: 455150, training_loss: 3.53070e+01
I0515 07:21:49.579469 140128494741248 run_lib.py:152] step: 455200, training_loss: 2.25413e+01
I0515 07:21:49.630951 140128494741248 run_lib.py:165] step: 455200, eval_loss: 3.87448e+01
I0515 07:21:55.800973 140128494741248 run_lib.py:152] step: 455250, training_loss: 3.85477e+01
I0515 07:22:02.223617 140128494741248 run_lib.py:152] step: 455300, training_loss: 2.24571e+01
I0515 07:22:02.273887 140128494741248 run_lib.py:165] step: 455300, eval_loss: 3.18892e+01
I0515 07:22:08.502475 140128494741248 run_lib.py:152] step: 455350, training_loss: 3.55717e+01
I0515 07:22:14.785927 140128494741248 run_lib.py:152] step: 455400, training_loss: 2.05675e+01
I0515 07:22:14.842144 140128494741248 run_lib.py:165] step: 455400, eval_loss: 2.59192e+01
I0515 07:22:21.345067 140128494741248 run_lib.py:152] step: 455450, training_loss: 3.37533e+01
I0515 07:22:27.610183 140128494741248 run_lib.py:152] step: 455500, training_loss: 2.33681e+01
I0515 07:22:27.660488 140128494741248 run_lib.py:165] step: 455500, eval_loss: 3.71385e+01
I0515 07:22:33.823373 140128494741248 run_lib.py:152] step: 455550, training_loss: 4.00881e+01
I0515 07:22:40.050636 140128494741248 run_lib.py:152] step: 455600, training_loss: 2.86831e+01
I0515 07:22:40.102442 140128494741248 run_lib.py:165] step: 455600, eval_loss: 2.08337e+01
I0515 07:22:46.617221 140128494741248 run_lib.py:152] step: 455650, training_loss: 4.58294e+01
I0515 07:22:52.939153 140128494741248 run_lib.py:152] step: 455700, training_loss: 3.59838e+01
I0515 07:22:52.995052 140128494741248 run_lib.py:165] step: 455700, eval_loss: 2.02791e+01
I0515 07:22:59.130830 140128494741248 run_lib.py:152] step: 455750, training_loss: 2.67268e+01
I0515 07:23:05.532322 140128494741248 run_lib.py:152] step: 455800, training_loss: 2.56859e+01
I0515 07:23:05.581757 140128494741248 run_lib.py:165] step: 455800, eval_loss: 4.51820e+01
I0515 07:23:11.913963 140128494741248 run_lib.py:152] step: 455850, training_loss: 2.08983e+01
I0515 07:23:18.076539 140128494741248 run_lib.py:152] step: 455900, training_loss: 4.78185e+01
I0515 07:23:18.127426 140128494741248 run_lib.py:165] step: 455900, eval_loss: 2.87729e+01
I0515 07:23:24.396790 140128494741248 run_lib.py:152] step: 455950, training_loss: 2.53643e+01
I0515 07:23:30.876638 140128494741248 run_lib.py:152] step: 456000, training_loss: 2.59821e+01
I0515 07:23:30.929772 140128494741248 run_lib.py:165] step: 456000, eval_loss: 2.97752e+01
I0515 07:23:37.210309 140128494741248 run_lib.py:152] step: 456050, training_loss: 3.93360e+01
I0515 07:23:43.491524 140128494741248 run_lib.py:152] step: 456100, training_loss: 3.29985e+01
I0515 07:23:43.541766 140128494741248 run_lib.py:165] step: 456100, eval_loss: 3.51968e+01
I0515 07:23:50.009727 140128494741248 run_lib.py:152] step: 456150, training_loss: 2.70940e+01
I0515 07:23:56.319530 140128494741248 run_lib.py:152] step: 456200, training_loss: 4.02932e+01
I0515 07:23:56.372033 140128494741248 run_lib.py:165] step: 456200, eval_loss: 3.68737e+01
I0515 07:24:02.532578 140128494741248 run_lib.py:152] step: 456250, training_loss: 3.64288e+01
I0515 07:24:08.794827 140128494741248 run_lib.py:152] step: 456300, training_loss: 3.54211e+01
I0515 07:24:08.851868 140128494741248 run_lib.py:165] step: 456300, eval_loss: 3.82044e+01
I0515 07:24:15.263137 140128494741248 run_lib.py:152] step: 456350, training_loss: 2.01734e+01
I0515 07:24:21.521506 140128494741248 run_lib.py:152] step: 456400, training_loss: 2.73041e+01
I0515 07:24:21.572074 140128494741248 run_lib.py:165] step: 456400, eval_loss: 2.91216e+01
I0515 07:24:27.740649 140128494741248 run_lib.py:152] step: 456450, training_loss: 3.68137e+01
I0515 07:24:34.240325 140128494741248 run_lib.py:152] step: 456500, training_loss: 2.75369e+01
I0515 07:24:34.294728 140128494741248 run_lib.py:165] step: 456500, eval_loss: 2.60817e+01
I0515 07:24:40.499902 140128494741248 run_lib.py:152] step: 456550, training_loss: 2.16118e+01
I0515 07:24:46.684757 140128494741248 run_lib.py:152] step: 456600, training_loss: 2.86602e+01
I0515 07:24:46.732645 140128494741248 run_lib.py:165] step: 456600, eval_loss: 3.48974e+01
I0515 07:24:53.035771 140128494741248 run_lib.py:152] step: 456650, training_loss: 3.39608e+01
I0515 07:24:59.586678 140128494741248 run_lib.py:152] step: 456700, training_loss: 3.75949e+01
I0515 07:24:59.642511 140128494741248 run_lib.py:165] step: 456700, eval_loss: 3.76458e+01
I0515 07:25:05.880201 140128494741248 run_lib.py:152] step: 456750, training_loss: 3.87706e+01
I0515 07:25:12.127890 140128494741248 run_lib.py:152] step: 456800, training_loss: 3.40002e+01
I0515 07:25:12.184345 140128494741248 run_lib.py:165] step: 456800, eval_loss: 3.60198e+01
I0515 07:25:18.565011 140128494741248 run_lib.py:152] step: 456850, training_loss: 2.64199e+01
I0515 07:25:24.699111 140128494741248 run_lib.py:152] step: 456900, training_loss: 3.12335e+01
I0515 07:25:24.752556 140128494741248 run_lib.py:165] step: 456900, eval_loss: 2.34740e+01
I0515 07:25:31.046083 140128494741248 run_lib.py:152] step: 456950, training_loss: 2.37936e+01
I0515 07:25:37.357563 140128494741248 run_lib.py:152] step: 457000, training_loss: 2.74593e+01
I0515 07:25:37.412715 140128494741248 run_lib.py:165] step: 457000, eval_loss: 5.02044e+01
I0515 07:25:43.867052 140128494741248 run_lib.py:152] step: 457050, training_loss: 3.48435e+01
I0515 07:25:50.052593 140128494741248 run_lib.py:152] step: 457100, training_loss: 3.12956e+01
I0515 07:25:50.099666 140128494741248 run_lib.py:165] step: 457100, eval_loss: 2.63830e+01
I0515 07:25:56.284679 140128494741248 run_lib.py:152] step: 457150, training_loss: 2.87083e+01
I0515 07:26:02.699274 140128494741248 run_lib.py:152] step: 457200, training_loss: 2.67395e+01
I0515 07:26:02.754218 140128494741248 run_lib.py:165] step: 457200, eval_loss: 3.23820e+01
I0515 07:26:09.010092 140128494741248 run_lib.py:152] step: 457250, training_loss: 2.13843e+01
I0515 07:26:15.236584 140128494741248 run_lib.py:152] step: 457300, training_loss: 3.63219e+01
I0515 07:26:15.287917 140128494741248 run_lib.py:165] step: 457300, eval_loss: 3.17772e+01
I0515 07:26:21.545588 140128494741248 run_lib.py:152] step: 457350, training_loss: 3.47438e+01
I0515 07:26:28.140466 140128494741248 run_lib.py:152] step: 457400, training_loss: 2.36947e+01
I0515 07:26:28.199191 140128494741248 run_lib.py:165] step: 457400, eval_loss: 2.05989e+01
I0515 07:26:34.396777 140128494741248 run_lib.py:152] step: 457450, training_loss: 3.70034e+01
I0515 07:26:40.742764 140128494741248 run_lib.py:152] step: 457500, training_loss: 3.79610e+01
I0515 07:26:40.798073 140128494741248 run_lib.py:165] step: 457500, eval_loss: 2.40691e+01
I0515 07:26:47.121226 140128494741248 run_lib.py:152] step: 457550, training_loss: 3.97476e+01
I0515 07:26:53.379421 140128494741248 run_lib.py:152] step: 457600, training_loss: 3.89230e+01
I0515 07:26:53.436195 140128494741248 run_lib.py:165] step: 457600, eval_loss: 3.39109e+01
I0515 07:26:59.658195 140128494741248 run_lib.py:152] step: 457650, training_loss: 3.19546e+01
I0515 07:27:05.888546 140128494741248 run_lib.py:152] step: 457700, training_loss: 1.75282e+01
I0515 07:27:05.941730 140128494741248 run_lib.py:165] step: 457700, eval_loss: 3.46861e+01
I0515 07:27:12.382036 140128494741248 run_lib.py:152] step: 457750, training_loss: 2.21987e+01
I0515 07:27:18.524193 140128494741248 run_lib.py:152] step: 457800, training_loss: 1.32276e+01
I0515 07:27:18.577449 140128494741248 run_lib.py:165] step: 457800, eval_loss: 2.82030e+01
I0515 07:27:24.889542 140128494741248 run_lib.py:152] step: 457850, training_loss: 1.70810e+01
I0515 07:27:31.323578 140128494741248 run_lib.py:152] step: 457900, training_loss: 1.88563e+01
I0515 07:27:31.376118 140128494741248 run_lib.py:165] step: 457900, eval_loss: 3.10055e+01
I0515 07:27:37.577301 140128494741248 run_lib.py:152] step: 457950, training_loss: 2.01363e+01
I0515 07:27:43.825138 140128494741248 run_lib.py:152] step: 458000, training_loss: 2.19899e+01
I0515 07:27:43.876236 140128494741248 run_lib.py:165] step: 458000, eval_loss: 1.46535e+01
I0515 07:27:50.133247 140128494741248 run_lib.py:152] step: 458050, training_loss: 3.47150e+01
I0515 07:27:56.646355 140128494741248 run_lib.py:152] step: 458100, training_loss: 2.01517e+01
I0515 07:27:56.699050 140128494741248 run_lib.py:165] step: 458100, eval_loss: 2.29662e+01
I0515 07:28:03.133605 140128494741248 run_lib.py:152] step: 458150, training_loss: 4.08624e+01
I0515 07:28:09.370191 140128494741248 run_lib.py:152] step: 458200, training_loss: 2.85056e+01
I0515 07:28:09.421193 140128494741248 run_lib.py:165] step: 458200, eval_loss: 2.61061e+01
I0515 07:28:15.978229 140128494741248 run_lib.py:152] step: 458250, training_loss: 3.38788e+01
I0515 07:28:22.185071 140128494741248 run_lib.py:152] step: 458300, training_loss: 3.07254e+01
I0515 07:28:22.234922 140128494741248 run_lib.py:165] step: 458300, eval_loss: 2.42330e+01
I0515 07:28:28.421745 140128494741248 run_lib.py:152] step: 458350, training_loss: 2.34199e+01
I0515 07:28:34.609400 140128494741248 run_lib.py:152] step: 458400, training_loss: 1.89540e+01
I0515 07:28:34.665015 140128494741248 run_lib.py:165] step: 458400, eval_loss: 2.02794e+01
I0515 07:28:41.150247 140128494741248 run_lib.py:152] step: 458450, training_loss: 2.86958e+01
I0515 07:28:47.470371 140128494741248 run_lib.py:152] step: 458500, training_loss: 1.48974e+01
I0515 07:28:47.522316 140128494741248 run_lib.py:165] step: 458500, eval_loss: 2.60181e+01
I0515 07:28:53.812101 140128494741248 run_lib.py:152] step: 458550, training_loss: 4.43914e+01
I0515 07:29:00.325154 140128494741248 run_lib.py:152] step: 458600, training_loss: 3.24909e+01
I0515 07:29:00.376525 140128494741248 run_lib.py:165] step: 458600, eval_loss: 1.53546e+01
I0515 07:29:06.697088 140128494741248 run_lib.py:152] step: 458650, training_loss: 2.65497e+01
I0515 07:29:12.897579 140128494741248 run_lib.py:152] step: 458700, training_loss: 2.68273e+01
I0515 07:29:12.962322 140128494741248 run_lib.py:165] step: 458700, eval_loss: 3.85256e+01
I0515 07:29:19.225872 140128494741248 run_lib.py:152] step: 458750, training_loss: 4.22517e+01
I0515 07:29:25.638647 140128494741248 run_lib.py:152] step: 458800, training_loss: 3.57919e+01
I0515 07:29:25.686608 140128494741248 run_lib.py:165] step: 458800, eval_loss: 3.57028e+01
I0515 07:29:31.979585 140128494741248 run_lib.py:152] step: 458850, training_loss: 4.92551e+01
I0515 07:29:38.220032 140128494741248 run_lib.py:152] step: 458900, training_loss: 3.49094e+01
I0515 07:29:38.272208 140128494741248 run_lib.py:165] step: 458900, eval_loss: 3.42610e+01
I0515 07:29:44.685589 140128494741248 run_lib.py:152] step: 458950, training_loss: 3.46088e+01
I0515 07:29:50.957607 140128494741248 run_lib.py:152] step: 459000, training_loss: 2.81167e+01
I0515 07:29:51.011581 140128494741248 run_lib.py:165] step: 459000, eval_loss: 2.65924e+01
I0515 07:29:57.199723 140128494741248 run_lib.py:152] step: 459050, training_loss: 2.74270e+01
I0515 07:30:03.494995 140128494741248 run_lib.py:152] step: 459100, training_loss: 3.47296e+01
I0515 07:30:03.546585 140128494741248 run_lib.py:165] step: 459100, eval_loss: 3.05663e+01
I0515 07:30:09.990708 140128494741248 run_lib.py:152] step: 459150, training_loss: 4.07058e+01
I0515 07:30:16.221872 140128494741248 run_lib.py:152] step: 459200, training_loss: 4.83120e+01
I0515 07:30:16.272591 140128494741248 run_lib.py:165] step: 459200, eval_loss: 2.70453e+01
I0515 07:30:22.492040 140128494741248 run_lib.py:152] step: 459250, training_loss: 2.09636e+01
I0515 07:30:28.945109 140128494741248 run_lib.py:152] step: 459300, training_loss: 2.94349e+01
I0515 07:30:28.995763 140128494741248 run_lib.py:165] step: 459300, eval_loss: 5.09386e+01
I0515 07:30:35.307396 140128494741248 run_lib.py:152] step: 459350, training_loss: 2.96509e+01
I0515 07:30:41.502458 140128494741248 run_lib.py:152] step: 459400, training_loss: 2.59232e+01
I0515 07:30:41.554094 140128494741248 run_lib.py:165] step: 459400, eval_loss: 3.06503e+01
I0515 07:30:47.757362 140128494741248 run_lib.py:152] step: 459450, training_loss: 3.46732e+01
I0515 07:30:54.290365 140128494741248 run_lib.py:152] step: 459500, training_loss: 3.81567e+01
I0515 07:30:54.343230 140128494741248 run_lib.py:165] step: 459500, eval_loss: 2.43636e+01
I0515 07:31:00.541258 140128494741248 run_lib.py:152] step: 459550, training_loss: 4.09923e+01
I0515 07:31:06.823398 140128494741248 run_lib.py:152] step: 459600, training_loss: 3.09227e+01
I0515 07:31:06.871720 140128494741248 run_lib.py:165] step: 459600, eval_loss: 5.43971e+01
I0515 07:31:13.333445 140128494741248 run_lib.py:152] step: 459650, training_loss: 4.06308e+01
I0515 07:31:19.562275 140128494741248 run_lib.py:152] step: 459700, training_loss: 2.70736e+01
I0515 07:31:19.619249 140128494741248 run_lib.py:165] step: 459700, eval_loss: 2.37401e+01
I0515 07:31:25.975936 140128494741248 run_lib.py:152] step: 459750, training_loss: 2.23712e+01
I0515 07:31:32.227687 140128494741248 run_lib.py:152] step: 459800, training_loss: 3.86169e+01
I0515 07:31:32.279774 140128494741248 run_lib.py:165] step: 459800, eval_loss: 3.06308e+01
I0515 07:31:38.729109 140128494741248 run_lib.py:152] step: 459850, training_loss: 3.65826e+01
I0515 07:31:44.982111 140128494741248 run_lib.py:152] step: 459900, training_loss: 3.28305e+01
I0515 07:31:45.033648 140128494741248 run_lib.py:165] step: 459900, eval_loss: 3.58813e+01
I0515 07:31:51.498843 140128494741248 run_lib.py:152] step: 459950, training_loss: 2.52554e+01
I0515 07:31:57.969023 140128494741248 run_lib.py:152] step: 460000, training_loss: 4.29647e+01
I0515 07:31:58.171906 140128494741248 run_lib.py:165] step: 460000, eval_loss: 2.01152e+01
I0515 07:32:04.432979 140128494741248 run_lib.py:152] step: 460050, training_loss: 4.66532e+01
I0515 07:32:10.707703 140128494741248 run_lib.py:152] step: 460100, training_loss: 3.81715e+01
I0515 07:32:10.764318 140128494741248 run_lib.py:165] step: 460100, eval_loss: 2.85041e+01
I0515 07:32:17.013919 140128494741248 run_lib.py:152] step: 460150, training_loss: 3.68161e+01
I0515 07:32:23.469116 140128494741248 run_lib.py:152] step: 460200, training_loss: 3.15402e+01
I0515 07:32:23.519908 140128494741248 run_lib.py:165] step: 460200, eval_loss: 3.15399e+01
I0515 07:32:29.686243 140128494741248 run_lib.py:152] step: 460250, training_loss: 3.50511e+01
I0515 07:32:35.916972 140128494741248 run_lib.py:152] step: 460300, training_loss: 2.23774e+01
I0515 07:32:35.966912 140128494741248 run_lib.py:165] step: 460300, eval_loss: 4.70507e+01
I0515 07:32:42.456380 140128494741248 run_lib.py:152] step: 460350, training_loss: 2.30000e+01
I0515 07:32:48.649629 140128494741248 run_lib.py:152] step: 460400, training_loss: 4.51437e+01
I0515 07:32:48.699513 140128494741248 run_lib.py:165] step: 460400, eval_loss: 2.20142e+01
I0515 07:32:54.930795 140128494741248 run_lib.py:152] step: 460450, training_loss: 3.27994e+01
I0515 07:33:01.081649 140128494741248 run_lib.py:152] step: 460500, training_loss: 3.39174e+01
I0515 07:33:01.131960 140128494741248 run_lib.py:165] step: 460500, eval_loss: 3.08308e+01
I0515 07:33:07.622461 140128494741248 run_lib.py:152] step: 460550, training_loss: 3.16154e+01
I0515 07:33:13.886384 140128494741248 run_lib.py:152] step: 460600, training_loss: 3.17914e+01
I0515 07:33:13.939314 140128494741248 run_lib.py:165] step: 460600, eval_loss: 1.79581e+01
I0515 07:33:20.037287 140128494741248 run_lib.py:152] step: 460650, training_loss: 1.89064e+01
I0515 07:33:26.409735 140128494741248 run_lib.py:152] step: 460700, training_loss: 2.72579e+01
I0515 07:33:26.462725 140128494741248 run_lib.py:165] step: 460700, eval_loss: 3.04062e+01
I0515 07:33:32.742784 140128494741248 run_lib.py:152] step: 460750, training_loss: 3.95569e+01
I0515 07:33:39.051235 140128494741248 run_lib.py:152] step: 460800, training_loss: 2.22399e+01
I0515 07:33:39.106225 140128494741248 run_lib.py:165] step: 460800, eval_loss: 4.68350e+01
I0515 07:33:45.327863 140128494741248 run_lib.py:152] step: 460850, training_loss: 4.02287e+01
I0515 07:33:51.799353 140128494741248 run_lib.py:152] step: 460900, training_loss: 2.72820e+01
I0515 07:33:51.852768 140128494741248 run_lib.py:165] step: 460900, eval_loss: 3.64201e+01
I0515 07:33:58.064812 140128494741248 run_lib.py:152] step: 460950, training_loss: 3.66876e+01
I0515 07:34:04.355171 140128494741248 run_lib.py:152] step: 461000, training_loss: 3.04126e+01
I0515 07:34:04.409620 140128494741248 run_lib.py:165] step: 461000, eval_loss: 1.78778e+01
I0515 07:34:10.844442 140128494741248 run_lib.py:152] step: 461050, training_loss: 3.32722e+01
I0515 07:34:17.142566 140128494741248 run_lib.py:152] step: 461100, training_loss: 2.05437e+01
I0515 07:34:17.199081 140128494741248 run_lib.py:165] step: 461100, eval_loss: 2.22087e+01
I0515 07:34:23.462819 140128494741248 run_lib.py:152] step: 461150, training_loss: 3.13712e+01
I0515 07:34:29.737109 140128494741248 run_lib.py:152] step: 461200, training_loss: 2.87250e+01
I0515 07:34:29.791759 140128494741248 run_lib.py:165] step: 461200, eval_loss: 2.69849e+01
I0515 07:34:36.235304 140128494741248 run_lib.py:152] step: 461250, training_loss: 2.87681e+01
I0515 07:34:42.512714 140128494741248 run_lib.py:152] step: 461300, training_loss: 4.29225e+01
I0515 07:34:42.564265 140128494741248 run_lib.py:165] step: 461300, eval_loss: 2.64643e+01
I0515 07:34:48.733408 140128494741248 run_lib.py:152] step: 461350, training_loss: 1.75516e+01
I0515 07:34:55.276215 140128494741248 run_lib.py:152] step: 461400, training_loss: 3.18980e+01
I0515 07:34:55.329401 140128494741248 run_lib.py:165] step: 461400, eval_loss: 3.31413e+01
I0515 07:35:01.553038 140128494741248 run_lib.py:152] step: 461450, training_loss: 3.34439e+01
I0515 07:35:07.842038 140128494741248 run_lib.py:152] step: 461500, training_loss: 3.02797e+01
I0515 07:35:07.895723 140128494741248 run_lib.py:165] step: 461500, eval_loss: 4.20315e+01
I0515 07:35:14.110233 140128494741248 run_lib.py:152] step: 461550, training_loss: 3.56583e+01
I0515 07:35:20.548289 140128494741248 run_lib.py:152] step: 461600, training_loss: 3.59184e+01
I0515 07:35:20.598475 140128494741248 run_lib.py:165] step: 461600, eval_loss: 1.96571e+01
I0515 07:35:26.844658 140128494741248 run_lib.py:152] step: 461650, training_loss: 4.47786e+01
I0515 07:35:32.999649 140128494741248 run_lib.py:152] step: 461700, training_loss: 3.19480e+01
I0515 07:35:33.052676 140128494741248 run_lib.py:165] step: 461700, eval_loss: 3.80175e+01
I0515 07:35:39.543029 140128494741248 run_lib.py:152] step: 461750, training_loss: 2.33270e+01
I0515 07:35:45.684270 140128494741248 run_lib.py:152] step: 461800, training_loss: 2.33508e+01
I0515 07:35:45.732079 140128494741248 run_lib.py:165] step: 461800, eval_loss: 2.52052e+01
I0515 07:35:52.043849 140128494741248 run_lib.py:152] step: 461850, training_loss: 2.74135e+01
I0515 07:35:58.318760 140128494741248 run_lib.py:152] step: 461900, training_loss: 2.55965e+01
I0515 07:35:58.369947 140128494741248 run_lib.py:165] step: 461900, eval_loss: 2.24984e+01
I0515 07:36:04.752817 140128494741248 run_lib.py:152] step: 461950, training_loss: 1.72602e+01
I0515 07:36:11.004075 140128494741248 run_lib.py:152] step: 462000, training_loss: 3.12962e+01
I0515 07:36:11.060943 140128494741248 run_lib.py:165] step: 462000, eval_loss: 3.68680e+01
I0515 07:36:17.234143 140128494741248 run_lib.py:152] step: 462050, training_loss: 2.76083e+01
I0515 07:36:23.768685 140128494741248 run_lib.py:152] step: 462100, training_loss: 3.81799e+01
I0515 07:36:23.819395 140128494741248 run_lib.py:165] step: 462100, eval_loss: 3.13412e+01
I0515 07:36:29.983367 140128494741248 run_lib.py:152] step: 462150, training_loss: 1.84004e+01
I0515 07:36:36.283872 140128494741248 run_lib.py:152] step: 462200, training_loss: 1.73807e+01
I0515 07:36:36.335375 140128494741248 run_lib.py:165] step: 462200, eval_loss: 1.37841e+01
I0515 07:36:42.438147 140128494741248 run_lib.py:152] step: 462250, training_loss: 3.06819e+01
I0515 07:36:48.974855 140128494741248 run_lib.py:152] step: 462300, training_loss: 1.83114e+01
I0515 07:36:49.032431 140128494741248 run_lib.py:165] step: 462300, eval_loss: 3.06116e+01
I0515 07:36:55.208679 140128494741248 run_lib.py:152] step: 462350, training_loss: 1.88166e+01
I0515 07:37:01.464211 140128494741248 run_lib.py:152] step: 462400, training_loss: 4.65549e+01
I0515 07:37:01.515316 140128494741248 run_lib.py:165] step: 462400, eval_loss: 1.86822e+01
I0515 07:37:08.157882 140128494741248 run_lib.py:152] step: 462450, training_loss: 3.80913e+01
I0515 07:37:14.341280 140128494741248 run_lib.py:152] step: 462500, training_loss: 2.92431e+01
I0515 07:37:14.410646 140128494741248 run_lib.py:165] step: 462500, eval_loss: 2.96249e+01
I0515 07:37:20.657858 140128494741248 run_lib.py:152] step: 462550, training_loss: 3.17841e+01
I0515 07:37:26.989439 140128494741248 run_lib.py:152] step: 462600, training_loss: 2.95131e+01
I0515 07:37:27.044642 140128494741248 run_lib.py:165] step: 462600, eval_loss: 3.20152e+01
I0515 07:37:33.471640 140128494741248 run_lib.py:152] step: 462650, training_loss: 2.38299e+01
I0515 07:37:39.707322 140128494741248 run_lib.py:152] step: 462700, training_loss: 2.03247e+01
I0515 07:37:39.761867 140128494741248 run_lib.py:165] step: 462700, eval_loss: 3.72320e+01
I0515 07:37:46.028248 140128494741248 run_lib.py:152] step: 462750, training_loss: 3.59373e+01
I0515 07:37:52.522333 140128494741248 run_lib.py:152] step: 462800, training_loss: 4.26939e+01
I0515 07:37:52.573598 140128494741248 run_lib.py:165] step: 462800, eval_loss: 2.52702e+01
I0515 07:37:58.733206 140128494741248 run_lib.py:152] step: 462850, training_loss: 3.96144e+01
I0515 07:38:04.827802 140128494741248 run_lib.py:152] step: 462900, training_loss: 3.29261e+01
I0515 07:38:04.879868 140128494741248 run_lib.py:165] step: 462900, eval_loss: 3.92688e+01
I0515 07:38:11.248231 140128494741248 run_lib.py:152] step: 462950, training_loss: 4.50255e+01
I0515 07:38:17.788998 140128494741248 run_lib.py:152] step: 463000, training_loss: 1.46377e+01
I0515 07:38:17.839076 140128494741248 run_lib.py:165] step: 463000, eval_loss: 4.08970e+01
I0515 07:38:24.093877 140128494741248 run_lib.py:152] step: 463050, training_loss: 2.86311e+01
I0515 07:38:30.454033 140128494741248 run_lib.py:152] step: 463100, training_loss: 4.96188e+01
I0515 07:38:30.508182 140128494741248 run_lib.py:165] step: 463100, eval_loss: 1.74158e+01
I0515 07:38:37.066825 140128494741248 run_lib.py:152] step: 463150, training_loss: 3.00269e+01
I0515 07:38:43.223285 140128494741248 run_lib.py:152] step: 463200, training_loss: 2.96204e+01
I0515 07:38:43.279257 140128494741248 run_lib.py:165] step: 463200, eval_loss: 2.84309e+01
I0515 07:38:49.445871 140128494741248 run_lib.py:152] step: 463250, training_loss: 4.16810e+01
I0515 07:38:55.811182 140128494741248 run_lib.py:152] step: 463300, training_loss: 2.15292e+01
I0515 07:38:55.862028 140128494741248 run_lib.py:165] step: 463300, eval_loss: 2.71240e+01
I0515 07:39:02.344127 140128494741248 run_lib.py:152] step: 463350, training_loss: 4.84677e+01
I0515 07:39:08.622072 140128494741248 run_lib.py:152] step: 463400, training_loss: 3.08796e+01
I0515 07:39:08.672827 140128494741248 run_lib.py:165] step: 463400, eval_loss: 2.47624e+01
I0515 07:39:15.024112 140128494741248 run_lib.py:152] step: 463450, training_loss: 2.96231e+01
I0515 07:39:21.366246 140128494741248 run_lib.py:152] step: 463500, training_loss: 2.69700e+01
I0515 07:39:21.419225 140128494741248 run_lib.py:165] step: 463500, eval_loss: 2.46442e+01
I0515 07:39:27.684509 140128494741248 run_lib.py:152] step: 463550, training_loss: 2.49212e+01
I0515 07:39:33.940666 140128494741248 run_lib.py:152] step: 463600, training_loss: 3.86989e+01
I0515 07:39:33.996194 140128494741248 run_lib.py:165] step: 463600, eval_loss: 2.63654e+01
I0515 07:39:40.251385 140128494741248 run_lib.py:152] step: 463650, training_loss: 2.99013e+01
I0515 07:39:46.653806 140128494741248 run_lib.py:152] step: 463700, training_loss: 2.20844e+01
I0515 07:39:46.702569 140128494741248 run_lib.py:165] step: 463700, eval_loss: 2.48582e+01
I0515 07:39:52.987228 140128494741248 run_lib.py:152] step: 463750, training_loss: 3.27453e+01
I0515 07:39:59.337543 140128494741248 run_lib.py:152] step: 463800, training_loss: 3.03877e+01
I0515 07:39:59.390337 140128494741248 run_lib.py:165] step: 463800, eval_loss: 3.63748e+01
I0515 07:40:05.821173 140128494741248 run_lib.py:152] step: 463850, training_loss: 3.79840e+01
I0515 07:40:12.151431 140128494741248 run_lib.py:152] step: 463900, training_loss: 4.43113e+01
I0515 07:40:12.209813 140128494741248 run_lib.py:165] step: 463900, eval_loss: 2.58418e+01
I0515 07:40:18.419341 140128494741248 run_lib.py:152] step: 463950, training_loss: 2.31858e+01
I0515 07:40:24.565992 140128494741248 run_lib.py:152] step: 464000, training_loss: 3.84367e+01
I0515 07:40:24.614200 140128494741248 run_lib.py:165] step: 464000, eval_loss: 4.10583e+01
I0515 07:40:31.077511 140128494741248 run_lib.py:152] step: 464050, training_loss: 2.35260e+01
I0515 07:40:37.284773 140128494741248 run_lib.py:152] step: 464100, training_loss: 4.44289e+01
I0515 07:40:37.336662 140128494741248 run_lib.py:165] step: 464100, eval_loss: 2.49311e+01
I0515 07:40:43.540007 140128494741248 run_lib.py:152] step: 464150, training_loss: 3.75677e+01
I0515 07:40:49.962440 140128494741248 run_lib.py:152] step: 464200, training_loss: 3.88221e+01
I0515 07:40:50.012493 140128494741248 run_lib.py:165] step: 464200, eval_loss: 2.52242e+01
I0515 07:40:56.214083 140128494741248 run_lib.py:152] step: 464250, training_loss: 3.05093e+01
I0515 07:41:02.427454 140128494741248 run_lib.py:152] step: 464300, training_loss: 4.17793e+01
I0515 07:41:02.477583 140128494741248 run_lib.py:165] step: 464300, eval_loss: 4.11372e+01
I0515 07:41:08.698555 140128494741248 run_lib.py:152] step: 464350, training_loss: 3.30970e+01
I0515 07:41:15.286089 140128494741248 run_lib.py:152] step: 464400, training_loss: 4.87990e+01
I0515 07:41:15.348129 140128494741248 run_lib.py:165] step: 464400, eval_loss: 4.24940e+01
I0515 07:41:21.634762 140128494741248 run_lib.py:152] step: 464450, training_loss: 2.51797e+01
I0515 07:41:27.790787 140128494741248 run_lib.py:152] step: 464500, training_loss: 1.83482e+01
I0515 07:41:27.838706 140128494741248 run_lib.py:165] step: 464500, eval_loss: 2.49690e+01
I0515 07:41:34.335639 140128494741248 run_lib.py:152] step: 464550, training_loss: 2.76464e+01
I0515 07:41:40.588728 140128494741248 run_lib.py:152] step: 464600, training_loss: 2.98829e+01
I0515 07:41:40.641664 140128494741248 run_lib.py:165] step: 464600, eval_loss: 3.03492e+01
I0515 07:41:46.786869 140128494741248 run_lib.py:152] step: 464650, training_loss: 2.64204e+01
I0515 07:41:53.075560 140128494741248 run_lib.py:152] step: 464700, training_loss: 2.59914e+01
I0515 07:41:53.127871 140128494741248 run_lib.py:165] step: 464700, eval_loss: 2.17568e+01
I0515 07:41:59.480358 140128494741248 run_lib.py:152] step: 464750, training_loss: 3.04506e+01
I0515 07:42:05.680227 140128494741248 run_lib.py:152] step: 464800, training_loss: 2.74472e+01
I0515 07:42:05.729660 140128494741248 run_lib.py:165] step: 464800, eval_loss: 2.10249e+01
I0515 07:42:11.964198 140128494741248 run_lib.py:152] step: 464850, training_loss: 3.16941e+01
I0515 07:42:18.441496 140128494741248 run_lib.py:152] step: 464900, training_loss: 3.92757e+01
I0515 07:42:18.495091 140128494741248 run_lib.py:165] step: 464900, eval_loss: 1.54286e+01
I0515 07:42:24.663109 140128494741248 run_lib.py:152] step: 464950, training_loss: 3.41467e+01
I0515 07:42:30.945423 140128494741248 run_lib.py:152] step: 465000, training_loss: 2.36241e+01
I0515 07:42:30.996201 140128494741248 run_lib.py:165] step: 465000, eval_loss: 2.65075e+01
I0515 07:42:37.178295 140128494741248 run_lib.py:152] step: 465050, training_loss: 2.54112e+01
I0515 07:42:43.621634 140128494741248 run_lib.py:152] step: 465100, training_loss: 4.26824e+01
I0515 07:42:43.675889 140128494741248 run_lib.py:165] step: 465100, eval_loss: 3.85212e+01
I0515 07:42:49.924752 140128494741248 run_lib.py:152] step: 465150, training_loss: 2.77279e+01
I0515 07:42:56.111618 140128494741248 run_lib.py:152] step: 465200, training_loss: 2.52332e+01
I0515 07:42:56.163079 140128494741248 run_lib.py:165] step: 465200, eval_loss: 2.79302e+01
I0515 07:43:02.683675 140128494741248 run_lib.py:152] step: 465250, training_loss: 2.51485e+01
I0515 07:43:08.914630 140128494741248 run_lib.py:152] step: 465300, training_loss: 2.56174e+01
I0515 07:43:08.971053 140128494741248 run_lib.py:165] step: 465300, eval_loss: 2.99938e+01
I0515 07:43:15.175569 140128494741248 run_lib.py:152] step: 465350, training_loss: 4.70544e+01
I0515 07:43:21.267635 140128494741248 run_lib.py:152] step: 465400, training_loss: 2.41906e+01
I0515 07:43:21.320495 140128494741248 run_lib.py:165] step: 465400, eval_loss: 3.28441e+01
I0515 07:43:27.823514 140128494741248 run_lib.py:152] step: 465450, training_loss: 3.16664e+01
I0515 07:43:34.080846 140128494741248 run_lib.py:152] step: 465500, training_loss: 2.75501e+01
I0515 07:43:34.130248 140128494741248 run_lib.py:165] step: 465500, eval_loss: 3.65184e+01
I0515 07:43:40.349952 140128494741248 run_lib.py:152] step: 465550, training_loss: 3.66085e+01
I0515 07:43:46.811458 140128494741248 run_lib.py:152] step: 465600, training_loss: 3.43875e+01
I0515 07:43:46.858560 140128494741248 run_lib.py:165] step: 465600, eval_loss: 4.14613e+01
I0515 07:43:53.077859 140128494741248 run_lib.py:152] step: 465650, training_loss: 3.47437e+01
I0515 07:43:59.296785 140128494741248 run_lib.py:152] step: 465700, training_loss: 2.84157e+01
I0515 07:43:59.349068 140128494741248 run_lib.py:165] step: 465700, eval_loss: 2.59084e+01
I0515 07:44:05.569521 140128494741248 run_lib.py:152] step: 465750, training_loss: 1.99959e+01
I0515 07:44:12.146122 140128494741248 run_lib.py:152] step: 465800, training_loss: 3.43375e+01
I0515 07:44:12.201444 140128494741248 run_lib.py:165] step: 465800, eval_loss: 1.99863e+01
I0515 07:44:18.556291 140128494741248 run_lib.py:152] step: 465850, training_loss: 3.14528e+01
I0515 07:44:24.792875 140128494741248 run_lib.py:152] step: 465900, training_loss: 3.10138e+01
I0515 07:44:24.845510 140128494741248 run_lib.py:165] step: 465900, eval_loss: 3.92436e+01
I0515 07:44:31.267208 140128494741248 run_lib.py:152] step: 465950, training_loss: 3.72396e+01
I0515 07:44:37.339989 140128494741248 run_lib.py:152] step: 466000, training_loss: 3.35537e+01
I0515 07:44:37.391213 140128494741248 run_lib.py:165] step: 466000, eval_loss: 3.14435e+01
I0515 07:44:43.659674 140128494741248 run_lib.py:152] step: 466050, training_loss: 2.48557e+01
I0515 07:44:49.833575 140128494741248 run_lib.py:152] step: 466100, training_loss: 3.80061e+01
I0515 07:44:49.886262 140128494741248 run_lib.py:165] step: 466100, eval_loss: 3.34998e+01
I0515 07:44:56.391720 140128494741248 run_lib.py:152] step: 466150, training_loss: 2.36188e+01
I0515 07:45:02.717102 140128494741248 run_lib.py:152] step: 466200, training_loss: 2.80618e+01
I0515 07:45:02.772277 140128494741248 run_lib.py:165] step: 466200, eval_loss: 2.98372e+01
I0515 07:45:08.942329 140128494741248 run_lib.py:152] step: 466250, training_loss: 2.80326e+01
I0515 07:45:15.428191 140128494741248 run_lib.py:152] step: 466300, training_loss: 2.39810e+01
I0515 07:45:15.483120 140128494741248 run_lib.py:165] step: 466300, eval_loss: 2.36115e+01
I0515 07:45:21.800620 140128494741248 run_lib.py:152] step: 466350, training_loss: 2.61672e+01
I0515 07:45:28.017531 140128494741248 run_lib.py:152] step: 466400, training_loss: 2.29820e+01
I0515 07:45:28.074871 140128494741248 run_lib.py:165] step: 466400, eval_loss: 2.69050e+01
I0515 07:45:34.339621 140128494741248 run_lib.py:152] step: 466450, training_loss: 2.13787e+01
I0515 07:45:40.774952 140128494741248 run_lib.py:152] step: 466500, training_loss: 3.31361e+01
I0515 07:45:40.825787 140128494741248 run_lib.py:165] step: 466500, eval_loss: 2.98054e+01
I0515 07:45:47.061898 140128494741248 run_lib.py:152] step: 466550, training_loss: 2.17496e+01
I0515 07:45:53.278826 140128494741248 run_lib.py:152] step: 466600, training_loss: 3.87660e+01
I0515 07:45:53.333774 140128494741248 run_lib.py:165] step: 466600, eval_loss: 3.48633e+01
I0515 07:45:59.752226 140128494741248 run_lib.py:152] step: 466650, training_loss: 3.22282e+01
I0515 07:46:05.956406 140128494741248 run_lib.py:152] step: 466700, training_loss: 1.87967e+01
I0515 07:46:06.004727 140128494741248 run_lib.py:165] step: 466700, eval_loss: 1.43812e+01
I0515 07:46:12.232435 140128494741248 run_lib.py:152] step: 466750, training_loss: 2.32939e+01
I0515 07:46:18.417748 140128494741248 run_lib.py:152] step: 466800, training_loss: 4.68776e+01
I0515 07:46:18.472241 140128494741248 run_lib.py:165] step: 466800, eval_loss: 3.39915e+01
I0515 07:46:24.949855 140128494741248 run_lib.py:152] step: 466850, training_loss: 3.00756e+01
I0515 07:46:31.158404 140128494741248 run_lib.py:152] step: 466900, training_loss: 1.90384e+01
I0515 07:46:31.210280 140128494741248 run_lib.py:165] step: 466900, eval_loss: 3.62549e+01
I0515 07:46:37.459002 140128494741248 run_lib.py:152] step: 466950, training_loss: 2.31713e+01
I0515 07:46:43.855567 140128494741248 run_lib.py:152] step: 467000, training_loss: 3.69383e+01
I0515 07:46:43.908138 140128494741248 run_lib.py:165] step: 467000, eval_loss: 2.90984e+01
I0515 07:46:50.148326 140128494741248 run_lib.py:152] step: 467050, training_loss: 2.78631e+01
I0515 07:46:56.384888 140128494741248 run_lib.py:152] step: 467100, training_loss: 3.34550e+01
I0515 07:46:56.448585 140128494741248 run_lib.py:165] step: 467100, eval_loss: 1.91922e+01
I0515 07:47:02.640115 140128494741248 run_lib.py:152] step: 467150, training_loss: 4.96503e+01
I0515 07:47:09.167321 140128494741248 run_lib.py:152] step: 467200, training_loss: 3.21808e+01
I0515 07:47:09.215564 140128494741248 run_lib.py:165] step: 467200, eval_loss: 3.18859e+01
I0515 07:47:15.442075 140128494741248 run_lib.py:152] step: 467250, training_loss: 3.16838e+01
I0515 07:47:21.483046 140128494741248 run_lib.py:152] step: 467300, training_loss: 4.08426e+01
I0515 07:47:21.532374 140128494741248 run_lib.py:165] step: 467300, eval_loss: 2.26252e+01
I0515 07:47:28.013511 140128494741248 run_lib.py:152] step: 467350, training_loss: 3.55572e+01
I0515 07:47:34.142935 140128494741248 run_lib.py:152] step: 467400, training_loss: 2.40759e+01
I0515 07:47:34.191569 140128494741248 run_lib.py:165] step: 467400, eval_loss: 2.82343e+01
I0515 07:47:40.478248 140128494741248 run_lib.py:152] step: 467450, training_loss: 2.77315e+01
I0515 07:47:46.669655 140128494741248 run_lib.py:152] step: 467500, training_loss: 3.41487e+01
I0515 07:47:46.719684 140128494741248 run_lib.py:165] step: 467500, eval_loss: 2.96124e+01
I0515 07:47:53.179745 140128494741248 run_lib.py:152] step: 467550, training_loss: 2.58592e+01
I0515 07:47:59.309223 140128494741248 run_lib.py:152] step: 467600, training_loss: 2.65973e+01
I0515 07:47:59.360867 140128494741248 run_lib.py:165] step: 467600, eval_loss: 3.05708e+01
I0515 07:48:05.607472 140128494741248 run_lib.py:152] step: 467650, training_loss: 2.05776e+01
I0515 07:48:12.082705 140128494741248 run_lib.py:152] step: 467700, training_loss: 3.08771e+01
I0515 07:48:12.134070 140128494741248 run_lib.py:165] step: 467700, eval_loss: 3.69864e+01
I0515 07:48:18.386321 140128494741248 run_lib.py:152] step: 467750, training_loss: 1.85693e+01
I0515 07:48:24.527557 140128494741248 run_lib.py:152] step: 467800, training_loss: 3.72009e+01
I0515 07:48:24.582349 140128494741248 run_lib.py:165] step: 467800, eval_loss: 1.81149e+01
I0515 07:48:30.852303 140128494741248 run_lib.py:152] step: 467850, training_loss: 2.82501e+01
I0515 07:48:37.315394 140128494741248 run_lib.py:152] step: 467900, training_loss: 3.59035e+01
I0515 07:48:37.366680 140128494741248 run_lib.py:165] step: 467900, eval_loss: 4.35580e+01
I0515 07:48:43.581895 140128494741248 run_lib.py:152] step: 467950, training_loss: 3.09669e+01
I0515 07:48:49.941885 140128494741248 run_lib.py:152] step: 468000, training_loss: 3.60624e+01
I0515 07:48:49.991602 140128494741248 run_lib.py:165] step: 468000, eval_loss: 3.73845e+01
I0515 07:48:56.337413 140128494741248 run_lib.py:152] step: 468050, training_loss: 3.13267e+01
I0515 07:49:02.548490 140128494741248 run_lib.py:152] step: 468100, training_loss: 3.29492e+01
I0515 07:49:02.600927 140128494741248 run_lib.py:165] step: 468100, eval_loss: 2.74983e+01
I0515 07:49:08.780117 140128494741248 run_lib.py:152] step: 468150, training_loss: 1.59629e+01
I0515 07:49:15.071741 140128494741248 run_lib.py:152] step: 468200, training_loss: 3.22198e+01
I0515 07:49:15.126272 140128494741248 run_lib.py:165] step: 468200, eval_loss: 3.91158e+01
I0515 07:49:21.785520 140128494741248 run_lib.py:152] step: 468250, training_loss: 2.86597e+01
I0515 07:49:28.141038 140128494741248 run_lib.py:152] step: 468300, training_loss: 3.09908e+01
I0515 07:49:28.194755 140128494741248 run_lib.py:165] step: 468300, eval_loss: 2.71688e+01
I0515 07:49:34.549210 140128494741248 run_lib.py:152] step: 468350, training_loss: 2.42613e+01
I0515 07:49:40.946327 140128494741248 run_lib.py:152] step: 468400, training_loss: 3.03110e+01
I0515 07:49:40.998381 140128494741248 run_lib.py:165] step: 468400, eval_loss: 3.68383e+01
I0515 07:49:47.236775 140128494741248 run_lib.py:152] step: 468450, training_loss: 3.28574e+01
I0515 07:49:53.445027 140128494741248 run_lib.py:152] step: 468500, training_loss: 2.02444e+01
I0515 07:49:53.496422 140128494741248 run_lib.py:165] step: 468500, eval_loss: 2.82840e+01
I0515 07:49:59.744646 140128494741248 run_lib.py:152] step: 468550, training_loss: 5.09532e+01
I0515 07:50:06.257787 140128494741248 run_lib.py:152] step: 468600, training_loss: 2.74946e+01
I0515 07:50:06.307665 140128494741248 run_lib.py:165] step: 468600, eval_loss: 3.19592e+01
I0515 07:50:12.591964 140128494741248 run_lib.py:152] step: 468650, training_loss: 3.57073e+01
I0515 07:50:18.934931 140128494741248 run_lib.py:152] step: 468700, training_loss: 2.59420e+01
I0515 07:50:18.991982 140128494741248 run_lib.py:165] step: 468700, eval_loss: 2.84519e+01
I0515 07:50:25.442176 140128494741248 run_lib.py:152] step: 468750, training_loss: 2.29574e+01
I0515 07:50:31.645774 140128494741248 run_lib.py:152] step: 468800, training_loss: 3.33980e+01
I0515 07:50:31.699767 140128494741248 run_lib.py:165] step: 468800, eval_loss: 3.06499e+01
I0515 07:50:37.974861 140128494741248 run_lib.py:152] step: 468850, training_loss: 2.53557e+01
I0515 07:50:44.212142 140128494741248 run_lib.py:152] step: 468900, training_loss: 2.13905e+01
I0515 07:50:44.269186 140128494741248 run_lib.py:165] step: 468900, eval_loss: 4.50668e+01
I0515 07:50:50.641964 140128494741248 run_lib.py:152] step: 468950, training_loss: 3.34178e+01
I0515 07:50:56.957405 140128494741248 run_lib.py:152] step: 469000, training_loss: 1.63306e+01
I0515 07:50:57.018121 140128494741248 run_lib.py:165] step: 469000, eval_loss: 3.27839e+01
I0515 07:51:03.257666 140128494741248 run_lib.py:152] step: 469050, training_loss: 2.77811e+01
I0515 07:51:09.754226 140128494741248 run_lib.py:152] step: 469100, training_loss: 4.19953e+01
I0515 07:51:09.804849 140128494741248 run_lib.py:165] step: 469100, eval_loss: 2.96963e+01
I0515 07:51:16.003588 140128494741248 run_lib.py:152] step: 469150, training_loss: 2.29237e+01
I0515 07:51:22.260195 140128494741248 run_lib.py:152] step: 469200, training_loss: 2.69553e+01
I0515 07:51:22.310881 140128494741248 run_lib.py:165] step: 469200, eval_loss: 3.36438e+01
I0515 07:51:28.631173 140128494741248 run_lib.py:152] step: 469250, training_loss: 2.37108e+01
I0515 07:51:35.092911 140128494741248 run_lib.py:152] step: 469300, training_loss: 3.54759e+01
I0515 07:51:35.147275 140128494741248 run_lib.py:165] step: 469300, eval_loss: 1.59558e+01
I0515 07:51:41.438980 140128494741248 run_lib.py:152] step: 469350, training_loss: 3.82239e+01
I0515 07:51:47.745258 140128494741248 run_lib.py:152] step: 469400, training_loss: 2.74034e+01
I0515 07:51:47.797946 140128494741248 run_lib.py:165] step: 469400, eval_loss: 2.45939e+01
I0515 07:51:54.290212 140128494741248 run_lib.py:152] step: 469450, training_loss: 4.83089e+01
I0515 07:52:00.482955 140128494741248 run_lib.py:152] step: 469500, training_loss: 3.11050e+01
I0515 07:52:00.534067 140128494741248 run_lib.py:165] step: 469500, eval_loss: 2.40312e+01
I0515 07:52:06.732556 140128494741248 run_lib.py:152] step: 469550, training_loss: 2.20112e+01
I0515 07:52:13.050220 140128494741248 run_lib.py:152] step: 469600, training_loss: 4.53560e+01
I0515 07:52:13.105477 140128494741248 run_lib.py:165] step: 469600, eval_loss: 2.38210e+01
I0515 07:52:19.472672 140128494741248 run_lib.py:152] step: 469650, training_loss: 3.15965e+01
I0515 07:52:25.715125 140128494741248 run_lib.py:152] step: 469700, training_loss: 2.98819e+01
I0515 07:52:25.773196 140128494741248 run_lib.py:165] step: 469700, eval_loss: 2.95205e+01
I0515 07:52:31.974743 140128494741248 run_lib.py:152] step: 469750, training_loss: 3.61490e+01
I0515 07:52:38.525264 140128494741248 run_lib.py:152] step: 469800, training_loss: 3.57773e+01
I0515 07:52:38.578560 140128494741248 run_lib.py:165] step: 469800, eval_loss: 3.68953e+01
I0515 07:52:44.702027 140128494741248 run_lib.py:152] step: 469850, training_loss: 2.82873e+01
I0515 07:52:50.916287 140128494741248 run_lib.py:152] step: 469900, training_loss: 2.38807e+01
I0515 07:52:50.970353 140128494741248 run_lib.py:165] step: 469900, eval_loss: 2.95903e+01
I0515 07:52:57.255574 140128494741248 run_lib.py:152] step: 469950, training_loss: 3.90545e+01
I0515 07:53:03.876047 140128494741248 run_lib.py:152] step: 470000, training_loss: 4.05586e+01
I0515 07:53:04.083543 140128494741248 run_lib.py:165] step: 470000, eval_loss: 3.55303e+01
I0515 07:53:10.328307 140128494741248 run_lib.py:152] step: 470050, training_loss: 2.38922e+01
I0515 07:53:16.645302 140128494741248 run_lib.py:152] step: 470100, training_loss: 3.63481e+01
I0515 07:53:16.701847 140128494741248 run_lib.py:165] step: 470100, eval_loss: 2.99268e+01
I0515 07:53:23.123499 140128494741248 run_lib.py:152] step: 470150, training_loss: 3.96711e+01
I0515 07:53:29.343079 140128494741248 run_lib.py:152] step: 470200, training_loss: 3.80255e+01
I0515 07:53:29.394592 140128494741248 run_lib.py:165] step: 470200, eval_loss: 2.61220e+01
I0515 07:53:35.584831 140128494741248 run_lib.py:152] step: 470250, training_loss: 2.09380e+01
I0515 07:53:41.759837 140128494741248 run_lib.py:152] step: 470300, training_loss: 2.20625e+01
I0515 07:53:41.811606 140128494741248 run_lib.py:165] step: 470300, eval_loss: 3.23721e+01
I0515 07:53:48.302461 140128494741248 run_lib.py:152] step: 470350, training_loss: 3.22695e+01
I0515 07:53:54.448219 140128494741248 run_lib.py:152] step: 470400, training_loss: 3.97766e+01
I0515 07:53:54.496715 140128494741248 run_lib.py:165] step: 470400, eval_loss: 2.03727e+01
I0515 07:54:00.691244 140128494741248 run_lib.py:152] step: 470450, training_loss: 4.17452e+01
I0515 07:54:07.166173 140128494741248 run_lib.py:152] step: 470500, training_loss: 5.47929e+01
I0515 07:54:07.220504 140128494741248 run_lib.py:165] step: 470500, eval_loss: 4.92938e+01
I0515 07:54:13.418096 140128494741248 run_lib.py:152] step: 470550, training_loss: 2.66129e+01
I0515 07:54:19.670030 140128494741248 run_lib.py:152] step: 470600, training_loss: 3.15807e+01
I0515 07:54:19.724972 140128494741248 run_lib.py:165] step: 470600, eval_loss: 2.65684e+01
I0515 07:54:25.902389 140128494741248 run_lib.py:152] step: 470650, training_loss: 3.28096e+01
I0515 07:54:32.470350 140128494741248 run_lib.py:152] step: 470700, training_loss: 4.86211e+01
I0515 07:54:32.522728 140128494741248 run_lib.py:165] step: 470700, eval_loss: 3.34270e+01
I0515 07:54:38.645864 140128494741248 run_lib.py:152] step: 470750, training_loss: 2.98507e+01
I0515 07:54:44.845156 140128494741248 run_lib.py:152] step: 470800, training_loss: 2.95968e+01
I0515 07:54:44.899143 140128494741248 run_lib.py:165] step: 470800, eval_loss: 2.12513e+01
I0515 07:54:51.333827 140128494741248 run_lib.py:152] step: 470850, training_loss: 3.57124e+01
I0515 07:54:57.663518 140128494741248 run_lib.py:152] step: 470900, training_loss: 4.57119e+01
I0515 07:54:57.718572 140128494741248 run_lib.py:165] step: 470900, eval_loss: 2.82370e+01
I0515 07:55:03.924103 140128494741248 run_lib.py:152] step: 470950, training_loss: 4.34225e+01
I0515 07:55:10.206046 140128494741248 run_lib.py:152] step: 471000, training_loss: 2.35478e+01
I0515 07:55:10.263223 140128494741248 run_lib.py:165] step: 471000, eval_loss: 2.66126e+01
I0515 07:55:16.762690 140128494741248 run_lib.py:152] step: 471050, training_loss: 3.83374e+01
I0515 07:55:23.099845 140128494741248 run_lib.py:152] step: 471100, training_loss: 2.25244e+01
I0515 07:55:23.151322 140128494741248 run_lib.py:165] step: 471100, eval_loss: 2.50779e+01
I0515 07:55:29.377852 140128494741248 run_lib.py:152] step: 471150, training_loss: 3.47296e+01
I0515 07:55:35.885542 140128494741248 run_lib.py:152] step: 471200, training_loss: 3.70461e+01
I0515 07:55:35.937218 140128494741248 run_lib.py:165] step: 471200, eval_loss: 2.23284e+01
I0515 07:55:42.109682 140128494741248 run_lib.py:152] step: 471250, training_loss: 3.01610e+01
I0515 07:55:48.469491 140128494741248 run_lib.py:152] step: 471300, training_loss: 6.06130e+01
I0515 07:55:48.520190 140128494741248 run_lib.py:165] step: 471300, eval_loss: 2.88658e+01
I0515 07:55:54.721015 140128494741248 run_lib.py:152] step: 471350, training_loss: 3.18510e+01
I0515 07:56:01.183190 140128494741248 run_lib.py:152] step: 471400, training_loss: 1.64404e+01
I0515 07:56:01.234961 140128494741248 run_lib.py:165] step: 471400, eval_loss: 3.33054e+01
I0515 07:56:07.451315 140128494741248 run_lib.py:152] step: 471450, training_loss: 3.24272e+01
I0515 07:56:13.641127 140128494741248 run_lib.py:152] step: 471500, training_loss: 2.99963e+01
I0515 07:56:13.691453 140128494741248 run_lib.py:165] step: 471500, eval_loss: 3.57730e+01
I0515 07:56:20.198558 140128494741248 run_lib.py:152] step: 471550, training_loss: 1.87442e+01
I0515 07:56:26.392579 140128494741248 run_lib.py:152] step: 471600, training_loss: 2.81527e+01
I0515 07:56:26.442575 140128494741248 run_lib.py:165] step: 471600, eval_loss: 2.15146e+01
I0515 07:56:32.719086 140128494741248 run_lib.py:152] step: 471650, training_loss: 3.49631e+01
I0515 07:56:38.976778 140128494741248 run_lib.py:152] step: 471700, training_loss: 1.98752e+01
I0515 07:56:39.030691 140128494741248 run_lib.py:165] step: 471700, eval_loss: 3.15188e+01
I0515 07:56:45.538374 140128494741248 run_lib.py:152] step: 471750, training_loss: 3.66438e+01
I0515 07:56:51.850279 140128494741248 run_lib.py:152] step: 471800, training_loss: 4.16452e+01
I0515 07:56:51.906723 140128494741248 run_lib.py:165] step: 471800, eval_loss: 2.71129e+01
I0515 07:56:58.170817 140128494741248 run_lib.py:152] step: 471850, training_loss: 2.48059e+01
I0515 07:57:04.663559 140128494741248 run_lib.py:152] step: 471900, training_loss: 2.64139e+01
I0515 07:57:04.716094 140128494741248 run_lib.py:165] step: 471900, eval_loss: 2.50931e+01
I0515 07:57:10.910897 140128494741248 run_lib.py:152] step: 471950, training_loss: 2.96003e+01
I0515 07:57:17.220774 140128494741248 run_lib.py:152] step: 472000, training_loss: 2.20432e+01
I0515 07:57:17.276914 140128494741248 run_lib.py:165] step: 472000, eval_loss: 3.09377e+01
I0515 07:57:23.547183 140128494741248 run_lib.py:152] step: 472050, training_loss: 2.54545e+01
I0515 07:57:29.990374 140128494741248 run_lib.py:152] step: 472100, training_loss: 2.55598e+01
I0515 07:57:30.042278 140128494741248 run_lib.py:165] step: 472100, eval_loss: 2.47320e+01
I0515 07:57:36.224521 140128494741248 run_lib.py:152] step: 472150, training_loss: 4.03736e+01
I0515 07:57:42.443083 140128494741248 run_lib.py:152] step: 472200, training_loss: 1.66886e+01
I0515 07:57:42.494643 140128494741248 run_lib.py:165] step: 472200, eval_loss: 2.77971e+01
I0515 07:57:48.906828 140128494741248 run_lib.py:152] step: 472250, training_loss: 2.96728e+01
I0515 07:57:55.252754 140128494741248 run_lib.py:152] step: 472300, training_loss: 4.70943e+01
I0515 07:57:55.310469 140128494741248 run_lib.py:165] step: 472300, eval_loss: 2.26561e+01
I0515 07:58:01.560538 140128494741248 run_lib.py:152] step: 472350, training_loss: 4.41650e+01
I0515 07:58:07.779930 140128494741248 run_lib.py:152] step: 472400, training_loss: 2.45257e+01
I0515 07:58:07.832851 140128494741248 run_lib.py:165] step: 472400, eval_loss: 3.04755e+01
I0515 07:58:14.349051 140128494741248 run_lib.py:152] step: 472450, training_loss: 4.09538e+01
I0515 07:58:20.556347 140128494741248 run_lib.py:152] step: 472500, training_loss: 4.58449e+01
I0515 07:58:20.610537 140128494741248 run_lib.py:165] step: 472500, eval_loss: 3.08248e+01
I0515 07:58:26.949519 140128494741248 run_lib.py:152] step: 472550, training_loss: 2.40263e+01
I0515 07:58:33.363234 140128494741248 run_lib.py:152] step: 472600, training_loss: 2.57116e+01
I0515 07:58:33.419909 140128494741248 run_lib.py:165] step: 472600, eval_loss: 2.30507e+01
I0515 07:58:39.768069 140128494741248 run_lib.py:152] step: 472650, training_loss: 2.10820e+01
I0515 07:58:46.023056 140128494741248 run_lib.py:152] step: 472700, training_loss: 2.53563e+01
I0515 07:58:46.074327 140128494741248 run_lib.py:165] step: 472700, eval_loss: 3.60471e+01
I0515 07:58:52.286877 140128494741248 run_lib.py:152] step: 472750, training_loss: 3.37430e+01
I0515 07:58:58.696709 140128494741248 run_lib.py:152] step: 472800, training_loss: 2.99958e+01
I0515 07:58:58.753648 140128494741248 run_lib.py:165] step: 472800, eval_loss: 2.52277e+01
I0515 07:59:05.054501 140128494741248 run_lib.py:152] step: 472850, training_loss: 4.46370e+01
I0515 07:59:11.293591 140128494741248 run_lib.py:152] step: 472900, training_loss: 3.45720e+01
I0515 07:59:11.344186 140128494741248 run_lib.py:165] step: 472900, eval_loss: 2.79531e+01
I0515 07:59:17.899855 140128494741248 run_lib.py:152] step: 472950, training_loss: 3.83957e+01
I0515 07:59:24.156401 140128494741248 run_lib.py:152] step: 473000, training_loss: 3.77575e+01
I0515 07:59:24.207591 140128494741248 run_lib.py:165] step: 473000, eval_loss: 4.18826e+01
I0515 07:59:30.482905 140128494741248 run_lib.py:152] step: 473050, training_loss: 3.36774e+01
I0515 07:59:36.800466 140128494741248 run_lib.py:152] step: 473100, training_loss: 3.49874e+01
I0515 07:59:36.854314 140128494741248 run_lib.py:165] step: 473100, eval_loss: 3.49509e+01
I0515 07:59:43.295821 140128494741248 run_lib.py:152] step: 473150, training_loss: 1.36926e+01
I0515 07:59:49.584507 140128494741248 run_lib.py:152] step: 473200, training_loss: 2.61860e+01
I0515 07:59:49.638297 140128494741248 run_lib.py:165] step: 473200, eval_loss: 2.73513e+01
I0515 07:59:55.846406 140128494741248 run_lib.py:152] step: 473250, training_loss: 2.96743e+01
I0515 08:00:02.352484 140128494741248 run_lib.py:152] step: 473300, training_loss: 3.96689e+01
I0515 08:00:02.404047 140128494741248 run_lib.py:165] step: 473300, eval_loss: 2.90392e+01
I0515 08:00:08.727769 140128494741248 run_lib.py:152] step: 473350, training_loss: 3.61611e+01
I0515 08:00:14.882782 140128494741248 run_lib.py:152] step: 473400, training_loss: 2.98286e+01
I0515 08:00:14.936209 140128494741248 run_lib.py:165] step: 473400, eval_loss: 3.43795e+01
I0515 08:00:21.169125 140128494741248 run_lib.py:152] step: 473450, training_loss: 1.86352e+01
I0515 08:00:27.612609 140128494741248 run_lib.py:152] step: 473500, training_loss: 1.79827e+01
I0515 08:00:27.670819 140128494741248 run_lib.py:165] step: 473500, eval_loss: 3.45209e+01
I0515 08:00:33.939694 140128494741248 run_lib.py:152] step: 473550, training_loss: 5.12284e+01
I0515 08:00:40.070809 140128494741248 run_lib.py:152] step: 473600, training_loss: 3.52891e+01
I0515 08:00:40.124397 140128494741248 run_lib.py:165] step: 473600, eval_loss: 1.65982e+01
I0515 08:00:46.562122 140128494741248 run_lib.py:152] step: 473650, training_loss: 4.16428e+01
I0515 08:00:52.726660 140128494741248 run_lib.py:152] step: 473700, training_loss: 3.65801e+01
I0515 08:00:52.774007 140128494741248 run_lib.py:165] step: 473700, eval_loss: 3.32796e+01
I0515 08:00:59.087280 140128494741248 run_lib.py:152] step: 473750, training_loss: 3.18840e+01
I0515 08:01:05.311250 140128494741248 run_lib.py:152] step: 473800, training_loss: 5.08619e+01
I0515 08:01:05.363484 140128494741248 run_lib.py:165] step: 473800, eval_loss: 2.50190e+01
I0515 08:01:11.893350 140128494741248 run_lib.py:152] step: 473850, training_loss: 3.31384e+01
I0515 08:01:18.133123 140128494741248 run_lib.py:152] step: 473900, training_loss: 3.29971e+01
I0515 08:01:18.182107 140128494741248 run_lib.py:165] step: 473900, eval_loss: 3.10680e+01
I0515 08:01:24.401157 140128494741248 run_lib.py:152] step: 473950, training_loss: 2.69210e+01
I0515 08:01:30.821989 140128494741248 run_lib.py:152] step: 474000, training_loss: 3.27350e+01
I0515 08:01:30.871941 140128494741248 run_lib.py:165] step: 474000, eval_loss: 3.40292e+01
I0515 08:01:37.119997 140128494741248 run_lib.py:152] step: 474050, training_loss: 3.45431e+01
I0515 08:01:43.348396 140128494741248 run_lib.py:152] step: 474100, training_loss: 3.22626e+01
I0515 08:01:43.400387 140128494741248 run_lib.py:165] step: 474100, eval_loss: 2.55311e+01
I0515 08:01:49.688162 140128494741248 run_lib.py:152] step: 474150, training_loss: 2.51856e+01
I0515 08:01:56.170570 140128494741248 run_lib.py:152] step: 474200, training_loss: 3.49343e+01
I0515 08:01:56.223725 140128494741248 run_lib.py:165] step: 474200, eval_loss: 2.68804e+01
I0515 08:02:02.544606 140128494741248 run_lib.py:152] step: 474250, training_loss: 2.77949e+01
I0515 08:02:08.699929 140128494741248 run_lib.py:152] step: 474300, training_loss: 2.86647e+01
I0515 08:02:08.750265 140128494741248 run_lib.py:165] step: 474300, eval_loss: 4.51339e+01
I0515 08:02:15.127853 140128494741248 run_lib.py:152] step: 474350, training_loss: 2.76259e+01
I0515 08:02:21.438915 140128494741248 run_lib.py:152] step: 474400, training_loss: 3.04178e+01
I0515 08:02:21.495326 140128494741248 run_lib.py:165] step: 474400, eval_loss: 2.88227e+01
I0515 08:02:27.709304 140128494741248 run_lib.py:152] step: 474450, training_loss: 2.83900e+01
I0515 08:02:33.977715 140128494741248 run_lib.py:152] step: 474500, training_loss: 2.84246e+01
I0515 08:02:34.031198 140128494741248 run_lib.py:165] step: 474500, eval_loss: 3.24247e+01
I0515 08:02:40.555337 140128494741248 run_lib.py:152] step: 474550, training_loss: 2.71308e+01
I0515 08:02:46.742115 140128494741248 run_lib.py:152] step: 474600, training_loss: 3.61884e+01
I0515 08:02:46.791223 140128494741248 run_lib.py:165] step: 474600, eval_loss: 2.66414e+01
I0515 08:02:52.909697 140128494741248 run_lib.py:152] step: 474650, training_loss: 2.65363e+01
I0515 08:02:59.350067 140128494741248 run_lib.py:152] step: 474700, training_loss: 3.17924e+01
I0515 08:02:59.403156 140128494741248 run_lib.py:165] step: 474700, eval_loss: 3.24348e+01
I0515 08:03:05.638450 140128494741248 run_lib.py:152] step: 474750, training_loss: 3.45384e+01
I0515 08:03:11.871271 140128494741248 run_lib.py:152] step: 474800, training_loss: 2.26506e+01
I0515 08:03:11.924540 140128494741248 run_lib.py:165] step: 474800, eval_loss: 1.83734e+01
I0515 08:03:18.157640 140128494741248 run_lib.py:152] step: 474850, training_loss: 1.42251e+01
I0515 08:03:24.628003 140128494741248 run_lib.py:152] step: 474900, training_loss: 2.58347e+01
I0515 08:03:24.678827 140128494741248 run_lib.py:165] step: 474900, eval_loss: 2.79178e+01
I0515 08:03:31.019974 140128494741248 run_lib.py:152] step: 474950, training_loss: 2.00264e+01
I0515 08:03:37.277881 140128494741248 run_lib.py:152] step: 475000, training_loss: 3.43939e+01
I0515 08:03:37.333667 140128494741248 run_lib.py:165] step: 475000, eval_loss: 3.61847e+01
I0515 08:03:43.826894 140128494741248 run_lib.py:152] step: 475050, training_loss: 1.32624e+01
I0515 08:03:50.021996 140128494741248 run_lib.py:152] step: 475100, training_loss: 3.38304e+01
I0515 08:03:50.071484 140128494741248 run_lib.py:165] step: 475100, eval_loss: 3.18338e+01
I0515 08:03:56.316112 140128494741248 run_lib.py:152] step: 475150, training_loss: 3.67978e+01
I0515 08:04:02.588434 140128494741248 run_lib.py:152] step: 475200, training_loss: 3.20584e+01
I0515 08:04:02.643316 140128494741248 run_lib.py:165] step: 475200, eval_loss: 2.61040e+01
I0515 08:04:09.059901 140128494741248 run_lib.py:152] step: 475250, training_loss: 2.71953e+01
I0515 08:04:15.388382 140128494741248 run_lib.py:152] step: 475300, training_loss: 2.62212e+01
I0515 08:04:15.450626 140128494741248 run_lib.py:165] step: 475300, eval_loss: 2.95530e+01
I0515 08:04:21.647196 140128494741248 run_lib.py:152] step: 475350, training_loss: 2.21765e+01
I0515 08:04:28.162289 140128494741248 run_lib.py:152] step: 475400, training_loss: 5.44611e+01
I0515 08:04:28.218247 140128494741248 run_lib.py:165] step: 475400, eval_loss: 2.01853e+01
I0515 08:04:34.501243 140128494741248 run_lib.py:152] step: 475450, training_loss: 3.57834e+01
I0515 08:04:40.689599 140128494741248 run_lib.py:152] step: 475500, training_loss: 3.27613e+01
I0515 08:04:40.741577 140128494741248 run_lib.py:165] step: 475500, eval_loss: 3.46541e+01
I0515 08:04:46.976297 140128494741248 run_lib.py:152] step: 475550, training_loss: 3.70387e+01
I0515 08:04:53.429850 140128494741248 run_lib.py:152] step: 475600, training_loss: 6.11205e+01
I0515 08:04:53.484851 140128494741248 run_lib.py:165] step: 475600, eval_loss: 2.28754e+01
I0515 08:04:59.778885 140128494741248 run_lib.py:152] step: 475650, training_loss: 3.91590e+01
I0515 08:05:05.969245 140128494741248 run_lib.py:152] step: 475700, training_loss: 3.31324e+01
I0515 08:05:06.018139 140128494741248 run_lib.py:165] step: 475700, eval_loss: 4.18344e+01
I0515 08:05:12.275768 140128494741248 run_lib.py:152] step: 475750, training_loss: 2.43690e+01
I0515 08:05:18.398119 140128494741248 run_lib.py:152] step: 475800, training_loss: 3.45389e+01
I0515 08:05:18.453871 140128494741248 run_lib.py:165] step: 475800, eval_loss: 1.97082e+01
I0515 08:05:24.803666 140128494741248 run_lib.py:152] step: 475850, training_loss: 3.82479e+01
I0515 08:05:31.017023 140128494741248 run_lib.py:152] step: 475900, training_loss: 1.97330e+01
I0515 08:05:31.073901 140128494741248 run_lib.py:165] step: 475900, eval_loss: 4.11479e+01
I0515 08:05:37.558726 140128494741248 run_lib.py:152] step: 475950, training_loss: 1.75819e+01
I0515 08:05:43.914283 140128494741248 run_lib.py:152] step: 476000, training_loss: 3.74185e+01
I0515 08:05:43.967808 140128494741248 run_lib.py:165] step: 476000, eval_loss: 3.66636e+01
I0515 08:05:50.292995 140128494741248 run_lib.py:152] step: 476050, training_loss: 2.87336e+01
I0515 08:05:56.731880 140128494741248 run_lib.py:152] step: 476100, training_loss: 3.49207e+01
I0515 08:05:56.786931 140128494741248 run_lib.py:165] step: 476100, eval_loss: 3.06367e+01
I0515 08:06:03.105170 140128494741248 run_lib.py:152] step: 476150, training_loss: 3.47461e+01
I0515 08:06:09.347624 140128494741248 run_lib.py:152] step: 476200, training_loss: 3.99818e+01
I0515 08:06:09.396394 140128494741248 run_lib.py:165] step: 476200, eval_loss: 2.75415e+01
I0515 08:06:15.631582 140128494741248 run_lib.py:152] step: 476250, training_loss: 3.62606e+01
I0515 08:06:22.165780 140128494741248 run_lib.py:152] step: 476300, training_loss: 2.54318e+01
I0515 08:06:22.224144 140128494741248 run_lib.py:165] step: 476300, eval_loss: 2.83004e+01
I0515 08:06:28.387848 140128494741248 run_lib.py:152] step: 476350, training_loss: 3.17895e+01
I0515 08:06:34.649688 140128494741248 run_lib.py:152] step: 476400, training_loss: 3.08797e+01
I0515 08:06:34.703752 140128494741248 run_lib.py:165] step: 476400, eval_loss: 4.47881e+01
I0515 08:06:41.141606 140128494741248 run_lib.py:152] step: 476450, training_loss: 3.64069e+01
I0515 08:06:47.445350 140128494741248 run_lib.py:152] step: 476500, training_loss: 3.87421e+01
I0515 08:06:47.497710 140128494741248 run_lib.py:165] step: 476500, eval_loss: 2.28632e+01
I0515 08:06:53.740701 140128494741248 run_lib.py:152] step: 476550, training_loss: 1.83443e+01
I0515 08:07:00.018631 140128494741248 run_lib.py:152] step: 476600, training_loss: 3.87697e+01
I0515 08:07:00.072504 140128494741248 run_lib.py:165] step: 476600, eval_loss: 1.42776e+01
I0515 08:07:06.505890 140128494741248 run_lib.py:152] step: 476650, training_loss: 3.25478e+01
I0515 08:07:12.833976 140128494741248 run_lib.py:152] step: 476700, training_loss: 3.38674e+01
I0515 08:07:12.883628 140128494741248 run_lib.py:165] step: 476700, eval_loss: 2.50113e+01
I0515 08:07:19.137713 140128494741248 run_lib.py:152] step: 476750, training_loss: 2.78165e+01
I0515 08:07:25.572501 140128494741248 run_lib.py:152] step: 476800, training_loss: 3.99380e+01
I0515 08:07:25.627766 140128494741248 run_lib.py:165] step: 476800, eval_loss: 2.60885e+01
I0515 08:07:31.840305 140128494741248 run_lib.py:152] step: 476850, training_loss: 3.13830e+01
I0515 08:07:38.017200 140128494741248 run_lib.py:152] step: 476900, training_loss: 3.57654e+01
I0515 08:07:38.071599 140128494741248 run_lib.py:165] step: 476900, eval_loss: 2.00130e+01
I0515 08:07:44.275334 140128494741248 run_lib.py:152] step: 476950, training_loss: 3.59699e+01
I0515 08:07:50.785711 140128494741248 run_lib.py:152] step: 477000, training_loss: 2.01646e+01
I0515 08:07:50.840601 140128494741248 run_lib.py:165] step: 477000, eval_loss: 2.61946e+01
I0515 08:07:57.008528 140128494741248 run_lib.py:152] step: 477050, training_loss: 3.33582e+01
I0515 08:08:03.229498 140128494741248 run_lib.py:152] step: 477100, training_loss: 2.47497e+01
I0515 08:08:03.282010 140128494741248 run_lib.py:165] step: 477100, eval_loss: 2.33584e+01
I0515 08:08:09.760387 140128494741248 run_lib.py:152] step: 477150, training_loss: 3.33336e+01
I0515 08:08:16.082461 140128494741248 run_lib.py:152] step: 477200, training_loss: 3.85077e+01
I0515 08:08:16.135399 140128494741248 run_lib.py:165] step: 477200, eval_loss: 3.93090e+01
I0515 08:08:22.457968 140128494741248 run_lib.py:152] step: 477250, training_loss: 4.30508e+01
I0515 08:08:28.705380 140128494741248 run_lib.py:152] step: 477300, training_loss: 2.06575e+01
I0515 08:08:28.761407 140128494741248 run_lib.py:165] step: 477300, eval_loss: 1.91747e+01
I0515 08:08:35.440654 140128494741248 run_lib.py:152] step: 477350, training_loss: 2.48471e+01
I0515 08:08:41.702820 140128494741248 run_lib.py:152] step: 477400, training_loss: 4.06371e+01
I0515 08:08:41.755761 140128494741248 run_lib.py:165] step: 477400, eval_loss: 2.98488e+01
I0515 08:08:48.034770 140128494741248 run_lib.py:152] step: 477450, training_loss: 2.11927e+01
I0515 08:08:54.438454 140128494741248 run_lib.py:152] step: 477500, training_loss: 2.71093e+01
I0515 08:08:54.486367 140128494741248 run_lib.py:165] step: 477500, eval_loss: 3.31213e+01
I0515 08:09:00.827491 140128494741248 run_lib.py:152] step: 477550, training_loss: 3.18907e+01
I0515 08:09:07.102344 140128494741248 run_lib.py:152] step: 477600, training_loss: 3.26875e+01
I0515 08:09:07.156396 140128494741248 run_lib.py:165] step: 477600, eval_loss: 2.73018e+01
I0515 08:09:13.420063 140128494741248 run_lib.py:152] step: 477650, training_loss: 2.24417e+01
I0515 08:09:19.905957 140128494741248 run_lib.py:152] step: 477700, training_loss: 2.83958e+01
I0515 08:09:19.961259 140128494741248 run_lib.py:165] step: 477700, eval_loss: 1.75426e+01
I0515 08:09:26.192179 140128494741248 run_lib.py:152] step: 477750, training_loss: 3.27710e+01
I0515 08:09:32.309347 140128494741248 run_lib.py:152] step: 477800, training_loss: 2.70864e+01
I0515 08:09:32.360958 140128494741248 run_lib.py:165] step: 477800, eval_loss: 3.17017e+01
I0515 08:09:38.956666 140128494741248 run_lib.py:152] step: 477850, training_loss: 3.85115e+01
I0515 08:09:45.200106 140128494741248 run_lib.py:152] step: 477900, training_loss: 2.59604e+01
I0515 08:09:45.252611 140128494741248 run_lib.py:165] step: 477900, eval_loss: 2.98686e+01
I0515 08:09:51.526457 140128494741248 run_lib.py:152] step: 477950, training_loss: 2.73961e+01
I0515 08:09:57.811390 140128494741248 run_lib.py:152] step: 478000, training_loss: 1.81779e+01
I0515 08:09:57.862033 140128494741248 run_lib.py:165] step: 478000, eval_loss: 3.11222e+01
I0515 08:10:04.426165 140128494741248 run_lib.py:152] step: 478050, training_loss: 3.79271e+01
I0515 08:10:10.684250 140128494741248 run_lib.py:152] step: 478100, training_loss: 2.89697e+01
I0515 08:10:10.740966 140128494741248 run_lib.py:165] step: 478100, eval_loss: 3.41229e+01
I0515 08:10:16.941308 140128494741248 run_lib.py:152] step: 478150, training_loss: 3.15833e+01
I0515 08:10:23.355434 140128494741248 run_lib.py:152] step: 478200, training_loss: 4.54565e+01
I0515 08:10:23.409529 140128494741248 run_lib.py:165] step: 478200, eval_loss: 2.33412e+01
I0515 08:10:29.667185 140128494741248 run_lib.py:152] step: 478250, training_loss: 3.10645e+01
I0515 08:10:35.919590 140128494741248 run_lib.py:152] step: 478300, training_loss: 2.40376e+01
I0515 08:10:35.969580 140128494741248 run_lib.py:165] step: 478300, eval_loss: 4.21157e+01
I0515 08:10:42.280321 140128494741248 run_lib.py:152] step: 478350, training_loss: 3.54093e+01
I0515 08:10:48.659779 140128494741248 run_lib.py:152] step: 478400, training_loss: 2.31069e+01
I0515 08:10:48.711269 140128494741248 run_lib.py:165] step: 478400, eval_loss: 2.44441e+01
I0515 08:10:54.997211 140128494741248 run_lib.py:152] step: 478450, training_loss: 3.56991e+01
I0515 08:11:01.236762 140128494741248 run_lib.py:152] step: 478500, training_loss: 3.84854e+01
I0515 08:11:01.293076 140128494741248 run_lib.py:165] step: 478500, eval_loss: 4.04097e+01
I0515 08:11:07.720285 140128494741248 run_lib.py:152] step: 478550, training_loss: 2.93155e+01
I0515 08:11:13.959083 140128494741248 run_lib.py:152] step: 478600, training_loss: 1.21723e+01
I0515 08:11:14.007944 140128494741248 run_lib.py:165] step: 478600, eval_loss: 4.58440e+01
I0515 08:11:20.221135 140128494741248 run_lib.py:152] step: 478650, training_loss: 3.59733e+01
I0515 08:11:26.490607 140128494741248 run_lib.py:152] step: 478700, training_loss: 3.51258e+01
I0515 08:11:26.541935 140128494741248 run_lib.py:165] step: 478700, eval_loss: 2.96295e+01
I0515 08:11:32.916338 140128494741248 run_lib.py:152] step: 478750, training_loss: 2.47533e+01
I0515 08:11:39.144021 140128494741248 run_lib.py:152] step: 478800, training_loss: 3.41218e+01
I0515 08:11:39.197569 140128494741248 run_lib.py:165] step: 478800, eval_loss: 3.60262e+01
I0515 08:11:45.368221 140128494741248 run_lib.py:152] step: 478850, training_loss: 2.82131e+01
I0515 08:11:51.752814 140128494741248 run_lib.py:152] step: 478900, training_loss: 2.95376e+01
I0515 08:11:51.803995 140128494741248 run_lib.py:165] step: 478900, eval_loss: 2.96707e+01
I0515 08:11:58.056607 140128494741248 run_lib.py:152] step: 478950, training_loss: 2.83780e+01
I0515 08:12:04.220760 140128494741248 run_lib.py:152] step: 479000, training_loss: 2.61663e+01
I0515 08:12:04.270004 140128494741248 run_lib.py:165] step: 479000, eval_loss: 3.72403e+01
I0515 08:12:10.425138 140128494741248 run_lib.py:152] step: 479050, training_loss: 4.63281e+01
I0515 08:12:16.855687 140128494741248 run_lib.py:152] step: 479100, training_loss: 4.11300e+01
I0515 08:12:16.909160 140128494741248 run_lib.py:165] step: 479100, eval_loss: 2.81160e+01
I0515 08:12:23.108120 140128494741248 run_lib.py:152] step: 479150, training_loss: 3.68739e+01
I0515 08:12:29.306489 140128494741248 run_lib.py:152] step: 479200, training_loss: 4.77067e+01
I0515 08:12:29.360144 140128494741248 run_lib.py:165] step: 479200, eval_loss: 4.50559e+01
I0515 08:12:35.862764 140128494741248 run_lib.py:152] step: 479250, training_loss: 2.92746e+01
I0515 08:12:42.057116 140128494741248 run_lib.py:152] step: 479300, training_loss: 2.61179e+01
I0515 08:12:42.111254 140128494741248 run_lib.py:165] step: 479300, eval_loss: 2.53290e+01
I0515 08:12:48.337862 140128494741248 run_lib.py:152] step: 479350, training_loss: 3.30716e+01
I0515 08:12:54.579542 140128494741248 run_lib.py:152] step: 479400, training_loss: 3.34458e+01
I0515 08:12:54.632390 140128494741248 run_lib.py:165] step: 479400, eval_loss: 1.70246e+01
I0515 08:13:01.089331 140128494741248 run_lib.py:152] step: 479450, training_loss: 3.35943e+01
I0515 08:13:07.284141 140128494741248 run_lib.py:152] step: 479500, training_loss: 3.27944e+01
I0515 08:13:07.335929 140128494741248 run_lib.py:165] step: 479500, eval_loss: 3.16653e+01
I0515 08:13:13.527728 140128494741248 run_lib.py:152] step: 479550, training_loss: 3.02050e+01
I0515 08:13:19.910725 140128494741248 run_lib.py:152] step: 479600, training_loss: 4.33219e+01
I0515 08:13:19.963323 140128494741248 run_lib.py:165] step: 479600, eval_loss: 3.30176e+01
I0515 08:13:26.233630 140128494741248 run_lib.py:152] step: 479650, training_loss: 3.34452e+01
I0515 08:13:32.535698 140128494741248 run_lib.py:152] step: 479700, training_loss: 2.03905e+01
I0515 08:13:32.586711 140128494741248 run_lib.py:165] step: 479700, eval_loss: 3.52848e+01
I0515 08:13:38.862115 140128494741248 run_lib.py:152] step: 479750, training_loss: 3.27919e+01
I0515 08:13:45.365458 140128494741248 run_lib.py:152] step: 479800, training_loss: 3.23837e+01
I0515 08:13:45.415564 140128494741248 run_lib.py:165] step: 479800, eval_loss: 4.58102e+01
I0515 08:13:51.675783 140128494741248 run_lib.py:152] step: 479850, training_loss: 3.20615e+01
I0515 08:13:57.931850 140128494741248 run_lib.py:152] step: 479900, training_loss: 3.68053e+01
I0515 08:13:57.985498 140128494741248 run_lib.py:165] step: 479900, eval_loss: 3.06124e+01
I0515 08:14:04.455366 140128494741248 run_lib.py:152] step: 479950, training_loss: 3.42920e+01
I0515 08:14:10.686461 140128494741248 run_lib.py:152] step: 480000, training_loss: 2.08453e+01
I0515 08:14:10.889398 140128494741248 run_lib.py:165] step: 480000, eval_loss: 2.44635e+01
I0515 08:14:17.044137 140128494741248 run_lib.py:152] step: 480050, training_loss: 1.38255e+01
I0515 08:14:23.283335 140128494741248 run_lib.py:152] step: 480100, training_loss: 3.00803e+01
I0515 08:14:23.335395 140128494741248 run_lib.py:165] step: 480100, eval_loss: 3.12179e+01
I0515 08:14:29.791339 140128494741248 run_lib.py:152] step: 480150, training_loss: 2.78017e+01
I0515 08:14:36.038094 140128494741248 run_lib.py:152] step: 480200, training_loss: 1.99051e+01
I0515 08:14:36.096301 140128494741248 run_lib.py:165] step: 480200, eval_loss: 3.83597e+01
I0515 08:14:42.351598 140128494741248 run_lib.py:152] step: 480250, training_loss: 3.25325e+01
I0515 08:14:48.892253 140128494741248 run_lib.py:152] step: 480300, training_loss: 3.56970e+01
I0515 08:14:48.943555 140128494741248 run_lib.py:165] step: 480300, eval_loss: 1.96034e+01
I0515 08:14:55.170422 140128494741248 run_lib.py:152] step: 480350, training_loss: 3.45397e+01
I0515 08:15:01.356511 140128494741248 run_lib.py:152] step: 480400, training_loss: 3.50398e+01
I0515 08:15:01.406163 140128494741248 run_lib.py:165] step: 480400, eval_loss: 1.70694e+01
I0515 08:15:07.705678 140128494741248 run_lib.py:152] step: 480450, training_loss: 2.04387e+01
I0515 08:15:14.126927 140128494741248 run_lib.py:152] step: 480500, training_loss: 3.11037e+01
I0515 08:15:14.178095 140128494741248 run_lib.py:165] step: 480500, eval_loss: 2.02641e+01
I0515 08:15:20.426217 140128494741248 run_lib.py:152] step: 480550, training_loss: 3.63052e+01
I0515 08:15:26.624786 140128494741248 run_lib.py:152] step: 480600, training_loss: 2.73576e+01
I0515 08:15:26.675681 140128494741248 run_lib.py:165] step: 480600, eval_loss: 3.58620e+01
I0515 08:15:33.201693 140128494741248 run_lib.py:152] step: 480650, training_loss: 2.97504e+01
I0515 08:15:39.382084 140128494741248 run_lib.py:152] step: 480700, training_loss: 2.82934e+01
I0515 08:15:39.437530 140128494741248 run_lib.py:165] step: 480700, eval_loss: 3.00714e+01
I0515 08:15:45.742405 140128494741248 run_lib.py:152] step: 480750, training_loss: 2.31712e+01
I0515 08:15:51.945605 140128494741248 run_lib.py:152] step: 480800, training_loss: 3.50461e+01
I0515 08:15:51.994297 140128494741248 run_lib.py:165] step: 480800, eval_loss: 3.03666e+01
I0515 08:15:58.486576 140128494741248 run_lib.py:152] step: 480850, training_loss: 2.81585e+01
I0515 08:16:04.759697 140128494741248 run_lib.py:152] step: 480900, training_loss: 2.91676e+01
I0515 08:16:04.813050 140128494741248 run_lib.py:165] step: 480900, eval_loss: 2.08722e+01
I0515 08:16:11.076658 140128494741248 run_lib.py:152] step: 480950, training_loss: 3.50443e+01
I0515 08:16:17.547379 140128494741248 run_lib.py:152] step: 481000, training_loss: 3.26454e+01
I0515 08:16:17.603456 140128494741248 run_lib.py:165] step: 481000, eval_loss: 4.66515e+01
I0515 08:16:23.834085 140128494741248 run_lib.py:152] step: 481050, training_loss: 1.96725e+01
I0515 08:16:30.033962 140128494741248 run_lib.py:152] step: 481100, training_loss: 4.20556e+01
I0515 08:16:30.084348 140128494741248 run_lib.py:165] step: 481100, eval_loss: 3.59002e+01
I0515 08:16:36.582397 140128494741248 run_lib.py:152] step: 481150, training_loss: 2.28143e+01
I0515 08:16:42.910895 140128494741248 run_lib.py:152] step: 481200, training_loss: 3.71715e+01
I0515 08:16:42.970469 140128494741248 run_lib.py:165] step: 481200, eval_loss: 2.48815e+01
I0515 08:16:49.220801 140128494741248 run_lib.py:152] step: 481250, training_loss: 3.90918e+01
I0515 08:16:55.429761 140128494741248 run_lib.py:152] step: 481300, training_loss: 2.38308e+01
I0515 08:16:55.478152 140128494741248 run_lib.py:165] step: 481300, eval_loss: 3.32858e+01
I0515 08:17:02.026887 140128494741248 run_lib.py:152] step: 481350, training_loss: 3.03706e+01
I0515 08:17:08.226664 140128494741248 run_lib.py:152] step: 481400, training_loss: 2.47015e+01
I0515 08:17:08.276990 140128494741248 run_lib.py:165] step: 481400, eval_loss: 3.02050e+01
I0515 08:17:14.557115 140128494741248 run_lib.py:152] step: 481450, training_loss: 3.95911e+01
I0515 08:17:20.986901 140128494741248 run_lib.py:152] step: 481500, training_loss: 2.53151e+01
I0515 08:17:21.036455 140128494741248 run_lib.py:165] step: 481500, eval_loss: 3.08458e+01
I0515 08:17:27.253257 140128494741248 run_lib.py:152] step: 481550, training_loss: 3.68841e+01
I0515 08:17:33.438549 140128494741248 run_lib.py:152] step: 481600, training_loss: 2.28569e+01
I0515 08:17:33.487349 140128494741248 run_lib.py:165] step: 481600, eval_loss: 3.33371e+01
I0515 08:17:39.722789 140128494741248 run_lib.py:152] step: 481650, training_loss: 3.09800e+01
I0515 08:17:46.191622 140128494741248 run_lib.py:152] step: 481700, training_loss: 3.39903e+01
I0515 08:17:46.243401 140128494741248 run_lib.py:165] step: 481700, eval_loss: 1.43828e+01
I0515 08:17:52.397634 140128494741248 run_lib.py:152] step: 481750, training_loss: 2.63490e+01
I0515 08:17:58.603728 140128494741248 run_lib.py:152] step: 481800, training_loss: 4.29781e+01
I0515 08:17:58.657303 140128494741248 run_lib.py:165] step: 481800, eval_loss: 3.00919e+01
I0515 08:18:05.302751 140128494741248 run_lib.py:152] step: 481850, training_loss: 3.34682e+01
I0515 08:18:11.518562 140128494741248 run_lib.py:152] step: 481900, training_loss: 4.05243e+01
I0515 08:18:11.575661 140128494741248 run_lib.py:165] step: 481900, eval_loss: 4.85765e+01
I0515 08:18:17.821692 140128494741248 run_lib.py:152] step: 481950, training_loss: 3.35648e+01
I0515 08:18:24.146527 140128494741248 run_lib.py:152] step: 482000, training_loss: 2.52136e+01
I0515 08:18:24.198013 140128494741248 run_lib.py:165] step: 482000, eval_loss: 3.56583e+01
I0515 08:18:30.613386 140128494741248 run_lib.py:152] step: 482050, training_loss: 1.57115e+01
I0515 08:18:36.797281 140128494741248 run_lib.py:152] step: 482100, training_loss: 2.79859e+01
I0515 08:18:36.847392 140128494741248 run_lib.py:165] step: 482100, eval_loss: 3.47177e+01
I0515 08:18:43.195215 140128494741248 run_lib.py:152] step: 482150, training_loss: 2.41581e+01
I0515 08:18:49.592762 140128494741248 run_lib.py:152] step: 482200, training_loss: 3.31917e+01
I0515 08:18:49.647367 140128494741248 run_lib.py:165] step: 482200, eval_loss: 4.67748e+01
I0515 08:18:55.924422 140128494741248 run_lib.py:152] step: 482250, training_loss: 4.28544e+01
I0515 08:19:02.231851 140128494741248 run_lib.py:152] step: 482300, training_loss: 2.44894e+01
I0515 08:19:02.282690 140128494741248 run_lib.py:165] step: 482300, eval_loss: 3.61227e+01
I0515 08:19:08.433629 140128494741248 run_lib.py:152] step: 482350, training_loss: 2.73782e+01
I0515 08:19:14.851562 140128494741248 run_lib.py:152] step: 482400, training_loss: 2.74952e+01
I0515 08:19:14.901293 140128494741248 run_lib.py:165] step: 482400, eval_loss: 3.23457e+01
I0515 08:19:21.198042 140128494741248 run_lib.py:152] step: 482450, training_loss: 3.55753e+01
I0515 08:19:27.437646 140128494741248 run_lib.py:152] step: 482500, training_loss: 4.04755e+01
I0515 08:19:27.488450 140128494741248 run_lib.py:165] step: 482500, eval_loss: 2.80854e+01
I0515 08:19:33.988535 140128494741248 run_lib.py:152] step: 482550, training_loss: 3.79607e+01
I0515 08:19:40.172394 140128494741248 run_lib.py:152] step: 482600, training_loss: 3.42483e+01
I0515 08:19:40.223224 140128494741248 run_lib.py:165] step: 482600, eval_loss: 2.68326e+01
I0515 08:19:46.533406 140128494741248 run_lib.py:152] step: 482650, training_loss: 4.22447e+01
I0515 08:19:52.793482 140128494741248 run_lib.py:152] step: 482700, training_loss: 2.82405e+01
I0515 08:19:52.843530 140128494741248 run_lib.py:165] step: 482700, eval_loss: 2.05656e+01
I0515 08:19:59.329625 140128494741248 run_lib.py:152] step: 482750, training_loss: 2.36409e+01
I0515 08:20:05.532515 140128494741248 run_lib.py:152] step: 482800, training_loss: 3.17071e+01
I0515 08:20:05.593274 140128494741248 run_lib.py:165] step: 482800, eval_loss: 4.07457e+01
I0515 08:20:11.751583 140128494741248 run_lib.py:152] step: 482850, training_loss: 4.13972e+01
I0515 08:20:18.297690 140128494741248 run_lib.py:152] step: 482900, training_loss: 2.30067e+01
I0515 08:20:18.349520 140128494741248 run_lib.py:165] step: 482900, eval_loss: 2.68022e+01
I0515 08:20:24.614109 140128494741248 run_lib.py:152] step: 482950, training_loss: 3.12236e+01
I0515 08:20:30.899242 140128494741248 run_lib.py:152] step: 483000, training_loss: 2.64848e+01
I0515 08:20:30.953623 140128494741248 run_lib.py:165] step: 483000, eval_loss: 3.23610e+01
I0515 08:20:37.048602 140128494741248 run_lib.py:152] step: 483050, training_loss: 3.98226e+01
I0515 08:20:43.518295 140128494741248 run_lib.py:152] step: 483100, training_loss: 2.53627e+01
I0515 08:20:43.569981 140128494741248 run_lib.py:165] step: 483100, eval_loss: 3.53803e+01
I0515 08:20:49.748151 140128494741248 run_lib.py:152] step: 483150, training_loss: 3.06521e+01
I0515 08:20:55.959978 140128494741248 run_lib.py:152] step: 483200, training_loss: 4.06649e+01
I0515 08:20:56.010902 140128494741248 run_lib.py:165] step: 483200, eval_loss: 2.94366e+01
I0515 08:21:02.480862 140128494741248 run_lib.py:152] step: 483250, training_loss: 4.46611e+01
I0515 08:21:08.746866 140128494741248 run_lib.py:152] step: 483300, training_loss: 2.83537e+01
I0515 08:21:08.797097 140128494741248 run_lib.py:165] step: 483300, eval_loss: 3.58514e+01
I0515 08:21:15.020778 140128494741248 run_lib.py:152] step: 483350, training_loss: 3.24141e+01
I0515 08:21:21.303511 140128494741248 run_lib.py:152] step: 483400, training_loss: 2.61573e+01
I0515 08:21:21.356612 140128494741248 run_lib.py:165] step: 483400, eval_loss: 2.16238e+01
I0515 08:21:27.848404 140128494741248 run_lib.py:152] step: 483450, training_loss: 3.88221e+01
I0515 08:21:34.188758 140128494741248 run_lib.py:152] step: 483500, training_loss: 3.43506e+01
I0515 08:21:34.244946 140128494741248 run_lib.py:165] step: 483500, eval_loss: 3.56063e+01
I0515 08:21:40.499006 140128494741248 run_lib.py:152] step: 483550, training_loss: 3.69339e+01
I0515 08:21:46.760462 140128494741248 run_lib.py:152] step: 483600, training_loss: 2.69251e+01
I0515 08:21:47.054796 140128494741248 run_lib.py:165] step: 483600, eval_loss: 4.68303e+01
I0515 08:21:53.270242 140128494741248 run_lib.py:152] step: 483650, training_loss: 4.30227e+01
I0515 08:21:59.523437 140128494741248 run_lib.py:152] step: 483700, training_loss: 2.34849e+01
I0515 08:21:59.580176 140128494741248 run_lib.py:165] step: 483700, eval_loss: 1.51845e+01
I0515 08:22:05.879068 140128494741248 run_lib.py:152] step: 483750, training_loss: 2.76904e+01
I0515 08:22:12.282034 140128494741248 run_lib.py:152] step: 483800, training_loss: 2.94860e+01
I0515 08:22:12.330788 140128494741248 run_lib.py:165] step: 483800, eval_loss: 2.82906e+01
I0515 08:22:18.483023 140128494741248 run_lib.py:152] step: 483850, training_loss: 5.03274e+01
I0515 08:22:24.764864 140128494741248 run_lib.py:152] step: 483900, training_loss: 2.84697e+01
I0515 08:22:24.819598 140128494741248 run_lib.py:165] step: 483900, eval_loss: 3.09762e+01
I0515 08:22:31.291327 140128494741248 run_lib.py:152] step: 483950, training_loss: 3.23416e+01
I0515 08:22:37.537303 140128494741248 run_lib.py:152] step: 484000, training_loss: 2.56078e+01
I0515 08:22:37.591311 140128494741248 run_lib.py:165] step: 484000, eval_loss: 2.47683e+01
I0515 08:22:43.836714 140128494741248 run_lib.py:152] step: 484050, training_loss: 3.88472e+01
I0515 08:22:49.969023 140128494741248 run_lib.py:152] step: 484100, training_loss: 3.22565e+01
I0515 08:22:50.022589 140128494741248 run_lib.py:165] step: 484100, eval_loss: 2.09961e+01
I0515 08:22:56.523453 140128494741248 run_lib.py:152] step: 484150, training_loss: 3.08439e+01
I0515 08:23:02.714684 140128494741248 run_lib.py:152] step: 484200, training_loss: 1.68454e+01
I0515 08:23:02.773004 140128494741248 run_lib.py:165] step: 484200, eval_loss: 2.45834e+01
I0515 08:23:08.982561 140128494741248 run_lib.py:152] step: 484250, training_loss: 4.33415e+01
I0515 08:23:15.446667 140128494741248 run_lib.py:152] step: 484300, training_loss: 3.50690e+01
I0515 08:23:15.506779 140128494741248 run_lib.py:165] step: 484300, eval_loss: 4.52080e+01
I0515 08:23:21.807235 140128494741248 run_lib.py:152] step: 484350, training_loss: 4.60411e+01
I0515 08:23:28.129493 140128494741248 run_lib.py:152] step: 484400, training_loss: 4.59250e+01
I0515 08:23:28.183274 140128494741248 run_lib.py:165] step: 484400, eval_loss: 2.14467e+01
I0515 08:23:34.360183 140128494741248 run_lib.py:152] step: 484450, training_loss: 2.85580e+01
I0515 08:23:40.876558 140128494741248 run_lib.py:152] step: 484500, training_loss: 2.13858e+01
I0515 08:23:40.928013 140128494741248 run_lib.py:165] step: 484500, eval_loss: 1.80679e+01
I0515 08:23:47.124917 140128494741248 run_lib.py:152] step: 484550, training_loss: 2.66991e+01
I0515 08:23:53.295641 140128494741248 run_lib.py:152] step: 484600, training_loss: 2.47637e+01
I0515 08:23:53.346095 140128494741248 run_lib.py:165] step: 484600, eval_loss: 4.79523e+01
I0515 08:23:59.883610 140128494741248 run_lib.py:152] step: 484650, training_loss: 2.49863e+01
I0515 08:24:06.280394 140128494741248 run_lib.py:152] step: 484700, training_loss: 2.21540e+01
I0515 08:24:06.333214 140128494741248 run_lib.py:165] step: 484700, eval_loss: 1.58944e+01
I0515 08:24:12.493786 140128494741248 run_lib.py:152] step: 484750, training_loss: 2.71370e+01
I0515 08:24:18.708422 140128494741248 run_lib.py:152] step: 484800, training_loss: 2.72974e+01
I0515 08:24:18.763883 140128494741248 run_lib.py:165] step: 484800, eval_loss: 2.05169e+01
I0515 08:24:25.270179 140128494741248 run_lib.py:152] step: 484850, training_loss: 2.62602e+01
I0515 08:24:31.555586 140128494741248 run_lib.py:152] step: 484900, training_loss: 2.88166e+01
I0515 08:24:31.612590 140128494741248 run_lib.py:165] step: 484900, eval_loss: 3.67994e+01
I0515 08:24:37.831622 140128494741248 run_lib.py:152] step: 484950, training_loss: 2.42107e+01
I0515 08:24:44.339553 140128494741248 run_lib.py:152] step: 485000, training_loss: 2.35520e+01
I0515 08:24:44.392071 140128494741248 run_lib.py:165] step: 485000, eval_loss: 2.76798e+01
I0515 08:24:50.695089 140128494741248 run_lib.py:152] step: 485050, training_loss: 2.88803e+01
I0515 08:24:56.975651 140128494741248 run_lib.py:152] step: 485100, training_loss: 2.78196e+01
I0515 08:24:57.027980 140128494741248 run_lib.py:165] step: 485100, eval_loss: 2.62630e+01
I0515 08:25:03.291943 140128494741248 run_lib.py:152] step: 485150, training_loss: 1.93921e+01
I0515 08:25:09.842747 140128494741248 run_lib.py:152] step: 485200, training_loss: 2.98159e+01
I0515 08:25:09.899591 140128494741248 run_lib.py:165] step: 485200, eval_loss: 3.75634e+01
I0515 08:25:16.065610 140128494741248 run_lib.py:152] step: 485250, training_loss: 3.78856e+01
I0515 08:25:22.298986 140128494741248 run_lib.py:152] step: 485300, training_loss: 3.08012e+01
I0515 08:25:22.357380 140128494741248 run_lib.py:165] step: 485300, eval_loss: 2.90507e+01
I0515 08:25:28.804195 140128494741248 run_lib.py:152] step: 485350, training_loss: 4.73752e+01
I0515 08:25:35.048361 140128494741248 run_lib.py:152] step: 485400, training_loss: 2.47542e+01
I0515 08:25:35.095742 140128494741248 run_lib.py:165] step: 485400, eval_loss: 3.39703e+01
I0515 08:25:41.397527 140128494741248 run_lib.py:152] step: 485450, training_loss: 4.41856e+01
I0515 08:25:47.624573 140128494741248 run_lib.py:152] step: 485500, training_loss: 3.65458e+01
I0515 08:25:47.676634 140128494741248 run_lib.py:165] step: 485500, eval_loss: 3.46092e+01
I0515 08:25:54.115041 140128494741248 run_lib.py:152] step: 485550, training_loss: 4.51105e+01
I0515 08:26:00.221732 140128494741248 run_lib.py:152] step: 485600, training_loss: 2.18922e+01
I0515 08:26:00.270629 140128494741248 run_lib.py:165] step: 485600, eval_loss: 3.08834e+01
I0515 08:26:06.572040 140128494741248 run_lib.py:152] step: 485650, training_loss: 4.34529e+01
I0515 08:26:12.946176 140128494741248 run_lib.py:152] step: 485700, training_loss: 3.00615e+01
I0515 08:26:12.996695 140128494741248 run_lib.py:165] step: 485700, eval_loss: 3.68156e+01
I0515 08:26:19.223944 140128494741248 run_lib.py:152] step: 485750, training_loss: 3.77548e+01
I0515 08:26:25.386202 140128494741248 run_lib.py:152] step: 485800, training_loss: 5.37378e+01
I0515 08:26:25.445338 140128494741248 run_lib.py:165] step: 485800, eval_loss: 2.53313e+01
I0515 08:26:31.650523 140128494741248 run_lib.py:152] step: 485850, training_loss: 3.33962e+01
I0515 08:26:38.154878 140128494741248 run_lib.py:152] step: 485900, training_loss: 3.03642e+01
I0515 08:26:38.209852 140128494741248 run_lib.py:165] step: 485900, eval_loss: 2.58785e+01
I0515 08:26:44.409827 140128494741248 run_lib.py:152] step: 485950, training_loss: 2.99853e+01
I0515 08:26:50.725652 140128494741248 run_lib.py:152] step: 486000, training_loss: 4.13637e+01
I0515 08:26:50.780427 140128494741248 run_lib.py:165] step: 486000, eval_loss: 1.58324e+01
I0515 08:26:57.186164 140128494741248 run_lib.py:152] step: 486050, training_loss: 1.49778e+01
I0515 08:27:03.423498 140128494741248 run_lib.py:152] step: 486100, training_loss: 2.64943e+01
I0515 08:27:03.474860 140128494741248 run_lib.py:165] step: 486100, eval_loss: 1.79097e+01
I0515 08:27:09.805768 140128494741248 run_lib.py:152] step: 486150, training_loss: 1.41130e+01
I0515 08:27:15.991241 140128494741248 run_lib.py:152] step: 486200, training_loss: 1.41043e+01
I0515 08:27:16.043071 140128494741248 run_lib.py:165] step: 486200, eval_loss: 3.49201e+01
I0515 08:27:22.485184 140128494741248 run_lib.py:152] step: 486250, training_loss: 4.02146e+01
I0515 08:27:28.801963 140128494741248 run_lib.py:152] step: 486300, training_loss: 3.06611e+01
I0515 08:27:28.854496 140128494741248 run_lib.py:165] step: 486300, eval_loss: 2.85024e+01
I0515 08:27:35.040206 140128494741248 run_lib.py:152] step: 486350, training_loss: 2.82871e+01
I0515 08:27:41.644725 140128494741248 run_lib.py:152] step: 486400, training_loss: 3.02661e+01
I0515 08:27:41.699110 140128494741248 run_lib.py:165] step: 486400, eval_loss: 3.30955e+01
I0515 08:27:47.851253 140128494741248 run_lib.py:152] step: 486450, training_loss: 3.27383e+01
I0515 08:27:54.130556 140128494741248 run_lib.py:152] step: 486500, training_loss: 2.26584e+01
I0515 08:27:54.181822 140128494741248 run_lib.py:165] step: 486500, eval_loss: 3.59200e+01
I0515 08:28:00.398200 140128494741248 run_lib.py:152] step: 486550, training_loss: 3.31715e+01
I0515 08:28:06.851188 140128494741248 run_lib.py:152] step: 486600, training_loss: 3.73539e+01
I0515 08:28:06.908848 140128494741248 run_lib.py:165] step: 486600, eval_loss: 4.05300e+01
I0515 08:28:13.022964 140128494741248 run_lib.py:152] step: 486650, training_loss: 5.18641e+01
I0515 08:28:19.324800 140128494741248 run_lib.py:152] step: 486700, training_loss: 2.97886e+01
I0515 08:28:19.376034 140128494741248 run_lib.py:165] step: 486700, eval_loss: 1.85276e+01
I0515 08:28:25.819784 140128494741248 run_lib.py:152] step: 486750, training_loss: 2.99960e+01
I0515 08:28:32.061809 140128494741248 run_lib.py:152] step: 486800, training_loss: 2.09638e+01
I0515 08:28:32.115282 140128494741248 run_lib.py:165] step: 486800, eval_loss: 1.62587e+01
I0515 08:28:38.238983 140128494741248 run_lib.py:152] step: 486850, training_loss: 3.37882e+01
I0515 08:28:44.497301 140128494741248 run_lib.py:152] step: 486900, training_loss: 1.94581e+01
I0515 08:28:44.550399 140128494741248 run_lib.py:165] step: 486900, eval_loss: 4.22365e+01
I0515 08:28:51.038435 140128494741248 run_lib.py:152] step: 486950, training_loss: 4.58345e+01
I0515 08:28:57.315407 140128494741248 run_lib.py:152] step: 487000, training_loss: 2.28260e+01
I0515 08:28:57.369881 140128494741248 run_lib.py:165] step: 487000, eval_loss: 2.83279e+01
I0515 08:29:03.553942 140128494741248 run_lib.py:152] step: 487050, training_loss: 2.37698e+01
I0515 08:29:09.800131 140128494741248 run_lib.py:152] step: 487100, training_loss: 2.32428e+01
I0515 08:29:10.076255 140128494741248 run_lib.py:165] step: 487100, eval_loss: 3.53694e+01
I0515 08:29:16.302214 140128494741248 run_lib.py:152] step: 487150, training_loss: 2.53779e+01
I0515 08:29:22.546732 140128494741248 run_lib.py:152] step: 487200, training_loss: 4.82624e+01
I0515 08:29:22.598503 140128494741248 run_lib.py:165] step: 487200, eval_loss: 3.28729e+01
I0515 08:29:28.803495 140128494741248 run_lib.py:152] step: 487250, training_loss: 3.10447e+01
I0515 08:29:35.217635 140128494741248 run_lib.py:152] step: 487300, training_loss: 2.98978e+01
I0515 08:29:35.263610 140128494741248 run_lib.py:165] step: 487300, eval_loss: 3.51492e+01
I0515 08:29:41.539096 140128494741248 run_lib.py:152] step: 487350, training_loss: 3.68198e+01
I0515 08:29:47.785790 140128494741248 run_lib.py:152] step: 487400, training_loss: 2.55512e+01
I0515 08:29:47.838456 140128494741248 run_lib.py:165] step: 487400, eval_loss: 2.61294e+01
I0515 08:29:54.307137 140128494741248 run_lib.py:152] step: 487450, training_loss: 4.04953e+01
I0515 08:30:00.566049 140128494741248 run_lib.py:152] step: 487500, training_loss: 3.34701e+01
I0515 08:30:00.616348 140128494741248 run_lib.py:165] step: 487500, eval_loss: 1.95932e+01
I0515 08:30:06.813959 140128494741248 run_lib.py:152] step: 487550, training_loss: 3.02185e+01
I0515 08:30:13.001548 140128494741248 run_lib.py:152] step: 487600, training_loss: 2.60640e+01
I0515 08:30:13.054367 140128494741248 run_lib.py:165] step: 487600, eval_loss: 3.27503e+01
I0515 08:30:19.604168 140128494741248 run_lib.py:152] step: 487650, training_loss: 4.27826e+01
I0515 08:30:25.893495 140128494741248 run_lib.py:152] step: 487700, training_loss: 3.28344e+01
I0515 08:30:25.946989 140128494741248 run_lib.py:165] step: 487700, eval_loss: 2.30135e+01
I0515 08:30:32.215443 140128494741248 run_lib.py:152] step: 487750, training_loss: 3.23352e+01
I0515 08:30:38.663475 140128494741248 run_lib.py:152] step: 487800, training_loss: 3.80221e+01
I0515 08:30:38.723419 140128494741248 run_lib.py:165] step: 487800, eval_loss: 3.74807e+01
I0515 08:30:45.018458 140128494741248 run_lib.py:152] step: 487850, training_loss: 2.32905e+01
I0515 08:30:51.209281 140128494741248 run_lib.py:152] step: 487900, training_loss: 2.71326e+01
I0515 08:30:51.258630 140128494741248 run_lib.py:165] step: 487900, eval_loss: 1.84931e+01
I0515 08:30:57.486419 140128494741248 run_lib.py:152] step: 487950, training_loss: 1.96316e+01
I0515 08:31:03.832667 140128494741248 run_lib.py:152] step: 488000, training_loss: 3.70065e+01
I0515 08:31:03.884461 140128494741248 run_lib.py:165] step: 488000, eval_loss: 1.81488e+01
I0515 08:31:09.906790 140128494741248 run_lib.py:152] step: 488050, training_loss: 2.66070e+01
I0515 08:31:15.987615 140128494741248 run_lib.py:152] step: 488100, training_loss: 3.45408e+01
I0515 08:31:16.042523 140128494741248 run_lib.py:165] step: 488100, eval_loss: 2.77474e+01
I0515 08:31:22.511031 140128494741248 run_lib.py:152] step: 488150, training_loss: 3.79240e+01
I0515 08:31:28.742357 140128494741248 run_lib.py:152] step: 488200, training_loss: 2.93100e+01
I0515 08:31:28.794652 140128494741248 run_lib.py:165] step: 488200, eval_loss: 3.52405e+01
I0515 08:31:35.132301 140128494741248 run_lib.py:152] step: 488250, training_loss: 3.52944e+01
I0515 08:31:41.553370 140128494741248 run_lib.py:152] step: 488300, training_loss: 1.56435e+01
I0515 08:31:41.610042 140128494741248 run_lib.py:165] step: 488300, eval_loss: 2.27460e+01
I0515 08:31:48.172059 140128494741248 run_lib.py:152] step: 488350, training_loss: 3.74915e+01
I0515 08:31:54.471085 140128494741248 run_lib.py:152] step: 488400, training_loss: 1.82586e+01
I0515 08:31:54.521926 140128494741248 run_lib.py:165] step: 488400, eval_loss: 3.20816e+01
I0515 08:32:00.797657 140128494741248 run_lib.py:152] step: 488450, training_loss: 3.80764e+01
I0515 08:32:07.298139 140128494741248 run_lib.py:152] step: 488500, training_loss: 3.86027e+01
I0515 08:32:07.356161 140128494741248 run_lib.py:165] step: 488500, eval_loss: 2.09951e+01
I0515 08:32:13.532521 140128494741248 run_lib.py:152] step: 488550, training_loss: 2.89605e+01
I0515 08:32:19.783476 140128494741248 run_lib.py:152] step: 488600, training_loss: 2.37088e+01
I0515 08:32:19.834516 140128494741248 run_lib.py:165] step: 488600, eval_loss: 3.43581e+01
I0515 08:32:26.066259 140128494741248 run_lib.py:152] step: 488650, training_loss: 3.67571e+01
I0515 08:32:33.956560 140128494741248 run_lib.py:152] step: 488700, training_loss: 3.45173e+01
I0515 08:32:34.018904 140128494741248 run_lib.py:165] step: 488700, eval_loss: 2.41617e+01
I0515 08:32:40.916682 140128494741248 run_lib.py:152] step: 488750, training_loss: 2.72619e+01
I0515 08:32:47.427746 140128494741248 run_lib.py:152] step: 488800, training_loss: 3.09536e+01
I0515 08:32:47.478594 140128494741248 run_lib.py:165] step: 488800, eval_loss: 2.56173e+01
I0515 08:32:53.914419 140128494741248 run_lib.py:152] step: 488850, training_loss: 2.52079e+01
I0515 08:33:00.290141 140128494741248 run_lib.py:152] step: 488900, training_loss: 3.88689e+01
I0515 08:33:00.337978 140128494741248 run_lib.py:165] step: 488900, eval_loss: 4.42949e+01
I0515 08:33:06.609428 140128494741248 run_lib.py:152] step: 488950, training_loss: 3.09841e+01
I0515 08:33:12.907066 140128494741248 run_lib.py:152] step: 489000, training_loss: 3.03965e+01
I0515 08:33:12.959890 140128494741248 run_lib.py:165] step: 489000, eval_loss: 3.04140e+01
I0515 08:33:19.407493 140128494741248 run_lib.py:152] step: 489050, training_loss: 2.96508e+01
I0515 08:33:25.642828 140128494741248 run_lib.py:152] step: 489100, training_loss: 3.61058e+01
I0515 08:33:25.692114 140128494741248 run_lib.py:165] step: 489100, eval_loss: 3.19698e+01
I0515 08:33:31.948999 140128494741248 run_lib.py:152] step: 489150, training_loss: 3.39530e+01
I0515 08:33:38.426090 140128494741248 run_lib.py:152] step: 489200, training_loss: 3.62936e+01
I0515 08:33:38.478698 140128494741248 run_lib.py:165] step: 489200, eval_loss: 3.02646e+01
I0515 08:33:44.946608 140128494741248 run_lib.py:152] step: 489250, training_loss: 3.14119e+01
I0515 08:33:51.230810 140128494741248 run_lib.py:152] step: 489300, training_loss: 2.74299e+01
I0515 08:33:51.282707 140128494741248 run_lib.py:165] step: 489300, eval_loss: 4.11266e+01
I0515 08:33:57.545600 140128494741248 run_lib.py:152] step: 489350, training_loss: 3.99064e+01
I0515 08:34:04.057193 140128494741248 run_lib.py:152] step: 489400, training_loss: 2.51368e+01
I0515 08:34:04.111287 140128494741248 run_lib.py:165] step: 489400, eval_loss: 2.89432e+01
I0515 08:34:10.319073 140128494741248 run_lib.py:152] step: 489450, training_loss: 2.48990e+01
I0515 08:34:16.709774 140128494741248 run_lib.py:152] step: 489500, training_loss: 3.34425e+01
I0515 08:34:16.761365 140128494741248 run_lib.py:165] step: 489500, eval_loss: 2.52948e+01
I0515 08:34:23.274194 140128494741248 run_lib.py:152] step: 489550, training_loss: 2.69998e+01
I0515 08:34:29.649181 140128494741248 run_lib.py:152] step: 489600, training_loss: 3.45204e+01
I0515 08:34:29.705350 140128494741248 run_lib.py:165] step: 489600, eval_loss: 2.92935e+01
I0515 08:34:35.966959 140128494741248 run_lib.py:152] step: 489650, training_loss: 2.06341e+01
I0515 08:34:42.308948 140128494741248 run_lib.py:152] step: 489700, training_loss: 2.26996e+01
I0515 08:34:42.357593 140128494741248 run_lib.py:165] step: 489700, eval_loss: 2.84418e+01
I0515 08:34:48.824696 140128494741248 run_lib.py:152] step: 489750, training_loss: 3.04755e+01
I0515 08:34:55.043146 140128494741248 run_lib.py:152] step: 489800, training_loss: 3.21525e+01
I0515 08:34:55.093338 140128494741248 run_lib.py:165] step: 489800, eval_loss: 2.80806e+01
I0515 08:35:01.426388 140128494741248 run_lib.py:152] step: 489850, training_loss: 3.01868e+01
I0515 08:35:08.080159 140128494741248 run_lib.py:152] step: 489900, training_loss: 2.90401e+01
I0515 08:35:08.135442 140128494741248 run_lib.py:165] step: 489900, eval_loss: 3.30121e+01
I0515 08:35:14.346691 140128494741248 run_lib.py:152] step: 489950, training_loss: 4.12110e+01
I0515 08:35:20.546065 140128494741248 run_lib.py:152] step: 490000, training_loss: 3.31432e+01
I0515 08:35:20.765392 140128494741248 run_lib.py:165] step: 490000, eval_loss: 4.35091e+01
I0515 08:35:27.015422 140128494741248 run_lib.py:152] step: 490050, training_loss: 2.76537e+01
I0515 08:35:33.448891 140128494741248 run_lib.py:152] step: 490100, training_loss: 2.22415e+01
I0515 08:35:33.498620 140128494741248 run_lib.py:165] step: 490100, eval_loss: 2.85131e+01
I0515 08:35:39.846386 140128494741248 run_lib.py:152] step: 490150, training_loss: 2.44633e+01
I0515 08:35:46.080353 140128494741248 run_lib.py:152] step: 490200, training_loss: 2.58198e+01
I0515 08:35:46.133275 140128494741248 run_lib.py:165] step: 490200, eval_loss: 2.78409e+01
I0515 08:35:52.655817 140128494741248 run_lib.py:152] step: 490250, training_loss: 2.74598e+01
I0515 08:35:58.913185 140128494741248 run_lib.py:152] step: 490300, training_loss: 3.69303e+01
I0515 08:35:58.961601 140128494741248 run_lib.py:165] step: 490300, eval_loss: 4.62297e+01
I0515 08:36:05.198112 140128494741248 run_lib.py:152] step: 490350, training_loss: 3.16455e+01
I0515 08:36:11.470254 140128494741248 run_lib.py:152] step: 490400, training_loss: 2.72670e+01
I0515 08:36:11.531234 140128494741248 run_lib.py:165] step: 490400, eval_loss: 2.81557e+01
I0515 08:36:18.908835 140128494741248 run_lib.py:152] step: 490450, training_loss: 2.39290e+01
I0515 08:36:25.279223 140128494741248 run_lib.py:152] step: 490500, training_loss: 2.62349e+01
I0515 08:36:25.333170 140128494741248 run_lib.py:165] step: 490500, eval_loss: 2.83278e+01
I0515 08:36:31.710211 140128494741248 run_lib.py:152] step: 490550, training_loss: 4.00595e+01
I0515 08:36:37.929975 140128494741248 run_lib.py:152] step: 490600, training_loss: 4.44701e+01
I0515 08:36:38.204455 140128494741248 run_lib.py:165] step: 490600, eval_loss: 4.25582e+01
I0515 08:36:44.588410 140128494741248 run_lib.py:152] step: 490650, training_loss: 1.67326e+01
I0515 08:36:50.892898 140128494741248 run_lib.py:152] step: 490700, training_loss: 4.51591e+01
I0515 08:36:50.950433 140128494741248 run_lib.py:165] step: 490700, eval_loss: 4.07983e+01
I0515 08:36:57.166067 140128494741248 run_lib.py:152] step: 490750, training_loss: 4.08473e+01
I0515 08:37:03.698321 140128494741248 run_lib.py:152] step: 490800, training_loss: 3.44261e+01
I0515 08:37:03.756498 140128494741248 run_lib.py:165] step: 490800, eval_loss: 3.63093e+01
I0515 08:37:10.018388 140128494741248 run_lib.py:152] step: 490850, training_loss: 2.16368e+01
I0515 08:37:16.318654 140128494741248 run_lib.py:152] step: 490900, training_loss: 2.57009e+01
I0515 08:37:16.373954 140128494741248 run_lib.py:165] step: 490900, eval_loss: 3.18001e+01
I0515 08:37:22.872846 140128494741248 run_lib.py:152] step: 490950, training_loss: 2.24615e+01
I0515 08:37:29.188224 140128494741248 run_lib.py:152] step: 491000, training_loss: 3.27343e+01
I0515 08:37:29.237994 140128494741248 run_lib.py:165] step: 491000, eval_loss: 4.07870e+01
I0515 08:37:35.507318 140128494741248 run_lib.py:152] step: 491050, training_loss: 3.36674e+01
I0515 08:37:41.902182 140128494741248 run_lib.py:152] step: 491100, training_loss: 2.23390e+01
I0515 08:37:41.963153 140128494741248 run_lib.py:165] step: 491100, eval_loss: 3.97596e+01
I0515 08:37:48.562337 140128494741248 run_lib.py:152] step: 491150, training_loss: 3.96797e+01
I0515 08:37:54.901251 140128494741248 run_lib.py:152] step: 491200, training_loss: 2.82701e+01
I0515 08:37:54.953699 140128494741248 run_lib.py:165] step: 491200, eval_loss: 2.01049e+01
I0515 08:38:01.355833 140128494741248 run_lib.py:152] step: 491250, training_loss: 2.65539e+01
I0515 08:38:07.914832 140128494741248 run_lib.py:152] step: 491300, training_loss: 1.90382e+01
I0515 08:38:07.969125 140128494741248 run_lib.py:165] step: 491300, eval_loss: 3.41456e+01
I0515 08:38:14.357752 140128494741248 run_lib.py:152] step: 491350, training_loss: 3.39589e+01
I0515 08:38:20.582025 140128494741248 run_lib.py:152] step: 491400, training_loss: 3.40588e+01
I0515 08:38:20.636049 140128494741248 run_lib.py:165] step: 491400, eval_loss: 3.28433e+01
I0515 08:38:26.934478 140128494741248 run_lib.py:152] step: 491450, training_loss: 2.78746e+01
I0515 08:38:33.581717 140128494741248 run_lib.py:152] step: 491500, training_loss: 2.08768e+01
I0515 08:38:33.633774 140128494741248 run_lib.py:165] step: 491500, eval_loss: 3.55479e+01
I0515 08:38:39.825754 140128494741248 run_lib.py:152] step: 491550, training_loss: 2.87028e+01
I0515 08:38:46.146678 140128494741248 run_lib.py:152] step: 491600, training_loss: 2.60442e+01
I0515 08:38:46.198945 140128494741248 run_lib.py:165] step: 491600, eval_loss: 2.46013e+01
I0515 08:38:52.752408 140128494741248 run_lib.py:152] step: 491650, training_loss: 2.90289e+01
I0515 08:38:58.982034 140128494741248 run_lib.py:152] step: 491700, training_loss: 3.50006e+01
I0515 08:38:59.034459 140128494741248 run_lib.py:165] step: 491700, eval_loss: 3.84245e+01
I0515 08:39:05.289203 140128494741248 run_lib.py:152] step: 491750, training_loss: 3.64750e+01
I0515 08:39:11.560159 140128494741248 run_lib.py:152] step: 491800, training_loss: 3.43344e+01
I0515 08:39:11.616577 140128494741248 run_lib.py:165] step: 491800, eval_loss: 1.42453e+01
I0515 08:39:18.121153 140128494741248 run_lib.py:152] step: 491850, training_loss: 2.93890e+01
I0515 08:39:24.464804 140128494741248 run_lib.py:152] step: 491900, training_loss: 4.14029e+01
I0515 08:39:24.515093 140128494741248 run_lib.py:165] step: 491900, eval_loss: 2.53555e+01
I0515 08:39:30.723763 140128494741248 run_lib.py:152] step: 491950, training_loss: 3.54669e+01
I0515 08:39:37.437106 140128494741248 run_lib.py:152] step: 492000, training_loss: 3.24551e+01
I0515 08:39:37.487770 140128494741248 run_lib.py:165] step: 492000, eval_loss: 2.89793e+01
I0515 08:39:43.851539 140128494741248 run_lib.py:152] step: 492050, training_loss: 2.75987e+01
I0515 08:39:50.125741 140128494741248 run_lib.py:152] step: 492100, training_loss: 2.88411e+01
I0515 08:39:50.178121 140128494741248 run_lib.py:165] step: 492100, eval_loss: 2.37405e+01
I0515 08:39:56.479862 140128494741248 run_lib.py:152] step: 492150, training_loss: 2.22842e+01
I0515 08:40:02.975295 140128494741248 run_lib.py:152] step: 492200, training_loss: 3.23268e+01
I0515 08:40:03.023768 140128494741248 run_lib.py:165] step: 492200, eval_loss: 2.46203e+01
I0515 08:40:09.274916 140128494741248 run_lib.py:152] step: 492250, training_loss: 3.56358e+01
I0515 08:40:15.528354 140128494741248 run_lib.py:152] step: 492300, training_loss: 3.27566e+01
I0515 08:40:15.580322 140128494741248 run_lib.py:165] step: 492300, eval_loss: 6.20011e+01
I0515 08:40:22.106237 140128494741248 run_lib.py:152] step: 492350, training_loss: 2.79181e+01
I0515 08:40:28.332545 140128494741248 run_lib.py:152] step: 492400, training_loss: 2.82157e+01
I0515 08:40:28.387638 140128494741248 run_lib.py:165] step: 492400, eval_loss: 3.93403e+01
I0515 08:40:34.737504 140128494741248 run_lib.py:152] step: 492450, training_loss: 3.18014e+01
I0515 08:40:40.903172 140128494741248 run_lib.py:152] step: 492500, training_loss: 3.74058e+01
I0515 08:40:40.955593 140128494741248 run_lib.py:165] step: 492500, eval_loss: 3.57001e+01
I0515 08:40:47.540519 140128494741248 run_lib.py:152] step: 492550, training_loss: 3.26602e+01
I0515 08:40:53.864794 140128494741248 run_lib.py:152] step: 492600, training_loss: 3.49407e+01
I0515 08:40:53.915457 140128494741248 run_lib.py:165] step: 492600, eval_loss: 3.11297e+01
I0515 08:41:00.222752 140128494741248 run_lib.py:152] step: 492650, training_loss: 3.88255e+01
I0515 08:41:06.699565 140128494741248 run_lib.py:152] step: 492700, training_loss: 2.62114e+01
I0515 08:41:06.753166 140128494741248 run_lib.py:165] step: 492700, eval_loss: 2.36952e+01
I0515 08:41:13.071705 140128494741248 run_lib.py:152] step: 492750, training_loss: 2.84614e+01
I0515 08:41:19.344757 140128494741248 run_lib.py:152] step: 492800, training_loss: 3.32189e+01
I0515 08:41:19.403889 140128494741248 run_lib.py:165] step: 492800, eval_loss: 2.59649e+01
I0515 08:41:25.665858 140128494741248 run_lib.py:152] step: 492850, training_loss: 3.36033e+01
I0515 08:41:32.150225 140128494741248 run_lib.py:152] step: 492900, training_loss: 4.52566e+01
I0515 08:41:32.198153 140128494741248 run_lib.py:165] step: 492900, eval_loss: 4.42124e+01
I0515 08:41:38.428663 140128494741248 run_lib.py:152] step: 492950, training_loss: 1.91531e+01
I0515 08:41:44.712715 140128494741248 run_lib.py:152] step: 493000, training_loss: 4.08981e+01
I0515 08:41:44.761069 140128494741248 run_lib.py:165] step: 493000, eval_loss: 4.68966e+01
I0515 08:41:51.303919 140128494741248 run_lib.py:152] step: 493050, training_loss: 3.36542e+01
I0515 08:41:57.448953 140128494741248 run_lib.py:152] step: 493100, training_loss: 3.23813e+01
I0515 08:41:57.498133 140128494741248 run_lib.py:165] step: 493100, eval_loss: 2.93191e+01
I0515 08:42:03.799188 140128494741248 run_lib.py:152] step: 493150, training_loss: 3.27407e+01
I0515 08:42:10.036111 140128494741248 run_lib.py:152] step: 493200, training_loss: 2.57180e+01
I0515 08:42:10.084545 140128494741248 run_lib.py:165] step: 493200, eval_loss: 3.98305e+01
I0515 08:42:16.520158 140128494741248 run_lib.py:152] step: 493250, training_loss: 2.68124e+01
I0515 08:42:22.695774 140128494741248 run_lib.py:152] step: 493300, training_loss: 2.51189e+01
I0515 08:42:22.748927 140128494741248 run_lib.py:165] step: 493300, eval_loss: 2.99889e+01
I0515 08:42:29.058813 140128494741248 run_lib.py:152] step: 493350, training_loss: 2.93215e+01
I0515 08:42:35.600415 140128494741248 run_lib.py:152] step: 493400, training_loss: 3.11369e+01
I0515 08:42:35.658882 140128494741248 run_lib.py:165] step: 493400, eval_loss: 2.33484e+01
I0515 08:42:41.957597 140128494741248 run_lib.py:152] step: 493450, training_loss: 2.95720e+01
I0515 08:42:48.109478 140128494741248 run_lib.py:152] step: 493500, training_loss: 2.14455e+01
I0515 08:42:48.158567 140128494741248 run_lib.py:165] step: 493500, eval_loss: 4.33011e+01
I0515 08:42:54.436590 140128494741248 run_lib.py:152] step: 493550, training_loss: 3.79656e+01
I0515 08:43:00.866520 140128494741248 run_lib.py:152] step: 493600, training_loss: 2.92290e+01
I0515 08:43:00.919299 140128494741248 run_lib.py:165] step: 493600, eval_loss: 3.75606e+01
I0515 08:43:07.160990 140128494741248 run_lib.py:152] step: 493650, training_loss: 4.36034e+01
I0515 08:43:13.299608 140128494741248 run_lib.py:152] step: 493700, training_loss: 4.07699e+01
I0515 08:43:13.350275 140128494741248 run_lib.py:165] step: 493700, eval_loss: 2.57571e+01
I0515 08:43:19.753279 140128494741248 run_lib.py:152] step: 493750, training_loss: 4.86375e+01
I0515 08:43:25.978131 140128494741248 run_lib.py:152] step: 493800, training_loss: 2.69632e+01
I0515 08:43:26.029426 140128494741248 run_lib.py:165] step: 493800, eval_loss: 3.89180e+01
I0515 08:43:32.361793 140128494741248 run_lib.py:152] step: 493850, training_loss: 3.68315e+01
I0515 08:43:38.701748 140128494741248 run_lib.py:152] step: 493900, training_loss: 2.67702e+01
I0515 08:43:38.754821 140128494741248 run_lib.py:165] step: 493900, eval_loss: 2.76744e+01
I0515 08:43:45.251752 140128494741248 run_lib.py:152] step: 493950, training_loss: 2.84432e+01
I0515 08:43:51.457106 140128494741248 run_lib.py:152] step: 494000, training_loss: 2.76169e+01
I0515 08:43:51.507463 140128494741248 run_lib.py:165] step: 494000, eval_loss: 3.44026e+01
I0515 08:43:57.796470 140128494741248 run_lib.py:152] step: 494050, training_loss: 2.04630e+01
I0515 08:44:04.069357 140128494741248 run_lib.py:152] step: 494100, training_loss: 1.72480e+01
I0515 08:44:04.357954 140128494741248 run_lib.py:165] step: 494100, eval_loss: 3.55504e+01
I0515 08:44:10.596669 140128494741248 run_lib.py:152] step: 494150, training_loss: 2.71962e+01
I0515 08:44:16.797144 140128494741248 run_lib.py:152] step: 494200, training_loss: 1.32333e+01
I0515 08:44:16.846832 140128494741248 run_lib.py:165] step: 494200, eval_loss: 2.30517e+01
I0515 08:44:23.093844 140128494741248 run_lib.py:152] step: 494250, training_loss: 3.21396e+01
I0515 08:44:29.554249 140128494741248 run_lib.py:152] step: 494300, training_loss: 2.52715e+01
I0515 08:44:29.606181 140128494741248 run_lib.py:165] step: 494300, eval_loss: 4.16122e+01
I0515 08:44:35.866386 140128494741248 run_lib.py:152] step: 494350, training_loss: 3.12952e+01
I0515 08:44:42.169809 140128494741248 run_lib.py:152] step: 494400, training_loss: 3.52198e+01
I0515 08:44:42.222795 140128494741248 run_lib.py:165] step: 494400, eval_loss: 4.47848e+01
I0515 08:44:48.650391 140128494741248 run_lib.py:152] step: 494450, training_loss: 3.94272e+01
I0515 08:44:54.836441 140128494741248 run_lib.py:152] step: 494500, training_loss: 3.01672e+01
I0515 08:44:54.891957 140128494741248 run_lib.py:165] step: 494500, eval_loss: 3.42101e+01
I0515 08:45:01.118162 140128494741248 run_lib.py:152] step: 494550, training_loss: 2.86532e+01
I0515 08:45:07.341024 140128494741248 run_lib.py:152] step: 494600, training_loss: 3.65314e+01
I0515 08:45:07.393281 140128494741248 run_lib.py:165] step: 494600, eval_loss: 3.03529e+01
I0515 08:45:13.933466 140128494741248 run_lib.py:152] step: 494650, training_loss: 2.34906e+01
I0515 08:45:20.204603 140128494741248 run_lib.py:152] step: 494700, training_loss: 3.04035e+01
I0515 08:45:20.259806 140128494741248 run_lib.py:165] step: 494700, eval_loss: 2.59967e+01
I0515 08:45:26.449225 140128494741248 run_lib.py:152] step: 494750, training_loss: 3.72304e+01
I0515 08:45:32.955769 140128494741248 run_lib.py:152] step: 494800, training_loss: 1.39220e+01
I0515 08:45:33.013538 140128494741248 run_lib.py:165] step: 494800, eval_loss: 3.66204e+01
I0515 08:45:39.255065 140128494741248 run_lib.py:152] step: 494850, training_loss: 3.93930e+01
I0515 08:45:45.535071 140128494741248 run_lib.py:152] step: 494900, training_loss: 4.40037e+01
I0515 08:45:45.587399 140128494741248 run_lib.py:165] step: 494900, eval_loss: 3.38387e+01
I0515 08:45:51.876410 140128494741248 run_lib.py:152] step: 494950, training_loss: 2.99292e+01
I0515 08:45:58.411628 140128494741248 run_lib.py:152] step: 495000, training_loss: 3.69187e+01
I0515 08:45:58.468517 140128494741248 run_lib.py:165] step: 495000, eval_loss: 2.21575e+01
I0515 08:46:04.696616 140128494741248 run_lib.py:152] step: 495050, training_loss: 5.92921e+01
I0515 08:46:11.132179 140128494741248 run_lib.py:152] step: 495100, training_loss: 3.46150e+01
I0515 08:46:11.183999 140128494741248 run_lib.py:165] step: 495100, eval_loss: 2.19669e+01
I0515 08:46:17.645131 140128494741248 run_lib.py:152] step: 495150, training_loss: 2.33252e+01
I0515 08:46:24.020422 140128494741248 run_lib.py:152] step: 495200, training_loss: 3.53034e+01
I0515 08:46:24.078250 140128494741248 run_lib.py:165] step: 495200, eval_loss: 2.88556e+01
I0515 08:46:30.286511 140128494741248 run_lib.py:152] step: 495250, training_loss: 1.79736e+01
I0515 08:46:36.552407 140128494741248 run_lib.py:152] step: 495300, training_loss: 2.43453e+01
I0515 08:46:36.605385 140128494741248 run_lib.py:165] step: 495300, eval_loss: 2.12322e+01
I0515 08:46:43.181461 140128494741248 run_lib.py:152] step: 495350, training_loss: 3.21717e+01
I0515 08:46:49.473884 140128494741248 run_lib.py:152] step: 495400, training_loss: 3.30246e+01
I0515 08:46:49.523081 140128494741248 run_lib.py:165] step: 495400, eval_loss: 3.63150e+01
I0515 08:46:55.871076 140128494741248 run_lib.py:152] step: 495450, training_loss: 3.14983e+01
I0515 08:47:02.327581 140128494741248 run_lib.py:152] step: 495500, training_loss: 3.41808e+01
I0515 08:47:02.377977 140128494741248 run_lib.py:165] step: 495500, eval_loss: 3.93344e+01
I0515 08:47:08.605919 140128494741248 run_lib.py:152] step: 495550, training_loss: 2.45374e+01
I0515 08:47:14.787744 140128494741248 run_lib.py:152] step: 495600, training_loss: 2.53965e+01
I0515 08:47:14.841636 140128494741248 run_lib.py:165] step: 495600, eval_loss: 2.76230e+01
I0515 08:47:21.088450 140128494741248 run_lib.py:152] step: 495650, training_loss: 3.24500e+01
I0515 08:47:27.712581 140128494741248 run_lib.py:152] step: 495700, training_loss: 2.46374e+01
I0515 08:47:27.761990 140128494741248 run_lib.py:165] step: 495700, eval_loss: 2.82142e+01
I0515 08:47:34.156047 140128494741248 run_lib.py:152] step: 495750, training_loss: 3.62257e+01
I0515 08:47:40.381201 140128494741248 run_lib.py:152] step: 495800, training_loss: 3.95538e+01
I0515 08:47:40.432106 140128494741248 run_lib.py:165] step: 495800, eval_loss: 3.58896e+01
I0515 08:47:46.945164 140128494741248 run_lib.py:152] step: 495850, training_loss: 4.10836e+01
I0515 08:47:53.128377 140128494741248 run_lib.py:152] step: 495900, training_loss: 3.79566e+01
I0515 08:47:53.179333 140128494741248 run_lib.py:165] step: 495900, eval_loss: 3.18031e+01
I0515 08:47:59.404847 140128494741248 run_lib.py:152] step: 495950, training_loss: 2.70938e+01
I0515 08:48:05.692342 140128494741248 run_lib.py:152] step: 496000, training_loss: 2.94535e+01
I0515 08:48:05.745219 140128494741248 run_lib.py:165] step: 496000, eval_loss: 3.76744e+01
I0515 08:48:12.255012 140128494741248 run_lib.py:152] step: 496050, training_loss: 2.47535e+01
I0515 08:48:18.482770 140128494741248 run_lib.py:152] step: 496100, training_loss: 3.25403e+01
I0515 08:48:18.535139 140128494741248 run_lib.py:165] step: 496100, eval_loss: 3.25384e+01
I0515 08:48:24.832028 140128494741248 run_lib.py:152] step: 496150, training_loss: 2.90389e+01
I0515 08:48:31.256660 140128494741248 run_lib.py:152] step: 496200, training_loss: 2.26745e+01
I0515 08:48:31.307586 140128494741248 run_lib.py:165] step: 496200, eval_loss: 1.88500e+01
I0515 08:48:37.647407 140128494741248 run_lib.py:152] step: 496250, training_loss: 1.51147e+01
I0515 08:48:43.845255 140128494741248 run_lib.py:152] step: 496300, training_loss: 2.71512e+01
I0515 08:48:43.897194 140128494741248 run_lib.py:165] step: 496300, eval_loss: 4.25795e+01
I0515 08:48:50.211122 140128494741248 run_lib.py:152] step: 496350, training_loss: 1.37756e+01
I0515 08:48:56.829009 140128494741248 run_lib.py:152] step: 496400, training_loss: 2.92574e+01
I0515 08:48:56.885906 140128494741248 run_lib.py:165] step: 496400, eval_loss: 2.81804e+01
I0515 08:49:03.117729 140128494741248 run_lib.py:152] step: 496450, training_loss: 3.42705e+01
I0515 08:49:09.352256 140128494741248 run_lib.py:152] step: 496500, training_loss: 2.93923e+01
I0515 08:49:09.402042 140128494741248 run_lib.py:165] step: 496500, eval_loss: 4.75405e+01
I0515 08:49:15.922657 140128494741248 run_lib.py:152] step: 496550, training_loss: 2.96737e+01
I0515 08:49:22.087001 140128494741248 run_lib.py:152] step: 496600, training_loss: 4.16456e+01
I0515 08:49:22.137994 140128494741248 run_lib.py:165] step: 496600, eval_loss: 4.13553e+01
I0515 08:49:28.321465 140128494741248 run_lib.py:152] step: 496650, training_loss: 3.79603e+01
I0515 08:49:34.681673 140128494741248 run_lib.py:152] step: 496700, training_loss: 4.67065e+01
I0515 08:49:34.737902 140128494741248 run_lib.py:165] step: 496700, eval_loss: 2.51904e+01
I0515 08:49:41.402853 140128494741248 run_lib.py:152] step: 496750, training_loss: 3.98076e+01
I0515 08:49:47.682209 140128494741248 run_lib.py:152] step: 496800, training_loss: 2.50850e+01
I0515 08:49:47.735264 140128494741248 run_lib.py:165] step: 496800, eval_loss: 2.36547e+01
I0515 08:49:53.904846 140128494741248 run_lib.py:152] step: 496850, training_loss: 1.76335e+01
I0515 08:50:00.423596 140128494741248 run_lib.py:152] step: 496900, training_loss: 1.62631e+01
I0515 08:50:00.480846 140128494741248 run_lib.py:165] step: 496900, eval_loss: 1.67017e+01
I0515 08:50:06.679633 140128494741248 run_lib.py:152] step: 496950, training_loss: 3.97588e+01
I0515 08:50:12.999719 140128494741248 run_lib.py:152] step: 497000, training_loss: 3.10169e+01
I0515 08:50:13.050902 140128494741248 run_lib.py:165] step: 497000, eval_loss: 3.01486e+01
I0515 08:50:19.368798 140128494741248 run_lib.py:152] step: 497050, training_loss: 2.44528e+01
I0515 08:50:25.949984 140128494741248 run_lib.py:152] step: 497100, training_loss: 3.22872e+01
I0515 08:50:26.004101 140128494741248 run_lib.py:165] step: 497100, eval_loss: 3.60733e+01
I0515 08:50:32.418552 140128494741248 run_lib.py:152] step: 497150, training_loss: 3.30042e+01
I0515 08:50:38.765646 140128494741248 run_lib.py:152] step: 497200, training_loss: 3.13785e+01
I0515 08:50:38.818141 140128494741248 run_lib.py:165] step: 497200, eval_loss: 2.49441e+01
I0515 08:50:45.320287 140128494741248 run_lib.py:152] step: 497250, training_loss: 3.57167e+01
I0515 08:50:51.651162 140128494741248 run_lib.py:152] step: 497300, training_loss: 2.03699e+01
I0515 08:50:51.703269 140128494741248 run_lib.py:165] step: 497300, eval_loss: 2.35284e+01
I0515 08:50:57.984138 140128494741248 run_lib.py:152] step: 497350, training_loss: 4.00176e+01
I0515 08:51:04.272313 140128494741248 run_lib.py:152] step: 497400, training_loss: 2.23924e+01
I0515 08:51:04.323041 140128494741248 run_lib.py:165] step: 497400, eval_loss: 3.87871e+01
I0515 08:51:10.772011 140128494741248 run_lib.py:152] step: 497450, training_loss: 2.89238e+01
I0515 08:51:16.995667 140128494741248 run_lib.py:152] step: 497500, training_loss: 3.31363e+01
I0515 08:51:17.050689 140128494741248 run_lib.py:165] step: 497500, eval_loss: 3.07369e+01
I0515 08:51:23.397770 140128494741248 run_lib.py:152] step: 497550, training_loss: 3.56691e+01
I0515 08:51:29.523791 140128494741248 run_lib.py:152] step: 497600, training_loss: 2.50856e+01
I0515 08:51:29.802933 140128494741248 run_lib.py:165] step: 497600, eval_loss: 2.22830e+01
I0515 08:51:36.147579 140128494741248 run_lib.py:152] step: 497650, training_loss: 3.94080e+01
I0515 08:51:42.445658 140128494741248 run_lib.py:152] step: 497700, training_loss: 3.26039e+01
I0515 08:51:42.497839 140128494741248 run_lib.py:165] step: 497700, eval_loss: 3.40946e+01
I0515 08:51:48.840065 140128494741248 run_lib.py:152] step: 497750, training_loss: 4.33853e+01
I0515 08:51:55.387753 140128494741248 run_lib.py:152] step: 497800, training_loss: 2.71313e+01
I0515 08:51:55.441861 140128494741248 run_lib.py:165] step: 497800, eval_loss: 5.99139e+01
I0515 08:52:01.701445 140128494741248 run_lib.py:152] step: 497850, training_loss: 3.52593e+01
I0515 08:52:07.909034 140128494741248 run_lib.py:152] step: 497900, training_loss: 2.78447e+01
I0515 08:52:07.962230 140128494741248 run_lib.py:165] step: 497900, eval_loss: 4.13109e+01
I0515 08:52:14.665725 140128494741248 run_lib.py:152] step: 497950, training_loss: 3.44821e+01
I0515 08:52:21.022912 140128494741248 run_lib.py:152] step: 498000, training_loss: 4.37916e+01
I0515 08:52:21.076052 140128494741248 run_lib.py:165] step: 498000, eval_loss: 2.30016e+01
I0515 08:52:27.397761 140128494741248 run_lib.py:152] step: 498050, training_loss: 2.58334e+01
I0515 08:52:33.766947 140128494741248 run_lib.py:152] step: 498100, training_loss: 1.85590e+01
I0515 08:52:33.820012 140128494741248 run_lib.py:165] step: 498100, eval_loss: 3.97963e+01
I0515 08:52:40.408552 140128494741248 run_lib.py:152] step: 498150, training_loss: 2.05987e+01
I0515 08:52:46.829853 140128494741248 run_lib.py:152] step: 498200, training_loss: 3.12095e+01
I0515 08:52:46.884478 140128494741248 run_lib.py:165] step: 498200, eval_loss: 3.11360e+01
I0515 08:52:53.183838 140128494741248 run_lib.py:152] step: 498250, training_loss: 3.13443e+01
I0515 08:52:59.799690 140128494741248 run_lib.py:152] step: 498300, training_loss: 3.93985e+01
I0515 08:52:59.851533 140128494741248 run_lib.py:165] step: 498300, eval_loss: 3.74762e+01
I0515 08:53:06.095066 140128494741248 run_lib.py:152] step: 498350, training_loss: 3.18816e+01
I0515 08:53:12.363353 140128494741248 run_lib.py:152] step: 498400, training_loss: 2.79567e+01
I0515 08:53:12.414466 140128494741248 run_lib.py:165] step: 498400, eval_loss: 3.41091e+01
I0515 08:53:18.758144 140128494741248 run_lib.py:152] step: 498450, training_loss: 3.72274e+01
I0515 08:53:25.174339 140128494741248 run_lib.py:152] step: 498500, training_loss: 3.78393e+01
I0515 08:53:25.222569 140128494741248 run_lib.py:165] step: 498500, eval_loss: 4.48487e+01
I0515 08:53:31.472167 140128494741248 run_lib.py:152] step: 498550, training_loss: 2.92622e+01
I0515 08:53:37.684940 140128494741248 run_lib.py:152] step: 498600, training_loss: 2.53389e+01
I0515 08:53:37.739989 140128494741248 run_lib.py:165] step: 498600, eval_loss: 2.09749e+01
I0515 08:53:44.160490 140128494741248 run_lib.py:152] step: 498650, training_loss: 2.68056e+01
I0515 08:53:50.385587 140128494741248 run_lib.py:152] step: 498700, training_loss: 3.54367e+01
I0515 08:53:50.435061 140128494741248 run_lib.py:165] step: 498700, eval_loss: 1.77116e+01
I0515 08:53:56.667467 140128494741248 run_lib.py:152] step: 498750, training_loss: 3.51263e+01
I0515 08:54:02.914902 140128494741248 run_lib.py:152] step: 498800, training_loss: 3.09616e+01
I0515 08:54:02.969748 140128494741248 run_lib.py:165] step: 498800, eval_loss: 2.36212e+01
I0515 08:54:09.462924 140128494741248 run_lib.py:152] step: 498850, training_loss: 2.90330e+01
I0515 08:54:15.699611 140128494741248 run_lib.py:152] step: 498900, training_loss: 3.48840e+01
I0515 08:54:15.755392 140128494741248 run_lib.py:165] step: 498900, eval_loss: 1.88643e+01
I0515 08:54:22.047492 140128494741248 run_lib.py:152] step: 498950, training_loss: 3.17988e+01
I0515 08:54:28.513415 140128494741248 run_lib.py:152] step: 499000, training_loss: 2.40419e+01
I0515 08:54:28.566127 140128494741248 run_lib.py:165] step: 499000, eval_loss: 3.32448e+01
I0515 08:54:34.796116 140128494741248 run_lib.py:152] step: 499050, training_loss: 2.15703e+01
I0515 08:54:40.952825 140128494741248 run_lib.py:152] step: 499100, training_loss: 3.39571e+01
I0515 08:54:41.009730 140128494741248 run_lib.py:165] step: 499100, eval_loss: 2.99186e+01
I0515 08:54:47.283190 140128494741248 run_lib.py:152] step: 499150, training_loss: 3.55406e+01
I0515 08:54:53.731181 140128494741248 run_lib.py:152] step: 499200, training_loss: 2.56397e+01
I0515 08:54:53.785008 140128494741248 run_lib.py:165] step: 499200, eval_loss: 3.79783e+01
I0515 08:55:00.055681 140128494741248 run_lib.py:152] step: 499250, training_loss: 4.03398e+01
I0515 08:55:06.242169 140128494741248 run_lib.py:152] step: 499300, training_loss: 1.85405e+01
I0515 08:55:06.294777 140128494741248 run_lib.py:165] step: 499300, eval_loss: 2.60778e+01
I0515 08:55:12.858852 140128494741248 run_lib.py:152] step: 499350, training_loss: 3.16857e+01
I0515 08:55:19.038158 140128494741248 run_lib.py:152] step: 499400, training_loss: 4.04308e+01
I0515 08:55:19.087742 140128494741248 run_lib.py:165] step: 499400, eval_loss: 3.37182e+01
I0515 08:55:25.487698 140128494741248 run_lib.py:152] step: 499450, training_loss: 3.29267e+01
I0515 08:55:31.631898 140128494741248 run_lib.py:152] step: 499500, training_loss: 3.46158e+01
I0515 08:55:31.686365 140128494741248 run_lib.py:165] step: 499500, eval_loss: 2.81225e+01
I0515 08:55:38.175912 140128494741248 run_lib.py:152] step: 499550, training_loss: 2.64959e+01
I0515 08:55:44.427358 140128494741248 run_lib.py:152] step: 499600, training_loss: 3.42015e+01
I0515 08:55:44.485386 140128494741248 run_lib.py:165] step: 499600, eval_loss: 3.39051e+01
I0515 08:55:50.721246 140128494741248 run_lib.py:152] step: 499650, training_loss: 3.28134e+01
I0515 08:55:57.178057 140128494741248 run_lib.py:152] step: 499700, training_loss: 2.84572e+01
I0515 08:55:57.230935 140128494741248 run_lib.py:165] step: 499700, eval_loss: 4.47166e+01
I0515 08:56:03.422988 140128494741248 run_lib.py:152] step: 499750, training_loss: 3.55424e+01
I0515 08:56:09.692214 140128494741248 run_lib.py:152] step: 499800, training_loss: 3.08456e+01
I0515 08:56:09.749871 140128494741248 run_lib.py:165] step: 499800, eval_loss: 3.78999e+01
I0515 08:56:15.943829 140128494741248 run_lib.py:152] step: 499850, training_loss: 4.52297e+01
I0515 08:56:22.468662 140128494741248 run_lib.py:152] step: 499900, training_loss: 3.97493e+01
I0515 08:56:22.526446 140128494741248 run_lib.py:165] step: 499900, eval_loss: 1.57922e+01
I0515 08:56:28.749455 140128494741248 run_lib.py:152] step: 499950, training_loss: 4.18857e+01
I0515 08:56:34.980586 140128494741248 run_lib.py:152] step: 500000, training_loss: 3.73003e+01
I0515 08:56:35.189961 140128494741248 run_lib.py:165] step: 500000, eval_loss: 3.85271e+01
I0515 08:57:55.974163 140128494741248 run_lib.py:152] step: 500050, training_loss: 2.33472e+01
I0515 08:58:02.207628 140128494741248 run_lib.py:152] step: 500100, training_loss: 3.11053e+01
I0515 08:58:02.260299 140128494741248 run_lib.py:165] step: 500100, eval_loss: 2.45613e+01
I0515 08:58:08.493476 140128494741248 run_lib.py:152] step: 500150, training_loss: 4.87123e+01
I0515 08:58:14.946902 140128494741248 run_lib.py:152] step: 500200, training_loss: 4.22568e+01
I0515 08:58:15.000184 140128494741248 run_lib.py:165] step: 500200, eval_loss: 2.12423e+01
I0515 08:58:21.361825 140128494741248 run_lib.py:152] step: 500250, training_loss: 2.04724e+01
I0515 08:58:27.608337 140128494741248 run_lib.py:152] step: 500300, training_loss: 5.21298e+01
I0515 08:58:27.659230 140128494741248 run_lib.py:165] step: 500300, eval_loss: 3.02830e+01
I0515 08:58:33.814280 140128494741248 run_lib.py:152] step: 500350, training_loss: 3.90236e+01
I0515 08:58:40.302220 140128494741248 run_lib.py:152] step: 500400, training_loss: 2.69144e+01
I0515 08:58:40.358609 140128494741248 run_lib.py:165] step: 500400, eval_loss: 2.34496e+01
I0515 08:58:46.570580 140128494741248 run_lib.py:152] step: 500450, training_loss: 2.35225e+01
I0515 08:58:52.824671 140128494741248 run_lib.py:152] step: 500500, training_loss: 3.05679e+01
I0515 08:58:52.878272 140128494741248 run_lib.py:165] step: 500500, eval_loss: 2.33943e+01
I0515 08:58:59.248749 140128494741248 run_lib.py:152] step: 500550, training_loss: 2.48811e+01
I0515 08:59:05.560569 140128494741248 run_lib.py:152] step: 500600, training_loss: 3.52020e+01
I0515 08:59:05.612287 140128494741248 run_lib.py:165] step: 500600, eval_loss: 3.21614e+01
I0515 08:59:12.031656 140128494741248 run_lib.py:152] step: 500650, training_loss: 3.15492e+01
I0515 08:59:18.191493 140128494741248 run_lib.py:152] step: 500700, training_loss: 5.65639e+01
I0515 08:59:18.239993 140128494741248 run_lib.py:165] step: 500700, eval_loss: 4.16255e+01
I0515 08:59:24.716687 140128494741248 run_lib.py:152] step: 500750, training_loss: 3.00697e+01
I0515 08:59:30.860123 140128494741248 run_lib.py:152] step: 500800, training_loss: 3.45521e+01
I0515 08:59:30.911034 140128494741248 run_lib.py:165] step: 500800, eval_loss: 2.23206e+01
I0515 08:59:37.119874 140128494741248 run_lib.py:152] step: 500850, training_loss: 4.01608e+01
I0515 08:59:43.623711 140128494741248 run_lib.py:152] step: 500900, training_loss: 2.82181e+01
I0515 08:59:43.678987 140128494741248 run_lib.py:165] step: 500900, eval_loss: 3.44473e+01
I0515 08:59:49.924151 140128494741248 run_lib.py:152] step: 500950, training_loss: 3.15373e+01
I0515 08:59:56.140352 140128494741248 run_lib.py:152] step: 501000, training_loss: 3.65227e+01
I0515 08:59:56.190211 140128494741248 run_lib.py:165] step: 501000, eval_loss: 1.76740e+01
I0515 09:00:02.512462 140128494741248 run_lib.py:152] step: 501050, training_loss: 2.61415e+01
I0515 09:00:08.958534 140128494741248 run_lib.py:152] step: 501100, training_loss: 4.83913e+01
I0515 09:00:09.011878 140128494741248 run_lib.py:165] step: 501100, eval_loss: 2.49160e+01
I0515 09:00:15.200756 140128494741248 run_lib.py:152] step: 501150, training_loss: 5.02496e+01
I0515 09:00:21.577542 140128494741248 run_lib.py:152] step: 501200, training_loss: 3.10136e+01
I0515 09:00:21.633609 140128494741248 run_lib.py:165] step: 501200, eval_loss: 2.94207e+01
I0515 09:00:28.140434 140128494741248 run_lib.py:152] step: 501250, training_loss: 3.09163e+01
I0515 09:00:34.345442 140128494741248 run_lib.py:152] step: 501300, training_loss: 5.11854e+01
I0515 09:00:34.396209 140128494741248 run_lib.py:165] step: 501300, eval_loss: 3.68923e+01
I0515 09:00:40.679356 140128494741248 run_lib.py:152] step: 501350, training_loss: 3.47257e+01
I0515 09:00:46.906280 140128494741248 run_lib.py:152] step: 501400, training_loss: 4.26159e+01
I0515 09:00:46.960544 140128494741248 run_lib.py:165] step: 501400, eval_loss: 3.00733e+01
I0515 09:00:53.500606 140128494741248 run_lib.py:152] step: 501450, training_loss: 3.34125e+01
I0515 09:00:59.680663 140128494741248 run_lib.py:152] step: 501500, training_loss: 4.85655e+01
I0515 09:00:59.727532 140128494741248 run_lib.py:165] step: 501500, eval_loss: 1.63954e+01
I0515 09:01:05.973030 140128494741248 run_lib.py:152] step: 501550, training_loss: 3.69536e+01
I0515 09:01:12.383839 140128494741248 run_lib.py:152] step: 501600, training_loss: 3.09516e+01
I0515 09:01:12.440077 140128494741248 run_lib.py:165] step: 501600, eval_loss: 3.50565e+01
I0515 09:01:18.739006 140128494741248 run_lib.py:152] step: 501650, training_loss: 3.31598e+01
I0515 09:01:24.955413 140128494741248 run_lib.py:152] step: 501700, training_loss: 2.14196e+01
I0515 09:01:25.006074 140128494741248 run_lib.py:165] step: 501700, eval_loss: 3.10190e+01
I0515 09:01:31.226815 140128494741248 run_lib.py:152] step: 501750, training_loss: 1.43677e+01
I0515 09:01:37.786217 140128494741248 run_lib.py:152] step: 501800, training_loss: 1.83748e+01
I0515 09:01:37.841523 140128494741248 run_lib.py:165] step: 501800, eval_loss: 3.47383e+01
I0515 09:01:44.072159 140128494741248 run_lib.py:152] step: 501850, training_loss: 3.46957e+01
I0515 09:01:50.346075 140128494741248 run_lib.py:152] step: 501900, training_loss: 2.93247e+01
I0515 09:01:50.397683 140128494741248 run_lib.py:165] step: 501900, eval_loss: 4.07496e+01
I0515 09:01:56.964246 140128494741248 run_lib.py:152] step: 501950, training_loss: 3.06943e+01
I0515 09:02:03.144993 140128494741248 run_lib.py:152] step: 502000, training_loss: 4.14121e+01
I0515 09:02:03.193529 140128494741248 run_lib.py:165] step: 502000, eval_loss: 2.37184e+01
I0515 09:02:09.520042 140128494741248 run_lib.py:152] step: 502050, training_loss: 2.02349e+01
I0515 09:02:15.751066 140128494741248 run_lib.py:152] step: 502100, training_loss: 3.58350e+01
I0515 09:02:15.802226 140128494741248 run_lib.py:165] step: 502100, eval_loss: 3.91878e+01
I0515 09:02:22.255789 140128494741248 run_lib.py:152] step: 502150, training_loss: 3.60304e+01
I0515 09:02:28.486054 140128494741248 run_lib.py:152] step: 502200, training_loss: 3.66790e+01
I0515 09:02:28.539564 140128494741248 run_lib.py:165] step: 502200, eval_loss: 4.10119e+01
I0515 09:02:34.812629 140128494741248 run_lib.py:152] step: 502250, training_loss: 2.02857e+01
I0515 09:02:41.233503 140128494741248 run_lib.py:152] step: 502300, training_loss: 3.15188e+01
I0515 09:02:41.291162 140128494741248 run_lib.py:165] step: 502300, eval_loss: 1.89321e+01
I0515 09:02:47.606061 140128494741248 run_lib.py:152] step: 502350, training_loss: 3.04035e+01
I0515 09:02:53.898824 140128494741248 run_lib.py:152] step: 502400, training_loss: 3.97431e+01
I0515 09:02:53.953587 140128494741248 run_lib.py:165] step: 502400, eval_loss: 1.80251e+01
I0515 09:03:00.157348 140128494741248 run_lib.py:152] step: 502450, training_loss: 2.48926e+01
I0515 09:03:06.671246 140128494741248 run_lib.py:152] step: 502500, training_loss: 3.16030e+01
I0515 09:03:06.725183 140128494741248 run_lib.py:165] step: 502500, eval_loss: 2.92471e+01
I0515 09:03:13.024253 140128494741248 run_lib.py:152] step: 502550, training_loss: 3.70930e+01
I0515 09:03:19.218015 140128494741248 run_lib.py:152] step: 502600, training_loss: 2.69094e+01
I0515 09:03:19.267161 140128494741248 run_lib.py:165] step: 502600, eval_loss: 2.30901e+01
I0515 09:03:25.837492 140128494741248 run_lib.py:152] step: 502650, training_loss: 3.15884e+01
I0515 09:03:31.973382 140128494741248 run_lib.py:152] step: 502700, training_loss: 2.04090e+01
I0515 09:03:32.032233 140128494741248 run_lib.py:165] step: 502700, eval_loss: 3.06139e+01
I0515 09:03:38.439098 140128494741248 run_lib.py:152] step: 502750, training_loss: 1.89009e+01
I0515 09:03:44.652616 140128494741248 run_lib.py:152] step: 502800, training_loss: 4.87301e+01
I0515 09:03:44.702428 140128494741248 run_lib.py:165] step: 502800, eval_loss: 9.19111e+00
I0515 09:03:51.183902 140128494741248 run_lib.py:152] step: 502850, training_loss: 3.17114e+01
I0515 09:03:57.376279 140128494741248 run_lib.py:152] step: 502900, training_loss: 3.45933e+01
I0515 09:03:57.423982 140128494741248 run_lib.py:165] step: 502900, eval_loss: 4.05140e+01
I0515 09:04:03.649203 140128494741248 run_lib.py:152] step: 502950, training_loss: 3.82758e+01
I0515 09:04:10.035961 140128494741248 run_lib.py:152] step: 503000, training_loss: 2.64933e+01
I0515 09:04:10.088297 140128494741248 run_lib.py:165] step: 503000, eval_loss: 1.33079e+01
I0515 09:04:16.383561 140128494741248 run_lib.py:152] step: 503050, training_loss: 2.86056e+01
I0515 09:04:22.590034 140128494741248 run_lib.py:152] step: 503100, training_loss: 2.65234e+01
I0515 09:04:22.641067 140128494741248 run_lib.py:165] step: 503100, eval_loss: 2.60624e+01
I0515 09:04:28.950259 140128494741248 run_lib.py:152] step: 503150, training_loss: 2.16679e+01
I0515 09:04:35.499030 140128494741248 run_lib.py:152] step: 503200, training_loss: 3.90383e+01
I0515 09:04:35.554879 140128494741248 run_lib.py:165] step: 503200, eval_loss: 2.28715e+01
I0515 09:04:41.849600 140128494741248 run_lib.py:152] step: 503250, training_loss: 3.96815e+01
I0515 09:04:48.022599 140128494741248 run_lib.py:152] step: 503300, training_loss: 3.04033e+01
I0515 09:04:48.077809 140128494741248 run_lib.py:165] step: 503300, eval_loss: 3.89514e+01
I0515 09:04:54.583364 140128494741248 run_lib.py:152] step: 503350, training_loss: 3.01680e+01
I0515 09:05:00.860170 140128494741248 run_lib.py:152] step: 503400, training_loss: 3.37592e+01
I0515 09:05:00.912333 140128494741248 run_lib.py:165] step: 503400, eval_loss: 2.11362e+01
I0515 09:05:07.219042 140128494741248 run_lib.py:152] step: 503450, training_loss: 2.80472e+01
I0515 09:05:13.390898 140128494741248 run_lib.py:152] step: 503500, training_loss: 3.54599e+01
I0515 09:05:13.443807 140128494741248 run_lib.py:165] step: 503500, eval_loss: 3.02865e+01
I0515 09:05:19.934874 140128494741248 run_lib.py:152] step: 503550, training_loss: 2.72083e+01
I0515 09:05:26.184252 140128494741248 run_lib.py:152] step: 503600, training_loss: 3.51604e+01
I0515 09:05:26.238976 140128494741248 run_lib.py:165] step: 503600, eval_loss: 3.52250e+01
I0515 09:05:32.483915 140128494741248 run_lib.py:152] step: 503650, training_loss: 3.08267e+01
I0515 09:05:39.050181 140128494741248 run_lib.py:152] step: 503700, training_loss: 3.21203e+01
I0515 09:05:39.105086 140128494741248 run_lib.py:165] step: 503700, eval_loss: 2.38272e+01
I0515 09:05:45.301316 140128494741248 run_lib.py:152] step: 503750, training_loss: 3.57851e+01
I0515 09:05:51.441108 140128494741248 run_lib.py:152] step: 503800, training_loss: 6.47207e+01
I0515 09:05:51.494128 140128494741248 run_lib.py:165] step: 503800, eval_loss: 2.77602e+01
I0515 09:05:57.740568 140128494741248 run_lib.py:152] step: 503850, training_loss: 2.25640e+01
I0515 09:06:04.280913 140128494741248 run_lib.py:152] step: 503900, training_loss: 2.30052e+01
I0515 09:06:04.340666 140128494741248 run_lib.py:165] step: 503900, eval_loss: 2.92886e+01
I0515 09:06:10.562454 140128494741248 run_lib.py:152] step: 503950, training_loss: 3.39122e+01
I0515 09:06:16.838905 140128494741248 run_lib.py:152] step: 504000, training_loss: 4.51894e+01
I0515 09:06:16.891347 140128494741248 run_lib.py:165] step: 504000, eval_loss: 3.33308e+01
I0515 09:06:23.421066 140128494741248 run_lib.py:152] step: 504050, training_loss: 3.34621e+01
I0515 09:06:29.697304 140128494741248 run_lib.py:152] step: 504100, training_loss: 4.60154e+01
I0515 09:06:29.746825 140128494741248 run_lib.py:165] step: 504100, eval_loss: 2.34832e+01
I0515 09:06:36.056715 140128494741248 run_lib.py:152] step: 504150, training_loss: 1.82241e+01
I0515 09:06:42.290875 140128494741248 run_lib.py:152] step: 504200, training_loss: 3.56982e+01
I0515 09:06:42.342785 140128494741248 run_lib.py:165] step: 504200, eval_loss: 2.29811e+01
I0515 09:06:48.921292 140128494741248 run_lib.py:152] step: 504250, training_loss: 5.32742e+01
I0515 09:06:55.242408 140128494741248 run_lib.py:152] step: 504300, training_loss: 4.29377e+01
I0515 09:06:55.294808 140128494741248 run_lib.py:165] step: 504300, eval_loss: 2.06883e+01
I0515 09:07:01.458142 140128494741248 run_lib.py:152] step: 504350, training_loss: 3.14028e+01
I0515 09:07:07.968283 140128494741248 run_lib.py:152] step: 504400, training_loss: 4.52591e+01
I0515 09:07:08.022441 140128494741248 run_lib.py:165] step: 504400, eval_loss: 3.86394e+01
I0515 09:07:14.277989 140128494741248 run_lib.py:152] step: 504450, training_loss: 2.12556e+01
I0515 09:07:20.543990 140128494741248 run_lib.py:152] step: 504500, training_loss: 2.58034e+01
I0515 09:07:20.595404 140128494741248 run_lib.py:165] step: 504500, eval_loss: 2.71797e+01
I0515 09:07:26.790562 140128494741248 run_lib.py:152] step: 504550, training_loss: 3.07384e+01
I0515 09:07:33.239506 140128494741248 run_lib.py:152] step: 504600, training_loss: 1.22953e+01
I0515 09:07:33.291870 140128494741248 run_lib.py:165] step: 504600, eval_loss: 1.32660e+01
I0515 09:07:39.442299 140128494741248 run_lib.py:152] step: 504650, training_loss: 2.42149e+01
I0515 09:07:45.719943 140128494741248 run_lib.py:152] step: 504700, training_loss: 4.58499e+01
I0515 09:07:45.771703 140128494741248 run_lib.py:165] step: 504700, eval_loss: 2.93669e+01
I0515 09:07:52.222090 140128494741248 run_lib.py:152] step: 504750, training_loss: 3.64995e+01
I0515 09:07:58.526262 140128494741248 run_lib.py:152] step: 504800, training_loss: 3.06296e+01
I0515 09:07:58.578697 140128494741248 run_lib.py:165] step: 504800, eval_loss: 5.09680e+01
I0515 09:08:04.796766 140128494741248 run_lib.py:152] step: 504850, training_loss: 3.32563e+01
I0515 09:08:11.075259 140128494741248 run_lib.py:152] step: 504900, training_loss: 4.47707e+01
I0515 09:08:11.124766 140128494741248 run_lib.py:165] step: 504900, eval_loss: 2.66449e+01
I0515 09:08:17.635603 140128494741248 run_lib.py:152] step: 504950, training_loss: 3.30821e+01
I0515 09:08:23.833826 140128494741248 run_lib.py:152] step: 505000, training_loss: 3.16924e+01
I0515 09:08:23.883783 140128494741248 run_lib.py:165] step: 505000, eval_loss: 2.31063e+01
I0515 09:08:30.180193 140128494741248 run_lib.py:152] step: 505050, training_loss: 4.75644e+01
I0515 09:08:36.604984 140128494741248 run_lib.py:152] step: 505100, training_loss: 2.39653e+01
I0515 09:08:36.650603 140128494741248 run_lib.py:165] step: 505100, eval_loss: 2.40037e+01
I0515 09:08:42.912023 140128494741248 run_lib.py:152] step: 505150, training_loss: 2.67788e+01
I0515 09:08:49.081703 140128494741248 run_lib.py:152] step: 505200, training_loss: 3.18573e+01
I0515 09:08:49.146851 140128494741248 run_lib.py:165] step: 505200, eval_loss: 2.98487e+01
I0515 09:08:55.405821 140128494741248 run_lib.py:152] step: 505250, training_loss: 3.88965e+01
I0515 09:09:01.909750 140128494741248 run_lib.py:152] step: 505300, training_loss: 2.80389e+01
I0515 09:09:01.957817 140128494741248 run_lib.py:165] step: 505300, eval_loss: 2.91280e+01
I0515 09:09:08.191987 140128494741248 run_lib.py:152] step: 505350, training_loss: 1.54281e+01
I0515 09:09:14.428541 140128494741248 run_lib.py:152] step: 505400, training_loss: 2.35561e+01
I0515 09:09:14.479989 140128494741248 run_lib.py:165] step: 505400, eval_loss: 3.38497e+01
I0515 09:09:20.931355 140128494741248 run_lib.py:152] step: 505450, training_loss: 4.14675e+01
I0515 09:09:27.226166 140128494741248 run_lib.py:152] step: 505500, training_loss: 3.67463e+01
I0515 09:09:27.282252 140128494741248 run_lib.py:165] step: 505500, eval_loss: 3.08831e+01
I0515 09:09:33.601555 140128494741248 run_lib.py:152] step: 505550, training_loss: 3.52183e+01
I0515 09:09:39.951893 140128494741248 run_lib.py:152] step: 505600, training_loss: 3.82974e+01
I0515 09:09:40.009229 140128494741248 run_lib.py:165] step: 505600, eval_loss: 2.87290e+01
I0515 09:09:46.587825 140128494741248 run_lib.py:152] step: 505650, training_loss: 3.21954e+01
I0515 09:09:52.948731 140128494741248 run_lib.py:152] step: 505700, training_loss: 3.75823e+01
I0515 09:09:53.002459 140128494741248 run_lib.py:165] step: 505700, eval_loss: 2.55548e+01
I0515 09:09:59.247040 140128494741248 run_lib.py:152] step: 505750, training_loss: 4.78378e+01
I0515 09:10:05.728920 140128494741248 run_lib.py:152] step: 505800, training_loss: 2.37145e+01
I0515 09:10:05.777674 140128494741248 run_lib.py:165] step: 505800, eval_loss: 3.58053e+01
I0515 09:10:12.024648 140128494741248 run_lib.py:152] step: 505850, training_loss: 3.76491e+01
I0515 09:10:18.422539 140128494741248 run_lib.py:152] step: 505900, training_loss: 2.34535e+01
I0515 09:10:18.474577 140128494741248 run_lib.py:165] step: 505900, eval_loss: 2.94313e+01
I0515 09:10:24.742325 140128494741248 run_lib.py:152] step: 505950, training_loss: 3.39805e+01
I0515 09:10:31.248860 140128494741248 run_lib.py:152] step: 506000, training_loss: 2.51530e+01
I0515 09:10:31.306126 140128494741248 run_lib.py:165] step: 506000, eval_loss: 4.68953e+01
I0515 09:10:37.570233 140128494741248 run_lib.py:152] step: 506050, training_loss: 2.13439e+01
I0515 09:10:43.885749 140128494741248 run_lib.py:152] step: 506100, training_loss: 2.21124e+01
I0515 09:10:43.939909 140128494741248 run_lib.py:165] step: 506100, eval_loss: 2.74578e+01
I0515 09:10:50.463296 140128494741248 run_lib.py:152] step: 506150, training_loss: 2.23314e+01
I0515 09:10:56.806848 140128494741248 run_lib.py:152] step: 506200, training_loss: 2.31958e+01
I0515 09:10:56.858786 140128494741248 run_lib.py:165] step: 506200, eval_loss: 3.20393e+01
I0515 09:11:03.238848 140128494741248 run_lib.py:152] step: 506250, training_loss: 3.78137e+01
I0515 09:11:09.573736 140128494741248 run_lib.py:152] step: 506300, training_loss: 1.85642e+01
I0515 09:11:09.627748 140128494741248 run_lib.py:165] step: 506300, eval_loss: 3.67844e+01
I0515 09:11:16.085838 140128494741248 run_lib.py:152] step: 506350, training_loss: 2.75331e+01
I0515 09:11:22.390509 140128494741248 run_lib.py:152] step: 506400, training_loss: 4.54834e+01
I0515 09:11:22.440670 140128494741248 run_lib.py:165] step: 506400, eval_loss: 2.84199e+01
I0515 09:11:28.519919 140128494741248 run_lib.py:152] step: 506450, training_loss: 4.10340e+01
I0515 09:11:34.990123 140128494741248 run_lib.py:152] step: 506500, training_loss: 2.99402e+01
I0515 09:11:35.042274 140128494741248 run_lib.py:165] step: 506500, eval_loss: 3.23516e+01
I0515 09:11:41.359572 140128494741248 run_lib.py:152] step: 506550, training_loss: 4.16177e+01
I0515 09:11:47.696501 140128494741248 run_lib.py:152] step: 506600, training_loss: 3.17248e+01
I0515 09:11:47.746794 140128494741248 run_lib.py:165] step: 506600, eval_loss: 3.19443e+01
I0515 09:11:54.087892 140128494741248 run_lib.py:152] step: 506650, training_loss: 2.85078e+01
I0515 09:12:00.782651 140128494741248 run_lib.py:152] step: 506700, training_loss: 2.19564e+01
I0515 09:12:00.834433 140128494741248 run_lib.py:165] step: 506700, eval_loss: 2.78664e+01
I0515 09:12:07.202193 140128494741248 run_lib.py:152] step: 506750, training_loss: 2.53500e+01
I0515 09:12:13.441738 140128494741248 run_lib.py:152] step: 506800, training_loss: 4.33101e+01
I0515 09:12:13.492268 140128494741248 run_lib.py:165] step: 506800, eval_loss: 3.25924e+01
I0515 09:12:20.013178 140128494741248 run_lib.py:152] step: 506850, training_loss: 3.50302e+01
I0515 09:12:26.242805 140128494741248 run_lib.py:152] step: 506900, training_loss: 2.07828e+01
I0515 09:12:26.296288 140128494741248 run_lib.py:165] step: 506900, eval_loss: 3.37518e+01
I0515 09:12:32.570239 140128494741248 run_lib.py:152] step: 506950, training_loss: 2.33371e+01
I0515 09:12:38.824540 140128494741248 run_lib.py:152] step: 507000, training_loss: 4.48627e+01
I0515 09:12:38.878477 140128494741248 run_lib.py:165] step: 507000, eval_loss: 3.22783e+01
I0515 09:12:45.327042 140128494741248 run_lib.py:152] step: 507050, training_loss: 3.18233e+01
I0515 09:12:51.680298 140128494741248 run_lib.py:152] step: 507100, training_loss: 4.43731e+01
I0515 09:12:51.739243 140128494741248 run_lib.py:165] step: 507100, eval_loss: 3.72827e+01
I0515 09:12:58.055525 140128494741248 run_lib.py:152] step: 507150, training_loss: 2.92928e+01
I0515 09:13:04.571878 140128494741248 run_lib.py:152] step: 507200, training_loss: 3.68222e+01
I0515 09:13:04.626422 140128494741248 run_lib.py:165] step: 507200, eval_loss: 4.40687e+01
I0515 09:13:10.867003 140128494741248 run_lib.py:152] step: 507250, training_loss: 3.04142e+01
I0515 09:13:17.113287 140128494741248 run_lib.py:152] step: 507300, training_loss: 4.33230e+01
I0515 09:13:17.166502 140128494741248 run_lib.py:165] step: 507300, eval_loss: 3.06891e+01
I0515 09:13:23.430252 140128494741248 run_lib.py:152] step: 507350, training_loss: 3.83006e+01
I0515 09:13:29.957552 140128494741248 run_lib.py:152] step: 507400, training_loss: 3.13929e+01
I0515 09:13:30.008094 140128494741248 run_lib.py:165] step: 507400, eval_loss: 2.01497e+01
I0515 09:13:36.223039 140128494741248 run_lib.py:152] step: 507450, training_loss: 3.44527e+01
I0515 09:13:42.442328 140128494741248 run_lib.py:152] step: 507500, training_loss: 3.68638e+01
I0515 09:13:42.488304 140128494741248 run_lib.py:165] step: 507500, eval_loss: 2.98721e+01
I0515 09:13:48.887410 140128494741248 run_lib.py:152] step: 507550, training_loss: 2.49335e+01
I0515 09:13:55.229982 140128494741248 run_lib.py:152] step: 507600, training_loss: 3.66003e+01
I0515 09:13:55.288738 140128494741248 run_lib.py:165] step: 507600, eval_loss: 2.63650e+01
I0515 09:14:01.534466 140128494741248 run_lib.py:152] step: 507650, training_loss: 2.48044e+01
I0515 09:14:07.802245 140128494741248 run_lib.py:152] step: 507700, training_loss: 2.98065e+01
I0515 09:14:07.858685 140128494741248 run_lib.py:165] step: 507700, eval_loss: 2.89129e+01
I0515 09:14:14.258492 140128494741248 run_lib.py:152] step: 507750, training_loss: 3.16358e+01
I0515 09:14:20.502130 140128494741248 run_lib.py:152] step: 507800, training_loss: 2.23747e+01
I0515 09:14:20.555770 140128494741248 run_lib.py:165] step: 507800, eval_loss: 2.35148e+01
I0515 09:14:26.826604 140128494741248 run_lib.py:152] step: 507850, training_loss: 2.68019e+01
I0515 09:14:33.365647 140128494741248 run_lib.py:152] step: 507900, training_loss: 3.36633e+01
I0515 09:14:33.418456 140128494741248 run_lib.py:165] step: 507900, eval_loss: 2.38328e+01
I0515 09:14:39.651529 140128494741248 run_lib.py:152] step: 507950, training_loss: 3.92555e+01
I0515 09:14:45.912883 140128494741248 run_lib.py:152] step: 508000, training_loss: 3.49969e+01
I0515 09:14:45.968669 140128494741248 run_lib.py:165] step: 508000, eval_loss: 2.85797e+01
I0515 09:14:52.258367 140128494741248 run_lib.py:152] step: 508050, training_loss: 2.38492e+01
I0515 09:14:58.822297 140128494741248 run_lib.py:152] step: 508100, training_loss: 3.93796e+01
I0515 09:14:58.877804 140128494741248 run_lib.py:165] step: 508100, eval_loss: 2.84479e+01
I0515 09:15:05.138393 140128494741248 run_lib.py:152] step: 508150, training_loss: 3.15947e+01
I0515 09:15:11.309230 140128494741248 run_lib.py:152] step: 508200, training_loss: 3.15119e+01
I0515 09:15:11.366919 140128494741248 run_lib.py:165] step: 508200, eval_loss: 4.37244e+01
I0515 09:15:17.835703 140128494741248 run_lib.py:152] step: 508250, training_loss: 2.56527e+01
I0515 09:15:24.170446 140128494741248 run_lib.py:152] step: 508300, training_loss: 4.11107e+01
I0515 09:15:24.222152 140128494741248 run_lib.py:165] step: 508300, eval_loss: 2.34599e+01
I0515 09:15:30.421611 140128494741248 run_lib.py:152] step: 508350, training_loss: 2.37953e+01
I0515 09:15:36.612041 140128494741248 run_lib.py:152] step: 508400, training_loss: 3.02014e+01
I0515 09:15:36.664152 140128494741248 run_lib.py:165] step: 508400, eval_loss: 2.61787e+01
I0515 09:15:43.113416 140128494741248 run_lib.py:152] step: 508450, training_loss: 4.15941e+01
I0515 09:15:49.339063 140128494741248 run_lib.py:152] step: 508500, training_loss: 3.39104e+01
I0515 09:15:49.392649 140128494741248 run_lib.py:165] step: 508500, eval_loss: 2.94329e+01
I0515 09:15:55.749405 140128494741248 run_lib.py:152] step: 508550, training_loss: 3.53954e+01
I0515 09:16:02.223792 140128494741248 run_lib.py:152] step: 508600, training_loss: 4.21398e+01
I0515 09:16:02.274510 140128494741248 run_lib.py:165] step: 508600, eval_loss: 3.75729e+01
I0515 09:16:08.489796 140128494741248 run_lib.py:152] step: 508650, training_loss: 1.55536e+01
I0515 09:16:14.796507 140128494741248 run_lib.py:152] step: 508700, training_loss: 3.59804e+01
I0515 09:16:14.847983 140128494741248 run_lib.py:165] step: 508700, eval_loss: 2.91516e+01
I0515 09:16:21.100615 140128494741248 run_lib.py:152] step: 508750, training_loss: 4.12634e+01
I0515 09:16:27.614904 140128494741248 run_lib.py:152] step: 508800, training_loss: 2.75737e+01
I0515 09:16:27.669320 140128494741248 run_lib.py:165] step: 508800, eval_loss: 3.26698e+01
I0515 09:16:33.838563 140128494741248 run_lib.py:152] step: 508850, training_loss: 4.16029e+01
I0515 09:16:40.068017 140128494741248 run_lib.py:152] step: 508900, training_loss: 2.12690e+01
I0515 09:16:40.118489 140128494741248 run_lib.py:165] step: 508900, eval_loss: 3.32798e+01
I0515 09:16:46.557932 140128494741248 run_lib.py:152] step: 508950, training_loss: 4.45738e+01
I0515 09:16:52.762387 140128494741248 run_lib.py:152] step: 509000, training_loss: 3.04938e+01
I0515 09:16:52.816491 140128494741248 run_lib.py:165] step: 509000, eval_loss: 3.24176e+01
I0515 09:16:59.014188 140128494741248 run_lib.py:152] step: 509050, training_loss: 3.33829e+01
I0515 09:17:05.292032 140128494741248 run_lib.py:152] step: 509100, training_loss: 4.55803e+01
I0515 09:17:05.340625 140128494741248 run_lib.py:165] step: 509100, eval_loss: 2.40221e+01
I0515 09:17:11.791195 140128494741248 run_lib.py:152] step: 509150, training_loss: 1.17927e+01
I0515 09:17:18.023814 140128494741248 run_lib.py:152] step: 509200, training_loss: 5.16596e+01
I0515 09:17:18.078283 140128494741248 run_lib.py:165] step: 509200, eval_loss: 3.93777e+01
I0515 09:17:24.351944 140128494741248 run_lib.py:152] step: 509250, training_loss: 3.86860e+01
I0515 09:17:30.894977 140128494741248 run_lib.py:152] step: 509300, training_loss: 2.02377e+01
I0515 09:17:30.951331 140128494741248 run_lib.py:165] step: 509300, eval_loss: 2.87003e+01
I0515 09:17:37.193824 140128494741248 run_lib.py:152] step: 509350, training_loss: 3.52925e+01
I0515 09:17:43.519888 140128494741248 run_lib.py:152] step: 509400, training_loss: 3.13038e+01
I0515 09:17:43.567914 140128494741248 run_lib.py:165] step: 509400, eval_loss: 3.70211e+01
I0515 09:17:49.742758 140128494741248 run_lib.py:152] step: 509450, training_loss: 2.52571e+01
I0515 09:17:56.263631 140128494741248 run_lib.py:152] step: 509500, training_loss: 2.80354e+01
I0515 09:17:56.314242 140128494741248 run_lib.py:165] step: 509500, eval_loss: 2.72311e+01
I0515 09:18:02.469070 140128494741248 run_lib.py:152] step: 509550, training_loss: 2.44506e+01
I0515 09:18:08.841326 140128494741248 run_lib.py:152] step: 509600, training_loss: 2.50820e+01
I0515 09:18:08.901598 140128494741248 run_lib.py:165] step: 509600, eval_loss: 3.81548e+01
I0515 09:18:15.357394 140128494741248 run_lib.py:152] step: 509650, training_loss: 2.88030e+01
I0515 09:18:21.625488 140128494741248 run_lib.py:152] step: 509700, training_loss: 3.41143e+01
I0515 09:18:21.675672 140128494741248 run_lib.py:165] step: 509700, eval_loss: 2.39015e+01
I0515 09:18:27.923333 140128494741248 run_lib.py:152] step: 509750, training_loss: 2.00509e+01
I0515 09:18:34.179113 140128494741248 run_lib.py:152] step: 509800, training_loss: 2.11145e+01
I0515 09:18:34.227906 140128494741248 run_lib.py:165] step: 509800, eval_loss: 3.66417e+01
I0515 09:18:40.758324 140128494741248 run_lib.py:152] step: 509850, training_loss: 2.65582e+01
I0515 09:18:47.010622 140128494741248 run_lib.py:152] step: 509900, training_loss: 2.08561e+01
I0515 09:18:47.061166 140128494741248 run_lib.py:165] step: 509900, eval_loss: 3.78891e+01
I0515 09:18:53.204945 140128494741248 run_lib.py:152] step: 509950, training_loss: 2.48955e+01
I0515 09:18:59.711940 140128494741248 run_lib.py:152] step: 510000, training_loss: 1.81800e+01
I0515 09:18:59.913929 140128494741248 run_lib.py:165] step: 510000, eval_loss: 1.82487e+01
I0515 09:19:06.195084 140128494741248 run_lib.py:152] step: 510050, training_loss: 4.13946e+01
I0515 09:19:12.492474 140128494741248 run_lib.py:152] step: 510100, training_loss: 2.62819e+01
I0515 09:19:12.547888 140128494741248 run_lib.py:165] step: 510100, eval_loss: 3.18196e+01
I0515 09:19:18.807302 140128494741248 run_lib.py:152] step: 510150, training_loss: 3.79078e+01
I0515 09:19:25.345377 140128494741248 run_lib.py:152] step: 510200, training_loss: 3.84640e+01
I0515 09:19:25.397102 140128494741248 run_lib.py:165] step: 510200, eval_loss: 2.24237e+01
I0515 09:19:31.711547 140128494741248 run_lib.py:152] step: 510250, training_loss: 2.21890e+01
I0515 09:19:37.960668 140128494741248 run_lib.py:152] step: 510300, training_loss: 3.63252e+01
I0515 09:19:38.017341 140128494741248 run_lib.py:165] step: 510300, eval_loss: 1.74932e+01
I0515 09:19:44.536028 140128494741248 run_lib.py:152] step: 510350, training_loss: 2.82504e+01
I0515 09:19:50.754149 140128494741248 run_lib.py:152] step: 510400, training_loss: 2.18327e+01
I0515 09:19:50.807825 140128494741248 run_lib.py:165] step: 510400, eval_loss: 3.34068e+01
I0515 09:19:56.930548 140128494741248 run_lib.py:152] step: 510450, training_loss: 2.27193e+01
I0515 09:20:03.300452 140128494741248 run_lib.py:152] step: 510500, training_loss: 2.04872e+01
I0515 09:20:03.349128 140128494741248 run_lib.py:165] step: 510500, eval_loss: 3.57284e+01
I0515 09:20:09.789158 140128494741248 run_lib.py:152] step: 510550, training_loss: 4.74172e+01
I0515 09:20:16.059808 140128494741248 run_lib.py:152] step: 510600, training_loss: 2.25693e+01
I0515 09:20:16.110567 140128494741248 run_lib.py:165] step: 510600, eval_loss: 2.56074e+01
I0515 09:20:22.300642 140128494741248 run_lib.py:152] step: 510650, training_loss: 4.30214e+01
I0515 09:20:28.864023 140128494741248 run_lib.py:152] step: 510700, training_loss: 3.82170e+01
I0515 09:20:28.918358 140128494741248 run_lib.py:165] step: 510700, eval_loss: 4.07254e+01
I0515 09:20:35.101992 140128494741248 run_lib.py:152] step: 510750, training_loss: 3.73440e+01
I0515 09:20:41.367764 140128494741248 run_lib.py:152] step: 510800, training_loss: 4.01665e+01
I0515 09:20:41.421860 140128494741248 run_lib.py:165] step: 510800, eval_loss: 2.69172e+01
I0515 09:20:47.719435 140128494741248 run_lib.py:152] step: 510850, training_loss: 2.95378e+01
I0515 09:20:54.231640 140128494741248 run_lib.py:152] step: 510900, training_loss: 3.37532e+01
I0515 09:20:54.283058 140128494741248 run_lib.py:165] step: 510900, eval_loss: 3.39975e+01
I0515 09:21:00.598586 140128494741248 run_lib.py:152] step: 510950, training_loss: 2.23136e+01
I0515 09:21:06.742688 140128494741248 run_lib.py:152] step: 511000, training_loss: 4.00461e+01
I0515 09:21:06.794861 140128494741248 run_lib.py:165] step: 511000, eval_loss: 3.12920e+01
I0515 09:21:13.360360 140128494741248 run_lib.py:152] step: 511050, training_loss: 3.90579e+01
I0515 09:21:19.632078 140128494741248 run_lib.py:152] step: 511100, training_loss: 4.02392e+01
I0515 09:21:19.681305 140128494741248 run_lib.py:165] step: 511100, eval_loss: 3.76094e+01
I0515 09:21:26.003142 140128494741248 run_lib.py:152] step: 511150, training_loss: 3.20246e+01
I0515 09:21:32.269525 140128494741248 run_lib.py:152] step: 511200, training_loss: 2.39962e+01
I0515 09:21:32.322609 140128494741248 run_lib.py:165] step: 511200, eval_loss: 3.98406e+01
I0515 09:21:38.852265 140128494741248 run_lib.py:152] step: 511250, training_loss: 1.39591e+01
I0515 09:21:45.039296 140128494741248 run_lib.py:152] step: 511300, training_loss: 2.77795e+01
I0515 09:21:45.092173 140128494741248 run_lib.py:165] step: 511300, eval_loss: 3.12576e+01
I0515 09:21:51.375154 140128494741248 run_lib.py:152] step: 511350, training_loss: 4.41945e+01
I0515 09:21:57.848870 140128494741248 run_lib.py:152] step: 511400, training_loss: 3.15329e+01
I0515 09:21:57.899285 140128494741248 run_lib.py:165] step: 511400, eval_loss: 2.53918e+01
I0515 09:22:04.149944 140128494741248 run_lib.py:152] step: 511450, training_loss: 2.87310e+01
I0515 09:22:10.444595 140128494741248 run_lib.py:152] step: 511500, training_loss: 3.20481e+01
I0515 09:22:10.494715 140128494741248 run_lib.py:165] step: 511500, eval_loss: 5.01647e+01
I0515 09:22:16.704565 140128494741248 run_lib.py:152] step: 511550, training_loss: 3.73720e+01
I0515 09:22:23.126135 140128494741248 run_lib.py:152] step: 511600, training_loss: 1.71541e+01
I0515 09:22:23.175881 140128494741248 run_lib.py:165] step: 511600, eval_loss: 3.03888e+01
I0515 09:22:29.486346 140128494741248 run_lib.py:152] step: 511650, training_loss: 3.38887e+01
I0515 09:22:35.765929 140128494741248 run_lib.py:152] step: 511700, training_loss: 4.15226e+01
I0515 09:22:35.820075 140128494741248 run_lib.py:165] step: 511700, eval_loss: 2.62319e+01
I0515 09:22:42.274250 140128494741248 run_lib.py:152] step: 511750, training_loss: 3.05365e+01
I0515 09:22:48.626018 140128494741248 run_lib.py:152] step: 511800, training_loss: 3.49551e+01
I0515 09:22:48.676358 140128494741248 run_lib.py:165] step: 511800, eval_loss: 1.88533e+01
I0515 09:22:54.871479 140128494741248 run_lib.py:152] step: 511850, training_loss: 2.04386e+01
I0515 09:23:01.096062 140128494741248 run_lib.py:152] step: 511900, training_loss: 3.48772e+01
I0515 09:23:01.149290 140128494741248 run_lib.py:165] step: 511900, eval_loss: 2.45673e+01
I0515 09:23:07.543874 140128494741248 run_lib.py:152] step: 511950, training_loss: 3.60207e+01
I0515 09:23:13.810805 140128494741248 run_lib.py:152] step: 512000, training_loss: 4.06507e+01
I0515 09:23:13.862383 140128494741248 run_lib.py:165] step: 512000, eval_loss: 2.02506e+01
I0515 09:23:20.034052 140128494741248 run_lib.py:152] step: 512050, training_loss: 4.20074e+01
I0515 09:23:26.559223 140128494741248 run_lib.py:152] step: 512100, training_loss: 2.86963e+01
I0515 09:23:26.611122 140128494741248 run_lib.py:165] step: 512100, eval_loss: 3.04549e+01
I0515 09:23:32.954054 140128494741248 run_lib.py:152] step: 512150, training_loss: 2.56943e+01
I0515 09:23:39.172025 140128494741248 run_lib.py:152] step: 512200, training_loss: 4.02501e+01
I0515 09:23:39.222882 140128494741248 run_lib.py:165] step: 512200, eval_loss: 2.70456e+01
I0515 09:23:45.406307 140128494741248 run_lib.py:152] step: 512250, training_loss: 3.57942e+01
I0515 09:23:51.899104 140128494741248 run_lib.py:152] step: 512300, training_loss: 2.68894e+01
I0515 09:23:51.950970 140128494741248 run_lib.py:165] step: 512300, eval_loss: 3.85875e+01
I0515 09:23:58.191711 140128494741248 run_lib.py:152] step: 512350, training_loss: 2.44641e+01
I0515 09:24:04.507327 140128494741248 run_lib.py:152] step: 512400, training_loss: 2.23859e+01
I0515 09:24:04.559588 140128494741248 run_lib.py:165] step: 512400, eval_loss: 2.74776e+01
I0515 09:24:11.019101 140128494741248 run_lib.py:152] step: 512450, training_loss: 4.44664e+01
I0515 09:24:17.303309 140128494741248 run_lib.py:152] step: 512500, training_loss: 2.55889e+01
I0515 09:24:17.357272 140128494741248 run_lib.py:165] step: 512500, eval_loss: 3.20239e+01
I0515 09:24:23.608855 140128494741248 run_lib.py:152] step: 512550, training_loss: 3.59897e+01
I0515 09:24:29.875980 140128494741248 run_lib.py:152] step: 512600, training_loss: 3.75757e+01
I0515 09:24:29.933753 140128494741248 run_lib.py:165] step: 512600, eval_loss: 2.85615e+01
I0515 09:24:36.463572 140128494741248 run_lib.py:152] step: 512650, training_loss: 3.25807e+01
I0515 09:24:42.739450 140128494741248 run_lib.py:152] step: 512700, training_loss: 5.24075e+01
I0515 09:24:42.796286 140128494741248 run_lib.py:165] step: 512700, eval_loss: 2.22097e+01
I0515 09:24:49.095053 140128494741248 run_lib.py:152] step: 512750, training_loss: 4.98639e+01
I0515 09:24:55.624066 140128494741248 run_lib.py:152] step: 512800, training_loss: 2.92719e+01
I0515 09:24:55.674405 140128494741248 run_lib.py:165] step: 512800, eval_loss: 2.39484e+01
I0515 09:25:01.949476 140128494741248 run_lib.py:152] step: 512850, training_loss: 2.08489e+01
I0515 09:25:08.274873 140128494741248 run_lib.py:152] step: 512900, training_loss: 3.43287e+01
I0515 09:25:08.329772 140128494741248 run_lib.py:165] step: 512900, eval_loss: 4.50873e+01
I0515 09:25:14.580859 140128494741248 run_lib.py:152] step: 512950, training_loss: 2.61202e+01
I0515 09:25:21.069875 140128494741248 run_lib.py:152] step: 513000, training_loss: 1.95868e+01
I0515 09:25:21.120726 140128494741248 run_lib.py:165] step: 513000, eval_loss: 1.74740e+01
I0515 09:25:27.349121 140128494741248 run_lib.py:152] step: 513050, training_loss: 5.57560e+01
I0515 09:25:33.657389 140128494741248 run_lib.py:152] step: 513100, training_loss: 2.31999e+01
I0515 09:25:33.709536 140128494741248 run_lib.py:165] step: 513100, eval_loss: 3.49800e+01
I0515 09:25:40.157291 140128494741248 run_lib.py:152] step: 513150, training_loss: 3.16477e+01
I0515 09:25:46.311887 140128494741248 run_lib.py:152] step: 513200, training_loss: 2.18702e+01
I0515 09:25:46.365939 140128494741248 run_lib.py:165] step: 513200, eval_loss: 2.81917e+01
I0515 09:25:52.682136 140128494741248 run_lib.py:152] step: 513250, training_loss: 3.28324e+01
I0515 09:25:58.933029 140128494741248 run_lib.py:152] step: 513300, training_loss: 4.06468e+01
I0515 09:25:58.989953 140128494741248 run_lib.py:165] step: 513300, eval_loss: 3.45674e+01
I0515 09:26:05.460190 140128494741248 run_lib.py:152] step: 513350, training_loss: 3.66834e+01
I0515 09:26:11.716247 140128494741248 run_lib.py:152] step: 513400, training_loss: 3.73481e+01
I0515 09:26:11.767727 140128494741248 run_lib.py:165] step: 513400, eval_loss: 1.60034e+01
I0515 09:26:18.069365 140128494741248 run_lib.py:152] step: 513450, training_loss: 3.36317e+01
I0515 09:26:24.567721 140128494741248 run_lib.py:152] step: 513500, training_loss: 3.27236e+01
I0515 09:26:24.619620 140128494741248 run_lib.py:165] step: 513500, eval_loss: 4.03054e+01
I0515 09:26:30.859204 140128494741248 run_lib.py:152] step: 513550, training_loss: 3.66324e+01
I0515 09:26:37.050064 140128494741248 run_lib.py:152] step: 513600, training_loss: 2.81964e+01
I0515 09:26:37.100150 140128494741248 run_lib.py:165] step: 513600, eval_loss: 1.66508e+01
I0515 09:26:43.423222 140128494741248 run_lib.py:152] step: 513650, training_loss: 4.33867e+01
I0515 09:26:49.888465 140128494741248 run_lib.py:152] step: 513700, training_loss: 2.41543e+01
I0515 09:26:49.947450 140128494741248 run_lib.py:165] step: 513700, eval_loss: 2.40703e+01
I0515 09:26:56.214910 140128494741248 run_lib.py:152] step: 513750, training_loss: 3.47115e+01
I0515 09:27:02.420657 140128494741248 run_lib.py:152] step: 513800, training_loss: 2.95360e+01
I0515 09:27:02.470461 140128494741248 run_lib.py:165] step: 513800, eval_loss: 3.12996e+01
I0515 09:27:08.949001 140128494741248 run_lib.py:152] step: 513850, training_loss: 2.41439e+01
I0515 09:27:15.175186 140128494741248 run_lib.py:152] step: 513900, training_loss: 2.04517e+01
I0515 09:27:15.225699 140128494741248 run_lib.py:165] step: 513900, eval_loss: 3.49177e+01
I0515 09:27:21.478847 140128494741248 run_lib.py:152] step: 513950, training_loss: 3.75452e+01
I0515 09:27:27.668226 140128494741248 run_lib.py:152] step: 514000, training_loss: 2.77273e+01
I0515 09:27:27.715386 140128494741248 run_lib.py:165] step: 514000, eval_loss: 2.57093e+01
I0515 09:27:34.146052 140128494741248 run_lib.py:152] step: 514050, training_loss: 2.57262e+01
I0515 09:27:40.374975 140128494741248 run_lib.py:152] step: 514100, training_loss: 2.29529e+01
I0515 09:27:40.428368 140128494741248 run_lib.py:165] step: 514100, eval_loss: 2.54163e+01
I0515 09:27:46.593576 140128494741248 run_lib.py:152] step: 514150, training_loss: 3.63202e+01
I0515 09:27:53.102239 140128494741248 run_lib.py:152] step: 514200, training_loss: 4.74499e+01
I0515 09:27:53.157855 140128494741248 run_lib.py:165] step: 514200, eval_loss: 1.99138e+01
I0515 09:27:59.348470 140128494741248 run_lib.py:152] step: 514250, training_loss: 3.83107e+01
I0515 09:28:05.639364 140128494741248 run_lib.py:152] step: 514300, training_loss: 2.48348e+01
I0515 09:28:05.688225 140128494741248 run_lib.py:165] step: 514300, eval_loss: 3.93897e+01
I0515 09:28:11.905324 140128494741248 run_lib.py:152] step: 514350, training_loss: 2.76592e+01
I0515 09:28:18.304001 140128494741248 run_lib.py:152] step: 514400, training_loss: 3.43877e+01
I0515 09:28:18.358628 140128494741248 run_lib.py:165] step: 514400, eval_loss: 1.56515e+01
I0515 09:28:24.493743 140128494741248 run_lib.py:152] step: 514450, training_loss: 2.49039e+01
I0515 09:28:30.834783 140128494741248 run_lib.py:152] step: 514500, training_loss: 3.29401e+01
I0515 09:28:30.893766 140128494741248 run_lib.py:165] step: 514500, eval_loss: 3.84483e+01
I0515 09:28:37.321159 140128494741248 run_lib.py:152] step: 514550, training_loss: 2.65863e+01
I0515 09:28:43.606009 140128494741248 run_lib.py:152] step: 514600, training_loss: 4.05865e+01
I0515 09:28:43.660170 140128494741248 run_lib.py:165] step: 514600, eval_loss: 4.50903e+01
I0515 09:28:49.930809 140128494741248 run_lib.py:152] step: 514650, training_loss: 1.78761e+01
I0515 09:28:56.163347 140128494741248 run_lib.py:152] step: 514700, training_loss: 3.27858e+01
I0515 09:28:56.216605 140128494741248 run_lib.py:165] step: 514700, eval_loss: 3.18106e+01
I0515 09:29:02.624813 140128494741248 run_lib.py:152] step: 514750, training_loss: 1.96030e+01
I0515 09:29:08.901235 140128494741248 run_lib.py:152] step: 514800, training_loss: 2.87133e+01
I0515 09:29:08.952563 140128494741248 run_lib.py:165] step: 514800, eval_loss: 3.50584e+01
I0515 09:29:15.278212 140128494741248 run_lib.py:152] step: 514850, training_loss: 2.49771e+01
I0515 09:29:21.766491 140128494741248 run_lib.py:152] step: 514900, training_loss: 1.96587e+01
I0515 09:29:21.816099 140128494741248 run_lib.py:165] step: 514900, eval_loss: 3.60129e+01
I0515 09:29:28.089079 140128494741248 run_lib.py:152] step: 514950, training_loss: 2.25774e+01
I0515 09:29:34.363460 140128494741248 run_lib.py:152] step: 515000, training_loss: 2.61718e+01
I0515 09:29:34.413867 140128494741248 run_lib.py:165] step: 515000, eval_loss: 3.21953e+01
I0515 09:29:40.703507 140128494741248 run_lib.py:152] step: 515050, training_loss: 5.00224e+01
I0515 09:29:47.167255 140128494741248 run_lib.py:152] step: 515100, training_loss: 2.98734e+01
I0515 09:29:47.223329 140128494741248 run_lib.py:165] step: 515100, eval_loss: 2.53814e+01
I0515 09:29:53.584015 140128494741248 run_lib.py:152] step: 515150, training_loss: 3.64409e+01
I0515 09:29:59.802341 140128494741248 run_lib.py:152] step: 515200, training_loss: 4.31172e+01
I0515 09:29:59.864805 140128494741248 run_lib.py:165] step: 515200, eval_loss: 3.10981e+01
I0515 09:30:06.388236 140128494741248 run_lib.py:152] step: 515250, training_loss: 3.72662e+01
I0515 09:30:12.597659 140128494741248 run_lib.py:152] step: 515300, training_loss: 1.84571e+01
I0515 09:30:12.646556 140128494741248 run_lib.py:165] step: 515300, eval_loss: 2.87939e+01
I0515 09:30:18.934889 140128494741248 run_lib.py:152] step: 515350, training_loss: 3.28218e+01
I0515 09:30:25.218409 140128494741248 run_lib.py:152] step: 515400, training_loss: 5.20894e+01
I0515 09:30:25.270448 140128494741248 run_lib.py:165] step: 515400, eval_loss: 2.23358e+01
I0515 09:30:31.717244 140128494741248 run_lib.py:152] step: 515450, training_loss: 3.39647e+01
I0515 09:30:37.890269 140128494741248 run_lib.py:152] step: 515500, training_loss: 3.33468e+01
I0515 09:30:37.948262 140128494741248 run_lib.py:165] step: 515500, eval_loss: 4.28217e+01
I0515 09:30:44.145582 140128494741248 run_lib.py:152] step: 515550, training_loss: 1.83318e+01
I0515 09:30:50.722700 140128494741248 run_lib.py:152] step: 515600, training_loss: 2.45893e+01
I0515 09:30:50.780456 140128494741248 run_lib.py:165] step: 515600, eval_loss: 2.58802e+01
I0515 09:30:57.009315 140128494741248 run_lib.py:152] step: 515650, training_loss: 4.90798e+01
I0515 09:31:03.269667 140128494741248 run_lib.py:152] step: 515700, training_loss: 4.43511e+01
I0515 09:31:03.320689 140128494741248 run_lib.py:165] step: 515700, eval_loss: 1.27905e+01
I0515 09:31:09.501562 140128494741248 run_lib.py:152] step: 515750, training_loss: 4.43618e+01
I0515 09:31:15.972651 140128494741248 run_lib.py:152] step: 515800, training_loss: 2.90718e+01
I0515 09:31:16.022320 140128494741248 run_lib.py:165] step: 515800, eval_loss: 3.64695e+01
I0515 09:31:22.243996 140128494741248 run_lib.py:152] step: 515850, training_loss: 3.78256e+01
I0515 09:31:28.568196 140128494741248 run_lib.py:152] step: 515900, training_loss: 2.59178e+01
I0515 09:31:28.621244 140128494741248 run_lib.py:165] step: 515900, eval_loss: 3.16056e+01
I0515 09:31:35.163510 140128494741248 run_lib.py:152] step: 515950, training_loss: 2.19747e+01
I0515 09:31:41.474488 140128494741248 run_lib.py:152] step: 516000, training_loss: 2.57274e+01
I0515 09:31:41.529726 140128494741248 run_lib.py:165] step: 516000, eval_loss: 2.97067e+01
I0515 09:31:47.749385 140128494741248 run_lib.py:152] step: 516050, training_loss: 3.89456e+01
I0515 09:31:53.997869 140128494741248 run_lib.py:152] step: 516100, training_loss: 2.02644e+01
I0515 09:31:54.049957 140128494741248 run_lib.py:165] step: 516100, eval_loss: 2.19769e+01
I0515 09:32:00.549267 140128494741248 run_lib.py:152] step: 516150, training_loss: 3.26882e+01
I0515 09:32:06.789613 140128494741248 run_lib.py:152] step: 516200, training_loss: 3.54831e+01
I0515 09:32:06.840130 140128494741248 run_lib.py:165] step: 516200, eval_loss: 3.52382e+01
I0515 09:32:13.185486 140128494741248 run_lib.py:152] step: 516250, training_loss: 4.25177e+01
I0515 09:32:19.658095 140128494741248 run_lib.py:152] step: 516300, training_loss: 1.58676e+01
I0515 09:32:19.710615 140128494741248 run_lib.py:165] step: 516300, eval_loss: 3.00306e+01
I0515 09:32:25.989411 140128494741248 run_lib.py:152] step: 516350, training_loss: 2.43350e+01
I0515 09:32:32.152238 140128494741248 run_lib.py:152] step: 516400, training_loss: 3.58462e+01
I0515 09:32:32.201483 140128494741248 run_lib.py:165] step: 516400, eval_loss: 3.02273e+01
I0515 09:32:38.424674 140128494741248 run_lib.py:152] step: 516450, training_loss: 2.85200e+01
I0515 09:32:44.938287 140128494741248 run_lib.py:152] step: 516500, training_loss: 3.57512e+01
I0515 09:32:44.997133 140128494741248 run_lib.py:165] step: 516500, eval_loss: 3.37411e+01
I0515 09:32:51.239271 140128494741248 run_lib.py:152] step: 516550, training_loss: 2.44488e+01
I0515 09:32:57.402512 140128494741248 run_lib.py:152] step: 516600, training_loss: 3.25837e+01
I0515 09:32:57.455006 140128494741248 run_lib.py:165] step: 516600, eval_loss: 3.67382e+01
I0515 09:33:03.902385 140128494741248 run_lib.py:152] step: 516650, training_loss: 2.82403e+01
I0515 09:33:10.124172 140128494741248 run_lib.py:152] step: 516700, training_loss: 3.04820e+01
I0515 09:33:10.178643 140128494741248 run_lib.py:165] step: 516700, eval_loss: 3.81031e+01
I0515 09:33:16.386117 140128494741248 run_lib.py:152] step: 516750, training_loss: 3.19989e+01
I0515 09:33:22.613840 140128494741248 run_lib.py:152] step: 516800, training_loss: 2.74342e+01
I0515 09:33:22.665325 140128494741248 run_lib.py:165] step: 516800, eval_loss: 2.56426e+01
I0515 09:33:29.174854 140128494741248 run_lib.py:152] step: 516850, training_loss: 3.04737e+01
I0515 09:33:35.363909 140128494741248 run_lib.py:152] step: 516900, training_loss: 3.52456e+01
I0515 09:33:35.418641 140128494741248 run_lib.py:165] step: 516900, eval_loss: 2.62586e+01
I0515 09:33:41.678996 140128494741248 run_lib.py:152] step: 516950, training_loss: 3.65645e+01
I0515 09:33:48.222068 140128494741248 run_lib.py:152] step: 517000, training_loss: 5.06473e+01
I0515 09:33:48.272661 140128494741248 run_lib.py:165] step: 517000, eval_loss: 4.58904e+01
I0515 09:33:54.649762 140128494741248 run_lib.py:152] step: 517050, training_loss: 3.68002e+01
I0515 09:34:00.913197 140128494741248 run_lib.py:152] step: 517100, training_loss: 3.38816e+01
I0515 09:34:00.967720 140128494741248 run_lib.py:165] step: 517100, eval_loss: 3.43598e+01
I0515 09:34:07.199475 140128494741248 run_lib.py:152] step: 517150, training_loss: 4.57955e+01
I0515 09:34:13.670919 140128494741248 run_lib.py:152] step: 517200, training_loss: 3.72059e+01
I0515 09:34:13.722666 140128494741248 run_lib.py:165] step: 517200, eval_loss: 2.71521e+01
I0515 09:34:19.946823 140128494741248 run_lib.py:152] step: 517250, training_loss: 5.12381e+01
I0515 09:34:26.048376 140128494741248 run_lib.py:152] step: 517300, training_loss: 2.31343e+01
I0515 09:34:26.103583 140128494741248 run_lib.py:165] step: 517300, eval_loss: 2.59886e+01
I0515 09:34:32.632408 140128494741248 run_lib.py:152] step: 517350, training_loss: 3.60090e+01
I0515 09:34:38.903013 140128494741248 run_lib.py:152] step: 517400, training_loss: 4.51574e+01
I0515 09:34:38.959073 140128494741248 run_lib.py:165] step: 517400, eval_loss: 5.04673e+01
I0515 09:34:45.240202 140128494741248 run_lib.py:152] step: 517450, training_loss: 2.87599e+01
I0515 09:34:51.512654 140128494741248 run_lib.py:152] step: 517500, training_loss: 2.94821e+01
I0515 09:34:51.573731 140128494741248 run_lib.py:165] step: 517500, eval_loss: 3.37189e+01
I0515 09:34:58.037349 140128494741248 run_lib.py:152] step: 517550, training_loss: 3.35028e+01
I0515 09:35:04.248508 140128494741248 run_lib.py:152] step: 517600, training_loss: 4.16991e+01
I0515 09:35:04.299307 140128494741248 run_lib.py:165] step: 517600, eval_loss: 2.40315e+01
I0515 09:35:10.599475 140128494741248 run_lib.py:152] step: 517650, training_loss: 2.53877e+01
I0515 09:35:17.093301 140128494741248 run_lib.py:152] step: 517700, training_loss: 3.51872e+01
I0515 09:35:17.146420 140128494741248 run_lib.py:165] step: 517700, eval_loss: 3.39093e+01
I0515 09:35:23.438236 140128494741248 run_lib.py:152] step: 517750, training_loss: 2.75502e+01
I0515 09:35:29.760652 140128494741248 run_lib.py:152] step: 517800, training_loss: 4.16496e+01
I0515 09:35:29.810303 140128494741248 run_lib.py:165] step: 517800, eval_loss: 2.34423e+01
I0515 09:35:35.992230 140128494741248 run_lib.py:152] step: 517850, training_loss: 3.18994e+01
I0515 09:35:42.518318 140128494741248 run_lib.py:152] step: 517900, training_loss: 2.75069e+01
I0515 09:35:42.574501 140128494741248 run_lib.py:165] step: 517900, eval_loss: 1.86722e+01
I0515 09:35:48.760964 140128494741248 run_lib.py:152] step: 517950, training_loss: 3.72018e+01
I0515 09:35:55.061533 140128494741248 run_lib.py:152] step: 518000, training_loss: 4.24940e+01
I0515 09:35:55.115382 140128494741248 run_lib.py:165] step: 518000, eval_loss: 3.19691e+01
I0515 09:36:01.501885 140128494741248 run_lib.py:152] step: 518050, training_loss: 3.01589e+01
I0515 09:36:07.833030 140128494741248 run_lib.py:152] step: 518100, training_loss: 1.43476e+01
I0515 09:36:07.892578 140128494741248 run_lib.py:165] step: 518100, eval_loss: 2.67151e+01
I0515 09:36:14.214897 140128494741248 run_lib.py:152] step: 518150, training_loss: 3.83740e+01
I0515 09:36:20.521845 140128494741248 run_lib.py:152] step: 518200, training_loss: 2.67494e+01
I0515 09:36:20.579275 140128494741248 run_lib.py:165] step: 518200, eval_loss: 3.88460e+01
I0515 09:36:27.147528 140128494741248 run_lib.py:152] step: 518250, training_loss: 1.94073e+01
I0515 09:36:33.351961 140128494741248 run_lib.py:152] step: 518300, training_loss: 4.47295e+01
I0515 09:36:33.400636 140128494741248 run_lib.py:165] step: 518300, eval_loss: 5.43526e+01
I0515 09:36:39.690723 140128494741248 run_lib.py:152] step: 518350, training_loss: 2.36369e+01
I0515 09:36:46.334778 140128494741248 run_lib.py:152] step: 518400, training_loss: 2.82979e+01
I0515 09:36:46.386579 140128494741248 run_lib.py:165] step: 518400, eval_loss: 2.51157e+01
I0515 09:36:52.586306 140128494741248 run_lib.py:152] step: 518450, training_loss: 5.11749e+01
I0515 09:36:58.852170 140128494741248 run_lib.py:152] step: 518500, training_loss: 3.49808e+01
I0515 09:36:58.914133 140128494741248 run_lib.py:165] step: 518500, eval_loss: 2.95480e+01
I0515 09:37:05.185044 140128494741248 run_lib.py:152] step: 518550, training_loss: 4.47194e+01
I0515 09:37:11.769222 140128494741248 run_lib.py:152] step: 518600, training_loss: 2.06051e+01
I0515 09:37:11.824126 140128494741248 run_lib.py:165] step: 518600, eval_loss: 2.94647e+01
I0515 09:37:18.057857 140128494741248 run_lib.py:152] step: 518650, training_loss: 3.00212e+01
I0515 09:37:24.372185 140128494741248 run_lib.py:152] step: 518700, training_loss: 3.33622e+01
I0515 09:37:24.425365 140128494741248 run_lib.py:165] step: 518700, eval_loss: 2.51752e+01
I0515 09:37:30.942190 140128494741248 run_lib.py:152] step: 518750, training_loss: 3.62155e+01
I0515 09:37:37.222527 140128494741248 run_lib.py:152] step: 518800, training_loss: 4.26646e+01
I0515 09:37:37.280164 140128494741248 run_lib.py:165] step: 518800, eval_loss: 2.74917e+01
I0515 09:37:43.474853 140128494741248 run_lib.py:152] step: 518850, training_loss: 2.78849e+01
I0515 09:37:49.949092 140128494741248 run_lib.py:152] step: 518900, training_loss: 2.46181e+01
I0515 09:37:49.996313 140128494741248 run_lib.py:165] step: 518900, eval_loss: 2.93039e+01
I0515 09:37:56.523073 140128494741248 run_lib.py:152] step: 518950, training_loss: 4.11060e+01
I0515 09:38:02.725097 140128494741248 run_lib.py:152] step: 519000, training_loss: 3.15719e+01
I0515 09:38:02.780459 140128494741248 run_lib.py:165] step: 519000, eval_loss: 2.72196e+01
I0515 09:38:09.151843 140128494741248 run_lib.py:152] step: 519050, training_loss: 2.02422e+01
I0515 09:38:15.624085 140128494741248 run_lib.py:152] step: 519100, training_loss: 2.61659e+01
I0515 09:38:15.674136 140128494741248 run_lib.py:165] step: 519100, eval_loss: 3.48894e+01
I0515 09:38:22.063395 140128494741248 run_lib.py:152] step: 519150, training_loss: 3.15600e+01
I0515 09:38:28.204731 140128494741248 run_lib.py:152] step: 519200, training_loss: 4.85836e+01
I0515 09:38:28.256983 140128494741248 run_lib.py:165] step: 519200, eval_loss: 2.03123e+01
I0515 09:38:34.693864 140128494741248 run_lib.py:152] step: 519250, training_loss: 2.52618e+01
I0515 09:38:41.314142 140128494741248 run_lib.py:152] step: 519300, training_loss: 1.74768e+01
I0515 09:38:41.364332 140128494741248 run_lib.py:165] step: 519300, eval_loss: 4.62191e+01
I0515 09:38:47.634402 140128494741248 run_lib.py:152] step: 519350, training_loss: 1.47707e+01
I0515 09:38:53.938284 140128494741248 run_lib.py:152] step: 519400, training_loss: 2.04860e+01
I0515 09:38:53.990103 140128494741248 run_lib.py:165] step: 519400, eval_loss: 2.87248e+01
I0515 09:39:00.492222 140128494741248 run_lib.py:152] step: 519450, training_loss: 4.53474e+01
I0515 09:39:06.661914 140128494741248 run_lib.py:152] step: 519500, training_loss: 3.30129e+01
I0515 09:39:06.713518 140128494741248 run_lib.py:165] step: 519500, eval_loss: 3.36020e+01
I0515 09:39:12.971867 140128494741248 run_lib.py:152] step: 519550, training_loss: 3.26183e+01
I0515 09:39:19.169034 140128494741248 run_lib.py:152] step: 519600, training_loss: 2.39088e+01
I0515 09:39:19.219129 140128494741248 run_lib.py:165] step: 519600, eval_loss: 3.65045e+01
I0515 09:39:25.729913 140128494741248 run_lib.py:152] step: 519650, training_loss: 3.32370e+01
I0515 09:39:31.902159 140128494741248 run_lib.py:152] step: 519700, training_loss: 2.62379e+01
I0515 09:39:31.952226 140128494741248 run_lib.py:165] step: 519700, eval_loss: 2.44295e+01
I0515 09:39:38.261961 140128494741248 run_lib.py:152] step: 519750, training_loss: 2.47992e+01
I0515 09:39:44.674421 140128494741248 run_lib.py:152] step: 519800, training_loss: 3.66063e+01
I0515 09:39:44.726593 140128494741248 run_lib.py:165] step: 519800, eval_loss: 3.14789e+01
I0515 09:39:50.986348 140128494741248 run_lib.py:152] step: 519850, training_loss: 2.75564e+01
I0515 09:39:57.139391 140128494741248 run_lib.py:152] step: 519900, training_loss: 2.93047e+01
I0515 09:39:57.189316 140128494741248 run_lib.py:165] step: 519900, eval_loss: 2.81421e+01
I0515 09:40:03.427222 140128494741248 run_lib.py:152] step: 519950, training_loss: 3.82192e+01
I0515 09:40:09.900859 140128494741248 run_lib.py:152] step: 520000, training_loss: 3.38688e+01
I0515 09:40:10.106780 140128494741248 run_lib.py:165] step: 520000, eval_loss: 2.93406e+01
I0515 09:40:16.415047 140128494741248 run_lib.py:152] step: 520050, training_loss: 2.56662e+01
I0515 09:40:22.725852 140128494741248 run_lib.py:152] step: 520100, training_loss: 2.79825e+01
I0515 09:40:22.776106 140128494741248 run_lib.py:165] step: 520100, eval_loss: 3.26971e+01
I0515 09:40:29.252599 140128494741248 run_lib.py:152] step: 520150, training_loss: 3.50416e+01
I0515 09:40:35.473892 140128494741248 run_lib.py:152] step: 520200, training_loss: 2.48492e+01
I0515 09:40:35.523721 140128494741248 run_lib.py:165] step: 520200, eval_loss: 2.93807e+01
I0515 09:40:41.822915 140128494741248 run_lib.py:152] step: 520250, training_loss: 2.46320e+01
I0515 09:40:48.006636 140128494741248 run_lib.py:152] step: 520300, training_loss: 3.77496e+01
I0515 09:40:48.060661 140128494741248 run_lib.py:165] step: 520300, eval_loss: 3.04852e+01
I0515 09:40:54.581846 140128494741248 run_lib.py:152] step: 520350, training_loss: 2.56378e+01
I0515 09:41:00.758279 140128494741248 run_lib.py:152] step: 520400, training_loss: 3.28473e+01
I0515 09:41:00.813295 140128494741248 run_lib.py:165] step: 520400, eval_loss: 4.56763e+01
I0515 09:41:07.073440 140128494741248 run_lib.py:152] step: 520450, training_loss: 4.15190e+01
I0515 09:41:13.556906 140128494741248 run_lib.py:152] step: 520500, training_loss: 3.12197e+01
I0515 09:41:13.607944 140128494741248 run_lib.py:165] step: 520500, eval_loss: 2.51207e+01
I0515 09:41:19.845807 140128494741248 run_lib.py:152] step: 520550, training_loss: 2.46756e+01
I0515 09:41:26.063741 140128494741248 run_lib.py:152] step: 520600, training_loss: 2.89939e+01
I0515 09:41:26.117806 140128494741248 run_lib.py:165] step: 520600, eval_loss: 3.77828e+01
I0515 09:41:32.288335 140128494741248 run_lib.py:152] step: 520650, training_loss: 4.10457e+01
I0515 09:41:38.762267 140128494741248 run_lib.py:152] step: 520700, training_loss: 3.59736e+01
I0515 09:41:38.817486 140128494741248 run_lib.py:165] step: 520700, eval_loss: 2.35720e+01
I0515 09:41:45.032591 140128494741248 run_lib.py:152] step: 520750, training_loss: 3.44849e+01
I0515 09:41:51.208682 140128494741248 run_lib.py:152] step: 520800, training_loss: 4.69195e+01
I0515 09:41:51.261630 140128494741248 run_lib.py:165] step: 520800, eval_loss: 2.19651e+01
I0515 09:41:57.673160 140128494741248 run_lib.py:152] step: 520850, training_loss: 2.46064e+01
I0515 09:42:03.892854 140128494741248 run_lib.py:152] step: 520900, training_loss: 1.96987e+01
I0515 09:42:03.943917 140128494741248 run_lib.py:165] step: 520900, eval_loss: 2.55130e+01
I0515 09:42:10.129537 140128494741248 run_lib.py:152] step: 520950, training_loss: 2.95913e+01
I0515 09:42:16.431362 140128494741248 run_lib.py:152] step: 521000, training_loss: 3.93667e+01
I0515 09:42:16.486524 140128494741248 run_lib.py:165] step: 521000, eval_loss: 2.66899e+01
I0515 09:42:22.963971 140128494741248 run_lib.py:152] step: 521050, training_loss: 4.51482e+01
I0515 09:42:29.317666 140128494741248 run_lib.py:152] step: 521100, training_loss: 2.40078e+01
I0515 09:42:29.365963 140128494741248 run_lib.py:165] step: 521100, eval_loss: 2.27549e+01
I0515 09:42:35.574620 140128494741248 run_lib.py:152] step: 521150, training_loss: 3.97439e+01
I0515 09:42:42.065142 140128494741248 run_lib.py:152] step: 521200, training_loss: 3.05695e+01
I0515 09:42:42.123359 140128494741248 run_lib.py:165] step: 521200, eval_loss: 3.34014e+01
I0515 09:42:48.354015 140128494741248 run_lib.py:152] step: 521250, training_loss: 3.73407e+01
I0515 09:42:54.562098 140128494741248 run_lib.py:152] step: 521300, training_loss: 2.73183e+01
I0515 09:42:54.609850 140128494741248 run_lib.py:165] step: 521300, eval_loss: 3.28407e+01
I0515 09:43:00.881754 140128494741248 run_lib.py:152] step: 521350, training_loss: 2.57382e+01
I0515 09:43:07.282777 140128494741248 run_lib.py:152] step: 521400, training_loss: 3.24547e+01
I0515 09:43:07.336522 140128494741248 run_lib.py:165] step: 521400, eval_loss: 1.99513e+01
I0515 09:43:13.644733 140128494741248 run_lib.py:152] step: 521450, training_loss: 2.41118e+01
I0515 09:43:19.804168 140128494741248 run_lib.py:152] step: 521500, training_loss: 2.66454e+01
I0515 09:43:19.852388 140128494741248 run_lib.py:165] step: 521500, eval_loss: 3.54842e+01
I0515 09:43:26.312160 140128494741248 run_lib.py:152] step: 521550, training_loss: 3.56212e+01
I0515 09:43:32.624244 140128494741248 run_lib.py:152] step: 521600, training_loss: 2.46024e+01
I0515 09:43:32.676066 140128494741248 run_lib.py:165] step: 521600, eval_loss: 2.80965e+01
I0515 09:43:38.870620 140128494741248 run_lib.py:152] step: 521650, training_loss: 2.40379e+01
I0515 09:43:45.197371 140128494741248 run_lib.py:152] step: 521700, training_loss: 2.94897e+01
I0515 09:43:45.249998 140128494741248 run_lib.py:165] step: 521700, eval_loss: 2.76672e+01
I0515 09:43:51.722041 140128494741248 run_lib.py:152] step: 521750, training_loss: 2.90728e+01
I0515 09:43:57.903156 140128494741248 run_lib.py:152] step: 521800, training_loss: 2.30112e+01
I0515 09:43:57.957233 140128494741248 run_lib.py:165] step: 521800, eval_loss: 2.36547e+01
I0515 09:44:04.207913 140128494741248 run_lib.py:152] step: 521850, training_loss: 2.09488e+01
I0515 09:44:10.645775 140128494741248 run_lib.py:152] step: 521900, training_loss: 2.24211e+01
I0515 09:44:10.699860 140128494741248 run_lib.py:165] step: 521900, eval_loss: 3.14296e+01
I0515 09:44:16.971430 140128494741248 run_lib.py:152] step: 521950, training_loss: 2.24547e+01
I0515 09:44:23.236407 140128494741248 run_lib.py:152] step: 522000, training_loss: 2.10301e+01
I0515 09:44:23.297575 140128494741248 run_lib.py:165] step: 522000, eval_loss: 3.06513e+01
I0515 09:44:29.534785 140128494741248 run_lib.py:152] step: 522050, training_loss: 3.78603e+01
I0515 09:44:35.927234 140128494741248 run_lib.py:152] step: 522100, training_loss: 2.59472e+01
I0515 09:44:35.983182 140128494741248 run_lib.py:165] step: 522100, eval_loss: 3.42715e+01
I0515 09:44:42.249062 140128494741248 run_lib.py:152] step: 522150, training_loss: 2.48917e+01
I0515 09:44:48.355129 140128494741248 run_lib.py:152] step: 522200, training_loss: 3.74616e+01
I0515 09:44:48.404813 140128494741248 run_lib.py:165] step: 522200, eval_loss: 2.87061e+01
I0515 09:44:54.907422 140128494741248 run_lib.py:152] step: 522250, training_loss: 2.23844e+01
I0515 09:45:01.102581 140128494741248 run_lib.py:152] step: 522300, training_loss: 3.20465e+01
I0515 09:45:01.154412 140128494741248 run_lib.py:165] step: 522300, eval_loss: 2.84277e+01
I0515 09:45:07.428129 140128494741248 run_lib.py:152] step: 522350, training_loss: 3.77058e+01
I0515 09:45:13.605880 140128494741248 run_lib.py:152] step: 522400, training_loss: 2.48953e+01
I0515 09:45:13.658195 140128494741248 run_lib.py:165] step: 522400, eval_loss: 2.17311e+01
I0515 09:45:20.159233 140128494741248 run_lib.py:152] step: 522450, training_loss: 3.72108e+01
I0515 09:45:26.312976 140128494741248 run_lib.py:152] step: 522500, training_loss: 1.19587e+01
I0515 09:45:26.363385 140128494741248 run_lib.py:165] step: 522500, eval_loss: 1.44883e+01
I0515 09:45:32.623035 140128494741248 run_lib.py:152] step: 522550, training_loss: 4.21729e+01
I0515 09:45:39.066352 140128494741248 run_lib.py:152] step: 522600, training_loss: 2.71812e+01
I0515 09:45:39.118384 140128494741248 run_lib.py:165] step: 522600, eval_loss: 3.59510e+01
I0515 09:45:45.388847 140128494741248 run_lib.py:152] step: 522650, training_loss: 3.19084e+01
I0515 09:45:51.643244 140128494741248 run_lib.py:152] step: 522700, training_loss: 2.29911e+01
I0515 09:45:51.692522 140128494741248 run_lib.py:165] step: 522700, eval_loss: 4.75277e+01
I0515 09:45:57.894956 140128494741248 run_lib.py:152] step: 522750, training_loss: 3.03479e+01
I0515 09:46:04.289774 140128494741248 run_lib.py:152] step: 522800, training_loss: 2.32029e+01
I0515 09:46:04.338797 140128494741248 run_lib.py:165] step: 522800, eval_loss: 4.89561e+01
I0515 09:46:10.523191 140128494741248 run_lib.py:152] step: 522850, training_loss: 3.59733e+01
I0515 09:46:16.736119 140128494741248 run_lib.py:152] step: 522900, training_loss: 3.51923e+01
I0515 09:46:16.784544 140128494741248 run_lib.py:165] step: 522900, eval_loss: 1.65612e+01
I0515 09:46:23.135127 140128494741248 run_lib.py:152] step: 522950, training_loss: 2.93362e+01
I0515 09:46:29.458734 140128494741248 run_lib.py:152] step: 523000, training_loss: 1.18955e+01
I0515 09:46:29.512043 140128494741248 run_lib.py:165] step: 523000, eval_loss: 2.61872e+01
I0515 09:46:35.864272 140128494741248 run_lib.py:152] step: 523050, training_loss: 2.55352e+01
I0515 09:46:42.059085 140128494741248 run_lib.py:152] step: 523100, training_loss: 3.07314e+01
I0515 09:46:42.111404 140128494741248 run_lib.py:165] step: 523100, eval_loss: 2.57876e+01
I0515 09:46:48.522776 140128494741248 run_lib.py:152] step: 523150, training_loss: 3.84953e+01
I0515 09:46:54.847503 140128494741248 run_lib.py:152] step: 523200, training_loss: 2.77344e+01
I0515 09:46:54.900214 140128494741248 run_lib.py:165] step: 523200, eval_loss: 2.47077e+01
I0515 09:47:01.125785 140128494741248 run_lib.py:152] step: 523250, training_loss: 3.75039e+01
I0515 09:47:07.602141 140128494741248 run_lib.py:152] step: 523300, training_loss: 2.84638e+01
I0515 09:47:07.658554 140128494741248 run_lib.py:165] step: 523300, eval_loss: 1.82025e+01
I0515 09:47:13.802201 140128494741248 run_lib.py:152] step: 523350, training_loss: 3.36961e+01
I0515 09:47:20.131643 140128494741248 run_lib.py:152] step: 523400, training_loss: 1.84526e+01
I0515 09:47:20.189754 140128494741248 run_lib.py:165] step: 523400, eval_loss: 2.87436e+01
I0515 09:47:26.392563 140128494741248 run_lib.py:152] step: 523450, training_loss: 3.66639e+01
I0515 09:47:32.972524 140128494741248 run_lib.py:152] step: 523500, training_loss: 2.80157e+01
I0515 09:47:33.022124 140128494741248 run_lib.py:165] step: 523500, eval_loss: 2.68924e+01
I0515 09:47:39.214530 140128494741248 run_lib.py:152] step: 523550, training_loss: 3.38195e+01
I0515 09:47:45.464167 140128494741248 run_lib.py:152] step: 523600, training_loss: 2.68934e+01
I0515 09:47:45.517486 140128494741248 run_lib.py:165] step: 523600, eval_loss: 2.62095e+01
I0515 09:47:51.952479 140128494741248 run_lib.py:152] step: 523650, training_loss: 3.08657e+01
I0515 09:47:58.223047 140128494741248 run_lib.py:152] step: 523700, training_loss: 4.19234e+01
I0515 09:47:58.273949 140128494741248 run_lib.py:165] step: 523700, eval_loss: 2.66300e+01
I0515 09:48:04.405185 140128494741248 run_lib.py:152] step: 523750, training_loss: 2.97446e+01
I0515 09:48:10.732918 140128494741248 run_lib.py:152] step: 523800, training_loss: 2.84993e+01
I0515 09:48:10.783194 140128494741248 run_lib.py:165] step: 523800, eval_loss: 3.89826e+01
I0515 09:48:17.256279 140128494741248 run_lib.py:152] step: 523850, training_loss: 2.52849e+01
I0515 09:48:23.542248 140128494741248 run_lib.py:152] step: 523900, training_loss: 2.96839e+01
I0515 09:48:23.599762 140128494741248 run_lib.py:165] step: 523900, eval_loss: 3.37041e+01
I0515 09:48:29.774605 140128494741248 run_lib.py:152] step: 523950, training_loss: 2.07826e+01
I0515 09:48:36.176646 140128494741248 run_lib.py:152] step: 524000, training_loss: 3.89255e+01
I0515 09:48:36.225911 140128494741248 run_lib.py:165] step: 524000, eval_loss: 2.72919e+01
I0515 09:48:42.444109 140128494741248 run_lib.py:152] step: 524050, training_loss: 3.70004e+01
I0515 09:48:48.721158 140128494741248 run_lib.py:152] step: 524100, training_loss: 3.03068e+01
I0515 09:48:48.773384 140128494741248 run_lib.py:165] step: 524100, eval_loss: 3.96563e+01
I0515 09:48:55.101821 140128494741248 run_lib.py:152] step: 524150, training_loss: 3.40502e+01
I0515 09:49:01.556297 140128494741248 run_lib.py:152] step: 524200, training_loss: 2.55440e+01
I0515 09:49:01.609655 140128494741248 run_lib.py:165] step: 524200, eval_loss: 3.49140e+01
I0515 09:49:07.821473 140128494741248 run_lib.py:152] step: 524250, training_loss: 2.87772e+01
I0515 09:49:14.074280 140128494741248 run_lib.py:152] step: 524300, training_loss: 3.48791e+01
I0515 09:49:14.122201 140128494741248 run_lib.py:165] step: 524300, eval_loss: 3.93581e+01
I0515 09:49:20.606100 140128494741248 run_lib.py:152] step: 524350, training_loss: 3.09546e+01
I0515 09:49:26.896473 140128494741248 run_lib.py:152] step: 524400, training_loss: 2.68617e+01
I0515 09:49:26.950058 140128494741248 run_lib.py:165] step: 524400, eval_loss: 2.51400e+01
I0515 09:49:33.236166 140128494741248 run_lib.py:152] step: 524450, training_loss: 4.84456e+01
I0515 09:49:39.539653 140128494741248 run_lib.py:152] step: 524500, training_loss: 2.54701e+01
I0515 09:49:39.588919 140128494741248 run_lib.py:165] step: 524500, eval_loss: 2.92985e+01
I0515 09:49:46.041921 140128494741248 run_lib.py:152] step: 524550, training_loss: 4.92522e+01
I0515 09:49:52.291912 140128494741248 run_lib.py:152] step: 524600, training_loss: 3.51340e+01
I0515 09:49:52.340109 140128494741248 run_lib.py:165] step: 524600, eval_loss: 2.46446e+01
I0515 09:49:58.645830 140128494741248 run_lib.py:152] step: 524650, training_loss: 3.29961e+01
I0515 09:50:05.223182 140128494741248 run_lib.py:152] step: 524700, training_loss: 2.95188e+01
I0515 09:50:05.276126 140128494741248 run_lib.py:165] step: 524700, eval_loss: 3.07055e+01
I0515 09:50:11.639098 140128494741248 run_lib.py:152] step: 524750, training_loss: 4.29032e+01
I0515 09:50:17.854015 140128494741248 run_lib.py:152] step: 524800, training_loss: 3.36898e+01
I0515 09:50:17.906745 140128494741248 run_lib.py:165] step: 524800, eval_loss: 2.13825e+01
I0515 09:50:24.196510 140128494741248 run_lib.py:152] step: 524850, training_loss: 3.85561e+01
I0515 09:50:30.598740 140128494741248 run_lib.py:152] step: 524900, training_loss: 4.00756e+01
I0515 09:50:30.652091 140128494741248 run_lib.py:165] step: 524900, eval_loss: 3.13296e+01
I0515 09:50:36.937399 140128494741248 run_lib.py:152] step: 524950, training_loss: 2.26792e+01
I0515 09:50:43.199837 140128494741248 run_lib.py:152] step: 525000, training_loss: 3.11871e+01
I0515 09:50:43.259761 140128494741248 run_lib.py:165] step: 525000, eval_loss: 3.13382e+01
I0515 09:50:49.742638 140128494741248 run_lib.py:152] step: 525050, training_loss: 4.60941e+01
I0515 09:50:56.096299 140128494741248 run_lib.py:152] step: 525100, training_loss: 2.39967e+01
I0515 09:50:56.153897 140128494741248 run_lib.py:165] step: 525100, eval_loss: 3.26474e+01
I0515 09:51:02.405673 140128494741248 run_lib.py:152] step: 525150, training_loss: 2.75508e+01
I0515 09:51:08.715136 140128494741248 run_lib.py:152] step: 525200, training_loss: 1.27445e+01
I0515 09:51:08.769824 140128494741248 run_lib.py:165] step: 525200, eval_loss: 2.54019e+01
I0515 09:51:15.155192 140128494741248 run_lib.py:152] step: 525250, training_loss: 3.78075e+01
I0515 09:51:21.394747 140128494741248 run_lib.py:152] step: 525300, training_loss: 2.07699e+01
I0515 09:51:21.444686 140128494741248 run_lib.py:165] step: 525300, eval_loss: 3.38432e+01
I0515 09:51:27.695857 140128494741248 run_lib.py:152] step: 525350, training_loss: 3.30941e+01
I0515 09:51:34.215848 140128494741248 run_lib.py:152] step: 525400, training_loss: 3.23658e+01
I0515 09:51:34.266868 140128494741248 run_lib.py:165] step: 525400, eval_loss: 3.09123e+01
I0515 09:51:40.463780 140128494741248 run_lib.py:152] step: 525450, training_loss: 3.18951e+01
I0515 09:51:46.603775 140128494741248 run_lib.py:152] step: 525500, training_loss: 3.31071e+01
I0515 09:51:46.656325 140128494741248 run_lib.py:165] step: 525500, eval_loss: 3.68570e+01
I0515 09:51:52.939091 140128494741248 run_lib.py:152] step: 525550, training_loss: 3.08850e+01
I0515 09:51:59.356328 140128494741248 run_lib.py:152] step: 525600, training_loss: 4.79200e+01
I0515 09:51:59.407000 140128494741248 run_lib.py:165] step: 525600, eval_loss: 2.11261e+01
I0515 09:52:05.677717 140128494741248 run_lib.py:152] step: 525650, training_loss: 4.42541e+01
I0515 09:52:11.955817 140128494741248 run_lib.py:152] step: 525700, training_loss: 3.23489e+01
I0515 09:52:12.010534 140128494741248 run_lib.py:165] step: 525700, eval_loss: 3.81892e+01
I0515 09:52:18.619946 140128494741248 run_lib.py:152] step: 525750, training_loss: 1.78266e+01
I0515 09:52:24.929658 140128494741248 run_lib.py:152] step: 525800, training_loss: 3.86395e+01
I0515 09:52:24.984506 140128494741248 run_lib.py:165] step: 525800, eval_loss: 1.70080e+01
I0515 09:52:31.320988 140128494741248 run_lib.py:152] step: 525850, training_loss: 1.50830e+01
I0515 09:52:37.510888 140128494741248 run_lib.py:152] step: 525900, training_loss: 1.90578e+01
I0515 09:52:37.561524 140128494741248 run_lib.py:165] step: 525900, eval_loss: 2.58893e+01
I0515 09:52:44.006020 140128494741248 run_lib.py:152] step: 525950, training_loss: 2.85447e+01
I0515 09:52:50.241520 140128494741248 run_lib.py:152] step: 526000, training_loss: 3.76995e+01
I0515 09:52:50.295640 140128494741248 run_lib.py:165] step: 526000, eval_loss: 2.53258e+01
I0515 09:52:56.476230 140128494741248 run_lib.py:152] step: 526050, training_loss: 3.68671e+01
I0515 09:53:03.057252 140128494741248 run_lib.py:152] step: 526100, training_loss: 3.61617e+01
I0515 09:53:03.110511 140128494741248 run_lib.py:165] step: 526100, eval_loss: 3.51673e+01
I0515 09:53:09.301913 140128494741248 run_lib.py:152] step: 526150, training_loss: 3.38441e+01
I0515 09:53:15.656066 140128494741248 run_lib.py:152] step: 526200, training_loss: 5.71777e+01
I0515 09:53:15.705647 140128494741248 run_lib.py:165] step: 526200, eval_loss: 3.42383e+01
I0515 09:53:22.086734 140128494741248 run_lib.py:152] step: 526250, training_loss: 2.71659e+01
I0515 09:53:28.657687 140128494741248 run_lib.py:152] step: 526300, training_loss: 2.83646e+01
I0515 09:53:28.710210 140128494741248 run_lib.py:165] step: 526300, eval_loss: 2.56585e+01
I0515 09:53:34.976892 140128494741248 run_lib.py:152] step: 526350, training_loss: 4.08073e+01
I0515 09:53:41.190534 140128494741248 run_lib.py:152] step: 526400, training_loss: 2.85907e+01
I0515 09:53:41.241069 140128494741248 run_lib.py:165] step: 526400, eval_loss: 3.27815e+01
I0515 09:53:47.854530 140128494741248 run_lib.py:152] step: 526450, training_loss: 2.57637e+01
I0515 09:53:54.069628 140128494741248 run_lib.py:152] step: 526500, training_loss: 3.44353e+01
I0515 09:53:54.121480 140128494741248 run_lib.py:165] step: 526500, eval_loss: 3.25045e+01
I0515 09:54:00.489478 140128494741248 run_lib.py:152] step: 526550, training_loss: 2.86812e+01
I0515 09:54:06.687880 140128494741248 run_lib.py:152] step: 526600, training_loss: 2.09452e+01
I0515 09:54:06.738090 140128494741248 run_lib.py:165] step: 526600, eval_loss: 2.45138e+01
I0515 09:54:13.219449 140128494741248 run_lib.py:152] step: 526650, training_loss: 2.79618e+01
I0515 09:54:19.452917 140128494741248 run_lib.py:152] step: 526700, training_loss: 2.08231e+01
I0515 09:54:19.500675 140128494741248 run_lib.py:165] step: 526700, eval_loss: 3.58771e+01
I0515 09:54:25.757396 140128494741248 run_lib.py:152] step: 526750, training_loss: 2.50862e+01
I0515 09:54:32.238425 140128494741248 run_lib.py:152] step: 526800, training_loss: 2.37405e+01
I0515 09:54:32.294960 140128494741248 run_lib.py:165] step: 526800, eval_loss: 4.29956e+01
I0515 09:54:38.716993 140128494741248 run_lib.py:152] step: 526850, training_loss: 2.82137e+01
I0515 09:54:44.897637 140128494741248 run_lib.py:152] step: 526900, training_loss: 2.79406e+01
I0515 09:54:44.960701 140128494741248 run_lib.py:165] step: 526900, eval_loss: 2.53263e+01
I0515 09:54:51.239705 140128494741248 run_lib.py:152] step: 526950, training_loss: 1.58621e+01
I0515 09:54:57.724729 140128494741248 run_lib.py:152] step: 527000, training_loss: 4.49993e+01
I0515 09:54:57.776665 140128494741248 run_lib.py:165] step: 527000, eval_loss: 2.67251e+01
I0515 09:55:03.999175 140128494741248 run_lib.py:152] step: 527050, training_loss: 2.76409e+01
I0515 09:55:10.307964 140128494741248 run_lib.py:152] step: 527100, training_loss: 3.10136e+01
I0515 09:55:10.354693 140128494741248 run_lib.py:165] step: 527100, eval_loss: 2.76500e+01
I0515 09:55:16.854748 140128494741248 run_lib.py:152] step: 527150, training_loss: 2.87012e+01
I0515 09:55:23.044702 140128494741248 run_lib.py:152] step: 527200, training_loss: 2.84172e+01
I0515 09:55:23.098497 140128494741248 run_lib.py:165] step: 527200, eval_loss: 3.01187e+01
I0515 09:55:29.425286 140128494741248 run_lib.py:152] step: 527250, training_loss: 4.29928e+01
I0515 09:55:35.676352 140128494741248 run_lib.py:152] step: 527300, training_loss: 3.39127e+01
I0515 09:55:35.725342 140128494741248 run_lib.py:165] step: 527300, eval_loss: 3.02901e+01
I0515 09:55:42.245505 140128494741248 run_lib.py:152] step: 527350, training_loss: 3.71521e+01
I0515 09:55:48.511125 140128494741248 run_lib.py:152] step: 527400, training_loss: 2.82975e+01
I0515 09:55:48.563185 140128494741248 run_lib.py:165] step: 527400, eval_loss: 2.47624e+01
I0515 09:55:54.879831 140128494741248 run_lib.py:152] step: 527450, training_loss: 5.06864e+01
I0515 09:56:01.427639 140128494741248 run_lib.py:152] step: 527500, training_loss: 2.41410e+01
I0515 09:56:01.482461 140128494741248 run_lib.py:165] step: 527500, eval_loss: 2.97818e+01
I0515 09:56:07.756011 140128494741248 run_lib.py:152] step: 527550, training_loss: 3.31961e+01
I0515 09:56:14.054222 140128494741248 run_lib.py:152] step: 527600, training_loss: 3.12895e+01
I0515 09:56:14.105451 140128494741248 run_lib.py:165] step: 527600, eval_loss: 3.28702e+01
I0515 09:56:20.383805 140128494741248 run_lib.py:152] step: 527650, training_loss: 3.04728e+01
I0515 09:56:26.969393 140128494741248 run_lib.py:152] step: 527700, training_loss: 2.07439e+01
I0515 09:56:27.025237 140128494741248 run_lib.py:165] step: 527700, eval_loss: 2.47924e+01
I0515 09:56:33.116172 140128494741248 run_lib.py:152] step: 527750, training_loss: 2.68591e+01
I0515 09:56:39.467787 140128494741248 run_lib.py:152] step: 527800, training_loss: 3.18489e+01
I0515 09:56:39.516390 140128494741248 run_lib.py:165] step: 527800, eval_loss: 2.05513e+01
I0515 09:56:45.928034 140128494741248 run_lib.py:152] step: 527850, training_loss: 2.10865e+01
I0515 09:56:52.189334 140128494741248 run_lib.py:152] step: 527900, training_loss: 3.36432e+01
I0515 09:56:52.243026 140128494741248 run_lib.py:165] step: 527900, eval_loss: 2.99540e+01
I0515 09:56:58.409842 140128494741248 run_lib.py:152] step: 527950, training_loss: 2.10360e+01
I0515 09:57:04.721747 140128494741248 run_lib.py:152] step: 528000, training_loss: 3.91726e+01
I0515 09:57:04.780403 140128494741248 run_lib.py:165] step: 528000, eval_loss: 3.79404e+01
I0515 09:57:11.241879 140128494741248 run_lib.py:152] step: 528050, training_loss: 3.55928e+01
I0515 09:57:17.525237 140128494741248 run_lib.py:152] step: 528100, training_loss: 3.16990e+01
I0515 09:57:17.578432 140128494741248 run_lib.py:165] step: 528100, eval_loss: 2.42362e+01
I0515 09:57:23.869635 140128494741248 run_lib.py:152] step: 528150, training_loss: 4.87803e+01
I0515 09:57:30.322061 140128494741248 run_lib.py:152] step: 528200, training_loss: 2.97934e+01
I0515 09:57:30.370044 140128494741248 run_lib.py:165] step: 528200, eval_loss: 3.59488e+01
I0515 09:57:36.512768 140128494741248 run_lib.py:152] step: 528250, training_loss: 2.02593e+01
I0515 09:57:42.836668 140128494741248 run_lib.py:152] step: 528300, training_loss: 3.11450e+01
I0515 09:57:42.893269 140128494741248 run_lib.py:165] step: 528300, eval_loss: 3.20422e+01
I0515 09:57:49.153714 140128494741248 run_lib.py:152] step: 528350, training_loss: 2.60555e+01
I0515 09:57:55.637964 140128494741248 run_lib.py:152] step: 528400, training_loss: 1.62564e+01
I0515 09:57:55.689520 140128494741248 run_lib.py:165] step: 528400, eval_loss: 5.29555e+01
I0515 09:58:02.034597 140128494741248 run_lib.py:152] step: 528450, training_loss: 2.11680e+01
I0515 09:58:08.231251 140128494741248 run_lib.py:152] step: 528500, training_loss: 1.84402e+01
I0515 09:58:08.281526 140128494741248 run_lib.py:165] step: 528500, eval_loss: 2.87207e+01
I0515 09:58:14.748475 140128494741248 run_lib.py:152] step: 528550, training_loss: 3.02727e+01
I0515 09:58:20.942916 140128494741248 run_lib.py:152] step: 528600, training_loss: 3.28058e+01
I0515 09:58:20.998333 140128494741248 run_lib.py:165] step: 528600, eval_loss: 2.98272e+01
I0515 09:58:27.284241 140128494741248 run_lib.py:152] step: 528650, training_loss: 2.23289e+01
I0515 09:58:33.474231 140128494741248 run_lib.py:152] step: 528700, training_loss: 3.17223e+01
I0515 09:58:33.525895 140128494741248 run_lib.py:165] step: 528700, eval_loss: 2.19969e+01
I0515 09:58:39.951058 140128494741248 run_lib.py:152] step: 528750, training_loss: 1.31488e+01
I0515 09:58:46.220183 140128494741248 run_lib.py:152] step: 528800, training_loss: 2.60436e+01
I0515 09:58:46.272227 140128494741248 run_lib.py:165] step: 528800, eval_loss: 2.22270e+01
I0515 09:58:52.577003 140128494741248 run_lib.py:152] step: 528850, training_loss: 3.25810e+01
I0515 09:58:59.091070 140128494741248 run_lib.py:152] step: 528900, training_loss: 2.67484e+01
I0515 09:58:59.138993 140128494741248 run_lib.py:165] step: 528900, eval_loss: 3.35688e+01
I0515 09:59:05.489803 140128494741248 run_lib.py:152] step: 528950, training_loss: 3.34611e+01
I0515 09:59:11.881364 140128494741248 run_lib.py:152] step: 529000, training_loss: 3.22171e+01
I0515 09:59:11.934844 140128494741248 run_lib.py:165] step: 529000, eval_loss: 2.56909e+01
I0515 09:59:18.249692 140128494741248 run_lib.py:152] step: 529050, training_loss: 2.93922e+01
I0515 09:59:24.776244 140128494741248 run_lib.py:152] step: 529100, training_loss: 3.17776e+01
I0515 09:59:24.827813 140128494741248 run_lib.py:165] step: 529100, eval_loss: 3.50443e+01
I0515 09:59:31.036366 140128494741248 run_lib.py:152] step: 529150, training_loss: 3.19631e+01
I0515 09:59:37.219952 140128494741248 run_lib.py:152] step: 529200, training_loss: 2.64475e+01
I0515 09:59:37.269411 140128494741248 run_lib.py:165] step: 529200, eval_loss: 2.52714e+01
I0515 09:59:43.763752 140128494741248 run_lib.py:152] step: 529250, training_loss: 2.84707e+01
I0515 09:59:49.970489 140128494741248 run_lib.py:152] step: 529300, training_loss: 3.36783e+01
I0515 09:59:50.028029 140128494741248 run_lib.py:165] step: 529300, eval_loss: 3.36037e+01
I0515 09:59:56.431905 140128494741248 run_lib.py:152] step: 529350, training_loss: 3.09296e+01
I0515 10:00:02.692251 140128494741248 run_lib.py:152] step: 529400, training_loss: 3.30026e+01
I0515 10:00:02.749622 140128494741248 run_lib.py:165] step: 529400, eval_loss: 2.15578e+01
I0515 10:00:09.189185 140128494741248 run_lib.py:152] step: 529450, training_loss: 2.83222e+01
I0515 10:00:15.383316 140128494741248 run_lib.py:152] step: 529500, training_loss: 1.65978e+01
I0515 10:00:15.433454 140128494741248 run_lib.py:165] step: 529500, eval_loss: 3.94468e+01
I0515 10:00:21.735097 140128494741248 run_lib.py:152] step: 529550, training_loss: 2.73247e+01
I0515 10:00:28.159105 140128494741248 run_lib.py:152] step: 529600, training_loss: 4.08254e+01
I0515 10:00:28.216305 140128494741248 run_lib.py:165] step: 529600, eval_loss: 2.57699e+01
I0515 10:00:34.472337 140128494741248 run_lib.py:152] step: 529650, training_loss: 3.13952e+01
I0515 10:00:40.649914 140128494741248 run_lib.py:152] step: 529700, training_loss: 2.35622e+01
I0515 10:00:40.700044 140128494741248 run_lib.py:165] step: 529700, eval_loss: 3.16825e+01
I0515 10:00:46.933889 140128494741248 run_lib.py:152] step: 529750, training_loss: 3.88279e+01
I0515 10:00:53.386156 140128494741248 run_lib.py:152] step: 529800, training_loss: 4.79518e+01
I0515 10:00:53.434572 140128494741248 run_lib.py:165] step: 529800, eval_loss: 2.65068e+01
I0515 10:00:59.675958 140128494741248 run_lib.py:152] step: 529850, training_loss: 3.47078e+01
I0515 10:01:06.046431 140128494741248 run_lib.py:152] step: 529900, training_loss: 3.17763e+01
I0515 10:01:06.099269 140128494741248 run_lib.py:165] step: 529900, eval_loss: 2.13455e+01
I0515 10:01:12.573995 140128494741248 run_lib.py:152] step: 529950, training_loss: 3.13522e+01
I0515 10:01:18.802568 140128494741248 run_lib.py:152] step: 530000, training_loss: 3.06940e+01
I0515 10:01:19.015928 140128494741248 run_lib.py:165] step: 530000, eval_loss: 3.28111e+01
I0515 10:01:25.258621 140128494741248 run_lib.py:152] step: 530050, training_loss: 1.92721e+01
I0515 10:01:31.408797 140128494741248 run_lib.py:152] step: 530100, training_loss: 4.03253e+01
I0515 10:01:31.463585 140128494741248 run_lib.py:165] step: 530100, eval_loss: 3.26503e+01
I0515 10:01:37.953040 140128494741248 run_lib.py:152] step: 530150, training_loss: 2.77946e+01
I0515 10:01:44.276531 140128494741248 run_lib.py:152] step: 530200, training_loss: 2.55147e+01
I0515 10:01:44.338541 140128494741248 run_lib.py:165] step: 530200, eval_loss: 2.06028e+01
I0515 10:01:50.571270 140128494741248 run_lib.py:152] step: 530250, training_loss: 4.19390e+01
I0515 10:01:57.062916 140128494741248 run_lib.py:152] step: 530300, training_loss: 2.99009e+01
I0515 10:01:57.120130 140128494741248 run_lib.py:165] step: 530300, eval_loss: 2.91240e+01
I0515 10:02:03.335284 140128494741248 run_lib.py:152] step: 530350, training_loss: 3.59754e+01
I0515 10:02:09.717854 140128494741248 run_lib.py:152] step: 530400, training_loss: 1.67846e+01
I0515 10:02:09.773868 140128494741248 run_lib.py:165] step: 530400, eval_loss: 2.84673e+01
I0515 10:02:16.107229 140128494741248 run_lib.py:152] step: 530450, training_loss: 3.25438e+01
I0515 10:02:22.575323 140128494741248 run_lib.py:152] step: 530500, training_loss: 3.87376e+01
I0515 10:02:22.628787 140128494741248 run_lib.py:165] step: 530500, eval_loss: 3.94280e+01
I0515 10:02:28.924589 140128494741248 run_lib.py:152] step: 530550, training_loss: 4.15462e+01
I0515 10:02:35.137814 140128494741248 run_lib.py:152] step: 530600, training_loss: 2.38205e+01
I0515 10:02:35.190284 140128494741248 run_lib.py:165] step: 530600, eval_loss: 3.22192e+01
I0515 10:02:41.645688 140128494741248 run_lib.py:152] step: 530650, training_loss: 3.10577e+01
I0515 10:02:48.065810 140128494741248 run_lib.py:152] step: 530700, training_loss: 3.96032e+01
I0515 10:02:48.118640 140128494741248 run_lib.py:165] step: 530700, eval_loss: 2.56717e+01
I0515 10:02:54.447238 140128494741248 run_lib.py:152] step: 530750, training_loss: 3.08285e+01
I0515 10:03:00.717684 140128494741248 run_lib.py:152] step: 530800, training_loss: 3.73220e+01
I0515 10:03:00.771075 140128494741248 run_lib.py:165] step: 530800, eval_loss: 3.48434e+01
I0515 10:03:07.374684 140128494741248 run_lib.py:152] step: 530850, training_loss: 2.85242e+01
I0515 10:03:13.533155 140128494741248 run_lib.py:152] step: 530900, training_loss: 2.85998e+01
I0515 10:03:13.585793 140128494741248 run_lib.py:165] step: 530900, eval_loss: 3.75384e+01
I0515 10:03:19.852924 140128494741248 run_lib.py:152] step: 530950, training_loss: 2.58688e+01
I0515 10:03:26.334681 140128494741248 run_lib.py:152] step: 531000, training_loss: 4.18143e+01
I0515 10:03:26.390002 140128494741248 run_lib.py:165] step: 531000, eval_loss: 2.24053e+01
I0515 10:03:32.585296 140128494741248 run_lib.py:152] step: 531050, training_loss: 2.46810e+01
I0515 10:03:38.751565 140128494741248 run_lib.py:152] step: 531100, training_loss: 3.35212e+01
I0515 10:03:38.804302 140128494741248 run_lib.py:165] step: 531100, eval_loss: 3.77493e+01
I0515 10:03:45.356188 140128494741248 run_lib.py:152] step: 531150, training_loss: 3.20163e+01
I0515 10:03:51.623694 140128494741248 run_lib.py:152] step: 531200, training_loss: 2.88348e+01
I0515 10:03:51.673995 140128494741248 run_lib.py:165] step: 531200, eval_loss: 1.58974e+01
I0515 10:03:57.948707 140128494741248 run_lib.py:152] step: 531250, training_loss: 3.20229e+01
I0515 10:04:04.259522 140128494741248 run_lib.py:152] step: 531300, training_loss: 1.94236e+01
I0515 10:04:04.312126 140128494741248 run_lib.py:165] step: 531300, eval_loss: 1.71225e+01
I0515 10:04:10.709697 140128494741248 run_lib.py:152] step: 531350, training_loss: 3.55723e+01
I0515 10:04:16.921751 140128494741248 run_lib.py:152] step: 531400, training_loss: 2.62291e+01
I0515 10:04:16.972154 140128494741248 run_lib.py:165] step: 531400, eval_loss: 2.95961e+01
I0515 10:04:23.183590 140128494741248 run_lib.py:152] step: 531450, training_loss: 4.27293e+01
I0515 10:04:29.600642 140128494741248 run_lib.py:152] step: 531500, training_loss: 2.86495e+01
I0515 10:04:29.654624 140128494741248 run_lib.py:165] step: 531500, eval_loss: 5.21357e+01
I0515 10:04:35.902678 140128494741248 run_lib.py:152] step: 531550, training_loss: 3.13957e+01
I0515 10:04:42.071356 140128494741248 run_lib.py:152] step: 531600, training_loss: 3.36173e+01
I0515 10:04:42.123645 140128494741248 run_lib.py:165] step: 531600, eval_loss: 3.99469e+01
I0515 10:04:48.480662 140128494741248 run_lib.py:152] step: 531650, training_loss: 3.58997e+01
I0515 10:04:54.950157 140128494741248 run_lib.py:152] step: 531700, training_loss: 2.65627e+01
I0515 10:04:55.011363 140128494741248 run_lib.py:165] step: 531700, eval_loss: 2.25201e+01
I0515 10:05:01.357706 140128494741248 run_lib.py:152] step: 531750, training_loss: 2.11947e+01
I0515 10:05:07.561084 140128494741248 run_lib.py:152] step: 531800, training_loss: 3.78896e+01
I0515 10:05:07.618002 140128494741248 run_lib.py:165] step: 531800, eval_loss: 2.69047e+01
I0515 10:05:14.136757 140128494741248 run_lib.py:152] step: 531850, training_loss: 3.43301e+01
I0515 10:05:20.325673 140128494741248 run_lib.py:152] step: 531900, training_loss: 2.94910e+01
I0515 10:05:20.385335 140128494741248 run_lib.py:165] step: 531900, eval_loss: 1.68297e+01
I0515 10:05:26.705579 140128494741248 run_lib.py:152] step: 531950, training_loss: 2.78788e+01
I0515 10:05:32.881869 140128494741248 run_lib.py:152] step: 532000, training_loss: 3.04451e+01
I0515 10:05:32.931588 140128494741248 run_lib.py:165] step: 532000, eval_loss: 4.02661e+01
I0515 10:05:39.486510 140128494741248 run_lib.py:152] step: 532050, training_loss: 4.08866e+01
I0515 10:05:45.762662 140128494741248 run_lib.py:152] step: 532100, training_loss: 1.90207e+01
I0515 10:05:45.815709 140128494741248 run_lib.py:165] step: 532100, eval_loss: 4.34988e+01
I0515 10:05:52.066787 140128494741248 run_lib.py:152] step: 532150, training_loss: 4.23022e+01
I0515 10:05:58.547769 140128494741248 run_lib.py:152] step: 532200, training_loss: 3.88807e+01
I0515 10:05:58.597406 140128494741248 run_lib.py:165] step: 532200, eval_loss: 2.17884e+01
I0515 10:06:04.876682 140128494741248 run_lib.py:152] step: 532250, training_loss: 3.67491e+01
I0515 10:06:11.120440 140128494741248 run_lib.py:152] step: 532300, training_loss: 2.28473e+01
I0515 10:06:11.180961 140128494741248 run_lib.py:165] step: 532300, eval_loss: 1.46804e+01
I0515 10:06:17.375540 140128494741248 run_lib.py:152] step: 532350, training_loss: 2.35795e+01
I0515 10:06:23.872956 140128494741248 run_lib.py:152] step: 532400, training_loss: 3.46018e+01
I0515 10:06:23.934810 140128494741248 run_lib.py:165] step: 532400, eval_loss: 5.62907e+01
I0515 10:06:30.149250 140128494741248 run_lib.py:152] step: 532450, training_loss: 3.12070e+01
I0515 10:06:36.357955 140128494741248 run_lib.py:152] step: 532500, training_loss: 1.87544e+01
I0515 10:06:36.408437 140128494741248 run_lib.py:165] step: 532500, eval_loss: 3.99857e+01
I0515 10:06:42.956208 140128494741248 run_lib.py:152] step: 532550, training_loss: 5.70300e+01
I0515 10:06:49.142797 140128494741248 run_lib.py:152] step: 532600, training_loss: 2.81976e+01
I0515 10:06:49.194803 140128494741248 run_lib.py:165] step: 532600, eval_loss: 2.50830e+01
I0515 10:06:55.436874 140128494741248 run_lib.py:152] step: 532650, training_loss: 1.91019e+01
I0515 10:07:01.652693 140128494741248 run_lib.py:152] step: 532700, training_loss: 3.94700e+01
I0515 10:07:01.701164 140128494741248 run_lib.py:165] step: 532700, eval_loss: 2.23045e+01
I0515 10:07:08.201190 140128494741248 run_lib.py:152] step: 532750, training_loss: 4.32676e+01
I0515 10:07:14.435357 140128494741248 run_lib.py:152] step: 532800, training_loss: 3.65493e+01
I0515 10:07:14.495752 140128494741248 run_lib.py:165] step: 532800, eval_loss: 2.74231e+01
I0515 10:07:20.759431 140128494741248 run_lib.py:152] step: 532850, training_loss: 3.19721e+01
I0515 10:07:27.299361 140128494741248 run_lib.py:152] step: 532900, training_loss: 3.33887e+01
I0515 10:07:27.353268 140128494741248 run_lib.py:165] step: 532900, eval_loss: 2.92991e+01
I0515 10:07:33.454041 140128494741248 run_lib.py:152] step: 532950, training_loss: 2.86295e+01
I0515 10:07:39.687851 140128494741248 run_lib.py:152] step: 533000, training_loss: 2.98144e+01
I0515 10:07:39.739301 140128494741248 run_lib.py:165] step: 533000, eval_loss: 1.81566e+01
I0515 10:07:46.087687 140128494741248 run_lib.py:152] step: 533050, training_loss: 2.54629e+01
I0515 10:07:52.470625 140128494741248 run_lib.py:152] step: 533100, training_loss: 2.86697e+01
I0515 10:07:52.525266 140128494741248 run_lib.py:165] step: 533100, eval_loss: 3.77489e+01
I0515 10:07:58.785284 140128494741248 run_lib.py:152] step: 533150, training_loss: 3.35630e+01
I0515 10:08:05.000378 140128494741248 run_lib.py:152] step: 533200, training_loss: 2.65812e+01
I0515 10:08:05.054617 140128494741248 run_lib.py:165] step: 533200, eval_loss: 4.61975e+01
I0515 10:08:11.663734 140128494741248 run_lib.py:152] step: 533250, training_loss: 2.95144e+01
I0515 10:08:17.892863 140128494741248 run_lib.py:152] step: 533300, training_loss: 2.74992e+01
I0515 10:08:17.944226 140128494741248 run_lib.py:165] step: 533300, eval_loss: 5.08876e+01
I0515 10:08:24.162371 140128494741248 run_lib.py:152] step: 533350, training_loss: 3.89678e+01
I0515 10:08:30.418667 140128494741248 run_lib.py:152] step: 533400, training_loss: 2.63000e+01
I0515 10:08:30.477788 140128494741248 run_lib.py:165] step: 533400, eval_loss: 4.49294e+01
I0515 10:08:36.902118 140128494741248 run_lib.py:152] step: 533450, training_loss: 3.19694e+01
I0515 10:08:43.187240 140128494741248 run_lib.py:152] step: 533500, training_loss: 3.16443e+01
I0515 10:08:43.237608 140128494741248 run_lib.py:165] step: 533500, eval_loss: 4.02724e+01
I0515 10:08:49.519850 140128494741248 run_lib.py:152] step: 533550, training_loss: 3.70378e+01
I0515 10:08:55.730334 140128494741248 run_lib.py:152] step: 533600, training_loss: 1.71538e+01
I0515 10:08:56.005176 140128494741248 run_lib.py:165] step: 533600, eval_loss: 4.16864e+01
I0515 10:09:02.288368 140128494741248 run_lib.py:152] step: 533650, training_loss: 2.19546e+01
I0515 10:09:08.593404 140128494741248 run_lib.py:152] step: 533700, training_loss: 3.78613e+01
I0515 10:09:08.649687 140128494741248 run_lib.py:165] step: 533700, eval_loss: 4.05253e+01
I0515 10:09:14.860261 140128494741248 run_lib.py:152] step: 533750, training_loss: 2.89043e+01
I0515 10:09:21.347142 140128494741248 run_lib.py:152] step: 533800, training_loss: 4.37007e+01
I0515 10:09:21.396303 140128494741248 run_lib.py:165] step: 533800, eval_loss: 2.45344e+01
I0515 10:09:27.747377 140128494741248 run_lib.py:152] step: 533850, training_loss: 1.70193e+01
I0515 10:09:33.976500 140128494741248 run_lib.py:152] step: 533900, training_loss: 2.54416e+01
I0515 10:09:34.027170 140128494741248 run_lib.py:165] step: 533900, eval_loss: 3.09301e+01
I0515 10:09:40.387523 140128494741248 run_lib.py:152] step: 533950, training_loss: 3.25348e+01
I0515 10:09:46.790353 140128494741248 run_lib.py:152] step: 534000, training_loss: 2.97285e+01
I0515 10:09:46.842187 140128494741248 run_lib.py:165] step: 534000, eval_loss: 3.64974e+01
I0515 10:09:53.055975 140128494741248 run_lib.py:152] step: 534050, training_loss: 3.06033e+01
I0515 10:09:59.344671 140128494741248 run_lib.py:152] step: 534100, training_loss: 3.04649e+01
I0515 10:09:59.396380 140128494741248 run_lib.py:165] step: 534100, eval_loss: 3.16186e+01
I0515 10:10:05.827498 140128494741248 run_lib.py:152] step: 534150, training_loss: 3.47972e+01
I0515 10:10:12.183408 140128494741248 run_lib.py:152] step: 534200, training_loss: 2.83644e+01
I0515 10:10:12.243093 140128494741248 run_lib.py:165] step: 534200, eval_loss: 3.71424e+01
I0515 10:10:18.543326 140128494741248 run_lib.py:152] step: 534250, training_loss: 3.15954e+01
I0515 10:10:25.073240 140128494741248 run_lib.py:152] step: 534300, training_loss: 3.57801e+01
I0515 10:10:25.123839 140128494741248 run_lib.py:165] step: 534300, eval_loss: 3.75825e+01
I0515 10:10:31.361502 140128494741248 run_lib.py:152] step: 534350, training_loss: 5.00274e+01
I0515 10:10:37.615876 140128494741248 run_lib.py:152] step: 534400, training_loss: 2.84699e+01
I0515 10:10:37.665737 140128494741248 run_lib.py:165] step: 534400, eval_loss: 2.47812e+01
I0515 10:10:43.913409 140128494741248 run_lib.py:152] step: 534450, training_loss: 3.91787e+01
I0515 10:10:50.428061 140128494741248 run_lib.py:152] step: 534500, training_loss: 2.30999e+01
I0515 10:10:50.481617 140128494741248 run_lib.py:165] step: 534500, eval_loss: 4.20581e+01
I0515 10:10:56.858788 140128494741248 run_lib.py:152] step: 534550, training_loss: 4.59317e+01
I0515 10:11:03.127023 140128494741248 run_lib.py:152] step: 534600, training_loss: 4.67756e+01
I0515 10:11:03.173823 140128494741248 run_lib.py:165] step: 534600, eval_loss: 3.91521e+01
I0515 10:11:09.737835 140128494741248 run_lib.py:152] step: 534650, training_loss: 3.53849e+01
I0515 10:11:15.968484 140128494741248 run_lib.py:152] step: 534700, training_loss: 2.88240e+01
I0515 10:11:16.019082 140128494741248 run_lib.py:165] step: 534700, eval_loss: 2.29528e+01
I0515 10:11:22.181715 140128494741248 run_lib.py:152] step: 534750, training_loss: 3.44903e+01
I0515 10:11:28.446386 140128494741248 run_lib.py:152] step: 534800, training_loss: 3.45066e+01
I0515 10:11:28.498864 140128494741248 run_lib.py:165] step: 534800, eval_loss: 2.91316e+01
I0515 10:11:35.027110 140128494741248 run_lib.py:152] step: 534850, training_loss: 2.78662e+01
I0515 10:11:41.208811 140128494741248 run_lib.py:152] step: 534900, training_loss: 3.81691e+01
I0515 10:11:41.257547 140128494741248 run_lib.py:165] step: 534900, eval_loss: 4.06318e+01
I0515 10:11:47.590215 140128494741248 run_lib.py:152] step: 534950, training_loss: 2.51259e+01
I0515 10:11:54.120935 140128494741248 run_lib.py:152] step: 535000, training_loss: 2.57244e+01
I0515 10:11:54.174144 140128494741248 run_lib.py:165] step: 535000, eval_loss: 1.78350e+01
I0515 10:12:00.434279 140128494741248 run_lib.py:152] step: 535050, training_loss: 2.93357e+01
I0515 10:12:06.694540 140128494741248 run_lib.py:152] step: 535100, training_loss: 4.43119e+01
I0515 10:12:06.759097 140128494741248 run_lib.py:165] step: 535100, eval_loss: 3.11308e+01
I0515 10:12:13.020422 140128494741248 run_lib.py:152] step: 535150, training_loss: 3.51603e+01
I0515 10:12:19.497795 140128494741248 run_lib.py:152] step: 535200, training_loss: 2.20662e+01
I0515 10:12:19.553909 140128494741248 run_lib.py:165] step: 535200, eval_loss: 4.08626e+01
I0515 10:12:25.811015 140128494741248 run_lib.py:152] step: 535250, training_loss: 3.56043e+01
I0515 10:12:32.153486 140128494741248 run_lib.py:152] step: 535300, training_loss: 1.68651e+01
I0515 10:12:32.205661 140128494741248 run_lib.py:165] step: 535300, eval_loss: 2.64817e+01
I0515 10:12:38.711842 140128494741248 run_lib.py:152] step: 535350, training_loss: 2.28068e+01
I0515 10:12:45.016084 140128494741248 run_lib.py:152] step: 535400, training_loss: 3.49349e+01
I0515 10:12:45.064489 140128494741248 run_lib.py:165] step: 535400, eval_loss: 3.43692e+01
I0515 10:12:51.379983 140128494741248 run_lib.py:152] step: 535450, training_loss: 2.75105e+01
I0515 10:12:57.593818 140128494741248 run_lib.py:152] step: 535500, training_loss: 3.32525e+01
I0515 10:12:57.650311 140128494741248 run_lib.py:165] step: 535500, eval_loss: 2.38670e+01
I0515 10:13:04.107266 140128494741248 run_lib.py:152] step: 535550, training_loss: 3.13812e+01
I0515 10:13:10.204012 140128494741248 run_lib.py:152] step: 535600, training_loss: 4.43967e+01
I0515 10:13:10.257798 140128494741248 run_lib.py:165] step: 535600, eval_loss: 4.22946e+01
I0515 10:13:16.563693 140128494741248 run_lib.py:152] step: 535650, training_loss: 2.14837e+01
I0515 10:13:23.086040 140128494741248 run_lib.py:152] step: 535700, training_loss: 2.22861e+01
I0515 10:13:23.136381 140128494741248 run_lib.py:165] step: 535700, eval_loss: 1.88297e+01
I0515 10:13:29.455980 140128494741248 run_lib.py:152] step: 535750, training_loss: 3.02872e+01
I0515 10:13:35.640953 140128494741248 run_lib.py:152] step: 535800, training_loss: 4.09757e+01
I0515 10:13:35.693944 140128494741248 run_lib.py:165] step: 535800, eval_loss: 3.29158e+01
I0515 10:13:41.938222 140128494741248 run_lib.py:152] step: 535850, training_loss: 4.86438e+01
I0515 10:13:48.389710 140128494741248 run_lib.py:152] step: 535900, training_loss: 2.43931e+01
I0515 10:13:48.439384 140128494741248 run_lib.py:165] step: 535900, eval_loss: 2.16585e+01
I0515 10:13:54.695679 140128494741248 run_lib.py:152] step: 535950, training_loss: 2.96515e+01
I0515 10:14:00.873640 140128494741248 run_lib.py:152] step: 536000, training_loss: 2.72037e+01
I0515 10:14:00.930005 140128494741248 run_lib.py:165] step: 536000, eval_loss: 5.02464e+01
I0515 10:14:07.348070 140128494741248 run_lib.py:152] step: 536050, training_loss: 4.83377e+01
I0515 10:14:13.609989 140128494741248 run_lib.py:152] step: 536100, training_loss: 4.34733e+01
I0515 10:14:13.665832 140128494741248 run_lib.py:165] step: 536100, eval_loss: 3.03712e+01
I0515 10:14:19.913206 140128494741248 run_lib.py:152] step: 536150, training_loss: 3.46329e+01
I0515 10:14:26.171453 140128494741248 run_lib.py:152] step: 536200, training_loss: 2.16408e+01
I0515 10:14:26.230788 140128494741248 run_lib.py:165] step: 536200, eval_loss: 3.70199e+01
I0515 10:14:32.833982 140128494741248 run_lib.py:152] step: 536250, training_loss: 2.50852e+01
I0515 10:14:39.056660 140128494741248 run_lib.py:152] step: 536300, training_loss: 2.02957e+01
I0515 10:14:39.106442 140128494741248 run_lib.py:165] step: 536300, eval_loss: 3.37710e+01
I0515 10:14:45.387274 140128494741248 run_lib.py:152] step: 536350, training_loss: 3.93395e+01
I0515 10:14:51.824632 140128494741248 run_lib.py:152] step: 536400, training_loss: 2.52392e+01
I0515 10:14:51.877896 140128494741248 run_lib.py:165] step: 536400, eval_loss: 2.27847e+01
I0515 10:14:58.157151 140128494741248 run_lib.py:152] step: 536450, training_loss: 2.57511e+01
I0515 10:15:04.391649 140128494741248 run_lib.py:152] step: 536500, training_loss: 2.69671e+01
I0515 10:15:04.439067 140128494741248 run_lib.py:165] step: 536500, eval_loss: 1.38795e+01
I0515 10:15:10.639616 140128494741248 run_lib.py:152] step: 536550, training_loss: 3.09539e+01
I0515 10:15:17.162206 140128494741248 run_lib.py:152] step: 536600, training_loss: 3.58783e+01
I0515 10:15:17.212285 140128494741248 run_lib.py:165] step: 536600, eval_loss: 4.51387e+01
I0515 10:15:23.508768 140128494741248 run_lib.py:152] step: 536650, training_loss: 4.10334e+01
I0515 10:15:29.904977 140128494741248 run_lib.py:152] step: 536700, training_loss: 4.01895e+01
I0515 10:15:29.956653 140128494741248 run_lib.py:165] step: 536700, eval_loss: 2.94764e+01
I0515 10:15:36.487182 140128494741248 run_lib.py:152] step: 536750, training_loss: 2.24434e+01
I0515 10:15:42.622298 140128494741248 run_lib.py:152] step: 536800, training_loss: 3.90461e+01
I0515 10:15:42.672170 140128494741248 run_lib.py:165] step: 536800, eval_loss: 2.63448e+01
I0515 10:15:48.905420 140128494741248 run_lib.py:152] step: 536850, training_loss: 5.30326e+01
I0515 10:15:55.088184 140128494741248 run_lib.py:152] step: 536900, training_loss: 3.58731e+01
I0515 10:15:55.136893 140128494741248 run_lib.py:165] step: 536900, eval_loss: 3.11858e+01
I0515 10:16:01.683414 140128494741248 run_lib.py:152] step: 536950, training_loss: 4.15442e+01
I0515 10:16:08.017339 140128494741248 run_lib.py:152] step: 537000, training_loss: 3.23953e+01
I0515 10:16:08.077738 140128494741248 run_lib.py:165] step: 537000, eval_loss: 3.02576e+01
I0515 10:16:14.285330 140128494741248 run_lib.py:152] step: 537050, training_loss: 3.53438e+01
I0515 10:16:20.548002 140128494741248 run_lib.py:152] step: 537100, training_loss: 4.05272e+01
I0515 10:16:20.828069 140128494741248 run_lib.py:165] step: 537100, eval_loss: 2.52761e+01
I0515 10:16:27.041105 140128494741248 run_lib.py:152] step: 537150, training_loss: 4.43435e+01
I0515 10:16:33.361492 140128494741248 run_lib.py:152] step: 537200, training_loss: 2.16068e+01
I0515 10:16:33.420177 140128494741248 run_lib.py:165] step: 537200, eval_loss: 3.10549e+01
I0515 10:16:39.732334 140128494741248 run_lib.py:152] step: 537250, training_loss: 3.12541e+01
I0515 10:16:46.241317 140128494741248 run_lib.py:152] step: 537300, training_loss: 2.81823e+01
I0515 10:16:46.287402 140128494741248 run_lib.py:165] step: 537300, eval_loss: 3.62568e+01
I0515 10:16:52.602775 140128494741248 run_lib.py:152] step: 537350, training_loss: 2.28534e+01
I0515 10:16:58.849656 140128494741248 run_lib.py:152] step: 537400, training_loss: 2.50144e+01
I0515 10:16:58.900681 140128494741248 run_lib.py:165] step: 537400, eval_loss: 3.06981e+01
I0515 10:17:05.333816 140128494741248 run_lib.py:152] step: 537450, training_loss: 3.22825e+01
I0515 10:17:11.623573 140128494741248 run_lib.py:152] step: 537500, training_loss: 4.16851e+01
I0515 10:17:11.681990 140128494741248 run_lib.py:165] step: 537500, eval_loss: 1.86615e+01
I0515 10:17:17.965260 140128494741248 run_lib.py:152] step: 537550, training_loss: 3.05304e+01
I0515 10:17:24.197828 140128494741248 run_lib.py:152] step: 537600, training_loss: 4.26532e+01
I0515 10:17:24.251057 140128494741248 run_lib.py:165] step: 537600, eval_loss: 2.35038e+01
I0515 10:17:30.738719 140128494741248 run_lib.py:152] step: 537650, training_loss: 2.61627e+01
I0515 10:17:37.157327 140128494741248 run_lib.py:152] step: 537700, training_loss: 1.89728e+01
I0515 10:17:37.209076 140128494741248 run_lib.py:165] step: 537700, eval_loss: 2.09281e+01
I0515 10:17:43.604998 140128494741248 run_lib.py:152] step: 537750, training_loss: 3.14406e+01
I0515 10:17:50.105256 140128494741248 run_lib.py:152] step: 537800, training_loss: 2.86031e+01
I0515 10:17:50.158342 140128494741248 run_lib.py:165] step: 537800, eval_loss: 3.19041e+01
I0515 10:17:56.500104 140128494741248 run_lib.py:152] step: 537850, training_loss: 2.72025e+01
I0515 10:18:02.648263 140128494741248 run_lib.py:152] step: 537900, training_loss: 2.87245e+01
I0515 10:18:02.697982 140128494741248 run_lib.py:165] step: 537900, eval_loss: 2.60311e+01
I0515 10:18:09.097145 140128494741248 run_lib.py:152] step: 537950, training_loss: 2.86114e+01
I0515 10:18:15.639175 140128494741248 run_lib.py:152] step: 538000, training_loss: 3.52024e+01
I0515 10:18:15.696019 140128494741248 run_lib.py:165] step: 538000, eval_loss: 3.99146e+01
I0515 10:18:21.966279 140128494741248 run_lib.py:152] step: 538050, training_loss: 2.37359e+01
I0515 10:18:28.274857 140128494741248 run_lib.py:152] step: 538100, training_loss: 3.46020e+01
I0515 10:18:28.335302 140128494741248 run_lib.py:165] step: 538100, eval_loss: 3.95811e+01
I0515 10:18:34.809037 140128494741248 run_lib.py:152] step: 538150, training_loss: 2.50704e+01
I0515 10:18:41.174221 140128494741248 run_lib.py:152] step: 538200, training_loss: 4.62382e+01
I0515 10:18:41.226669 140128494741248 run_lib.py:165] step: 538200, eval_loss: 3.18523e+01
I0515 10:18:47.487220 140128494741248 run_lib.py:152] step: 538250, training_loss: 2.96663e+01
I0515 10:18:53.688233 140128494741248 run_lib.py:152] step: 538300, training_loss: 2.48363e+01
I0515 10:18:53.744540 140128494741248 run_lib.py:165] step: 538300, eval_loss: 3.83685e+01
I0515 10:19:00.173419 140128494741248 run_lib.py:152] step: 538350, training_loss: 2.04790e+01
I0515 10:19:06.577196 140128494741248 run_lib.py:152] step: 538400, training_loss: 4.11303e+01
I0515 10:19:06.625155 140128494741248 run_lib.py:165] step: 538400, eval_loss: 4.38812e+01
I0515 10:19:12.749303 140128494741248 run_lib.py:152] step: 538450, training_loss: 3.68730e+01
I0515 10:19:19.373062 140128494741248 run_lib.py:152] step: 538500, training_loss: 2.58470e+01
I0515 10:19:19.424457 140128494741248 run_lib.py:165] step: 538500, eval_loss: 2.78993e+01
I0515 10:19:25.541773 140128494741248 run_lib.py:152] step: 538550, training_loss: 4.03610e+01
I0515 10:19:31.827447 140128494741248 run_lib.py:152] step: 538600, training_loss: 2.45698e+01
I0515 10:19:31.878975 140128494741248 run_lib.py:165] step: 538600, eval_loss: 3.68670e+01
I0515 10:19:38.004686 140128494741248 run_lib.py:152] step: 538650, training_loss: 3.15113e+01
I0515 10:19:44.479051 140128494741248 run_lib.py:152] step: 538700, training_loss: 4.42859e+01
I0515 10:19:44.533583 140128494741248 run_lib.py:165] step: 538700, eval_loss: 3.28507e+01
I0515 10:19:50.831481 140128494741248 run_lib.py:152] step: 538750, training_loss: 4.31385e+01
I0515 10:19:57.088545 140128494741248 run_lib.py:152] step: 538800, training_loss: 3.26585e+01
I0515 10:19:57.146194 140128494741248 run_lib.py:165] step: 538800, eval_loss: 3.17757e+01
I0515 10:20:03.626451 140128494741248 run_lib.py:152] step: 538850, training_loss: 2.67508e+01
I0515 10:20:09.911912 140128494741248 run_lib.py:152] step: 538900, training_loss: 2.36637e+01
I0515 10:20:09.963532 140128494741248 run_lib.py:165] step: 538900, eval_loss: 1.57589e+01
I0515 10:20:16.156224 140128494741248 run_lib.py:152] step: 538950, training_loss: 2.12141e+01
I0515 10:20:22.468073 140128494741248 run_lib.py:152] step: 539000, training_loss: 1.42417e+01
I0515 10:20:22.520502 140128494741248 run_lib.py:165] step: 539000, eval_loss: 1.99847e+01
I0515 10:20:28.994786 140128494741248 run_lib.py:152] step: 539050, training_loss: 2.01210e+01
I0515 10:20:35.354471 140128494741248 run_lib.py:152] step: 539100, training_loss: 2.16703e+01
I0515 10:20:35.409276 140128494741248 run_lib.py:165] step: 539100, eval_loss: 3.00919e+01
I0515 10:20:41.643640 140128494741248 run_lib.py:152] step: 539150, training_loss: 2.80304e+01
I0515 10:20:48.160234 140128494741248 run_lib.py:152] step: 539200, training_loss: 2.22969e+01
I0515 10:20:48.210498 140128494741248 run_lib.py:165] step: 539200, eval_loss: 3.58724e+01
I0515 10:20:54.452080 140128494741248 run_lib.py:152] step: 539250, training_loss: 4.13712e+01
I0515 10:21:00.624628 140128494741248 run_lib.py:152] step: 539300, training_loss: 2.86853e+01
I0515 10:21:00.678882 140128494741248 run_lib.py:165] step: 539300, eval_loss: 2.37023e+01
I0515 10:21:06.921713 140128494741248 run_lib.py:152] step: 539350, training_loss: 4.03903e+01
I0515 10:21:13.457357 140128494741248 run_lib.py:152] step: 539400, training_loss: 3.16431e+01
I0515 10:21:13.512529 140128494741248 run_lib.py:165] step: 539400, eval_loss: 2.94794e+01
I0515 10:21:19.833328 140128494741248 run_lib.py:152] step: 539450, training_loss: 3.19686e+01
I0515 10:21:26.083775 140128494741248 run_lib.py:152] step: 539500, training_loss: 3.14542e+01
I0515 10:21:26.132645 140128494741248 run_lib.py:165] step: 539500, eval_loss: 2.35926e+01
I0515 10:21:32.667971 140128494741248 run_lib.py:152] step: 539550, training_loss: 4.71292e+01
I0515 10:21:38.920250 140128494741248 run_lib.py:152] step: 539600, training_loss: 2.22942e+01
I0515 10:21:38.971936 140128494741248 run_lib.py:165] step: 539600, eval_loss: 2.58058e+01
I0515 10:21:45.233490 140128494741248 run_lib.py:152] step: 539650, training_loss: 2.58387e+01
I0515 10:21:51.426659 140128494741248 run_lib.py:152] step: 539700, training_loss: 2.59743e+01
I0515 10:21:51.482300 140128494741248 run_lib.py:165] step: 539700, eval_loss: 3.92932e+01
I0515 10:21:58.013892 140128494741248 run_lib.py:152] step: 539750, training_loss: 3.62043e+01
I0515 10:22:04.253594 140128494741248 run_lib.py:152] step: 539800, training_loss: 3.48629e+01
I0515 10:22:04.305669 140128494741248 run_lib.py:165] step: 539800, eval_loss: 3.43820e+01
I0515 10:22:10.599717 140128494741248 run_lib.py:152] step: 539850, training_loss: 3.27362e+01
I0515 10:22:16.970124 140128494741248 run_lib.py:152] step: 539900, training_loss: 3.69321e+01
I0515 10:22:17.023661 140128494741248 run_lib.py:165] step: 539900, eval_loss: 4.00158e+01
I0515 10:22:23.253652 140128494741248 run_lib.py:152] step: 539950, training_loss: 2.58594e+01
I0515 10:22:29.418261 140128494741248 run_lib.py:152] step: 540000, training_loss: 2.68603e+01
I0515 10:22:29.616006 140128494741248 run_lib.py:165] step: 540000, eval_loss: 5.09197e+01
I0515 10:22:35.855879 140128494741248 run_lib.py:152] step: 540050, training_loss: 3.14563e+01
I0515 10:22:42.335429 140128494741248 run_lib.py:152] step: 540100, training_loss: 2.04284e+01
I0515 10:22:42.393378 140128494741248 run_lib.py:165] step: 540100, eval_loss: 2.30792e+01
I0515 10:22:48.624238 140128494741248 run_lib.py:152] step: 540150, training_loss: 3.30070e+01
I0515 10:22:54.953615 140128494741248 run_lib.py:152] step: 540200, training_loss: 3.15427e+01
I0515 10:22:55.011200 140128494741248 run_lib.py:165] step: 540200, eval_loss: 2.25921e+01
I0515 10:23:01.567178 140128494741248 run_lib.py:152] step: 540250, training_loss: 4.05793e+01
I0515 10:23:07.778318 140128494741248 run_lib.py:152] step: 540300, training_loss: 3.62270e+01
I0515 10:23:07.827632 140128494741248 run_lib.py:165] step: 540300, eval_loss: 2.92993e+01
I0515 10:23:14.112370 140128494741248 run_lib.py:152] step: 540350, training_loss: 3.49424e+01
I0515 10:23:20.467758 140128494741248 run_lib.py:152] step: 540400, training_loss: 1.66433e+01
I0515 10:23:20.517903 140128494741248 run_lib.py:165] step: 540400, eval_loss: 4.85822e+01
I0515 10:23:26.979021 140128494741248 run_lib.py:152] step: 540450, training_loss: 3.66760e+01
I0515 10:23:33.347917 140128494741248 run_lib.py:152] step: 540500, training_loss: 3.51340e+01
I0515 10:23:33.398330 140128494741248 run_lib.py:165] step: 540500, eval_loss: 4.46540e+01
I0515 10:23:39.647010 140128494741248 run_lib.py:152] step: 540550, training_loss: 1.40277e+01
I0515 10:23:45.938727 140128494741248 run_lib.py:152] step: 540600, training_loss: 3.17064e+01
I0515 10:23:46.214504 140128494741248 run_lib.py:165] step: 540600, eval_loss: 2.47873e+01
I0515 10:23:52.505193 140128494741248 run_lib.py:152] step: 540650, training_loss: 3.27287e+01
I0515 10:23:58.757732 140128494741248 run_lib.py:152] step: 540700, training_loss: 3.27864e+01
I0515 10:23:58.813331 140128494741248 run_lib.py:165] step: 540700, eval_loss: 2.92321e+01
I0515 10:24:05.139864 140128494741248 run_lib.py:152] step: 540750, training_loss: 2.27899e+01
I0515 10:24:11.714153 140128494741248 run_lib.py:152] step: 540800, training_loss: 4.68130e+01
I0515 10:24:11.768589 140128494741248 run_lib.py:165] step: 540800, eval_loss: 3.28647e+01
I0515 10:24:18.117396 140128494741248 run_lib.py:152] step: 540850, training_loss: 3.16665e+01
I0515 10:24:24.376688 140128494741248 run_lib.py:152] step: 540900, training_loss: 3.03704e+01
I0515 10:24:24.427987 140128494741248 run_lib.py:165] step: 540900, eval_loss: 2.95699e+01
I0515 10:24:31.038314 140128494741248 run_lib.py:152] step: 540950, training_loss: 5.70105e+01
